Choosing the GPU device has largest free memory...
Sorted by free memory size
Using GPU 0:
index:0
gpu_name:GeForce GTX 1080 Ti
memory.free:11166
memory.total:11178
power.draw:9
power.limit:250
specified:True
lcf_bert - laptop - cdm - No.1 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:897287680
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3a3fdbf268>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 0
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc53.45
max_acc:53.45  f1:23.22
loss: 0.9993, acc: 50.00, test_acc: 53.45, f1: 23.22
>> saved: state_dict/lcf_bert_laptop_acc55.02
max_acc:55.02  f1:29.54
loss: 1.0912, acc: 46.88, test_acc: 55.02, f1: 29.54
loss: 0.9594, acc: 52.08, test_acc: 38.09, f1: 30.53
>> saved: state_dict/lcf_bert_laptop_acc67.4
max_acc:67.4  f1:51.37
loss: 0.8903, acc: 56.25, test_acc: 67.40, f1: 51.37
loss: 0.7976, acc: 61.25, test_acc: 66.30, f1: 49.87
loss: 0.8514, acc: 61.46, test_acc: 62.54, f1: 49.40
>> saved: state_dict/lcf_bert_laptop_acc71.16
max_acc:71.16  f1:56.97
loss: 0.6672, acc: 63.39, test_acc: 71.16, f1: 56.97
>> saved: state_dict/lcf_bert_laptop_acc74.61
max_acc:74.61  f1:66.74
loss: 0.5513, acc: 65.62, test_acc: 74.61, f1: 66.74
>> saved: state_dict/lcf_bert_laptop_acc75.24
max_acc:75.24  f1:68.85
loss: 0.6707, acc: 67.36, test_acc: 75.24, f1: 68.85
loss: 0.8911, acc: 66.88, test_acc: 74.45, f1: 64.95
loss: 0.5801, acc: 67.61, test_acc: 73.98, f1: 62.12
>> saved: state_dict/lcf_bert_laptop_acc76.65
max_acc:76.65  f1:69.96
loss: 0.3981, acc: 69.27, test_acc: 76.65, f1: 69.96
>> saved: state_dict/lcf_bert_laptop_acc78.84
max_acc:78.84  f1:74.16
loss: 0.6778, acc: 69.71, test_acc: 78.84, f1: 74.16
loss: 0.6420, acc: 69.20, test_acc: 75.55, f1: 69.76
loss: 0.7138, acc: 68.33, test_acc: 77.27, f1: 72.21
loss: 0.4040, acc: 69.14, test_acc: 78.84, f1: 74.71
loss: 0.3315, acc: 69.85, test_acc: 77.59, f1: 69.96
loss: 0.3573, acc: 70.49, test_acc: 74.92, f1: 65.03
loss: 0.2410, acc: 71.71, test_acc: 77.74, f1: 73.03
loss: 0.5852, acc: 72.19, test_acc: 77.27, f1: 72.71
loss: 0.4876, acc: 72.92, test_acc: 77.59, f1: 71.92
loss: 0.4597, acc: 72.73, test_acc: 78.37, f1: 72.67
loss: 0.3580, acc: 73.64, test_acc: 78.06, f1: 73.27
>> saved: state_dict/lcf_bert_laptop_acc79.94
max_acc:79.94  f1:76.1
loss: 0.2481, acc: 74.22, test_acc: 79.94, f1: 76.10
loss: 0.5379, acc: 74.25, test_acc: 79.94, f1: 75.91
>> saved: state_dict/lcf_bert_laptop_acc80.25
max_acc:80.25  f1:76.17
loss: 0.3557, acc: 74.76, test_acc: 80.25, f1: 76.17
loss: 0.2381, acc: 75.46, test_acc: 78.06, f1: 72.59
loss: 0.7173, acc: 75.45, test_acc: 76.80, f1: 70.69
loss: 0.4476, acc: 75.86, test_acc: 76.80, f1: 71.10
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.7482, acc: 62.50, test_acc: 78.37, f1: 73.53
loss: 0.1661, acc: 81.25, test_acc: 75.39, f1: 71.78
loss: 0.4796, acc: 81.25, test_acc: 75.24, f1: 70.63
loss: 0.1406, acc: 84.38, test_acc: 78.37, f1: 73.00
loss: 0.5850, acc: 83.75, test_acc: 77.27, f1: 71.43
loss: 0.1290, acc: 86.46, test_acc: 78.37, f1: 73.14
loss: 0.3060, acc: 86.61, test_acc: 76.33, f1: 69.58
loss: 0.4081, acc: 85.94, test_acc: 79.47, f1: 74.90
loss: 0.9368, acc: 84.03, test_acc: 80.09, f1: 75.89
>> saved: state_dict/lcf_bert_laptop_acc81.5
max_acc:81.5  f1:78.08
loss: 0.3040, acc: 83.75, test_acc: 81.50, f1: 78.08
loss: 0.2550, acc: 84.09, test_acc: 80.56, f1: 76.52
loss: 0.4044, acc: 83.85, test_acc: 79.62, f1: 75.40
loss: 0.4945, acc: 83.65, test_acc: 79.47, f1: 74.42
loss: 0.7033, acc: 82.59, test_acc: 79.62, f1: 74.95
loss: 0.2021, acc: 83.75, test_acc: 80.72, f1: 77.49
loss: 0.3342, acc: 83.20, test_acc: 78.53, f1: 73.33
loss: 0.3810, acc: 83.46, test_acc: 76.96, f1: 70.85
loss: 0.5055, acc: 83.33, test_acc: 80.25, f1: 76.43
loss: 0.5339, acc: 82.89, test_acc: 80.09, f1: 76.43
loss: 0.4634, acc: 83.12, test_acc: 79.47, f1: 74.65
loss: 0.2516, acc: 83.33, test_acc: 78.06, f1: 70.95
loss: 0.2847, acc: 83.24, test_acc: 75.71, f1: 67.66
loss: 0.4150, acc: 83.15, test_acc: 77.59, f1: 73.48
loss: 0.3831, acc: 83.07, test_acc: 78.84, f1: 74.29
loss: 0.5047, acc: 83.50, test_acc: 76.65, f1: 69.92
loss: 0.2051, acc: 83.89, test_acc: 78.37, f1: 73.70
loss: 0.2890, acc: 83.80, test_acc: 81.03, f1: 77.68
loss: 0.4229, acc: 83.71, test_acc: 80.88, f1: 78.34
loss: 0.5458, acc: 83.62, test_acc: 78.84, f1: 75.72
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2205, acc: 93.75, test_acc: 75.39, f1: 66.71
loss: 0.3090, acc: 90.62, test_acc: 75.86, f1: 66.21
loss: 0.1390, acc: 89.58, test_acc: 78.37, f1: 73.08
loss: 0.0983, acc: 92.19, test_acc: 80.72, f1: 77.65
loss: 0.0178, acc: 93.75, test_acc: 79.62, f1: 76.04
loss: 0.2772, acc: 92.71, test_acc: 79.15, f1: 74.82
loss: 0.1582, acc: 92.86, test_acc: 78.84, f1: 74.62
loss: 0.0322, acc: 93.75, test_acc: 78.84, f1: 73.71
loss: 0.0585, acc: 94.44, test_acc: 79.94, f1: 75.33
loss: 0.0828, acc: 94.38, test_acc: 80.72, f1: 77.27
loss: 0.4087, acc: 93.75, test_acc: 79.00, f1: 75.97
loss: 0.1673, acc: 93.75, test_acc: 80.56, f1: 76.05
loss: 0.3108, acc: 93.75, test_acc: 79.62, f1: 74.93
loss: 0.1192, acc: 94.20, test_acc: 80.09, f1: 77.59
loss: 0.0852, acc: 94.58, test_acc: 80.56, f1: 77.70
loss: 0.1180, acc: 94.92, test_acc: 80.88, f1: 77.05
loss: 0.2230, acc: 94.49, test_acc: 81.03, f1: 77.32
loss: 0.3537, acc: 94.10, test_acc: 81.19, f1: 77.72
loss: 0.5562, acc: 93.42, test_acc: 80.56, f1: 76.86
loss: 0.3277, acc: 93.44, test_acc: 78.37, f1: 72.41
loss: 0.2199, acc: 93.45, test_acc: 78.37, f1: 72.34
loss: 0.0471, acc: 93.75, test_acc: 79.94, f1: 75.68
loss: 0.1727, acc: 93.75, test_acc: 81.50, f1: 78.76
loss: 0.0856, acc: 94.01, test_acc: 81.35, f1: 78.74
loss: 0.2496, acc: 93.50, test_acc: 79.94, f1: 75.91
loss: 0.1369, acc: 93.51, test_acc: 77.43, f1: 71.21
loss: 0.0228, acc: 93.75, test_acc: 77.90, f1: 71.87
loss: 0.2427, acc: 93.53, test_acc: 77.90, f1: 72.43
loss: 0.2362, acc: 93.53, test_acc: 79.78, f1: 75.74
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.2523, acc: 87.50, test_acc: 78.84, f1: 73.92
loss: 0.0180, acc: 93.75, test_acc: 78.06, f1: 71.69
loss: 0.3088, acc: 91.67, test_acc: 77.90, f1: 71.23
loss: 0.1624, acc: 92.19, test_acc: 79.15, f1: 74.10
loss: 0.1178, acc: 92.50, test_acc: 80.25, f1: 75.69
loss: 0.0089, acc: 93.75, test_acc: 80.56, f1: 76.22
loss: 0.0988, acc: 93.75, test_acc: 78.06, f1: 72.54
loss: 0.1231, acc: 94.53, test_acc: 78.06, f1: 72.21
loss: 0.0321, acc: 95.14, test_acc: 79.62, f1: 75.39
loss: 0.0169, acc: 95.62, test_acc: 81.03, f1: 77.38
loss: 0.0297, acc: 96.02, test_acc: 79.47, f1: 75.65
loss: 0.0449, acc: 96.35, test_acc: 79.15, f1: 74.79
loss: 0.0353, acc: 96.63, test_acc: 79.00, f1: 74.35
loss: 0.0246, acc: 96.88, test_acc: 79.31, f1: 74.40
loss: 0.1174, acc: 96.25, test_acc: 79.31, f1: 74.29
loss: 0.3233, acc: 96.09, test_acc: 79.62, f1: 75.25
loss: 0.3334, acc: 95.22, test_acc: 81.19, f1: 77.69
loss: 0.1795, acc: 94.79, test_acc: 80.88, f1: 77.07
loss: 0.1494, acc: 94.74, test_acc: 80.56, f1: 76.39
loss: 0.1365, acc: 94.69, test_acc: 80.41, f1: 76.24
loss: 0.0578, acc: 94.94, test_acc: 80.56, f1: 76.52
loss: 0.1339, acc: 94.89, test_acc: 80.41, f1: 75.96
loss: 0.0075, acc: 95.11, test_acc: 80.56, f1: 76.14
loss: 0.0695, acc: 95.31, test_acc: 80.72, f1: 76.51
loss: 0.0300, acc: 95.50, test_acc: 80.88, f1: 76.69
loss: 0.0274, acc: 95.67, test_acc: 80.88, f1: 76.92
loss: 0.0721, acc: 95.83, test_acc: 80.56, f1: 76.78
loss: 0.3432, acc: 95.09, test_acc: 80.72, f1: 77.01
>> saved: state_dict/lcf_bert_laptop_acc81.66
max_acc:81.66  f1:78.06
loss: 0.3591, acc: 95.04, test_acc: 81.66, f1: 78.06
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0179, acc: 100.00, test_acc: 80.25, f1: 75.81
loss: 0.1244, acc: 96.88, test_acc: 79.00, f1: 73.79
loss: 0.0358, acc: 97.92, test_acc: 78.21, f1: 72.15
loss: 0.3005, acc: 96.88, test_acc: 79.31, f1: 74.29
loss: 0.1189, acc: 96.25, test_acc: 81.35, f1: 77.36
>> saved: state_dict/lcf_bert_laptop_acc81.97
max_acc:81.97  f1:78.62
loss: 0.0260, acc: 96.88, test_acc: 81.97, f1: 78.62
>> saved: state_dict/lcf_bert_laptop_acc82.29
max_acc:82.29  f1:78.94
loss: 0.1008, acc: 96.43, test_acc: 82.29, f1: 78.94
loss: 0.2867, acc: 95.31, test_acc: 81.19, f1: 77.09
loss: 0.0074, acc: 95.83, test_acc: 79.78, f1: 74.76
loss: 0.0546, acc: 95.62, test_acc: 80.72, f1: 76.33
loss: 0.0081, acc: 96.02, test_acc: 81.82, f1: 78.20
loss: 0.0063, acc: 96.35, test_acc: 81.97, f1: 78.44
loss: 0.1021, acc: 96.15, test_acc: 81.03, f1: 76.70
loss: 0.0165, acc: 96.43, test_acc: 80.25, f1: 75.38
loss: 0.0464, acc: 96.67, test_acc: 79.94, f1: 75.10
loss: 0.1415, acc: 96.48, test_acc: 80.72, f1: 76.32
loss: 0.0276, acc: 96.69, test_acc: 79.47, f1: 74.21
loss: 0.4867, acc: 96.18, test_acc: 79.31, f1: 73.85
loss: 0.0240, acc: 96.38, test_acc: 78.68, f1: 72.70
loss: 0.0187, acc: 96.56, test_acc: 79.15, f1: 73.50
loss: 0.2435, acc: 96.43, test_acc: 80.56, f1: 76.76
loss: 0.0217, acc: 96.59, test_acc: 79.62, f1: 76.20
loss: 0.0446, acc: 96.74, test_acc: 79.31, f1: 75.43
loss: 0.2463, acc: 96.61, test_acc: 78.68, f1: 73.05
loss: 0.0288, acc: 96.75, test_acc: 78.37, f1: 72.32
loss: 0.1012, acc: 96.63, test_acc: 79.47, f1: 74.66
loss: 0.2471, acc: 96.53, test_acc: 81.50, f1: 77.89
loss: 0.0134, acc: 96.65, test_acc: 81.35, f1: 77.60
loss: 0.2386, acc: 96.55, test_acc: 79.78, f1: 75.13
loss: 0.0054, acc: 96.61, test_acc: 79.31, f1: 74.16
####################################################################################################
max_test_acc_overall:82.2884012539185
max_f1_overall:78.94258986162124
####################################################################################################
1 test_acc_overall: 82.29  f1_overall:78.94
max_acc_overall:82.29  f1_overall:78.94
mean_acc_overall:82.29  mean_f1_overall:78.94
####################################################################################################
lcf_bert - laptop - cdm - No.2 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3a3fdbf268>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 1
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc43.26
max_acc:43.26  f1:34.07
loss: 1.1144, acc: 31.25, test_acc: 43.26, f1: 34.07
>> saved: state_dict/lcf_bert_laptop_acc57.21
max_acc:57.21  f1:33.93
loss: 1.0674, acc: 37.50, test_acc: 57.21, f1: 33.93
>> saved: state_dict/lcf_bert_laptop_acc61.13
max_acc:61.13  f1:45.32
loss: 0.9182, acc: 45.83, test_acc: 61.13, f1: 45.32
>> saved: state_dict/lcf_bert_laptop_acc65.52
max_acc:65.52  f1:47.01
loss: 0.7648, acc: 53.12, test_acc: 65.52, f1: 47.01
>> saved: state_dict/lcf_bert_laptop_acc72.26
max_acc:72.26  f1:63.33
loss: 0.7843, acc: 58.75, test_acc: 72.26, f1: 63.33
loss: 0.7645, acc: 59.38, test_acc: 68.97, f1: 53.14
>> saved: state_dict/lcf_bert_laptop_acc72.88
max_acc:72.88  f1:63.9
loss: 0.9655, acc: 59.82, test_acc: 72.88, f1: 63.90
loss: 0.6265, acc: 60.94, test_acc: 72.26, f1: 64.16
loss: 0.7713, acc: 62.50, test_acc: 71.47, f1: 59.64
>> saved: state_dict/lcf_bert_laptop_acc73.35
max_acc:73.35  f1:65.04
loss: 0.6510, acc: 63.75, test_acc: 73.35, f1: 65.04
>> saved: state_dict/lcf_bert_laptop_acc76.49
max_acc:76.49  f1:70.15
loss: 0.8317, acc: 64.20, test_acc: 76.49, f1: 70.15
>> saved: state_dict/lcf_bert_laptop_acc77.43
max_acc:77.43  f1:73.26
loss: 0.7271, acc: 65.10, test_acc: 77.43, f1: 73.26
loss: 0.5847, acc: 65.87, test_acc: 73.98, f1: 67.46
loss: 0.7853, acc: 65.18, test_acc: 73.20, f1: 62.15
>> saved: state_dict/lcf_bert_laptop_acc77.59
max_acc:77.59  f1:70.88
loss: 0.4723, acc: 66.25, test_acc: 77.59, f1: 70.88
loss: 1.1379, acc: 65.23, test_acc: 77.43, f1: 72.06
loss: 0.6948, acc: 65.44, test_acc: 74.76, f1: 66.24
loss: 0.8916, acc: 65.62, test_acc: 76.49, f1: 68.35
loss: 0.3260, acc: 66.78, test_acc: 76.80, f1: 70.43
loss: 0.6517, acc: 66.88, test_acc: 74.76, f1: 64.86
>> saved: state_dict/lcf_bert_laptop_acc78.06
max_acc:78.06  f1:71.69
loss: 0.2854, acc: 67.86, test_acc: 78.06, f1: 71.69
>> saved: state_dict/lcf_bert_laptop_acc79.0
max_acc:79.0  f1:75.65
loss: 0.6663, acc: 67.90, test_acc: 79.00, f1: 75.65
loss: 0.1714, acc: 69.29, test_acc: 77.59, f1: 70.74
loss: 0.4709, acc: 69.79, test_acc: 76.33, f1: 68.16
>> saved: state_dict/lcf_bert_laptop_acc80.09
max_acc:80.09  f1:76.29
loss: 0.6819, acc: 69.75, test_acc: 80.09, f1: 76.29
loss: 0.5363, acc: 70.19, test_acc: 79.00, f1: 73.92
loss: 0.4374, acc: 70.83, test_acc: 79.00, f1: 73.70
loss: 0.3384, acc: 71.43, test_acc: 78.53, f1: 72.83
loss: 0.6651, acc: 71.77, test_acc: 79.15, f1: 74.14
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
>> saved: state_dict/lcf_bert_laptop_acc80.25
max_acc:80.25  f1:75.75
loss: 0.5710, acc: 75.00, test_acc: 80.25, f1: 75.75
loss: 0.2139, acc: 84.38, test_acc: 79.62, f1: 75.39
loss: 0.1591, acc: 89.58, test_acc: 79.15, f1: 74.88
loss: 0.6529, acc: 85.94, test_acc: 77.59, f1: 70.97
loss: 0.0600, acc: 88.75, test_acc: 77.90, f1: 72.30
loss: 0.1663, acc: 90.62, test_acc: 79.62, f1: 75.60
loss: 0.2973, acc: 91.07, test_acc: 79.78, f1: 74.97
loss: 0.5935, acc: 89.84, test_acc: 75.71, f1: 66.91
loss: 0.1039, acc: 90.28, test_acc: 78.84, f1: 74.33
loss: 0.5296, acc: 89.38, test_acc: 77.74, f1: 75.57
loss: 0.7383, acc: 88.07, test_acc: 77.74, f1: 72.38
loss: 0.3697, acc: 88.02, test_acc: 77.43, f1: 71.96
loss: 0.3627, acc: 87.50, test_acc: 75.86, f1: 68.53
loss: 0.4689, acc: 87.05, test_acc: 75.71, f1: 67.83
loss: 0.2240, acc: 87.08, test_acc: 77.59, f1: 71.75
loss: 0.6237, acc: 86.72, test_acc: 80.09, f1: 76.07
loss: 0.1696, acc: 87.13, test_acc: 80.25, f1: 76.41
loss: 0.3131, acc: 87.15, test_acc: 78.37, f1: 72.46
loss: 0.5823, acc: 87.17, test_acc: 78.68, f1: 73.54
>> saved: state_dict/lcf_bert_laptop_acc80.72
max_acc:80.72  f1:77.0
loss: 0.1831, acc: 87.81, test_acc: 80.72, f1: 77.00
loss: 0.1971, acc: 88.10, test_acc: 78.68, f1: 73.15
loss: 0.3501, acc: 87.78, test_acc: 76.96, f1: 69.99
>> saved: state_dict/lcf_bert_laptop_acc82.13
max_acc:82.13  f1:78.41
loss: 0.0535, acc: 88.32, test_acc: 82.13, f1: 78.41
loss: 0.1442, acc: 88.80, test_acc: 81.35, f1: 77.24
loss: 0.0685, acc: 89.25, test_acc: 79.31, f1: 74.01
loss: 0.3737, acc: 88.70, test_acc: 80.88, f1: 76.49
loss: 0.4235, acc: 88.43, test_acc: 80.09, f1: 75.40
loss: 0.3463, acc: 88.39, test_acc: 79.31, f1: 74.12
loss: 0.4993, acc: 88.36, test_acc: 79.62, f1: 74.23
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.0988, acc: 100.00, test_acc: 81.19, f1: 76.84
loss: 0.3116, acc: 93.75, test_acc: 81.35, f1: 77.22
loss: 0.2687, acc: 93.75, test_acc: 80.25, f1: 75.76
loss: 0.0796, acc: 95.31, test_acc: 79.94, f1: 75.31
loss: 0.2143, acc: 95.00, test_acc: 81.03, f1: 76.21
loss: 0.0574, acc: 95.83, test_acc: 80.56, f1: 75.49
loss: 0.1121, acc: 95.54, test_acc: 80.41, f1: 75.74
loss: 0.0422, acc: 96.09, test_acc: 80.72, f1: 76.42
>> saved: state_dict/lcf_bert_laptop_acc82.29
max_acc:82.29  f1:78.42
loss: 0.2988, acc: 95.14, test_acc: 82.29, f1: 78.42
loss: 0.0273, acc: 95.62, test_acc: 81.50, f1: 77.22
loss: 0.0207, acc: 96.02, test_acc: 81.50, f1: 77.33
loss: 0.0417, acc: 96.35, test_acc: 79.31, f1: 75.24
loss: 0.0699, acc: 96.63, test_acc: 80.41, f1: 75.55
loss: 0.1403, acc: 96.88, test_acc: 78.53, f1: 73.26
loss: 0.6336, acc: 95.83, test_acc: 79.78, f1: 75.19
loss: 0.2005, acc: 95.70, test_acc: 79.00, f1: 73.88
loss: 0.0866, acc: 95.59, test_acc: 75.55, f1: 71.53
loss: 0.3046, acc: 95.14, test_acc: 79.94, f1: 75.67
loss: 0.1040, acc: 95.07, test_acc: 81.82, f1: 78.02
loss: 0.4713, acc: 94.06, test_acc: 81.19, f1: 77.27
loss: 0.2783, acc: 93.75, test_acc: 79.15, f1: 74.59
loss: 0.2784, acc: 93.75, test_acc: 79.47, f1: 76.02
loss: 0.1294, acc: 93.75, test_acc: 80.25, f1: 76.31
loss: 0.1833, acc: 93.75, test_acc: 78.68, f1: 72.90
loss: 0.0530, acc: 94.00, test_acc: 77.27, f1: 69.56
loss: 0.0875, acc: 93.99, test_acc: 78.37, f1: 72.01
loss: 0.1040, acc: 94.21, test_acc: 80.09, f1: 76.68
loss: 0.1008, acc: 94.42, test_acc: 78.68, f1: 73.53
loss: 0.0838, acc: 94.61, test_acc: 76.96, f1: 70.14
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.1322, acc: 93.75, test_acc: 76.33, f1: 68.10
loss: 0.1858, acc: 93.75, test_acc: 79.15, f1: 74.59
loss: 0.1792, acc: 93.75, test_acc: 80.72, f1: 76.73
loss: 0.0562, acc: 95.31, test_acc: 80.72, f1: 76.65
loss: 0.1199, acc: 96.25, test_acc: 81.03, f1: 77.09
loss: 0.0790, acc: 95.83, test_acc: 79.78, f1: 75.17
loss: 0.1605, acc: 95.54, test_acc: 80.56, f1: 76.28
loss: 0.0747, acc: 96.09, test_acc: 81.50, f1: 77.90
loss: 0.0945, acc: 95.83, test_acc: 80.88, f1: 76.98
loss: 0.2334, acc: 94.38, test_acc: 79.62, f1: 73.92
loss: 0.1796, acc: 94.32, test_acc: 79.00, f1: 72.46
loss: 0.0630, acc: 94.79, test_acc: 79.00, f1: 73.62
loss: 0.0147, acc: 95.19, test_acc: 81.66, f1: 78.79
loss: 0.0664, acc: 95.54, test_acc: 81.50, f1: 78.06
loss: 0.1347, acc: 95.42, test_acc: 78.68, f1: 72.30
loss: 0.1604, acc: 95.31, test_acc: 78.68, f1: 72.03
loss: 0.2579, acc: 94.85, test_acc: 80.56, f1: 75.43
loss: 0.1374, acc: 95.14, test_acc: 80.25, f1: 75.78
loss: 0.0425, acc: 95.39, test_acc: 79.78, f1: 74.77
loss: 0.0613, acc: 95.62, test_acc: 79.31, f1: 73.24
loss: 0.0492, acc: 95.83, test_acc: 80.09, f1: 75.61
loss: 0.0352, acc: 96.02, test_acc: 81.97, f1: 78.77
loss: 0.2109, acc: 95.92, test_acc: 79.62, f1: 74.28
loss: 0.0749, acc: 95.83, test_acc: 77.12, f1: 68.92
loss: 0.4249, acc: 95.50, test_acc: 79.15, f1: 73.17
loss: 0.2455, acc: 95.19, test_acc: 79.94, f1: 76.33
loss: 0.6823, acc: 94.44, test_acc: 78.84, f1: 75.94
loss: 0.0087, acc: 94.64, test_acc: 79.78, f1: 74.72
loss: 0.0138, acc: 94.83, test_acc: 77.27, f1: 69.40
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.2012, acc: 93.75, test_acc: 77.27, f1: 70.06
loss: 0.0265, acc: 96.88, test_acc: 79.31, f1: 74.61
loss: 0.0993, acc: 95.83, test_acc: 80.88, f1: 76.95
loss: 0.0344, acc: 96.88, test_acc: 79.94, f1: 75.50
loss: 0.1319, acc: 97.50, test_acc: 79.78, f1: 74.41
loss: 0.0666, acc: 96.88, test_acc: 79.15, f1: 73.38
loss: 0.2179, acc: 95.54, test_acc: 79.00, f1: 73.12
loss: 0.0408, acc: 96.09, test_acc: 79.62, f1: 74.51
loss: 0.1391, acc: 95.83, test_acc: 80.25, f1: 75.38
loss: 0.1966, acc: 95.62, test_acc: 80.88, f1: 76.89
loss: 0.1884, acc: 95.45, test_acc: 80.41, f1: 76.34
loss: 0.0851, acc: 95.31, test_acc: 79.15, f1: 73.83
loss: 0.1765, acc: 95.19, test_acc: 79.94, f1: 75.32
loss: 0.0083, acc: 95.54, test_acc: 80.41, f1: 76.29
loss: 0.2224, acc: 95.42, test_acc: 80.41, f1: 76.44
loss: 0.3432, acc: 94.92, test_acc: 79.00, f1: 73.44
loss: 0.2004, acc: 94.49, test_acc: 78.37, f1: 72.00
loss: 0.1404, acc: 94.44, test_acc: 79.62, f1: 75.26
loss: 0.0362, acc: 94.74, test_acc: 80.72, f1: 76.89
loss: 0.0311, acc: 95.00, test_acc: 80.09, f1: 75.93
loss: 0.0686, acc: 95.24, test_acc: 79.94, f1: 75.62
loss: 0.0170, acc: 95.45, test_acc: 80.25, f1: 75.90
loss: 0.0042, acc: 95.65, test_acc: 80.72, f1: 76.91
loss: 0.0238, acc: 95.83, test_acc: 81.19, f1: 77.59
loss: 0.1911, acc: 95.75, test_acc: 79.78, f1: 75.33
loss: 0.3343, acc: 95.67, test_acc: 79.47, f1: 74.84
loss: 0.5504, acc: 95.37, test_acc: 80.56, f1: 76.83
loss: 0.0164, acc: 95.54, test_acc: 80.88, f1: 76.86
loss: 0.1422, acc: 95.47, test_acc: 79.94, f1: 75.78
loss: 0.0444, acc: 95.55, test_acc: 80.09, f1: 75.25
####################################################################################################
max_test_acc_overall:82.2884012539185
max_f1_overall:78.79211899564896
####################################################################################################
1 test_acc_overall: 82.29  f1_overall:78.94
2 test_acc_overall: 82.29  f1_overall:78.79
max_acc_overall:82.29  f1_overall:78.94
mean_acc_overall:82.29  mean_f1_overall:78.87
####################################################################################################
lcf_bert - laptop - cdm - No.3 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3a3fdbf268>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 2
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc52.98
max_acc:52.98  f1:25.25
loss: 1.1671, acc: 43.75, test_acc: 52.98, f1: 25.25
>> saved: state_dict/lcf_bert_laptop_acc55.49
max_acc:55.49  f1:34.78
loss: 1.0120, acc: 53.12, test_acc: 55.49, f1: 34.78
loss: 1.0724, acc: 50.00, test_acc: 54.39, f1: 30.16
loss: 0.9958, acc: 45.31, test_acc: 21.94, f1: 13.58
>> saved: state_dict/lcf_bert_laptop_acc69.59
max_acc:69.59  f1:52.53
loss: 0.7811, acc: 51.25, test_acc: 69.59, f1: 52.53
>> saved: state_dict/lcf_bert_laptop_acc71.32
max_acc:71.32  f1:57.3
loss: 0.7738, acc: 54.17, test_acc: 71.32, f1: 57.30
loss: 0.7560, acc: 57.14, test_acc: 70.22, f1: 57.15
loss: 0.7620, acc: 58.59, test_acc: 70.22, f1: 57.31
>> saved: state_dict/lcf_bert_laptop_acc74.61
max_acc:74.61  f1:66.62
loss: 0.7267, acc: 59.03, test_acc: 74.61, f1: 66.62
>> saved: state_dict/lcf_bert_laptop_acc76.02
max_acc:76.02  f1:69.99
loss: 0.4736, acc: 60.62, test_acc: 76.02, f1: 69.99
loss: 0.6549, acc: 61.93, test_acc: 69.75, f1: 57.04
loss: 0.9667, acc: 60.94, test_acc: 75.55, f1: 69.34
>> saved: state_dict/lcf_bert_laptop_acc76.65
max_acc:76.65  f1:72.5
loss: 0.7788, acc: 61.06, test_acc: 76.65, f1: 72.50
loss: 0.7592, acc: 62.05, test_acc: 74.45, f1: 66.93
loss: 0.4436, acc: 63.33, test_acc: 74.76, f1: 64.49
loss: 0.5021, acc: 64.45, test_acc: 75.86, f1: 67.67
>> saved: state_dict/lcf_bert_laptop_acc79.0
max_acc:79.0  f1:73.16
loss: 0.7405, acc: 64.34, test_acc: 79.00, f1: 73.16
loss: 0.3807, acc: 65.62, test_acc: 79.00, f1: 73.01
loss: 0.6610, acc: 66.12, test_acc: 77.43, f1: 70.05
loss: 0.6373, acc: 66.56, test_acc: 77.59, f1: 69.31
loss: 0.7251, acc: 66.67, test_acc: 76.96, f1: 71.10
>> saved: state_dict/lcf_bert_laptop_acc79.15
max_acc:79.15  f1:74.64
loss: 0.5237, acc: 66.76, test_acc: 79.15, f1: 74.64
loss: 0.3870, acc: 67.39, test_acc: 78.21, f1: 72.75
loss: 0.3550, acc: 68.49, test_acc: 76.96, f1: 69.49
loss: 0.7111, acc: 68.50, test_acc: 79.00, f1: 72.67
>> saved: state_dict/lcf_bert_laptop_acc80.09
max_acc:80.09  f1:76.69
loss: 0.4669, acc: 68.99, test_acc: 80.09, f1: 76.69
loss: 0.4212, acc: 69.68, test_acc: 78.84, f1: 73.41
loss: 0.2652, acc: 70.54, test_acc: 76.96, f1: 69.27
loss: 0.5727, acc: 70.69, test_acc: 78.68, f1: 73.67
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.0896, acc: 100.00, test_acc: 77.74, f1: 71.87
loss: 0.2443, acc: 93.75, test_acc: 79.47, f1: 75.88
loss: 0.6601, acc: 87.50, test_acc: 79.31, f1: 75.26
loss: 0.2194, acc: 89.06, test_acc: 76.49, f1: 69.13
loss: 0.3553, acc: 87.50, test_acc: 78.21, f1: 72.65
loss: 0.4027, acc: 86.46, test_acc: 79.62, f1: 75.86
loss: 0.2750, acc: 86.61, test_acc: 79.00, f1: 74.71
loss: 0.2736, acc: 86.72, test_acc: 76.96, f1: 71.56
loss: 0.5804, acc: 86.11, test_acc: 79.00, f1: 75.62
loss: 0.2272, acc: 86.25, test_acc: 79.00, f1: 76.17
loss: 0.1102, acc: 86.93, test_acc: 79.62, f1: 74.48
loss: 0.1046, acc: 88.02, test_acc: 74.14, f1: 64.42
loss: 0.6325, acc: 87.02, test_acc: 74.76, f1: 64.89
loss: 0.2635, acc: 87.50, test_acc: 78.21, f1: 72.45
loss: 0.4450, acc: 87.08, test_acc: 79.31, f1: 74.90
loss: 0.4599, acc: 86.33, test_acc: 78.84, f1: 74.16
loss: 0.4585, acc: 86.40, test_acc: 77.90, f1: 72.67
loss: 0.4579, acc: 86.11, test_acc: 76.65, f1: 69.62
loss: 0.1680, acc: 86.51, test_acc: 79.31, f1: 73.98
>> saved: state_dict/lcf_bert_laptop_acc80.56
max_acc:80.56  f1:76.58
loss: 0.3214, acc: 86.25, test_acc: 80.56, f1: 76.58
loss: 0.4635, acc: 86.01, test_acc: 79.78, f1: 75.55
loss: 0.3983, acc: 85.80, test_acc: 80.09, f1: 75.77
loss: 0.3668, acc: 86.14, test_acc: 79.31, f1: 74.32
loss: 0.1216, acc: 86.72, test_acc: 80.41, f1: 76.09
>> saved: state_dict/lcf_bert_laptop_acc80.88
max_acc:80.88  f1:77.21
loss: 0.4309, acc: 86.75, test_acc: 80.88, f1: 77.21
loss: 0.6730, acc: 86.54, test_acc: 79.62, f1: 76.58
loss: 0.2305, acc: 86.81, test_acc: 77.27, f1: 70.92
loss: 0.3264, acc: 86.83, test_acc: 74.76, f1: 64.87
loss: 0.2302, acc: 86.85, test_acc: 75.39, f1: 66.47
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1840, acc: 93.75, test_acc: 80.41, f1: 76.09
loss: 0.2581, acc: 90.62, test_acc: 80.09, f1: 76.06
loss: 0.1315, acc: 91.67, test_acc: 78.21, f1: 73.03
loss: 0.0881, acc: 93.75, test_acc: 78.37, f1: 72.67
loss: 0.1901, acc: 93.75, test_acc: 79.00, f1: 74.09
loss: 0.1666, acc: 93.75, test_acc: 79.47, f1: 75.21
loss: 0.1426, acc: 93.75, test_acc: 80.56, f1: 77.56
loss: 0.3034, acc: 92.19, test_acc: 79.94, f1: 75.89
loss: 0.0290, acc: 93.06, test_acc: 79.78, f1: 74.89
loss: 0.0768, acc: 93.75, test_acc: 79.94, f1: 75.37
loss: 0.0402, acc: 94.32, test_acc: 79.94, f1: 75.24
loss: 0.0897, acc: 94.79, test_acc: 79.78, f1: 74.90
loss: 0.1729, acc: 94.71, test_acc: 79.31, f1: 74.30
loss: 0.2924, acc: 94.20, test_acc: 79.94, f1: 75.44
>> saved: state_dict/lcf_bert_laptop_acc81.35
max_acc:81.35  f1:77.67
loss: 0.1951, acc: 93.75, test_acc: 81.35, f1: 77.67
loss: 0.2462, acc: 93.36, test_acc: 79.00, f1: 74.03
loss: 0.3512, acc: 93.01, test_acc: 77.90, f1: 72.48
loss: 0.1978, acc: 93.06, test_acc: 80.09, f1: 75.44
>> saved: state_dict/lcf_bert_laptop_acc81.97
max_acc:81.97  f1:78.35
loss: 0.0965, acc: 93.42, test_acc: 81.97, f1: 78.35
loss: 0.2378, acc: 93.12, test_acc: 79.78, f1: 74.82
loss: 0.0931, acc: 93.45, test_acc: 77.27, f1: 70.24
loss: 0.3084, acc: 93.18, test_acc: 79.15, f1: 74.69
loss: 0.0688, acc: 93.48, test_acc: 79.78, f1: 75.93
loss: 0.1038, acc: 93.49, test_acc: 79.78, f1: 75.61
loss: 0.3490, acc: 93.25, test_acc: 80.72, f1: 77.12
loss: 0.8319, acc: 92.79, test_acc: 81.82, f1: 79.19
loss: 0.1019, acc: 93.06, test_acc: 81.03, f1: 77.33
loss: 0.5363, acc: 92.86, test_acc: 80.25, f1: 76.14
loss: 0.1801, acc: 92.89, test_acc: 80.88, f1: 77.06
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.1592, acc: 87.50, test_acc: 81.35, f1: 77.73
loss: 0.2232, acc: 90.62, test_acc: 80.56, f1: 76.47
loss: 0.0379, acc: 93.75, test_acc: 78.68, f1: 73.44
loss: 0.0715, acc: 95.31, test_acc: 79.00, f1: 73.35
loss: 0.2302, acc: 95.00, test_acc: 79.62, f1: 74.48
loss: 0.1185, acc: 94.79, test_acc: 80.41, f1: 76.11
loss: 0.0354, acc: 95.54, test_acc: 80.25, f1: 75.97
loss: 0.4557, acc: 94.53, test_acc: 79.62, f1: 74.28
loss: 0.0077, acc: 95.14, test_acc: 80.09, f1: 75.04
loss: 0.1512, acc: 95.00, test_acc: 80.09, f1: 75.84
loss: 0.0131, acc: 95.45, test_acc: 79.78, f1: 76.14
loss: 0.2273, acc: 94.79, test_acc: 79.31, f1: 74.50
loss: 0.2325, acc: 93.75, test_acc: 77.27, f1: 70.06
loss: 0.1090, acc: 93.75, test_acc: 79.47, f1: 73.98
loss: 0.0273, acc: 94.17, test_acc: 80.72, f1: 76.78
loss: 0.0896, acc: 94.53, test_acc: 80.72, f1: 76.83
loss: 0.5688, acc: 93.75, test_acc: 78.84, f1: 74.25
loss: 0.1984, acc: 93.40, test_acc: 80.25, f1: 75.96
loss: 0.0147, acc: 93.75, test_acc: 79.31, f1: 73.96
loss: 0.0766, acc: 94.06, test_acc: 77.43, f1: 69.39
loss: 0.0429, acc: 94.35, test_acc: 78.53, f1: 72.77
loss: 0.0463, acc: 94.60, test_acc: 78.21, f1: 74.20
loss: 0.1796, acc: 94.57, test_acc: 76.65, f1: 71.70
loss: 0.1550, acc: 94.27, test_acc: 79.00, f1: 73.57
loss: 0.0306, acc: 94.50, test_acc: 81.03, f1: 76.64
loss: 0.1205, acc: 94.47, test_acc: 81.03, f1: 76.97
loss: 0.0169, acc: 94.68, test_acc: 77.90, f1: 71.26
loss: 0.3949, acc: 94.42, test_acc: 78.21, f1: 71.52
loss: 0.1711, acc: 94.18, test_acc: 80.56, f1: 76.07
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.1144, acc: 93.75, test_acc: 80.41, f1: 76.95
loss: 0.1208, acc: 96.88, test_acc: 80.72, f1: 77.00
loss: 0.0494, acc: 97.92, test_acc: 79.47, f1: 74.43
loss: 0.2328, acc: 95.31, test_acc: 78.84, f1: 72.79
loss: 0.0421, acc: 96.25, test_acc: 79.62, f1: 74.38
loss: 0.0543, acc: 96.88, test_acc: 80.72, f1: 76.24
loss: 0.0622, acc: 96.43, test_acc: 80.41, f1: 76.07
loss: 0.2243, acc: 95.31, test_acc: 80.09, f1: 76.21
loss: 0.0139, acc: 95.83, test_acc: 79.47, f1: 75.28
loss: 0.1251, acc: 95.62, test_acc: 80.72, f1: 76.41
loss: 0.0101, acc: 96.02, test_acc: 81.50, f1: 77.53
loss: 0.0150, acc: 96.35, test_acc: 81.35, f1: 77.31
loss: 0.1097, acc: 96.15, test_acc: 80.72, f1: 76.54
loss: 0.0085, acc: 96.43, test_acc: 81.35, f1: 77.13
loss: 0.0147, acc: 96.67, test_acc: 81.50, f1: 77.73
loss: 0.2656, acc: 96.48, test_acc: 81.66, f1: 77.88
loss: 0.0034, acc: 96.69, test_acc: 81.66, f1: 77.65
loss: 0.0127, acc: 96.88, test_acc: 81.03, f1: 76.74
loss: 0.0115, acc: 97.04, test_acc: 80.72, f1: 76.00
loss: 0.0208, acc: 97.19, test_acc: 80.41, f1: 75.56
loss: 0.0199, acc: 97.32, test_acc: 81.35, f1: 77.03
loss: 0.0075, acc: 97.44, test_acc: 81.35, f1: 77.29
>> saved: state_dict/lcf_bert_laptop_acc82.92
max_acc:82.92  f1:79.31
loss: 0.0102, acc: 97.55, test_acc: 82.92, f1: 79.31
loss: 0.0226, acc: 97.66, test_acc: 81.82, f1: 77.98
loss: 0.0096, acc: 97.75, test_acc: 79.94, f1: 75.10
loss: 0.0079, acc: 97.84, test_acc: 79.47, f1: 73.63
loss: 0.1407, acc: 97.69, test_acc: 79.31, f1: 73.97
loss: 0.1573, acc: 97.54, test_acc: 79.94, f1: 76.22
loss: 0.0288, acc: 97.63, test_acc: 81.66, f1: 78.17
loss: 0.2585, acc: 97.46, test_acc: 81.03, f1: 76.84
####################################################################################################
max_test_acc_overall:82.9153605015674
max_f1_overall:79.30924265066314
####################################################################################################
1 test_acc_overall: 82.29  f1_overall:78.94
2 test_acc_overall: 82.29  f1_overall:78.79
3 test_acc_overall: 82.92  f1_overall:79.31
max_acc_overall:82.92  f1_overall:79.31
mean_acc_overall:82.5  mean_f1_overall:79.01
####################################################################################################
lcf_bert - laptop - cdm - No.4 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3a3fdbf268>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 3
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc51.1
max_acc:51.1  f1:37.53
loss: 0.9960, acc: 50.00, test_acc: 51.10, f1: 37.53
>> saved: state_dict/lcf_bert_laptop_acc54.7
max_acc:54.7  f1:30.3
loss: 1.0569, acc: 46.88, test_acc: 54.70, f1: 30.30
>> saved: state_dict/lcf_bert_laptop_acc62.38
max_acc:62.38  f1:43.91
loss: 1.2048, acc: 33.33, test_acc: 62.38, f1: 43.91
>> saved: state_dict/lcf_bert_laptop_acc69.91
max_acc:69.91  f1:58.47
loss: 0.9423, acc: 39.06, test_acc: 69.91, f1: 58.47
loss: 1.0098, acc: 37.50, test_acc: 66.46, f1: 50.01
loss: 1.0609, acc: 39.58, test_acc: 69.12, f1: 54.28
loss: 0.9418, acc: 40.18, test_acc: 69.75, f1: 55.82
>> saved: state_dict/lcf_bert_laptop_acc71.0
max_acc:71.0  f1:59.05
loss: 0.6603, acc: 42.97, test_acc: 71.00, f1: 59.05
>> saved: state_dict/lcf_bert_laptop_acc71.16
max_acc:71.16  f1:62.43
loss: 0.5784, acc: 47.22, test_acc: 71.16, f1: 62.43
loss: 0.5666, acc: 50.62, test_acc: 70.53, f1: 61.05
>> saved: state_dict/lcf_bert_laptop_acc71.63
max_acc:71.63  f1:60.51
loss: 0.4902, acc: 52.84, test_acc: 71.63, f1: 60.51
>> saved: state_dict/lcf_bert_laptop_acc73.51
max_acc:73.51  f1:63.01
loss: 0.6679, acc: 54.17, test_acc: 73.51, f1: 63.01
>> saved: state_dict/lcf_bert_laptop_acc76.18
max_acc:76.18  f1:73.73
loss: 0.3854, acc: 56.25, test_acc: 76.18, f1: 73.73
>> saved: state_dict/lcf_bert_laptop_acc77.59
max_acc:77.59  f1:72.05
loss: 0.5522, acc: 58.04, test_acc: 77.59, f1: 72.05
loss: 0.3472, acc: 59.58, test_acc: 75.08, f1: 67.10
>> saved: state_dict/lcf_bert_laptop_acc78.21
max_acc:78.21  f1:73.21
loss: 0.5358, acc: 60.16, test_acc: 78.21, f1: 73.21
>> saved: state_dict/lcf_bert_laptop_acc79.15
max_acc:79.15  f1:75.07
loss: 0.7489, acc: 61.03, test_acc: 79.15, f1: 75.07
loss: 0.5526, acc: 62.15, test_acc: 77.43, f1: 73.16
loss: 0.6080, acc: 62.83, test_acc: 77.59, f1: 74.10
loss: 0.6836, acc: 62.81, test_acc: 77.90, f1: 73.44
loss: 0.6459, acc: 63.69, test_acc: 75.08, f1: 66.57
loss: 0.6046, acc: 64.49, test_acc: 73.04, f1: 62.70
loss: 0.4731, acc: 65.22, test_acc: 76.33, f1: 68.36
>> saved: state_dict/lcf_bert_laptop_acc79.94
max_acc:79.94  f1:76.48
loss: 0.3623, acc: 66.15, test_acc: 79.94, f1: 76.48
loss: 0.6863, acc: 66.25, test_acc: 79.15, f1: 75.09
loss: 0.4383, acc: 67.07, test_acc: 79.15, f1: 75.13
loss: 0.3836, acc: 67.36, test_acc: 76.80, f1: 72.43
loss: 0.6469, acc: 67.41, test_acc: 78.37, f1: 72.44
loss: 0.7350, acc: 67.46, test_acc: 78.53, f1: 73.08
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.4850, acc: 87.50, test_acc: 79.94, f1: 75.86
loss: 0.4642, acc: 84.38, test_acc: 78.06, f1: 74.54
loss: 0.4676, acc: 85.42, test_acc: 77.12, f1: 70.91
loss: 0.4294, acc: 82.81, test_acc: 73.04, f1: 63.94
loss: 0.3992, acc: 83.75, test_acc: 76.80, f1: 70.57
loss: 0.0453, acc: 86.46, test_acc: 78.06, f1: 72.24
loss: 0.2169, acc: 86.61, test_acc: 78.21, f1: 72.27
>> saved: state_dict/lcf_bert_laptop_acc80.09
max_acc:80.09  f1:76.11
loss: 0.5150, acc: 85.94, test_acc: 80.09, f1: 76.11
>> saved: state_dict/lcf_bert_laptop_acc82.6
max_acc:82.6  f1:79.35
loss: 0.5071, acc: 86.11, test_acc: 82.60, f1: 79.35
loss: 0.4536, acc: 86.25, test_acc: 78.53, f1: 72.90
loss: 0.0728, acc: 87.50, test_acc: 76.18, f1: 69.34
loss: 0.4220, acc: 87.50, test_acc: 77.74, f1: 71.88
loss: 0.2773, acc: 87.50, test_acc: 80.88, f1: 77.10
loss: 0.3436, acc: 87.95, test_acc: 80.41, f1: 76.33
loss: 0.1678, acc: 88.75, test_acc: 79.31, f1: 74.25
loss: 0.3283, acc: 88.28, test_acc: 79.62, f1: 74.80
loss: 0.2515, acc: 88.97, test_acc: 79.15, f1: 73.96
loss: 0.3273, acc: 88.89, test_acc: 79.94, f1: 75.50
loss: 0.2143, acc: 89.14, test_acc: 80.41, f1: 75.81
loss: 0.3400, acc: 89.06, test_acc: 80.72, f1: 76.52
loss: 0.2213, acc: 88.69, test_acc: 80.88, f1: 77.01
loss: 0.2957, acc: 88.64, test_acc: 81.82, f1: 78.26
loss: 0.4933, acc: 88.32, test_acc: 79.94, f1: 77.06
loss: 0.4913, acc: 88.02, test_acc: 79.62, f1: 75.53
loss: 0.6845, acc: 87.25, test_acc: 77.12, f1: 71.18
loss: 0.3307, acc: 87.50, test_acc: 76.33, f1: 70.81
loss: 0.3364, acc: 87.73, test_acc: 76.96, f1: 70.64
loss: 0.3428, acc: 87.72, test_acc: 77.74, f1: 71.93
loss: 0.3970, acc: 87.72, test_acc: 79.47, f1: 75.28
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.0749, acc: 100.00, test_acc: 78.37, f1: 73.24
loss: 0.6317, acc: 87.50, test_acc: 77.74, f1: 72.34
loss: 0.3084, acc: 87.50, test_acc: 79.31, f1: 75.48
loss: 0.2779, acc: 85.94, test_acc: 79.62, f1: 76.31
loss: 0.1749, acc: 87.50, test_acc: 79.78, f1: 76.53
loss: 0.1071, acc: 88.54, test_acc: 78.06, f1: 73.73
loss: 0.3593, acc: 89.29, test_acc: 79.31, f1: 75.33
loss: 0.2737, acc: 89.06, test_acc: 79.15, f1: 75.18
loss: 0.2094, acc: 88.89, test_acc: 77.90, f1: 72.48
loss: 0.1871, acc: 89.38, test_acc: 77.59, f1: 71.80
loss: 0.1949, acc: 89.77, test_acc: 79.15, f1: 74.84
loss: 0.1301, acc: 90.62, test_acc: 78.68, f1: 73.78
loss: 0.0361, acc: 91.35, test_acc: 80.72, f1: 76.64
loss: 0.2805, acc: 91.07, test_acc: 78.53, f1: 73.75
loss: 0.0959, acc: 91.25, test_acc: 79.15, f1: 74.20
loss: 0.3850, acc: 91.02, test_acc: 79.94, f1: 75.97
loss: 0.1609, acc: 91.18, test_acc: 80.09, f1: 75.94
loss: 0.0568, acc: 91.67, test_acc: 78.06, f1: 72.47
loss: 0.1580, acc: 91.78, test_acc: 76.96, f1: 72.66
loss: 0.1362, acc: 91.88, test_acc: 80.41, f1: 77.68
loss: 0.2430, acc: 91.67, test_acc: 81.66, f1: 78.40
loss: 0.1928, acc: 91.76, test_acc: 81.03, f1: 77.44
loss: 0.0177, acc: 92.12, test_acc: 80.09, f1: 75.92
loss: 0.1390, acc: 92.19, test_acc: 78.06, f1: 72.26
loss: 0.0875, acc: 92.25, test_acc: 79.31, f1: 74.08
loss: 0.2162, acc: 92.31, test_acc: 79.94, f1: 75.35
loss: 0.1067, acc: 92.59, test_acc: 80.72, f1: 76.83
loss: 0.5732, acc: 91.96, test_acc: 79.31, f1: 74.98
loss: 0.1272, acc: 92.03, test_acc: 79.62, f1: 75.39
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.1714, acc: 93.75, test_acc: 78.06, f1: 71.38
loss: 0.0356, acc: 96.88, test_acc: 77.27, f1: 70.08
loss: 0.1247, acc: 95.83, test_acc: 79.15, f1: 73.69
loss: 0.0340, acc: 96.88, test_acc: 80.41, f1: 77.26
loss: 0.0367, acc: 97.50, test_acc: 80.88, f1: 77.29
loss: 0.1062, acc: 96.88, test_acc: 79.94, f1: 75.65
loss: 0.6506, acc: 93.75, test_acc: 79.15, f1: 74.26
loss: 0.0269, acc: 94.53, test_acc: 81.19, f1: 77.67
loss: 0.0553, acc: 95.14, test_acc: 81.50, f1: 78.63
loss: 0.1289, acc: 95.62, test_acc: 79.94, f1: 76.82
loss: 0.0080, acc: 96.02, test_acc: 79.00, f1: 74.94
loss: 0.1695, acc: 95.83, test_acc: 79.47, f1: 75.03
loss: 0.1442, acc: 95.67, test_acc: 80.09, f1: 76.70
loss: 0.0806, acc: 95.98, test_acc: 80.41, f1: 77.18
loss: 0.1116, acc: 95.83, test_acc: 78.06, f1: 73.41
loss: 0.3982, acc: 94.92, test_acc: 78.06, f1: 72.26
loss: 0.0454, acc: 95.22, test_acc: 79.31, f1: 74.68
loss: 0.0229, acc: 95.49, test_acc: 80.56, f1: 77.50
loss: 0.0127, acc: 95.72, test_acc: 81.35, f1: 78.22
loss: 0.0992, acc: 95.62, test_acc: 81.03, f1: 77.67
loss: 0.0443, acc: 95.83, test_acc: 82.13, f1: 78.73
loss: 0.0858, acc: 96.02, test_acc: 80.09, f1: 75.77
loss: 0.0152, acc: 96.20, test_acc: 78.21, f1: 72.56
loss: 0.0576, acc: 96.35, test_acc: 78.68, f1: 73.51
loss: 0.1923, acc: 96.25, test_acc: 79.31, f1: 75.19
loss: 0.0232, acc: 96.39, test_acc: 80.25, f1: 75.99
loss: 0.3632, acc: 96.06, test_acc: 81.35, f1: 77.99
loss: 0.0149, acc: 96.21, test_acc: 81.03, f1: 77.29
loss: 0.3802, acc: 95.69, test_acc: 78.68, f1: 73.31
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0265, acc: 100.00, test_acc: 78.06, f1: 72.74
loss: 0.1366, acc: 96.88, test_acc: 79.00, f1: 74.65
loss: 0.0198, acc: 97.92, test_acc: 81.19, f1: 78.26
loss: 0.0728, acc: 98.44, test_acc: 81.19, f1: 78.41
loss: 0.1647, acc: 97.50, test_acc: 79.47, f1: 74.98
loss: 0.0081, acc: 97.92, test_acc: 76.80, f1: 70.58
loss: 0.0039, acc: 98.21, test_acc: 77.74, f1: 72.25
loss: 0.0139, acc: 98.44, test_acc: 79.31, f1: 74.86
loss: 0.0451, acc: 98.61, test_acc: 81.82, f1: 78.73
loss: 0.0275, acc: 98.75, test_acc: 81.82, f1: 78.63
loss: 0.0178, acc: 98.86, test_acc: 79.78, f1: 75.30
loss: 0.0171, acc: 98.96, test_acc: 79.47, f1: 74.79
loss: 0.1769, acc: 98.56, test_acc: 79.47, f1: 74.89
loss: 0.0500, acc: 98.66, test_acc: 81.35, f1: 78.40
loss: 0.0635, acc: 98.75, test_acc: 80.56, f1: 77.84
loss: 0.0857, acc: 98.44, test_acc: 79.94, f1: 76.18
loss: 0.0069, acc: 98.53, test_acc: 79.00, f1: 73.66
loss: 0.1609, acc: 97.92, test_acc: 76.33, f1: 69.22
loss: 0.0174, acc: 98.03, test_acc: 78.84, f1: 73.78
loss: 0.0059, acc: 98.12, test_acc: 80.72, f1: 76.62
loss: 0.0207, acc: 98.21, test_acc: 81.50, f1: 77.75
loss: 0.0611, acc: 98.01, test_acc: 81.03, f1: 77.28
loss: 0.0458, acc: 98.10, test_acc: 82.45, f1: 79.42
loss: 0.3663, acc: 97.40, test_acc: 82.13, f1: 78.84
loss: 0.0304, acc: 97.50, test_acc: 78.21, f1: 72.30
loss: 0.1700, acc: 97.36, test_acc: 78.06, f1: 72.28
loss: 0.0842, acc: 97.22, test_acc: 81.19, f1: 77.54
loss: 0.2676, acc: 96.88, test_acc: 82.29, f1: 78.91
loss: 0.1797, acc: 96.77, test_acc: 82.13, f1: 78.49
loss: 0.0401, acc: 96.82, test_acc: 81.35, f1: 77.39
####################################################################################################
max_test_acc_overall:82.60188087774296
max_f1_overall:79.42381076892178
####################################################################################################
1 test_acc_overall: 82.29  f1_overall:78.94
2 test_acc_overall: 82.29  f1_overall:78.79
3 test_acc_overall: 82.92  f1_overall:79.31
4 test_acc_overall: 82.6  f1_overall:79.42
max_acc_overall:82.92  f1_overall:79.31
mean_acc_overall:82.52  mean_f1_overall:79.12
####################################################################################################
lcf_bert - laptop - cdm - No.5 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3a3fdbf268>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 4
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc54.08
max_acc:54.08  f1:33.48
loss: 1.1601, acc: 25.00, test_acc: 54.08, f1: 33.48
loss: 1.0236, acc: 34.38, test_acc: 52.51, f1: 39.27
>> saved: state_dict/lcf_bert_laptop_acc57.99
max_acc:57.99  f1:36.64
loss: 0.8399, acc: 52.08, test_acc: 57.99, f1: 36.64
>> saved: state_dict/lcf_bert_laptop_acc65.52
max_acc:65.52  f1:47.47
loss: 0.8922, acc: 56.25, test_acc: 65.52, f1: 47.47
>> saved: state_dict/lcf_bert_laptop_acc70.69
max_acc:70.69  f1:65.0
loss: 0.8450, acc: 57.50, test_acc: 70.69, f1: 65.00
loss: 0.4963, acc: 62.50, test_acc: 70.69, f1: 60.77
loss: 0.4972, acc: 65.18, test_acc: 69.12, f1: 51.74
loss: 0.3157, acc: 68.75, test_acc: 70.69, f1: 56.71
>> saved: state_dict/lcf_bert_laptop_acc74.14
max_acc:74.14  f1:65.14
loss: 0.6141, acc: 68.75, test_acc: 74.14, f1: 65.14
>> saved: state_dict/lcf_bert_laptop_acc77.12
max_acc:77.12  f1:74.21
loss: 0.6924, acc: 69.38, test_acc: 77.12, f1: 74.21
loss: 0.6864, acc: 68.75, test_acc: 75.24, f1: 67.67
loss: 0.5851, acc: 69.79, test_acc: 76.65, f1: 70.06
loss: 0.4735, acc: 70.67, test_acc: 72.26, f1: 61.54
loss: 0.5999, acc: 70.54, test_acc: 75.86, f1: 66.22
>> saved: state_dict/lcf_bert_laptop_acc79.78
max_acc:79.78  f1:75.81
loss: 0.7312, acc: 70.42, test_acc: 79.78, f1: 75.81
loss: 0.6285, acc: 71.09, test_acc: 79.62, f1: 75.85
loss: 1.0292, acc: 69.85, test_acc: 79.15, f1: 72.73
loss: 0.6000, acc: 70.14, test_acc: 78.06, f1: 70.70
loss: 0.4280, acc: 70.72, test_acc: 78.68, f1: 73.54
loss: 0.4990, acc: 71.56, test_acc: 77.12, f1: 70.85
loss: 0.6973, acc: 71.43, test_acc: 76.18, f1: 68.10
loss: 0.2914, acc: 72.44, test_acc: 78.84, f1: 73.91
loss: 0.6054, acc: 72.01, test_acc: 78.53, f1: 72.43
loss: 0.1230, acc: 73.18, test_acc: 79.15, f1: 74.85
loss: 0.7349, acc: 73.25, test_acc: 79.00, f1: 74.13
loss: 0.4927, acc: 73.32, test_acc: 79.00, f1: 72.82
>> saved: state_dict/lcf_bert_laptop_acc80.09
max_acc:80.09  f1:75.8
loss: 0.8249, acc: 73.15, test_acc: 80.09, f1: 75.80
loss: 0.7267, acc: 73.21, test_acc: 79.94, f1: 76.76
loss: 0.3720, acc: 73.71, test_acc: 78.84, f1: 74.49
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.2642, acc: 87.50, test_acc: 79.47, f1: 74.28
loss: 0.3762, acc: 87.50, test_acc: 78.84, f1: 73.19
loss: 0.1961, acc: 87.50, test_acc: 78.53, f1: 72.77
loss: 0.5434, acc: 84.38, test_acc: 78.84, f1: 74.50
loss: 0.1571, acc: 87.50, test_acc: 79.47, f1: 74.49
loss: 0.3596, acc: 87.50, test_acc: 79.15, f1: 73.72
loss: 0.3650, acc: 87.50, test_acc: 79.47, f1: 74.89
loss: 0.3622, acc: 85.94, test_acc: 78.53, f1: 72.86
loss: 0.4956, acc: 85.42, test_acc: 78.21, f1: 72.75
loss: 0.5216, acc: 84.38, test_acc: 77.12, f1: 71.37
loss: 0.2118, acc: 85.23, test_acc: 78.21, f1: 73.40
loss: 0.1708, acc: 85.94, test_acc: 76.02, f1: 67.94
loss: 0.2513, acc: 86.06, test_acc: 76.02, f1: 67.73
loss: 0.2662, acc: 86.16, test_acc: 77.27, f1: 70.81
loss: 0.2785, acc: 85.83, test_acc: 77.12, f1: 72.27
loss: 0.5896, acc: 84.77, test_acc: 76.80, f1: 73.78
loss: 0.3171, acc: 84.93, test_acc: 79.00, f1: 74.25
loss: 0.5333, acc: 84.38, test_acc: 75.08, f1: 67.25
loss: 0.4660, acc: 84.54, test_acc: 78.68, f1: 73.16
loss: 0.5747, acc: 84.38, test_acc: 79.00, f1: 76.72
>> saved: state_dict/lcf_bert_laptop_acc80.88
max_acc:80.88  f1:76.72
loss: 0.8344, acc: 83.33, test_acc: 80.88, f1: 76.72
loss: 0.2648, acc: 83.52, test_acc: 75.55, f1: 67.28
loss: 0.1925, acc: 84.24, test_acc: 80.41, f1: 76.32
loss: 0.4007, acc: 84.64, test_acc: 79.94, f1: 76.63
loss: 0.3145, acc: 84.75, test_acc: 79.31, f1: 73.96
loss: 0.4525, acc: 84.86, test_acc: 76.49, f1: 69.52
loss: 0.1127, acc: 85.42, test_acc: 78.37, f1: 74.00
loss: 0.4474, acc: 85.49, test_acc: 79.31, f1: 75.54
loss: 0.3943, acc: 85.34, test_acc: 78.06, f1: 71.91
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2823, acc: 93.75, test_acc: 79.78, f1: 74.86
loss: 0.0713, acc: 93.75, test_acc: 80.88, f1: 76.56
>> saved: state_dict/lcf_bert_laptop_acc81.35
max_acc:81.35  f1:77.43
loss: 0.0385, acc: 95.83, test_acc: 81.35, f1: 77.43
loss: 0.1290, acc: 95.31, test_acc: 80.56, f1: 76.35
loss: 0.0210, acc: 96.25, test_acc: 81.03, f1: 77.42
loss: 0.3043, acc: 94.79, test_acc: 81.35, f1: 77.81
loss: 0.2404, acc: 94.64, test_acc: 80.41, f1: 76.22
loss: 0.1820, acc: 94.53, test_acc: 81.03, f1: 77.20
>> saved: state_dict/lcf_bert_laptop_acc82.13
max_acc:82.13  f1:78.79
loss: 0.2402, acc: 94.44, test_acc: 82.13, f1: 78.79
loss: 0.1367, acc: 94.38, test_acc: 80.25, f1: 75.54
loss: 0.2044, acc: 94.32, test_acc: 76.33, f1: 69.12
loss: 0.2127, acc: 93.23, test_acc: 80.09, f1: 75.76
loss: 0.1070, acc: 93.27, test_acc: 80.72, f1: 78.09
>> saved: state_dict/lcf_bert_laptop_acc82.29
max_acc:82.29  f1:78.7
loss: 0.1842, acc: 93.30, test_acc: 82.29, f1: 78.70
loss: 0.1394, acc: 93.33, test_acc: 81.97, f1: 78.23
loss: 0.2707, acc: 93.36, test_acc: 81.66, f1: 78.91
loss: 0.2322, acc: 93.38, test_acc: 81.66, f1: 79.06
loss: 0.3888, acc: 93.06, test_acc: 78.53, f1: 72.65
loss: 0.2127, acc: 93.09, test_acc: 76.33, f1: 68.91
loss: 0.1340, acc: 93.44, test_acc: 79.15, f1: 73.52
loss: 0.3666, acc: 93.15, test_acc: 80.25, f1: 75.77
loss: 0.0912, acc: 93.18, test_acc: 81.03, f1: 77.50
loss: 0.3534, acc: 93.21, test_acc: 79.78, f1: 75.11
loss: 0.1386, acc: 93.23, test_acc: 79.94, f1: 75.52
loss: 0.0886, acc: 93.50, test_acc: 80.56, f1: 76.98
loss: 0.3717, acc: 93.27, test_acc: 79.47, f1: 75.36
loss: 0.1762, acc: 93.29, test_acc: 79.00, f1: 74.36
loss: 0.0620, acc: 93.53, test_acc: 76.18, f1: 69.76
loss: 0.8547, acc: 92.46, test_acc: 76.18, f1: 69.42
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0410, acc: 100.00, test_acc: 78.53, f1: 73.94
loss: 0.1184, acc: 100.00, test_acc: 78.84, f1: 74.62
loss: 0.0852, acc: 100.00, test_acc: 77.43, f1: 71.97
loss: 0.0364, acc: 100.00, test_acc: 76.96, f1: 70.92
loss: 0.1113, acc: 98.75, test_acc: 78.53, f1: 73.74
loss: 0.1041, acc: 97.92, test_acc: 79.62, f1: 75.69
loss: 0.0353, acc: 98.21, test_acc: 79.31, f1: 75.02
loss: 0.0328, acc: 98.44, test_acc: 79.62, f1: 75.52
loss: 0.1878, acc: 97.92, test_acc: 79.31, f1: 75.03
loss: 0.0401, acc: 98.12, test_acc: 79.31, f1: 74.56
loss: 0.0098, acc: 98.30, test_acc: 79.31, f1: 74.35
loss: 0.0232, acc: 98.44, test_acc: 79.47, f1: 74.68
loss: 0.4095, acc: 97.60, test_acc: 78.53, f1: 73.39
loss: 0.0523, acc: 97.77, test_acc: 79.31, f1: 74.90
loss: 0.0099, acc: 97.92, test_acc: 79.15, f1: 74.87
loss: 0.1345, acc: 98.05, test_acc: 79.47, f1: 74.55
loss: 0.2911, acc: 97.06, test_acc: 79.00, f1: 74.79
loss: 0.2034, acc: 96.53, test_acc: 80.09, f1: 76.73
loss: 0.4409, acc: 95.39, test_acc: 79.62, f1: 74.89
loss: 0.0565, acc: 95.62, test_acc: 76.49, f1: 69.32
loss: 0.0039, acc: 95.83, test_acc: 79.15, f1: 73.53
loss: 0.0366, acc: 96.02, test_acc: 81.19, f1: 77.18
loss: 0.1445, acc: 95.92, test_acc: 80.56, f1: 78.06
loss: 0.0464, acc: 96.09, test_acc: 80.72, f1: 76.29
loss: 0.3587, acc: 96.00, test_acc: 78.21, f1: 72.26
loss: 0.0839, acc: 96.15, test_acc: 80.72, f1: 77.46
loss: 0.2208, acc: 96.06, test_acc: 80.72, f1: 77.15
loss: 0.1727, acc: 95.98, test_acc: 78.68, f1: 73.65
loss: 0.2002, acc: 95.91, test_acc: 78.53, f1: 73.74
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0159, acc: 100.00, test_acc: 80.09, f1: 75.50
loss: 0.0128, acc: 100.00, test_acc: 81.35, f1: 77.43
loss: 0.1703, acc: 95.83, test_acc: 81.50, f1: 77.67
loss: 0.0174, acc: 96.88, test_acc: 81.35, f1: 77.66
loss: 0.0491, acc: 97.50, test_acc: 80.25, f1: 75.67
loss: 0.0582, acc: 97.92, test_acc: 79.62, f1: 74.77
loss: 0.1872, acc: 97.32, test_acc: 80.88, f1: 77.07
loss: 0.1082, acc: 96.88, test_acc: 81.66, f1: 78.13
loss: 0.1716, acc: 96.53, test_acc: 82.29, f1: 78.94
loss: 0.2455, acc: 96.25, test_acc: 81.19, f1: 77.74
loss: 0.0288, acc: 96.59, test_acc: 80.88, f1: 76.95
loss: 0.0356, acc: 96.88, test_acc: 79.78, f1: 75.86
loss: 0.0911, acc: 96.63, test_acc: 80.25, f1: 76.05
loss: 0.0251, acc: 96.88, test_acc: 80.56, f1: 76.06
loss: 0.0166, acc: 97.08, test_acc: 80.25, f1: 75.56
loss: 0.0513, acc: 97.27, test_acc: 79.94, f1: 74.98
loss: 0.0026, acc: 97.43, test_acc: 79.78, f1: 74.72
loss: 0.1972, acc: 97.22, test_acc: 79.47, f1: 74.35
loss: 0.1328, acc: 97.04, test_acc: 79.78, f1: 75.39
loss: 0.2894, acc: 96.88, test_acc: 79.47, f1: 75.14
loss: 0.0090, acc: 97.02, test_acc: 81.35, f1: 77.25
loss: 0.0069, acc: 97.16, test_acc: 81.97, f1: 78.62
>> saved: state_dict/lcf_bert_laptop_acc82.45
max_acc:82.45  f1:78.97
loss: 0.2693, acc: 96.47, test_acc: 82.45, f1: 78.97
loss: 0.2162, acc: 96.35, test_acc: 80.09, f1: 75.39
loss: 0.0094, acc: 96.50, test_acc: 79.00, f1: 73.61
loss: 0.0373, acc: 96.63, test_acc: 79.62, f1: 74.72
loss: 0.0145, acc: 96.76, test_acc: 80.25, f1: 76.03
loss: 0.0118, acc: 96.88, test_acc: 81.19, f1: 77.43
loss: 0.1831, acc: 96.77, test_acc: 79.94, f1: 75.27
loss: 0.0008, acc: 96.82, test_acc: 78.68, f1: 73.18
####################################################################################################
max_test_acc_overall:82.44514106583071
max_f1_overall:79.05885689736166
####################################################################################################
1 test_acc_overall: 82.29  f1_overall:78.94
2 test_acc_overall: 82.29  f1_overall:78.79
3 test_acc_overall: 82.92  f1_overall:79.31
4 test_acc_overall: 82.6  f1_overall:79.42
5 test_acc_overall: 82.45  f1_overall:79.06
max_acc_overall:82.92  f1_overall:79.31
mean_acc_overall:82.51  mean_f1_overall:79.11
####################################################################################################
lcf_bert - restaurant - cdm - No.1 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3a3fdbf268>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 0
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc65.0
max_acc:65.0  f1:27.23
loss: 0.8838, acc: 93.75, test_acc: 65.00, f1: 27.23
loss: 0.7767, acc: 81.25, test_acc: 65.00, f1: 26.26
>> saved: state_dict/lcf_bert_restaurant_acc65.09
max_acc:65.09  f1:26.94
loss: 1.0337, acc: 70.83, test_acc: 65.09, f1: 26.94
loss: 0.8653, acc: 68.75, test_acc: 65.00, f1: 26.26
loss: 0.7875, acc: 70.00, test_acc: 65.00, f1: 26.26
loss: 0.8447, acc: 68.75, test_acc: 65.00, f1: 26.26
>> saved: state_dict/lcf_bert_restaurant_acc69.02
max_acc:69.02  f1:38.84
loss: 0.7818, acc: 66.96, test_acc: 69.02, f1: 38.84
>> saved: state_dict/lcf_bert_restaurant_acc77.41
max_acc:77.41  f1:59.26
loss: 0.6086, acc: 70.31, test_acc: 77.41, f1: 59.26
>> saved: state_dict/lcf_bert_restaurant_acc80.09
max_acc:80.09  f1:62.98
loss: 0.8158, acc: 68.75, test_acc: 80.09, f1: 62.98
loss: 0.8187, acc: 68.12, test_acc: 78.39, f1: 57.63
>> saved: state_dict/lcf_bert_restaurant_acc82.23
max_acc:82.23  f1:71.03
loss: 0.4990, acc: 69.32, test_acc: 82.23, f1: 71.03
loss: 0.7551, acc: 68.23, test_acc: 80.09, f1: 61.52
loss: 0.6384, acc: 69.23, test_acc: 79.29, f1: 59.94
loss: 0.5366, acc: 69.20, test_acc: 82.23, f1: 72.19
>> saved: state_dict/lcf_bert_restaurant_acc82.77
max_acc:82.77  f1:70.43
loss: 0.4492, acc: 70.00, test_acc: 82.77, f1: 70.43
loss: 0.9313, acc: 69.14, test_acc: 80.71, f1: 63.70
loss: 0.7069, acc: 69.49, test_acc: 81.07, f1: 63.85
loss: 0.5286, acc: 70.14, test_acc: 81.96, f1: 66.84
loss: 0.7128, acc: 70.07, test_acc: 80.54, f1: 67.84
loss: 0.5462, acc: 70.62, test_acc: 79.64, f1: 64.56
loss: 0.3570, acc: 71.43, test_acc: 82.05, f1: 68.12
loss: 0.2531, acc: 72.44, test_acc: 81.16, f1: 64.15
loss: 0.4133, acc: 72.55, test_acc: 81.25, f1: 63.90
loss: 0.3269, acc: 73.18, test_acc: 82.50, f1: 70.46
loss: 0.6747, acc: 73.00, test_acc: 82.23, f1: 69.48
>> saved: state_dict/lcf_bert_restaurant_acc83.04
max_acc:83.04  f1:69.92
loss: 0.5320, acc: 73.32, test_acc: 83.04, f1: 69.92
loss: 0.5524, acc: 73.38, test_acc: 80.36, f1: 64.03
loss: 0.5665, acc: 73.66, test_acc: 82.23, f1: 66.69
loss: 0.6097, acc: 73.92, test_acc: 82.14, f1: 71.15
loss: 0.3539, acc: 74.38, test_acc: 82.05, f1: 71.47
>> saved: state_dict/lcf_bert_restaurant_acc84.29
max_acc:84.29  f1:75.18
loss: 0.3440, acc: 74.80, test_acc: 84.29, f1: 75.18
loss: 0.6570, acc: 74.80, test_acc: 82.68, f1: 67.65
loss: 0.3610, acc: 75.19, test_acc: 81.96, f1: 64.58
loss: 0.3688, acc: 75.37, test_acc: 83.57, f1: 70.23
>> saved: state_dict/lcf_bert_restaurant_acc86.07
max_acc:86.07  f1:77.41
loss: 0.4900, acc: 75.36, test_acc: 86.07, f1: 77.41
loss: 0.3857, acc: 75.69, test_acc: 84.38, f1: 73.77
loss: 0.6168, acc: 75.51, test_acc: 82.59, f1: 67.58
loss: 0.3040, acc: 75.49, test_acc: 83.84, f1: 72.16
loss: 0.3769, acc: 75.48, test_acc: 85.71, f1: 77.49
loss: 0.3284, acc: 75.94, test_acc: 85.80, f1: 78.22
loss: 0.6687, acc: 76.22, test_acc: 84.73, f1: 74.70
loss: 0.2771, acc: 76.34, test_acc: 83.30, f1: 70.57
loss: 0.3395, acc: 76.60, test_acc: 84.02, f1: 71.61
loss: 0.2339, acc: 76.85, test_acc: 84.46, f1: 72.65
loss: 0.4413, acc: 77.08, test_acc: 86.07, f1: 77.30
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.5944, acc: 81.25, test_acc: 85.00, f1: 76.60
loss: 0.1983, acc: 90.62, test_acc: 84.38, f1: 74.16
loss: 0.4802, acc: 85.42, test_acc: 85.27, f1: 74.31
loss: 0.5997, acc: 82.81, test_acc: 84.82, f1: 74.87
loss: 0.5259, acc: 83.75, test_acc: 85.45, f1: 77.36
loss: 0.2117, acc: 85.42, test_acc: 84.55, f1: 75.86
loss: 0.4512, acc: 83.93, test_acc: 83.66, f1: 73.39
loss: 0.1635, acc: 85.16, test_acc: 82.95, f1: 71.30
loss: 0.1667, acc: 86.81, test_acc: 83.84, f1: 73.55
loss: 0.1575, acc: 87.50, test_acc: 84.20, f1: 74.15
loss: 0.2766, acc: 86.93, test_acc: 85.00, f1: 76.32
loss: 0.2538, acc: 88.02, test_acc: 84.29, f1: 73.39
loss: 0.3114, acc: 87.98, test_acc: 85.00, f1: 75.12
loss: 0.1978, acc: 87.95, test_acc: 85.54, f1: 78.08
loss: 0.3654, acc: 87.50, test_acc: 85.54, f1: 77.14
loss: 0.0891, acc: 88.28, test_acc: 84.11, f1: 70.55
loss: 0.1507, acc: 88.60, test_acc: 83.21, f1: 66.74
loss: 0.0877, acc: 88.89, test_acc: 85.36, f1: 74.81
>> saved: state_dict/lcf_bert_restaurant_acc86.25
max_acc:86.25  f1:80.03
loss: 0.4684, acc: 88.49, test_acc: 86.25, f1: 80.03
loss: 0.3055, acc: 88.44, test_acc: 83.39, f1: 73.53
loss: 0.1546, acc: 88.69, test_acc: 83.12, f1: 71.88
loss: 0.2679, acc: 88.92, test_acc: 84.38, f1: 72.28
loss: 0.4329, acc: 88.86, test_acc: 85.89, f1: 77.00
loss: 0.3824, acc: 88.54, test_acc: 85.62, f1: 78.86
>> saved: state_dict/lcf_bert_restaurant_acc86.96
max_acc:86.96  f1:80.02
loss: 0.4827, acc: 88.50, test_acc: 86.96, f1: 80.02
loss: 0.3376, acc: 88.46, test_acc: 83.48, f1: 72.26
loss: 0.2120, acc: 88.66, test_acc: 84.46, f1: 74.19
loss: 0.6825, acc: 88.39, test_acc: 86.96, f1: 79.80
>> saved: state_dict/lcf_bert_restaurant_acc87.41
max_acc:87.41  f1:81.77
loss: 0.2424, acc: 88.36, test_acc: 87.41, f1: 81.77
loss: 0.3333, acc: 88.12, test_acc: 86.70, f1: 78.87
loss: 0.5732, acc: 87.90, test_acc: 84.20, f1: 74.11
loss: 0.2019, acc: 88.09, test_acc: 83.39, f1: 73.60
loss: 0.2204, acc: 88.26, test_acc: 85.89, f1: 78.51
loss: 0.5751, acc: 88.05, test_acc: 85.71, f1: 77.21
loss: 0.2845, acc: 88.04, test_acc: 85.89, f1: 77.86
loss: 0.5833, acc: 87.85, test_acc: 85.89, f1: 79.24
loss: 0.3446, acc: 87.67, test_acc: 84.38, f1: 76.34
loss: 0.5281, acc: 87.34, test_acc: 86.07, f1: 77.68
loss: 0.2326, acc: 87.50, test_acc: 86.34, f1: 78.77
loss: 0.2724, acc: 87.34, test_acc: 86.16, f1: 78.74
loss: 0.1992, acc: 87.50, test_acc: 85.80, f1: 78.10
loss: 0.2497, acc: 87.65, test_acc: 86.07, f1: 78.62
loss: 0.5370, acc: 87.65, test_acc: 86.07, f1: 78.06
loss: 0.2321, acc: 87.78, test_acc: 86.34, f1: 77.94
loss: 0.2147, acc: 87.92, test_acc: 86.34, f1: 77.64
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2473, acc: 93.75, test_acc: 85.18, f1: 75.67
loss: 0.0249, acc: 96.88, test_acc: 86.43, f1: 77.67
loss: 0.1175, acc: 97.92, test_acc: 86.16, f1: 78.01
loss: 0.2813, acc: 96.88, test_acc: 86.25, f1: 79.09
loss: 0.1916, acc: 95.00, test_acc: 85.98, f1: 78.55
loss: 0.1259, acc: 94.79, test_acc: 86.07, f1: 78.11
loss: 0.0325, acc: 95.54, test_acc: 86.61, f1: 78.96
loss: 0.1275, acc: 95.31, test_acc: 86.96, f1: 79.26
loss: 0.2294, acc: 94.44, test_acc: 86.79, f1: 78.88
loss: 0.1755, acc: 94.38, test_acc: 87.14, f1: 80.01
loss: 0.0493, acc: 94.89, test_acc: 87.23, f1: 79.97
loss: 0.1536, acc: 94.79, test_acc: 87.41, f1: 80.23
loss: 0.1966, acc: 94.71, test_acc: 86.88, f1: 79.38
loss: 0.5976, acc: 93.30, test_acc: 86.96, f1: 79.49
>> saved: state_dict/lcf_bert_restaurant_acc87.68
max_acc:87.68  f1:81.37
loss: 0.2948, acc: 93.33, test_acc: 87.68, f1: 81.37
loss: 0.2328, acc: 93.36, test_acc: 87.23, f1: 80.44
loss: 0.0570, acc: 93.75, test_acc: 87.14, f1: 79.35
loss: 0.1222, acc: 93.40, test_acc: 86.16, f1: 76.49
loss: 0.1731, acc: 93.42, test_acc: 86.70, f1: 78.80
loss: 0.0811, acc: 93.75, test_acc: 85.80, f1: 78.59
loss: 0.1006, acc: 93.75, test_acc: 85.54, f1: 77.67
loss: 0.5466, acc: 92.61, test_acc: 83.66, f1: 71.91
loss: 0.0530, acc: 92.93, test_acc: 85.27, f1: 76.39
loss: 0.0880, acc: 92.97, test_acc: 85.18, f1: 77.48
loss: 0.5900, acc: 92.75, test_acc: 85.71, f1: 77.56
loss: 0.0571, acc: 93.03, test_acc: 84.02, f1: 73.97
loss: 0.2768, acc: 92.82, test_acc: 86.70, f1: 78.97
loss: 0.0671, acc: 93.08, test_acc: 86.79, f1: 79.20
>> saved: state_dict/lcf_bert_restaurant_acc87.95
max_acc:87.95  f1:81.39
loss: 0.0777, acc: 93.10, test_acc: 87.95, f1: 81.39
>> saved: state_dict/lcf_bert_restaurant_acc88.84
max_acc:88.84  f1:83.3
loss: 0.1695, acc: 93.12, test_acc: 88.84, f1: 83.30
loss: 0.4873, acc: 92.54, test_acc: 87.50, f1: 81.17
loss: 0.3043, acc: 92.38, test_acc: 87.23, f1: 80.27
loss: 0.1766, acc: 92.23, test_acc: 87.05, f1: 79.64
loss: 0.4104, acc: 92.10, test_acc: 86.70, f1: 79.56
loss: 0.1319, acc: 92.14, test_acc: 86.07, f1: 79.15
loss: 0.2376, acc: 92.01, test_acc: 86.43, f1: 79.03
loss: 0.1807, acc: 91.89, test_acc: 86.43, f1: 78.12
loss: 0.2802, acc: 91.94, test_acc: 86.34, f1: 78.47
loss: 0.5474, acc: 91.83, test_acc: 87.14, f1: 80.56
loss: 0.0860, acc: 92.03, test_acc: 87.41, f1: 81.86
loss: 0.0706, acc: 92.23, test_acc: 87.32, f1: 80.74
loss: 0.1965, acc: 92.11, test_acc: 86.34, f1: 78.13
loss: 0.2212, acc: 92.15, test_acc: 84.82, f1: 75.15
loss: 0.1236, acc: 92.19, test_acc: 84.38, f1: 74.95
loss: 0.1182, acc: 92.36, test_acc: 85.45, f1: 77.40
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0501, acc: 100.00, test_acc: 85.80, f1: 77.67
loss: 0.1881, acc: 96.88, test_acc: 86.25, f1: 77.87
loss: 0.0812, acc: 97.92, test_acc: 86.34, f1: 78.30
loss: 0.0568, acc: 98.44, test_acc: 86.52, f1: 78.73
loss: 0.1238, acc: 97.50, test_acc: 86.43, f1: 78.68
loss: 0.0110, acc: 97.92, test_acc: 86.70, f1: 79.16
loss: 0.0345, acc: 98.21, test_acc: 87.23, f1: 80.24
loss: 0.0974, acc: 98.44, test_acc: 87.32, f1: 80.93
loss: 0.3591, acc: 97.22, test_acc: 87.32, f1: 81.44
loss: 0.1119, acc: 96.88, test_acc: 87.23, f1: 81.23
loss: 0.0927, acc: 96.59, test_acc: 87.41, f1: 81.89
loss: 0.0128, acc: 96.88, test_acc: 87.14, f1: 80.12
loss: 0.0232, acc: 97.12, test_acc: 87.23, f1: 80.06
loss: 0.0313, acc: 97.32, test_acc: 87.14, f1: 79.45
loss: 0.1033, acc: 97.08, test_acc: 86.79, f1: 78.38
loss: 0.0335, acc: 97.27, test_acc: 87.32, f1: 79.99
loss: 0.2540, acc: 97.06, test_acc: 88.04, f1: 82.16
loss: 0.0321, acc: 97.22, test_acc: 87.86, f1: 81.64
loss: 0.0084, acc: 97.37, test_acc: 86.96, f1: 79.85
loss: 0.0883, acc: 97.19, test_acc: 86.96, f1: 79.48
loss: 0.0465, acc: 97.32, test_acc: 87.05, f1: 79.60
loss: 0.3745, acc: 96.31, test_acc: 87.77, f1: 81.04
loss: 0.0359, acc: 96.47, test_acc: 88.04, f1: 82.76
loss: 0.0599, acc: 96.61, test_acc: 88.12, f1: 83.09
loss: 0.1113, acc: 96.50, test_acc: 88.57, f1: 83.24
loss: 0.0366, acc: 96.63, test_acc: 88.12, f1: 81.77
loss: 0.0433, acc: 96.76, test_acc: 88.21, f1: 81.70
loss: 0.0827, acc: 96.65, test_acc: 87.86, f1: 81.00
loss: 0.1580, acc: 96.55, test_acc: 88.21, f1: 82.52
loss: 0.0031, acc: 96.67, test_acc: 88.39, f1: 83.04
loss: 0.1883, acc: 96.57, test_acc: 88.39, f1: 82.82
loss: 0.0538, acc: 96.68, test_acc: 88.39, f1: 82.32
loss: 0.0098, acc: 96.78, test_acc: 87.59, f1: 81.03
loss: 0.0127, acc: 96.88, test_acc: 87.14, f1: 80.38
loss: 0.0196, acc: 96.96, test_acc: 86.52, f1: 79.09
loss: 0.3145, acc: 96.88, test_acc: 86.43, f1: 79.13
loss: 0.4430, acc: 96.62, test_acc: 86.52, f1: 79.49
loss: 0.1044, acc: 96.55, test_acc: 86.43, f1: 77.79
loss: 0.0895, acc: 96.63, test_acc: 86.43, f1: 77.49
loss: 0.0311, acc: 96.72, test_acc: 87.14, f1: 79.95
loss: 0.2805, acc: 96.49, test_acc: 86.70, f1: 79.44
loss: 0.0135, acc: 96.58, test_acc: 86.07, f1: 78.30
loss: 0.0080, acc: 96.66, test_acc: 85.71, f1: 76.82
loss: 0.0748, acc: 96.73, test_acc: 85.18, f1: 75.73
loss: 0.0596, acc: 96.81, test_acc: 85.45, f1: 77.48
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0953, acc: 100.00, test_acc: 85.45, f1: 78.19
loss: 0.0176, acc: 100.00, test_acc: 86.88, f1: 79.68
loss: 0.0069, acc: 100.00, test_acc: 86.34, f1: 78.32
loss: 0.0614, acc: 100.00, test_acc: 86.25, f1: 77.67
loss: 0.0009, acc: 100.00, test_acc: 86.16, f1: 77.15
loss: 0.0038, acc: 100.00, test_acc: 86.16, f1: 77.03
loss: 0.0629, acc: 99.11, test_acc: 87.41, f1: 80.33
loss: 0.0049, acc: 99.22, test_acc: 87.95, f1: 81.83
loss: 0.0100, acc: 99.31, test_acc: 88.21, f1: 82.41
loss: 0.0077, acc: 99.38, test_acc: 87.95, f1: 81.48
loss: 0.0330, acc: 99.43, test_acc: 88.04, f1: 81.24
loss: 0.0043, acc: 99.48, test_acc: 88.84, f1: 82.79
>> saved: state_dict/lcf_bert_restaurant_acc89.02
max_acc:89.02  f1:83.1
loss: 0.0236, acc: 99.52, test_acc: 89.02, f1: 83.10
>> saved: state_dict/lcf_bert_restaurant_acc89.11
max_acc:89.11  f1:83.61
loss: 0.0069, acc: 99.55, test_acc: 89.11, f1: 83.61
loss: 0.0492, acc: 99.58, test_acc: 87.50, f1: 79.52
loss: 0.1280, acc: 99.22, test_acc: 86.25, f1: 76.15
loss: 0.0523, acc: 98.90, test_acc: 86.88, f1: 78.49
loss: 0.0156, acc: 98.96, test_acc: 88.66, f1: 83.35
loss: 0.0090, acc: 99.01, test_acc: 88.48, f1: 83.33
loss: 0.2155, acc: 98.75, test_acc: 88.84, f1: 83.95
loss: 0.0136, acc: 98.81, test_acc: 88.48, f1: 83.36
loss: 0.0363, acc: 98.86, test_acc: 88.48, f1: 83.33
loss: 0.0054, acc: 98.91, test_acc: 87.50, f1: 81.54
loss: 0.0027, acc: 98.96, test_acc: 87.86, f1: 81.32
loss: 0.0018, acc: 99.00, test_acc: 87.05, f1: 79.81
loss: 0.0262, acc: 99.04, test_acc: 86.70, f1: 79.41
loss: 0.0787, acc: 98.84, test_acc: 86.34, f1: 78.54
loss: 0.0071, acc: 98.88, test_acc: 86.61, f1: 78.22
loss: 0.0089, acc: 98.92, test_acc: 87.14, f1: 79.26
loss: 0.0200, acc: 98.96, test_acc: 86.88, f1: 79.68
loss: 0.0204, acc: 98.99, test_acc: 86.43, f1: 79.35
loss: 0.0136, acc: 99.02, test_acc: 86.88, f1: 79.65
loss: 0.1241, acc: 98.86, test_acc: 88.30, f1: 81.82
loss: 0.0551, acc: 98.90, test_acc: 87.59, f1: 80.89
loss: 0.0132, acc: 98.93, test_acc: 87.05, f1: 80.17
loss: 0.0112, acc: 98.96, test_acc: 86.88, f1: 79.79
loss: 0.2609, acc: 98.82, test_acc: 87.32, f1: 80.26
loss: 0.2231, acc: 98.68, test_acc: 86.70, f1: 78.66
loss: 0.0051, acc: 98.72, test_acc: 87.05, f1: 79.12
loss: 0.0049, acc: 98.75, test_acc: 87.50, f1: 80.08
loss: 0.0557, acc: 98.78, test_acc: 87.77, f1: 81.02
loss: 0.0409, acc: 98.81, test_acc: 88.12, f1: 81.93
loss: 0.0471, acc: 98.84, test_acc: 88.30, f1: 82.10
loss: 0.1115, acc: 98.72, test_acc: 88.66, f1: 82.56
loss: 0.0028, acc: 98.75, test_acc: 88.57, f1: 82.31
loss: 0.0086, acc: 98.76, test_acc: 88.75, f1: 82.62
####################################################################################################
max_test_acc_overall:89.10714285714286
max_f1_overall:83.94543298850428
####################################################################################################
1 test_acc_overall: 89.11  f1_overall:83.95
max_acc_overall:89.11  f1_overall:83.95
mean_acc_overall:89.11  mean_f1_overall:83.95
####################################################################################################
lcf_bert - restaurant - cdm - No.2 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3a3fdbf268>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 1
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc64.82
max_acc:64.82  f1:31.27
loss: 1.1847, acc: 43.75, test_acc: 64.82, f1: 31.27
>> saved: state_dict/lcf_bert_restaurant_acc65.0
max_acc:65.0  f1:26.26
loss: 0.8003, acc: 59.38, test_acc: 65.00, f1: 26.26
loss: 0.8209, acc: 62.50, test_acc: 65.00, f1: 26.26
>> saved: state_dict/lcf_bert_restaurant_acc68.75
max_acc:68.75  f1:38.59
loss: 0.9553, acc: 60.94, test_acc: 68.75, f1: 38.59
loss: 0.6837, acc: 65.00, test_acc: 68.30, f1: 37.58
loss: 0.8227, acc: 63.54, test_acc: 68.21, f1: 37.01
>> saved: state_dict/lcf_bert_restaurant_acc79.46
max_acc:79.46  f1:64.34
loss: 0.6983, acc: 66.07, test_acc: 79.46, f1: 64.34
>> saved: state_dict/lcf_bert_restaurant_acc80.0
max_acc:80.0  f1:62.48
loss: 0.7918, acc: 65.62, test_acc: 80.00, f1: 62.48
loss: 0.9845, acc: 65.28, test_acc: 78.84, f1: 56.47
loss: 0.5836, acc: 66.25, test_acc: 78.75, f1: 56.79
>> saved: state_dict/lcf_bert_restaurant_acc81.07
max_acc:81.07  f1:64.39
loss: 0.5992, acc: 68.18, test_acc: 81.07, f1: 64.39
loss: 0.5155, acc: 69.27, test_acc: 78.84, f1: 55.98
loss: 0.7706, acc: 68.75, test_acc: 79.29, f1: 61.37
loss: 0.4254, acc: 69.64, test_acc: 79.55, f1: 66.60
>> saved: state_dict/lcf_bert_restaurant_acc82.95
max_acc:82.95  f1:74.1
loss: 0.7875, acc: 68.75, test_acc: 82.95, f1: 74.10
loss: 0.3527, acc: 69.53, test_acc: 79.64, f1: 59.23
loss: 1.0003, acc: 68.75, test_acc: 79.82, f1: 59.60
>> saved: state_dict/lcf_bert_restaurant_acc84.55
max_acc:84.55  f1:76.58
loss: 0.3520, acc: 69.79, test_acc: 84.55, f1: 76.58
loss: 0.6914, acc: 69.41, test_acc: 83.30, f1: 73.47
loss: 0.3785, acc: 70.31, test_acc: 82.86, f1: 69.03
loss: 0.4128, acc: 70.83, test_acc: 82.68, f1: 67.84
loss: 0.7107, acc: 71.02, test_acc: 83.04, f1: 70.04
loss: 1.2722, acc: 70.38, test_acc: 82.41, f1: 66.70
loss: 0.7906, acc: 70.57, test_acc: 83.39, f1: 71.98
loss: 0.3552, acc: 71.00, test_acc: 83.39, f1: 71.38
loss: 0.6744, acc: 71.39, test_acc: 81.61, f1: 64.74
loss: 0.2979, acc: 71.99, test_acc: 81.70, f1: 65.16
loss: 0.8569, acc: 71.43, test_acc: 84.20, f1: 74.80
loss: 0.7770, acc: 71.34, test_acc: 83.48, f1: 78.09
loss: 0.4133, acc: 71.88, test_acc: 83.04, f1: 70.50
loss: 0.5272, acc: 71.98, test_acc: 80.62, f1: 62.94
loss: 0.5674, acc: 72.07, test_acc: 80.09, f1: 60.89
loss: 0.2173, acc: 72.73, test_acc: 83.04, f1: 69.43
>> saved: state_dict/lcf_bert_restaurant_acc85.54
max_acc:85.54  f1:77.21
loss: 0.5950, acc: 72.79, test_acc: 85.54, f1: 77.21
loss: 0.5468, acc: 72.86, test_acc: 84.20, f1: 74.73
loss: 0.7483, acc: 72.92, test_acc: 82.59, f1: 69.35
loss: 0.2589, acc: 73.48, test_acc: 81.70, f1: 64.46
loss: 0.5743, acc: 73.52, test_acc: 82.41, f1: 66.43
loss: 0.4524, acc: 73.72, test_acc: 83.48, f1: 70.64
loss: 0.5943, acc: 73.75, test_acc: 83.84, f1: 74.31
loss: 0.3777, acc: 73.93, test_acc: 83.66, f1: 74.65
loss: 0.4442, acc: 74.11, test_acc: 84.29, f1: 75.14
loss: 0.3875, acc: 74.13, test_acc: 84.55, f1: 73.56
loss: 0.4922, acc: 74.29, test_acc: 83.30, f1: 70.06
loss: 0.4006, acc: 74.17, test_acc: 83.93, f1: 72.01
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.5534, acc: 75.00, test_acc: 85.18, f1: 75.15
loss: 0.0853, acc: 87.50, test_acc: 84.11, f1: 75.03
loss: 0.5541, acc: 85.42, test_acc: 83.93, f1: 73.90
loss: 0.2392, acc: 85.94, test_acc: 85.54, f1: 76.12
loss: 0.1119, acc: 88.75, test_acc: 85.18, f1: 75.60
loss: 0.5678, acc: 87.50, test_acc: 85.54, f1: 76.80
loss: 0.3807, acc: 86.61, test_acc: 84.20, f1: 78.09
loss: 0.4320, acc: 86.72, test_acc: 83.93, f1: 72.97
loss: 0.2293, acc: 86.81, test_acc: 82.77, f1: 68.86
loss: 0.3278, acc: 86.88, test_acc: 83.93, f1: 71.84
loss: 0.3455, acc: 86.93, test_acc: 83.75, f1: 73.07
loss: 0.2784, acc: 87.50, test_acc: 83.75, f1: 73.58
loss: 0.3506, acc: 87.50, test_acc: 83.75, f1: 70.31
loss: 0.6800, acc: 86.61, test_acc: 83.30, f1: 67.77
loss: 0.1885, acc: 86.67, test_acc: 84.38, f1: 72.17
loss: 0.5688, acc: 86.33, test_acc: 85.45, f1: 76.16
loss: 0.2745, acc: 86.76, test_acc: 85.27, f1: 76.08
>> saved: state_dict/lcf_bert_restaurant_acc86.34
max_acc:86.34  f1:78.56
loss: 0.2705, acc: 86.46, test_acc: 86.34, f1: 78.56
loss: 0.4502, acc: 86.18, test_acc: 86.34, f1: 79.03
loss: 0.1580, acc: 86.56, test_acc: 85.89, f1: 77.33
loss: 0.6790, acc: 86.31, test_acc: 84.55, f1: 73.06
loss: 0.4515, acc: 86.08, test_acc: 85.45, f1: 77.27
loss: 0.4614, acc: 86.14, test_acc: 85.00, f1: 76.23
loss: 0.3316, acc: 86.46, test_acc: 85.62, f1: 76.18
loss: 0.4943, acc: 86.00, test_acc: 85.00, f1: 73.79
loss: 0.2095, acc: 86.30, test_acc: 84.29, f1: 73.40
loss: 0.3021, acc: 86.11, test_acc: 84.73, f1: 74.68
loss: 0.0645, acc: 86.61, test_acc: 84.02, f1: 72.71
loss: 0.2741, acc: 86.64, test_acc: 85.27, f1: 75.34
>> saved: state_dict/lcf_bert_restaurant_acc86.43
max_acc:86.43  f1:79.41
loss: 0.7298, acc: 86.25, test_acc: 86.43, f1: 79.41
loss: 0.4847, acc: 86.09, test_acc: 85.62, f1: 77.88
loss: 0.3391, acc: 85.94, test_acc: 84.91, f1: 75.39
loss: 0.1615, acc: 86.17, test_acc: 85.09, f1: 76.15
loss: 0.8334, acc: 85.48, test_acc: 85.89, f1: 78.13
loss: 0.2249, acc: 85.71, test_acc: 83.57, f1: 70.91
loss: 0.3368, acc: 85.59, test_acc: 83.84, f1: 74.02
loss: 0.2840, acc: 85.47, test_acc: 85.18, f1: 76.82
loss: 0.2493, acc: 85.53, test_acc: 85.89, f1: 77.71
loss: 0.1606, acc: 85.58, test_acc: 85.36, f1: 75.03
loss: 0.4194, acc: 85.47, test_acc: 86.34, f1: 79.43
loss: 0.6369, acc: 85.06, test_acc: 85.62, f1: 77.27
loss: 0.4012, acc: 84.97, test_acc: 82.50, f1: 69.16
loss: 0.0423, acc: 85.32, test_acc: 82.68, f1: 70.29
loss: 0.2144, acc: 85.51, test_acc: 85.71, f1: 77.89
loss: 0.3358, acc: 85.28, test_acc: 86.25, f1: 79.21
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2917, acc: 87.50, test_acc: 85.89, f1: 79.59
loss: 0.1533, acc: 90.62, test_acc: 86.25, f1: 77.83
loss: 0.1744, acc: 91.67, test_acc: 84.82, f1: 74.17
loss: 0.0644, acc: 92.19, test_acc: 84.29, f1: 73.45
loss: 0.2011, acc: 91.25, test_acc: 85.98, f1: 78.12
loss: 0.0608, acc: 91.67, test_acc: 86.34, f1: 78.79
loss: 0.1335, acc: 91.96, test_acc: 84.73, f1: 74.63
loss: 0.0779, acc: 92.97, test_acc: 85.54, f1: 76.11
>> saved: state_dict/lcf_bert_restaurant_acc86.88
max_acc:86.88  f1:80.1
loss: 0.1502, acc: 93.75, test_acc: 86.88, f1: 80.10
loss: 0.0445, acc: 94.38, test_acc: 86.52, f1: 80.18
loss: 0.2395, acc: 93.75, test_acc: 85.71, f1: 77.05
loss: 0.3474, acc: 93.75, test_acc: 83.84, f1: 72.03
loss: 0.1695, acc: 93.75, test_acc: 84.73, f1: 75.46
loss: 0.1249, acc: 93.75, test_acc: 85.62, f1: 76.71
loss: 0.1460, acc: 93.75, test_acc: 85.36, f1: 75.24
loss: 0.3064, acc: 93.36, test_acc: 85.27, f1: 75.86
loss: 0.1928, acc: 93.38, test_acc: 85.80, f1: 78.22
loss: 0.1650, acc: 93.40, test_acc: 86.16, f1: 79.33
loss: 0.4241, acc: 93.42, test_acc: 86.25, f1: 78.10
loss: 0.9703, acc: 92.19, test_acc: 84.46, f1: 71.48
loss: 0.1010, acc: 92.26, test_acc: 84.20, f1: 73.47
loss: 0.0729, acc: 92.61, test_acc: 84.82, f1: 76.01
loss: 0.3775, acc: 92.39, test_acc: 85.27, f1: 77.20
loss: 0.2575, acc: 92.19, test_acc: 85.54, f1: 77.68
loss: 0.0952, acc: 92.50, test_acc: 85.71, f1: 77.67
loss: 0.3211, acc: 92.07, test_acc: 84.64, f1: 75.26
loss: 0.0440, acc: 92.36, test_acc: 84.46, f1: 74.26
loss: 0.4916, acc: 92.19, test_acc: 85.00, f1: 74.87
loss: 0.0431, acc: 92.46, test_acc: 85.80, f1: 77.62
loss: 0.1197, acc: 92.71, test_acc: 86.52, f1: 79.38
loss: 0.0858, acc: 92.74, test_acc: 86.34, f1: 78.36
loss: 0.1622, acc: 92.58, test_acc: 86.43, f1: 78.34
loss: 0.1138, acc: 92.61, test_acc: 86.79, f1: 78.87
loss: 0.4085, acc: 92.46, test_acc: 86.61, f1: 78.42
loss: 0.0847, acc: 92.68, test_acc: 85.98, f1: 77.49
loss: 0.0888, acc: 92.88, test_acc: 86.43, f1: 78.68
loss: 0.1553, acc: 92.74, test_acc: 86.79, f1: 79.03
loss: 0.0118, acc: 92.93, test_acc: 86.07, f1: 77.42
loss: 0.2902, acc: 92.79, test_acc: 85.89, f1: 76.14
loss: 0.2569, acc: 92.81, test_acc: 86.79, f1: 78.96
loss: 0.3147, acc: 92.53, test_acc: 86.52, f1: 79.39
loss: 0.1512, acc: 92.56, test_acc: 86.25, f1: 78.60
loss: 0.1508, acc: 92.73, test_acc: 86.52, f1: 78.71
loss: 0.5618, acc: 92.61, test_acc: 86.25, f1: 77.55
>> saved: state_dict/lcf_bert_restaurant_acc87.05
max_acc:87.05  f1:79.01
loss: 0.0077, acc: 92.78, test_acc: 87.05, f1: 79.01
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0106, acc: 100.00, test_acc: 86.79, f1: 78.70
loss: 0.0527, acc: 100.00, test_acc: 86.34, f1: 77.80
loss: 0.0107, acc: 100.00, test_acc: 85.18, f1: 76.26
loss: 0.0202, acc: 100.00, test_acc: 85.36, f1: 77.13
loss: 0.0672, acc: 100.00, test_acc: 85.80, f1: 77.56
loss: 0.0491, acc: 100.00, test_acc: 86.52, f1: 78.95
loss: 0.0076, acc: 100.00, test_acc: 86.43, f1: 78.59
>> saved: state_dict/lcf_bert_restaurant_acc87.59
max_acc:87.59  f1:80.8
loss: 0.2449, acc: 99.22, test_acc: 87.59, f1: 80.80
>> saved: state_dict/lcf_bert_restaurant_acc88.3
max_acc:88.3  f1:81.81
loss: 0.0336, acc: 99.31, test_acc: 88.30, f1: 81.81
loss: 0.0710, acc: 99.38, test_acc: 87.32, f1: 80.08
loss: 0.2259, acc: 98.86, test_acc: 87.77, f1: 81.00
>> saved: state_dict/lcf_bert_restaurant_acc89.02
max_acc:89.02  f1:83.59
loss: 0.0166, acc: 98.96, test_acc: 89.02, f1: 83.59
loss: 0.0240, acc: 99.04, test_acc: 88.30, f1: 82.64
loss: 0.0363, acc: 99.11, test_acc: 87.50, f1: 81.09
loss: 0.1096, acc: 98.75, test_acc: 86.96, f1: 79.61
loss: 0.0047, acc: 98.83, test_acc: 85.62, f1: 76.36
loss: 0.1122, acc: 98.53, test_acc: 86.88, f1: 79.32
loss: 0.3966, acc: 97.92, test_acc: 86.61, f1: 79.22
loss: 0.0534, acc: 98.03, test_acc: 86.96, f1: 79.67
loss: 0.0668, acc: 97.81, test_acc: 86.07, f1: 77.69
loss: 0.0582, acc: 97.92, test_acc: 85.45, f1: 76.14
loss: 0.0056, acc: 98.01, test_acc: 85.27, f1: 75.38
loss: 0.2414, acc: 97.83, test_acc: 86.16, f1: 77.16
loss: 0.2785, acc: 97.66, test_acc: 86.70, f1: 79.51
loss: 0.1964, acc: 97.25, test_acc: 87.41, f1: 80.98
loss: 0.0176, acc: 97.36, test_acc: 87.86, f1: 81.15
loss: 0.0864, acc: 97.22, test_acc: 86.52, f1: 78.06
loss: 0.0175, acc: 97.32, test_acc: 86.07, f1: 77.55
loss: 0.0268, acc: 97.41, test_acc: 85.89, f1: 77.43
loss: 0.0029, acc: 97.50, test_acc: 86.07, f1: 78.27
loss: 0.0722, acc: 97.38, test_acc: 86.70, f1: 79.04
loss: 0.1319, acc: 97.07, test_acc: 86.16, f1: 77.98
loss: 0.0010, acc: 97.16, test_acc: 85.98, f1: 77.76
loss: 0.0445, acc: 97.24, test_acc: 86.79, f1: 78.95
loss: 0.0357, acc: 97.32, test_acc: 86.88, f1: 79.37
loss: 0.0102, acc: 97.40, test_acc: 87.05, f1: 80.05
loss: 0.0496, acc: 97.47, test_acc: 86.61, f1: 78.71
loss: 0.0820, acc: 97.37, test_acc: 86.43, f1: 78.13
loss: 0.1497, acc: 97.28, test_acc: 85.00, f1: 75.61
loss: 0.1947, acc: 97.03, test_acc: 85.54, f1: 76.85
loss: 0.0469, acc: 97.10, test_acc: 86.52, f1: 78.68
loss: 0.3457, acc: 96.88, test_acc: 86.88, f1: 78.28
loss: 0.1338, acc: 96.80, test_acc: 86.25, f1: 77.47
loss: 0.0708, acc: 96.73, test_acc: 85.36, f1: 76.35
loss: 0.1365, acc: 96.67, test_acc: 84.82, f1: 75.77
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0264, acc: 100.00, test_acc: 84.91, f1: 75.89
loss: 0.0322, acc: 100.00, test_acc: 85.80, f1: 77.75
loss: 0.0095, acc: 100.00, test_acc: 85.71, f1: 77.11
loss: 0.0897, acc: 98.44, test_acc: 86.25, f1: 77.58
loss: 0.0280, acc: 98.75, test_acc: 87.23, f1: 80.24
loss: 0.0623, acc: 98.96, test_acc: 87.50, f1: 81.73
loss: 0.0039, acc: 99.11, test_acc: 87.41, f1: 81.51
loss: 0.0076, acc: 99.22, test_acc: 87.86, f1: 81.41
loss: 0.1457, acc: 98.61, test_acc: 87.14, f1: 79.77
loss: 0.0326, acc: 98.75, test_acc: 87.23, f1: 80.53
loss: 0.0445, acc: 98.86, test_acc: 87.50, f1: 81.03
loss: 0.1937, acc: 98.44, test_acc: 87.41, f1: 80.12
loss: 0.0196, acc: 98.56, test_acc: 87.77, f1: 80.12
loss: 0.0529, acc: 98.66, test_acc: 86.61, f1: 77.30
loss: 0.0492, acc: 98.75, test_acc: 87.68, f1: 80.63
loss: 0.0040, acc: 98.83, test_acc: 87.41, f1: 80.35
loss: 0.0218, acc: 98.90, test_acc: 87.05, f1: 79.70
loss: 0.0065, acc: 98.96, test_acc: 86.96, f1: 79.55
loss: 0.0084, acc: 99.01, test_acc: 86.88, f1: 79.43
loss: 0.2613, acc: 98.44, test_acc: 87.14, f1: 79.87
loss: 0.0998, acc: 98.21, test_acc: 86.88, f1: 79.70
loss: 0.0879, acc: 98.30, test_acc: 85.89, f1: 78.15
loss: 0.0185, acc: 98.37, test_acc: 85.71, f1: 77.59
loss: 0.0252, acc: 98.44, test_acc: 86.43, f1: 77.92
loss: 0.1535, acc: 98.25, test_acc: 86.96, f1: 78.49
loss: 0.0018, acc: 98.32, test_acc: 86.88, f1: 78.87
loss: 0.0159, acc: 98.38, test_acc: 87.50, f1: 79.95
loss: 0.0703, acc: 98.21, test_acc: 87.32, f1: 78.93
loss: 0.0012, acc: 98.28, test_acc: 87.59, f1: 79.90
loss: 0.0041, acc: 98.33, test_acc: 87.59, f1: 80.21
loss: 0.0575, acc: 98.19, test_acc: 88.21, f1: 81.33
loss: 0.0565, acc: 98.05, test_acc: 88.48, f1: 81.64
loss: 0.0595, acc: 98.11, test_acc: 88.12, f1: 81.07
loss: 0.1388, acc: 97.98, test_acc: 88.30, f1: 81.81
loss: 0.0732, acc: 98.04, test_acc: 87.50, f1: 80.68
loss: 0.0477, acc: 98.09, test_acc: 87.95, f1: 81.00
loss: 0.0139, acc: 98.14, test_acc: 85.98, f1: 77.02
loss: 0.0668, acc: 98.19, test_acc: 85.54, f1: 75.84
loss: 0.0042, acc: 98.24, test_acc: 85.98, f1: 76.94
loss: 0.0345, acc: 98.28, test_acc: 86.96, f1: 79.41
loss: 0.0648, acc: 98.32, test_acc: 86.70, f1: 80.05
loss: 0.0332, acc: 98.36, test_acc: 86.88, f1: 79.74
loss: 0.0705, acc: 98.40, test_acc: 86.34, f1: 78.32
loss: 0.1326, acc: 98.30, test_acc: 87.05, f1: 79.35
loss: 0.4767, acc: 98.06, test_acc: 87.50, f1: 80.27
loss: 0.0016, acc: 98.08, test_acc: 86.79, f1: 79.16
####################################################################################################
max_test_acc_overall:89.01785714285714
max_f1_overall:83.58778079922281
####################################################################################################
1 test_acc_overall: 89.11  f1_overall:83.95
2 test_acc_overall: 89.02  f1_overall:83.59
max_acc_overall:89.11  f1_overall:83.95
mean_acc_overall:89.06  mean_f1_overall:83.77
####################################################################################################
lcf_bert - restaurant - cdm - No.3 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3a3fdbf268>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 2
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc64.73
max_acc:64.73  f1:26.2
loss: 0.9040, acc: 62.50, test_acc: 64.73, f1: 26.20
>> saved: state_dict/lcf_bert_restaurant_acc65.0
max_acc:65.0  f1:26.26
loss: 1.0377, acc: 59.38, test_acc: 65.00, f1: 26.26
>> saved: state_dict/lcf_bert_restaurant_acc65.09
max_acc:65.09  f1:26.62
loss: 0.9263, acc: 60.42, test_acc: 65.09, f1: 26.62
loss: 1.3466, acc: 53.12, test_acc: 65.00, f1: 26.26
>> saved: state_dict/lcf_bert_restaurant_acc67.95
max_acc:67.95  f1:36.56
loss: 0.9623, acc: 53.75, test_acc: 67.95, f1: 36.56
loss: 0.8475, acc: 55.21, test_acc: 67.86, f1: 35.96
>> saved: state_dict/lcf_bert_restaurant_acc75.89
max_acc:75.89  f1:52.37
loss: 0.6964, acc: 58.04, test_acc: 75.89, f1: 52.37
>> saved: state_dict/lcf_bert_restaurant_acc78.12
max_acc:78.12  f1:54.49
loss: 0.7492, acc: 60.16, test_acc: 78.12, f1: 54.49
loss: 0.2944, acc: 63.89, test_acc: 78.04, f1: 54.51
>> saved: state_dict/lcf_bert_restaurant_acc79.11
max_acc:79.11  f1:61.39
loss: 0.4209, acc: 65.62, test_acc: 79.11, f1: 61.39
loss: 0.7400, acc: 65.91, test_acc: 74.38, f1: 55.97
loss: 0.7441, acc: 67.19, test_acc: 74.02, f1: 54.21
loss: 0.5539, acc: 66.83, test_acc: 79.11, f1: 66.11
>> saved: state_dict/lcf_bert_restaurant_acc80.18
max_acc:80.18  f1:61.02
loss: 0.6030, acc: 67.41, test_acc: 80.18, f1: 61.02
loss: 0.5905, acc: 67.50, test_acc: 79.73, f1: 60.28
>> saved: state_dict/lcf_bert_restaurant_acc80.62
max_acc:80.62  f1:62.2
loss: 0.6547, acc: 67.58, test_acc: 80.62, f1: 62.20
>> saved: state_dict/lcf_bert_restaurant_acc83.04
max_acc:83.04  f1:72.52
loss: 0.6073, acc: 68.01, test_acc: 83.04, f1: 72.52
loss: 0.3979, acc: 69.10, test_acc: 82.23, f1: 70.19
loss: 0.4458, acc: 69.74, test_acc: 80.18, f1: 61.87
loss: 0.4380, acc: 70.31, test_acc: 81.34, f1: 68.46
loss: 0.3430, acc: 71.13, test_acc: 82.23, f1: 72.85
>> saved: state_dict/lcf_bert_restaurant_acc83.75
max_acc:83.75  f1:74.05
loss: 0.3931, acc: 71.88, test_acc: 83.75, f1: 74.05
loss: 0.5160, acc: 72.28, test_acc: 79.91, f1: 58.84
loss: 0.6064, acc: 72.66, test_acc: 79.46, f1: 55.96
loss: 0.5354, acc: 73.00, test_acc: 80.71, f1: 62.04
loss: 0.7127, acc: 73.08, test_acc: 83.48, f1: 74.51
loss: 0.4251, acc: 73.61, test_acc: 82.95, f1: 71.40
loss: 0.3869, acc: 73.88, test_acc: 82.59, f1: 67.42
loss: 0.6167, acc: 73.92, test_acc: 83.21, f1: 69.66
>> saved: state_dict/lcf_bert_restaurant_acc84.46
max_acc:84.46  f1:74.01
loss: 0.6882, acc: 73.75, test_acc: 84.46, f1: 74.01
>> saved: state_dict/lcf_bert_restaurant_acc85.45
max_acc:85.45  f1:77.96
loss: 0.8144, acc: 73.59, test_acc: 85.45, f1: 77.96
loss: 0.5077, acc: 73.83, test_acc: 84.29, f1: 73.38
loss: 0.5512, acc: 74.05, test_acc: 81.07, f1: 62.12
loss: 0.4527, acc: 74.26, test_acc: 82.86, f1: 68.10
loss: 0.6758, acc: 74.29, test_acc: 83.66, f1: 70.60
loss: 0.3126, acc: 74.65, test_acc: 84.64, f1: 74.98
loss: 0.6053, acc: 74.66, test_acc: 82.59, f1: 72.12
loss: 0.5529, acc: 74.51, test_acc: 84.64, f1: 77.84
loss: 0.3194, acc: 74.84, test_acc: 84.11, f1: 75.55
loss: 0.2751, acc: 75.16, test_acc: 82.68, f1: 67.18
loss: 0.3188, acc: 75.46, test_acc: 81.61, f1: 66.21
loss: 0.2432, acc: 75.74, test_acc: 81.52, f1: 70.32
loss: 0.3962, acc: 75.87, test_acc: 85.09, f1: 77.17
loss: 0.1980, acc: 76.28, test_acc: 84.38, f1: 73.44
loss: 0.5872, acc: 76.39, test_acc: 84.02, f1: 71.46
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.2829, acc: 87.50, test_acc: 84.11, f1: 73.29
loss: 0.1945, acc: 90.62, test_acc: 84.55, f1: 73.79
loss: 0.1087, acc: 91.67, test_acc: 85.09, f1: 74.07
loss: 0.4652, acc: 89.06, test_acc: 85.36, f1: 75.30
>> saved: state_dict/lcf_bert_restaurant_acc86.34
max_acc:86.34  f1:78.66
loss: 0.3729, acc: 87.50, test_acc: 86.34, f1: 78.66
loss: 0.3725, acc: 86.46, test_acc: 85.71, f1: 77.40
loss: 0.0802, acc: 88.39, test_acc: 84.91, f1: 74.62
loss: 0.1500, acc: 89.06, test_acc: 85.45, f1: 77.13
loss: 0.2489, acc: 89.58, test_acc: 85.71, f1: 79.08
loss: 0.4239, acc: 88.75, test_acc: 85.80, f1: 78.57
loss: 0.5739, acc: 88.64, test_acc: 85.36, f1: 74.82
loss: 0.1244, acc: 89.06, test_acc: 83.21, f1: 67.67
loss: 0.3079, acc: 89.42, test_acc: 83.66, f1: 70.60
>> saved: state_dict/lcf_bert_restaurant_acc86.52
max_acc:86.52  f1:78.95
loss: 0.4222, acc: 89.73, test_acc: 86.52, f1: 78.95
loss: 0.1057, acc: 90.42, test_acc: 86.25, f1: 77.83
loss: 0.2455, acc: 90.23, test_acc: 85.89, f1: 76.44
loss: 0.1891, acc: 90.44, test_acc: 86.07, f1: 77.76
loss: 0.3966, acc: 90.28, test_acc: 85.89, f1: 78.72
loss: 0.2008, acc: 90.13, test_acc: 85.36, f1: 77.43
loss: 0.0797, acc: 90.31, test_acc: 83.57, f1: 72.86
loss: 0.6191, acc: 89.88, test_acc: 84.02, f1: 72.18
loss: 0.6008, acc: 89.20, test_acc: 85.89, f1: 78.72
loss: 0.3584, acc: 89.13, test_acc: 86.52, f1: 79.05
loss: 0.1732, acc: 89.06, test_acc: 84.46, f1: 75.52
loss: 0.0923, acc: 89.50, test_acc: 84.29, f1: 74.53
loss: 0.5643, acc: 89.18, test_acc: 85.00, f1: 76.35
loss: 0.4194, acc: 89.12, test_acc: 85.36, f1: 77.26
loss: 0.3549, acc: 89.06, test_acc: 84.91, f1: 75.26
loss: 0.1149, acc: 89.22, test_acc: 85.71, f1: 77.82
>> saved: state_dict/lcf_bert_restaurant_acc86.96
max_acc:86.96  f1:80.21
loss: 0.4393, acc: 88.75, test_acc: 86.96, f1: 80.21
>> saved: state_dict/lcf_bert_restaurant_acc87.32
max_acc:87.32  f1:80.83
loss: 0.3852, acc: 88.71, test_acc: 87.32, f1: 80.83
loss: 0.4180, acc: 88.48, test_acc: 85.71, f1: 76.87
loss: 0.3265, acc: 88.64, test_acc: 85.27, f1: 74.68
loss: 0.5030, acc: 88.60, test_acc: 85.62, f1: 75.89
loss: 0.4736, acc: 88.21, test_acc: 87.14, f1: 79.10
loss: 0.4012, acc: 88.02, test_acc: 86.16, f1: 76.64
loss: 0.2164, acc: 88.18, test_acc: 86.43, f1: 78.60
loss: 0.2058, acc: 88.32, test_acc: 86.52, f1: 79.21
loss: 0.3698, acc: 88.30, test_acc: 86.34, f1: 78.14
loss: 0.2032, acc: 88.28, test_acc: 85.89, f1: 77.00
loss: 0.0973, acc: 88.57, test_acc: 85.80, f1: 76.82
loss: 0.3511, acc: 88.39, test_acc: 86.25, f1: 78.61
loss: 0.6937, acc: 88.08, test_acc: 85.62, f1: 77.07
loss: 0.3018, acc: 88.07, test_acc: 84.46, f1: 73.36
loss: 0.4959, acc: 87.92, test_acc: 84.82, f1: 74.33
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1249, acc: 100.00, test_acc: 84.20, f1: 74.59
loss: 0.2212, acc: 96.88, test_acc: 84.20, f1: 74.87
loss: 0.4124, acc: 91.67, test_acc: 85.45, f1: 76.69
loss: 0.0399, acc: 93.75, test_acc: 83.93, f1: 70.65
loss: 0.1635, acc: 93.75, test_acc: 84.29, f1: 72.59
loss: 0.0963, acc: 93.75, test_acc: 85.18, f1: 76.71
loss: 0.1712, acc: 93.75, test_acc: 85.00, f1: 76.70
loss: 0.0417, acc: 94.53, test_acc: 85.71, f1: 77.62
loss: 0.0559, acc: 95.14, test_acc: 85.54, f1: 76.72
loss: 0.3485, acc: 95.00, test_acc: 86.07, f1: 78.06
>> saved: state_dict/lcf_bert_restaurant_acc87.59
max_acc:87.59  f1:81.37
loss: 0.1875, acc: 94.89, test_acc: 87.59, f1: 81.37
loss: 0.6964, acc: 93.23, test_acc: 87.32, f1: 80.35
loss: 0.1645, acc: 93.27, test_acc: 86.79, f1: 80.14
loss: 0.0226, acc: 93.75, test_acc: 85.36, f1: 76.42
loss: 0.2520, acc: 93.33, test_acc: 84.73, f1: 73.97
loss: 0.4864, acc: 92.97, test_acc: 84.29, f1: 71.33
>> saved: state_dict/lcf_bert_restaurant_acc87.77
max_acc:87.77  f1:81.49
loss: 0.2677, acc: 92.65, test_acc: 87.77, f1: 81.49
loss: 0.0895, acc: 93.06, test_acc: 86.79, f1: 80.03
loss: 0.0380, acc: 93.42, test_acc: 86.07, f1: 77.66
loss: 0.1702, acc: 93.12, test_acc: 86.07, f1: 77.27
loss: 0.3054, acc: 93.15, test_acc: 86.70, f1: 78.74
loss: 0.0121, acc: 93.47, test_acc: 86.61, f1: 79.16
loss: 0.1124, acc: 93.75, test_acc: 86.70, f1: 79.22
loss: 0.2629, acc: 93.49, test_acc: 86.88, f1: 78.81
>> saved: state_dict/lcf_bert_restaurant_acc88.04
max_acc:88.04  f1:81.89
loss: 0.0854, acc: 93.50, test_acc: 88.04, f1: 81.89
loss: 0.0351, acc: 93.75, test_acc: 87.14, f1: 79.75
loss: 0.1840, acc: 93.52, test_acc: 86.25, f1: 76.89
loss: 0.0516, acc: 93.75, test_acc: 86.25, f1: 76.72
loss: 0.1484, acc: 93.75, test_acc: 85.09, f1: 76.09
loss: 0.2930, acc: 93.75, test_acc: 85.27, f1: 76.94
loss: 0.1462, acc: 93.55, test_acc: 85.98, f1: 78.26
loss: 0.2376, acc: 93.55, test_acc: 87.50, f1: 80.82
loss: 0.3900, acc: 93.56, test_acc: 87.59, f1: 79.86
loss: 0.1685, acc: 93.57, test_acc: 86.88, f1: 78.45
loss: 0.0763, acc: 93.75, test_acc: 87.23, f1: 79.58
loss: 0.2578, acc: 93.75, test_acc: 86.96, f1: 79.92
loss: 0.0243, acc: 93.92, test_acc: 86.70, f1: 79.31
loss: 0.2367, acc: 93.75, test_acc: 86.34, f1: 78.09
loss: 0.1790, acc: 93.75, test_acc: 84.46, f1: 71.90
loss: 0.2026, acc: 93.59, test_acc: 86.52, f1: 77.61
loss: 0.0897, acc: 93.60, test_acc: 87.41, f1: 82.06
loss: 0.5659, acc: 93.45, test_acc: 87.05, f1: 81.31
loss: 0.1827, acc: 93.31, test_acc: 86.07, f1: 77.81
loss: 0.4419, acc: 93.04, test_acc: 85.18, f1: 75.45
>> saved: state_dict/lcf_bert_restaurant_acc88.48
max_acc:88.48  f1:82.52
loss: 0.0717, acc: 93.19, test_acc: 88.48, f1: 82.52
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0542, acc: 100.00, test_acc: 88.04, f1: 82.22
loss: 0.0384, acc: 100.00, test_acc: 86.25, f1: 76.72
loss: 0.7492, acc: 95.83, test_acc: 85.71, f1: 74.65
loss: 0.1576, acc: 93.75, test_acc: 87.32, f1: 79.53
loss: 0.0379, acc: 95.00, test_acc: 87.05, f1: 80.15
loss: 0.0896, acc: 94.79, test_acc: 86.07, f1: 78.15
loss: 0.1412, acc: 94.64, test_acc: 86.79, f1: 79.03
loss: 0.0423, acc: 95.31, test_acc: 87.59, f1: 80.23
loss: 0.0578, acc: 95.14, test_acc: 88.30, f1: 81.68
loss: 0.1050, acc: 95.00, test_acc: 88.39, f1: 81.85
loss: 0.0191, acc: 95.45, test_acc: 87.23, f1: 79.11
loss: 0.0075, acc: 95.83, test_acc: 87.23, f1: 78.62
loss: 0.0187, acc: 96.15, test_acc: 86.43, f1: 77.27
loss: 0.0228, acc: 96.43, test_acc: 86.43, f1: 77.45
loss: 0.0344, acc: 96.67, test_acc: 85.45, f1: 75.76
loss: 0.0105, acc: 96.88, test_acc: 85.62, f1: 76.23
loss: 0.1940, acc: 96.32, test_acc: 87.41, f1: 80.25
loss: 0.1593, acc: 96.18, test_acc: 88.21, f1: 82.93
loss: 0.0628, acc: 96.38, test_acc: 87.77, f1: 82.34
loss: 0.1559, acc: 96.25, test_acc: 88.12, f1: 81.65
loss: 0.0282, acc: 96.43, test_acc: 86.96, f1: 78.91
loss: 0.0847, acc: 96.31, test_acc: 86.52, f1: 78.57
loss: 0.0498, acc: 96.47, test_acc: 88.30, f1: 82.14
>> saved: state_dict/lcf_bert_restaurant_acc88.75
max_acc:88.75  f1:82.52
loss: 0.0695, acc: 96.35, test_acc: 88.75, f1: 82.52
loss: 0.0052, acc: 96.50, test_acc: 86.61, f1: 77.72
loss: 0.2955, acc: 95.91, test_acc: 86.88, f1: 78.28
loss: 0.1347, acc: 95.60, test_acc: 87.77, f1: 81.28
loss: 0.0671, acc: 95.76, test_acc: 87.05, f1: 81.34
loss: 0.0244, acc: 95.91, test_acc: 87.77, f1: 81.62
loss: 0.2529, acc: 95.83, test_acc: 86.88, f1: 79.76
loss: 0.1483, acc: 95.77, test_acc: 86.61, f1: 78.27
loss: 0.0307, acc: 95.90, test_acc: 86.61, f1: 78.23
loss: 0.0317, acc: 96.02, test_acc: 87.41, f1: 79.82
loss: 0.2796, acc: 95.96, test_acc: 87.14, f1: 79.80
loss: 0.1727, acc: 95.71, test_acc: 87.59, f1: 81.18
loss: 0.1119, acc: 95.66, test_acc: 86.52, f1: 78.74
loss: 0.2164, acc: 95.44, test_acc: 86.07, f1: 77.89
loss: 0.4077, acc: 95.07, test_acc: 85.80, f1: 77.62
loss: 0.0549, acc: 95.19, test_acc: 86.07, f1: 77.82
loss: 0.0700, acc: 95.31, test_acc: 86.61, f1: 79.26
loss: 0.0171, acc: 95.43, test_acc: 86.88, f1: 79.24
loss: 0.0393, acc: 95.54, test_acc: 87.05, f1: 79.05
loss: 0.0033, acc: 95.64, test_acc: 86.96, f1: 78.24
loss: 0.1107, acc: 95.60, test_acc: 86.96, f1: 78.36
loss: 0.2110, acc: 95.42, test_acc: 87.50, f1: 80.44
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0261, acc: 100.00, test_acc: 87.50, f1: 80.57
loss: 0.3747, acc: 96.88, test_acc: 87.95, f1: 81.31
loss: 0.0128, acc: 97.92, test_acc: 87.77, f1: 81.01
loss: 0.0147, acc: 98.44, test_acc: 87.50, f1: 79.99
loss: 0.0065, acc: 98.75, test_acc: 86.52, f1: 78.06
loss: 0.0356, acc: 98.96, test_acc: 86.96, f1: 78.51
loss: 0.0157, acc: 99.11, test_acc: 87.23, f1: 79.20
loss: 0.0320, acc: 99.22, test_acc: 87.32, f1: 79.32
loss: 0.0142, acc: 99.31, test_acc: 87.23, f1: 79.87
loss: 0.0779, acc: 98.75, test_acc: 86.96, f1: 78.81
loss: 0.0269, acc: 98.86, test_acc: 87.77, f1: 80.41
loss: 0.0341, acc: 98.96, test_acc: 87.86, f1: 81.24
loss: 0.0138, acc: 99.04, test_acc: 87.41, f1: 80.24
loss: 0.0210, acc: 99.11, test_acc: 87.50, f1: 80.37
loss: 0.0239, acc: 99.17, test_acc: 86.79, f1: 79.06
loss: 0.0153, acc: 99.22, test_acc: 86.43, f1: 78.63
loss: 0.0503, acc: 99.26, test_acc: 86.70, f1: 78.92
loss: 0.0216, acc: 99.31, test_acc: 86.96, f1: 79.19
loss: 0.0034, acc: 99.34, test_acc: 87.14, f1: 79.67
loss: 0.2767, acc: 99.06, test_acc: 87.05, f1: 79.40
loss: 0.0113, acc: 99.11, test_acc: 85.80, f1: 76.35
loss: 0.1025, acc: 98.86, test_acc: 86.25, f1: 77.44
loss: 0.0051, acc: 98.91, test_acc: 86.88, f1: 79.22
loss: 0.0021, acc: 98.96, test_acc: 87.41, f1: 80.14
loss: 0.0090, acc: 99.00, test_acc: 88.12, f1: 81.62
loss: 0.0074, acc: 99.04, test_acc: 87.59, f1: 81.24
loss: 0.3625, acc: 98.84, test_acc: 87.05, f1: 80.83
loss: 0.0092, acc: 98.88, test_acc: 88.04, f1: 81.31
loss: 0.0077, acc: 98.92, test_acc: 88.12, f1: 80.91
loss: 0.0224, acc: 98.96, test_acc: 87.14, f1: 78.69
loss: 0.0157, acc: 98.99, test_acc: 86.88, f1: 78.13
loss: 0.0044, acc: 99.02, test_acc: 87.23, f1: 78.94
loss: 0.0149, acc: 99.05, test_acc: 87.77, f1: 80.66
loss: 0.0110, acc: 99.08, test_acc: 87.59, f1: 80.35
loss: 0.0099, acc: 99.11, test_acc: 87.95, f1: 80.89
loss: 0.0563, acc: 99.13, test_acc: 88.39, f1: 81.81
loss: 0.0843, acc: 99.16, test_acc: 88.75, f1: 83.02
>> saved: state_dict/lcf_bert_restaurant_acc88.93
max_acc:88.93  f1:82.82
loss: 0.1962, acc: 99.01, test_acc: 88.93, f1: 82.82
loss: 0.0996, acc: 98.88, test_acc: 86.88, f1: 77.28
loss: 0.1397, acc: 98.75, test_acc: 86.16, f1: 76.11
loss: 0.0930, acc: 98.63, test_acc: 87.59, f1: 80.32
loss: 0.2681, acc: 98.36, test_acc: 87.77, f1: 81.12
loss: 0.3392, acc: 98.26, test_acc: 87.50, f1: 80.89
loss: 0.1403, acc: 98.15, test_acc: 87.86, f1: 81.05
loss: 0.0178, acc: 98.19, test_acc: 87.23, f1: 78.72
loss: 0.3084, acc: 98.08, test_acc: 86.70, f1: 77.85
####################################################################################################
max_test_acc_overall:88.92857142857142
max_f1_overall:83.02221502203379
####################################################################################################
1 test_acc_overall: 89.11  f1_overall:83.95
2 test_acc_overall: 89.02  f1_overall:83.59
3 test_acc_overall: 88.93  f1_overall:83.02
max_acc_overall:89.11  f1_overall:83.95
mean_acc_overall:89.02  mean_f1_overall:83.52
####################################################################################################
lcf_bert - restaurant - cdm - No.4 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3a3fdbf268>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 3
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc65.0
max_acc:65.0  f1:26.26
loss: 0.9682, acc: 62.50, test_acc: 65.00, f1: 26.26
loss: 0.6195, acc: 68.75, test_acc: 65.00, f1: 26.26
loss: 1.1975, acc: 60.42, test_acc: 65.00, f1: 26.26
>> saved: state_dict/lcf_bert_restaurant_acc65.45
max_acc:65.45  f1:28.01
loss: 0.8784, acc: 60.94, test_acc: 65.45, f1: 28.01
loss: 0.7531, acc: 62.50, test_acc: 65.45, f1: 28.01
>> saved: state_dict/lcf_bert_restaurant_acc76.79
max_acc:76.79  f1:52.76
loss: 0.6213, acc: 67.71, test_acc: 76.79, f1: 52.76
>> saved: state_dict/lcf_bert_restaurant_acc76.88
max_acc:76.88  f1:52.78
loss: 0.6078, acc: 68.75, test_acc: 76.88, f1: 52.78
>> saved: state_dict/lcf_bert_restaurant_acc78.48
max_acc:78.48  f1:59.05
loss: 0.6583, acc: 68.75, test_acc: 78.48, f1: 59.05
>> saved: state_dict/lcf_bert_restaurant_acc80.36
max_acc:80.36  f1:65.21
loss: 0.5646, acc: 69.44, test_acc: 80.36, f1: 65.21
loss: 0.7413, acc: 66.88, test_acc: 80.18, f1: 68.02
loss: 0.4421, acc: 68.18, test_acc: 79.64, f1: 62.76
loss: 0.3128, acc: 69.79, test_acc: 80.27, f1: 68.03
loss: 0.6101, acc: 69.71, test_acc: 79.38, f1: 65.51
loss: 0.5567, acc: 70.09, test_acc: 77.23, f1: 57.78
>> saved: state_dict/lcf_bert_restaurant_acc80.62
max_acc:80.62  f1:61.58
loss: 0.5589, acc: 70.42, test_acc: 80.62, f1: 61.58
loss: 0.7621, acc: 70.70, test_acc: 80.00, f1: 59.69
>> saved: state_dict/lcf_bert_restaurant_acc82.5
max_acc:82.5  f1:69.51
loss: 0.6104, acc: 70.59, test_acc: 82.50, f1: 69.51
loss: 0.5653, acc: 71.18, test_acc: 82.32, f1: 70.33
>> saved: state_dict/lcf_bert_restaurant_acc83.21
max_acc:83.21  f1:72.73
loss: 0.4458, acc: 71.71, test_acc: 83.21, f1: 72.73
loss: 0.6106, acc: 71.56, test_acc: 83.12, f1: 71.58
loss: 0.4429, acc: 72.02, test_acc: 83.04, f1: 69.82
loss: 0.5939, acc: 71.88, test_acc: 82.50, f1: 69.38
loss: 0.8359, acc: 71.20, test_acc: 82.95, f1: 72.90
>> saved: state_dict/lcf_bert_restaurant_acc83.57
max_acc:83.57  f1:72.61
loss: 0.5320, acc: 71.88, test_acc: 83.57, f1: 72.61
>> saved: state_dict/lcf_bert_restaurant_acc84.02
max_acc:84.02  f1:72.18
loss: 0.4947, acc: 72.50, test_acc: 84.02, f1: 72.18
>> saved: state_dict/lcf_bert_restaurant_acc84.64
max_acc:84.64  f1:76.18
loss: 0.4335, acc: 72.60, test_acc: 84.64, f1: 76.18
loss: 0.7067, acc: 72.92, test_acc: 83.30, f1: 72.12
>> saved: state_dict/lcf_bert_restaurant_acc84.73
max_acc:84.73  f1:74.78
loss: 0.5978, acc: 72.99, test_acc: 84.73, f1: 74.78
>> saved: state_dict/lcf_bert_restaurant_acc85.62
max_acc:85.62  f1:76.42
loss: 0.7146, acc: 72.84, test_acc: 85.62, f1: 76.42
loss: 0.6569, acc: 73.33, test_acc: 84.82, f1: 73.74
loss: 0.7649, acc: 72.98, test_acc: 83.21, f1: 69.88
loss: 0.6978, acc: 73.05, test_acc: 80.09, f1: 64.75
loss: 0.3066, acc: 73.67, test_acc: 83.57, f1: 71.30
loss: 0.1416, acc: 74.45, test_acc: 84.82, f1: 74.37
loss: 0.3221, acc: 74.82, test_acc: 84.55, f1: 75.68
loss: 0.3079, acc: 75.00, test_acc: 85.18, f1: 76.41
>> saved: state_dict/lcf_bert_restaurant_acc85.98
max_acc:85.98  f1:79.59
loss: 0.5646, acc: 75.00, test_acc: 85.98, f1: 79.59
loss: 0.6323, acc: 75.49, test_acc: 84.91, f1: 74.93
loss: 0.4060, acc: 75.80, test_acc: 83.84, f1: 71.10
loss: 0.2765, acc: 76.09, test_acc: 83.57, f1: 72.34
loss: 0.5366, acc: 76.07, test_acc: 84.73, f1: 74.99
loss: 0.4776, acc: 76.34, test_acc: 84.55, f1: 74.49
loss: 0.6833, acc: 76.31, test_acc: 84.73, f1: 75.62
loss: 0.7765, acc: 76.14, test_acc: 85.27, f1: 75.59
>> saved: state_dict/lcf_bert_restaurant_acc86.25
max_acc:86.25  f1:77.44
loss: 0.3218, acc: 76.39, test_acc: 86.25, f1: 77.44
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.1227, acc: 100.00, test_acc: 84.46, f1: 72.31
loss: 0.5779, acc: 90.62, test_acc: 83.30, f1: 71.13
loss: 0.4025, acc: 89.58, test_acc: 84.82, f1: 74.69
loss: 0.1581, acc: 92.19, test_acc: 85.00, f1: 74.69
loss: 0.5169, acc: 90.00, test_acc: 85.18, f1: 76.26
>> saved: state_dict/lcf_bert_restaurant_acc86.43
max_acc:86.43  f1:80.38
loss: 0.5495, acc: 88.54, test_acc: 86.43, f1: 80.38
loss: 0.3740, acc: 87.50, test_acc: 84.02, f1: 70.93
loss: 0.1863, acc: 88.28, test_acc: 82.59, f1: 65.56
loss: 0.3575, acc: 88.19, test_acc: 86.07, f1: 77.75
>> saved: state_dict/lcf_bert_restaurant_acc86.88
max_acc:86.88  f1:80.12
loss: 0.1857, acc: 88.12, test_acc: 86.88, f1: 80.12
loss: 0.1488, acc: 88.64, test_acc: 85.89, f1: 76.60
loss: 0.5045, acc: 88.02, test_acc: 85.36, f1: 74.94
loss: 0.4694, acc: 87.50, test_acc: 86.52, f1: 78.89
loss: 0.1378, acc: 87.95, test_acc: 82.77, f1: 74.16
loss: 0.1915, acc: 88.33, test_acc: 84.20, f1: 75.59
loss: 0.8055, acc: 87.50, test_acc: 84.73, f1: 73.71
loss: 0.4802, acc: 87.13, test_acc: 84.38, f1: 72.74
loss: 0.2455, acc: 87.15, test_acc: 85.09, f1: 76.16
loss: 0.2900, acc: 86.84, test_acc: 83.84, f1: 73.72
loss: 0.6389, acc: 86.25, test_acc: 84.29, f1: 74.83
loss: 0.2518, acc: 86.61, test_acc: 85.54, f1: 77.70
loss: 0.2571, acc: 86.65, test_acc: 85.09, f1: 75.80
loss: 0.6228, acc: 86.68, test_acc: 84.73, f1: 74.84
loss: 0.2995, acc: 86.46, test_acc: 85.27, f1: 77.13
loss: 0.5819, acc: 86.25, test_acc: 85.45, f1: 77.36
loss: 0.3348, acc: 86.30, test_acc: 84.73, f1: 76.18
loss: 0.2183, acc: 86.57, test_acc: 85.45, f1: 78.13
loss: 0.2121, acc: 86.83, test_acc: 85.36, f1: 76.46
loss: 0.5807, acc: 86.42, test_acc: 85.54, f1: 76.81
loss: 0.2649, acc: 86.46, test_acc: 85.71, f1: 77.14
loss: 0.2704, acc: 86.49, test_acc: 85.54, f1: 76.51
loss: 0.3516, acc: 86.33, test_acc: 85.98, f1: 78.07
loss: 0.4744, acc: 85.98, test_acc: 85.80, f1: 78.27
loss: 0.3737, acc: 86.03, test_acc: 85.98, f1: 78.61
loss: 0.1027, acc: 86.25, test_acc: 85.45, f1: 75.14
loss: 0.4805, acc: 86.11, test_acc: 84.46, f1: 71.72
loss: 0.1713, acc: 86.49, test_acc: 85.71, f1: 75.34
loss: 0.4318, acc: 86.18, test_acc: 86.07, f1: 78.09
loss: 0.2401, acc: 86.38, test_acc: 86.52, f1: 80.19
loss: 0.2812, acc: 86.41, test_acc: 86.88, f1: 79.64
loss: 0.2393, acc: 86.43, test_acc: 86.25, f1: 78.13
>> saved: state_dict/lcf_bert_restaurant_acc87.32
max_acc:87.32  f1:80.06
loss: 0.5221, acc: 86.31, test_acc: 87.32, f1: 80.06
loss: 0.0884, acc: 86.63, test_acc: 87.23, f1: 80.03
loss: 0.4061, acc: 86.65, test_acc: 87.32, f1: 80.29
loss: 0.2103, acc: 86.53, test_acc: 86.61, f1: 77.93
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2786, acc: 87.50, test_acc: 84.46, f1: 71.71
loss: 0.1070, acc: 90.62, test_acc: 85.36, f1: 74.95
>> saved: state_dict/lcf_bert_restaurant_acc87.86
max_acc:87.86  f1:80.93
loss: 0.0628, acc: 93.75, test_acc: 87.86, f1: 80.93
>> saved: state_dict/lcf_bert_restaurant_acc88.48
max_acc:88.48  f1:82.93
loss: 0.1119, acc: 93.75, test_acc: 88.48, f1: 82.93
loss: 0.0508, acc: 95.00, test_acc: 86.43, f1: 78.10
loss: 0.0916, acc: 95.83, test_acc: 85.27, f1: 74.61
loss: 0.3046, acc: 93.75, test_acc: 86.43, f1: 77.84
loss: 0.2085, acc: 93.75, test_acc: 87.23, f1: 80.21
loss: 0.2631, acc: 93.06, test_acc: 86.43, f1: 78.52
loss: 0.1453, acc: 93.12, test_acc: 86.70, f1: 78.45
loss: 0.3136, acc: 92.61, test_acc: 87.05, f1: 79.71
loss: 0.1268, acc: 92.71, test_acc: 87.41, f1: 80.12
loss: 0.4903, acc: 92.31, test_acc: 87.77, f1: 80.75
loss: 0.0961, acc: 92.86, test_acc: 87.68, f1: 80.99
loss: 0.0517, acc: 93.33, test_acc: 87.41, f1: 80.08
loss: 0.1449, acc: 93.36, test_acc: 87.23, f1: 79.16
loss: 0.2662, acc: 93.01, test_acc: 87.14, f1: 79.98
loss: 0.1259, acc: 93.06, test_acc: 87.95, f1: 81.10
loss: 0.3113, acc: 93.09, test_acc: 87.41, f1: 79.57
loss: 0.0572, acc: 93.12, test_acc: 88.48, f1: 82.26
loss: 0.2753, acc: 92.56, test_acc: 87.86, f1: 81.51
loss: 0.2422, acc: 92.61, test_acc: 87.50, f1: 80.05
loss: 0.2700, acc: 92.66, test_acc: 87.14, f1: 79.04
loss: 0.1100, acc: 92.71, test_acc: 87.50, f1: 80.16
loss: 0.3751, acc: 92.50, test_acc: 87.86, f1: 81.39
loss: 0.2064, acc: 92.31, test_acc: 88.48, f1: 83.43
loss: 0.1585, acc: 92.13, test_acc: 87.41, f1: 80.44
loss: 0.0566, acc: 92.41, test_acc: 84.73, f1: 75.56
loss: 0.5295, acc: 92.24, test_acc: 84.11, f1: 74.70
loss: 0.2657, acc: 92.08, test_acc: 85.89, f1: 77.25
loss: 0.2770, acc: 91.94, test_acc: 87.41, f1: 80.54
loss: 0.0615, acc: 91.99, test_acc: 87.77, f1: 81.02
loss: 0.0222, acc: 92.23, test_acc: 87.59, f1: 81.26
loss: 0.2092, acc: 92.10, test_acc: 86.79, f1: 79.67
loss: 0.0337, acc: 92.32, test_acc: 87.23, f1: 79.92
loss: 0.2901, acc: 92.36, test_acc: 87.68, f1: 80.63
loss: 0.1387, acc: 92.40, test_acc: 87.68, f1: 81.65
loss: 0.0750, acc: 92.43, test_acc: 87.41, f1: 81.78
loss: 0.2563, acc: 92.31, test_acc: 87.86, f1: 81.48
loss: 0.6167, acc: 91.88, test_acc: 86.88, f1: 78.91
loss: 0.2176, acc: 91.77, test_acc: 86.88, f1: 79.43
loss: 0.0803, acc: 91.82, test_acc: 86.07, f1: 78.70
loss: 0.2458, acc: 91.86, test_acc: 86.16, f1: 77.93
loss: 0.0105, acc: 92.05, test_acc: 86.07, f1: 77.98
loss: 0.1798, acc: 92.08, test_acc: 85.71, f1: 77.12
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0599, acc: 100.00, test_acc: 85.98, f1: 78.17
loss: 0.1179, acc: 96.88, test_acc: 86.52, f1: 79.68
loss: 0.0448, acc: 97.92, test_acc: 86.34, f1: 78.47
loss: 0.0159, acc: 98.44, test_acc: 86.25, f1: 77.46
loss: 0.0401, acc: 98.75, test_acc: 86.34, f1: 78.45
loss: 0.1024, acc: 97.92, test_acc: 87.14, f1: 80.72
loss: 0.1169, acc: 97.32, test_acc: 87.14, f1: 80.63
loss: 0.0335, acc: 97.66, test_acc: 87.32, f1: 80.26
loss: 0.0559, acc: 97.92, test_acc: 87.32, f1: 80.13
loss: 0.1284, acc: 96.88, test_acc: 86.79, f1: 79.17
loss: 0.0413, acc: 97.16, test_acc: 86.88, f1: 79.22
loss: 0.4182, acc: 95.83, test_acc: 88.04, f1: 81.46
loss: 0.0245, acc: 96.15, test_acc: 87.50, f1: 82.14
loss: 0.1780, acc: 95.98, test_acc: 87.77, f1: 82.54
loss: 0.0035, acc: 96.25, test_acc: 87.14, f1: 79.32
loss: 0.1818, acc: 95.70, test_acc: 86.96, f1: 78.52
loss: 0.2163, acc: 95.59, test_acc: 87.50, f1: 80.25
loss: 0.0217, acc: 95.83, test_acc: 87.50, f1: 80.64
loss: 0.0184, acc: 96.05, test_acc: 87.05, f1: 80.09
loss: 0.0757, acc: 96.25, test_acc: 87.50, f1: 81.16
loss: 0.0807, acc: 96.43, test_acc: 87.95, f1: 81.83
loss: 0.0323, acc: 96.59, test_acc: 87.23, f1: 80.88
loss: 0.0191, acc: 96.74, test_acc: 86.61, f1: 79.01
loss: 0.2278, acc: 96.61, test_acc: 86.07, f1: 77.52
loss: 0.0428, acc: 96.75, test_acc: 85.54, f1: 76.61
loss: 0.1477, acc: 96.63, test_acc: 86.61, f1: 78.61
loss: 0.0476, acc: 96.76, test_acc: 87.23, f1: 80.83
loss: 0.0354, acc: 96.88, test_acc: 87.68, f1: 80.93
loss: 0.0249, acc: 96.98, test_acc: 87.86, f1: 81.38
loss: 0.0314, acc: 97.08, test_acc: 86.88, f1: 80.63
loss: 0.0225, acc: 97.18, test_acc: 88.04, f1: 81.83
loss: 0.0247, acc: 97.27, test_acc: 86.79, f1: 78.29
loss: 0.1861, acc: 97.16, test_acc: 87.77, f1: 80.94
loss: 0.3251, acc: 97.06, test_acc: 88.39, f1: 82.20
loss: 0.1061, acc: 96.96, test_acc: 88.04, f1: 81.70
loss: 0.2274, acc: 96.70, test_acc: 87.77, f1: 81.64
loss: 0.1752, acc: 96.62, test_acc: 87.95, f1: 81.51
loss: 0.0274, acc: 96.71, test_acc: 87.14, f1: 80.21
loss: 0.1233, acc: 96.47, test_acc: 87.05, f1: 79.98
loss: 0.0106, acc: 96.56, test_acc: 86.34, f1: 77.82
loss: 0.5299, acc: 96.34, test_acc: 86.96, f1: 79.29
loss: 0.0717, acc: 96.28, test_acc: 86.61, f1: 79.64
loss: 0.1705, acc: 96.22, test_acc: 87.05, f1: 80.34
loss: 0.4480, acc: 96.02, test_acc: 87.14, f1: 80.33
loss: 0.0183, acc: 96.11, test_acc: 87.23, f1: 79.82
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0369, acc: 100.00, test_acc: 86.61, f1: 78.66
loss: 0.0056, acc: 100.00, test_acc: 87.23, f1: 79.44
loss: 0.0101, acc: 100.00, test_acc: 87.59, f1: 79.95
loss: 0.0040, acc: 100.00, test_acc: 87.68, f1: 80.59
loss: 0.0043, acc: 100.00, test_acc: 87.50, f1: 80.70
loss: 0.0288, acc: 100.00, test_acc: 87.41, f1: 80.68
loss: 0.0564, acc: 100.00, test_acc: 87.14, f1: 80.14
loss: 0.0175, acc: 100.00, test_acc: 87.32, f1: 80.24
loss: 0.0195, acc: 100.00, test_acc: 86.79, f1: 78.65
loss: 0.2371, acc: 98.75, test_acc: 86.70, f1: 78.24
loss: 0.0324, acc: 98.86, test_acc: 86.25, f1: 77.53
loss: 0.0133, acc: 98.96, test_acc: 86.25, f1: 77.31
loss: 0.0243, acc: 99.04, test_acc: 86.25, f1: 77.36
loss: 0.0018, acc: 99.11, test_acc: 87.14, f1: 80.17
loss: 0.0048, acc: 99.17, test_acc: 86.96, f1: 80.85
loss: 0.0226, acc: 99.22, test_acc: 86.70, f1: 80.46
loss: 0.0597, acc: 98.90, test_acc: 87.14, f1: 80.43
loss: 0.0268, acc: 98.96, test_acc: 86.61, f1: 78.86
loss: 0.0046, acc: 99.01, test_acc: 86.79, f1: 78.83
loss: 0.0380, acc: 99.06, test_acc: 86.52, f1: 78.42
loss: 0.0431, acc: 99.11, test_acc: 86.96, f1: 79.95
loss: 0.0576, acc: 98.86, test_acc: 86.34, f1: 79.20
loss: 0.0422, acc: 98.91, test_acc: 86.25, f1: 78.90
loss: 0.0027, acc: 98.96, test_acc: 85.62, f1: 77.42
loss: 0.0008, acc: 99.00, test_acc: 85.62, f1: 76.89
loss: 0.0752, acc: 98.80, test_acc: 85.62, f1: 77.04
loss: 0.0560, acc: 98.84, test_acc: 86.96, f1: 79.79
loss: 0.2069, acc: 98.66, test_acc: 87.50, f1: 81.08
loss: 0.0091, acc: 98.71, test_acc: 88.04, f1: 81.66
loss: 0.0242, acc: 98.75, test_acc: 88.12, f1: 81.11
loss: 0.1539, acc: 98.59, test_acc: 88.30, f1: 81.76
loss: 0.1976, acc: 98.44, test_acc: 87.41, f1: 80.96
loss: 0.0424, acc: 98.48, test_acc: 86.43, f1: 78.26
loss: 0.0590, acc: 98.35, test_acc: 85.18, f1: 75.81
loss: 0.0222, acc: 98.39, test_acc: 84.38, f1: 74.23
loss: 0.0578, acc: 98.44, test_acc: 84.64, f1: 74.95
loss: 0.3874, acc: 98.14, test_acc: 85.98, f1: 77.85
loss: 0.0084, acc: 98.19, test_acc: 87.14, f1: 81.00
loss: 0.0498, acc: 98.24, test_acc: 88.04, f1: 82.57
loss: 0.0119, acc: 98.28, test_acc: 87.41, f1: 79.18
loss: 0.0386, acc: 98.32, test_acc: 87.59, f1: 79.14
loss: 0.1561, acc: 98.21, test_acc: 87.68, f1: 80.54
loss: 0.0015, acc: 98.26, test_acc: 87.86, f1: 81.00
loss: 0.0178, acc: 98.30, test_acc: 88.12, f1: 81.70
loss: 0.0076, acc: 98.33, test_acc: 88.30, f1: 82.19
loss: 0.0465, acc: 98.35, test_acc: 88.12, f1: 82.02
####################################################################################################
max_test_acc_overall:88.48214285714285
max_f1_overall:83.43486742836167
####################################################################################################
1 test_acc_overall: 89.11  f1_overall:83.95
2 test_acc_overall: 89.02  f1_overall:83.59
3 test_acc_overall: 88.93  f1_overall:83.02
4 test_acc_overall: 88.48  f1_overall:83.43
max_acc_overall:89.11  f1_overall:83.95
mean_acc_overall:88.88  mean_f1_overall:83.5
####################################################################################################
lcf_bert - restaurant - cdm - No.5 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3a3fdbf268>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 4
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc46.07
max_acc:46.07  f1:28.77
loss: 0.9718, acc: 62.50, test_acc: 46.07, f1: 28.77
>> saved: state_dict/lcf_bert_restaurant_acc65.0
max_acc:65.0  f1:26.26
loss: 1.0845, acc: 56.25, test_acc: 65.00, f1: 26.26
loss: 1.0504, acc: 58.33, test_acc: 36.52, f1: 26.74
>> saved: state_dict/lcf_bert_restaurant_acc65.36
max_acc:65.36  f1:27.96
loss: 1.0555, acc: 53.12, test_acc: 65.36, f1: 27.96
loss: 0.6471, acc: 56.25, test_acc: 65.36, f1: 27.96
>> saved: state_dict/lcf_bert_restaurant_acc74.91
max_acc:74.91  f1:51.37
loss: 0.7977, acc: 58.33, test_acc: 74.91, f1: 51.37
loss: 0.6579, acc: 61.61, test_acc: 74.82, f1: 50.01
>> saved: state_dict/lcf_bert_restaurant_acc78.12
max_acc:78.12  f1:64.96
loss: 0.8188, acc: 63.28, test_acc: 78.12, f1: 64.96
>> saved: state_dict/lcf_bert_restaurant_acc78.84
max_acc:78.84  f1:61.7
loss: 0.8002, acc: 63.89, test_acc: 78.84, f1: 61.70
loss: 0.6839, acc: 64.38, test_acc: 77.68, f1: 53.96
loss: 0.9227, acc: 63.64, test_acc: 78.48, f1: 55.01
>> saved: state_dict/lcf_bert_restaurant_acc79.73
max_acc:79.73  f1:60.7
loss: 0.4892, acc: 65.10, test_acc: 79.73, f1: 60.70
>> saved: state_dict/lcf_bert_restaurant_acc80.62
max_acc:80.62  f1:64.82
loss: 0.6508, acc: 65.87, test_acc: 80.62, f1: 64.82
>> saved: state_dict/lcf_bert_restaurant_acc81.7
max_acc:81.7  f1:67.2
loss: 0.5063, acc: 66.07, test_acc: 81.70, f1: 67.20
>> saved: state_dict/lcf_bert_restaurant_acc81.88
max_acc:81.88  f1:68.13
loss: 0.7237, acc: 65.83, test_acc: 81.88, f1: 68.13
>> saved: state_dict/lcf_bert_restaurant_acc83.66
max_acc:83.66  f1:71.06
loss: 0.2213, acc: 67.58, test_acc: 83.66, f1: 71.06
loss: 0.5527, acc: 67.65, test_acc: 83.04, f1: 69.63
loss: 0.3910, acc: 68.75, test_acc: 82.05, f1: 66.73
loss: 0.7337, acc: 68.75, test_acc: 80.80, f1: 62.87
loss: 0.7120, acc: 69.06, test_acc: 82.59, f1: 70.58
loss: 0.7194, acc: 68.15, test_acc: 83.57, f1: 73.69
loss: 0.5054, acc: 68.18, test_acc: 81.34, f1: 64.91
loss: 0.3862, acc: 69.02, test_acc: 79.82, f1: 58.08
>> saved: state_dict/lcf_bert_restaurant_acc84.29
max_acc:84.29  f1:74.44
loss: 0.4161, acc: 69.79, test_acc: 84.29, f1: 74.44
loss: 0.5412, acc: 70.00, test_acc: 83.39, f1: 75.43
loss: 0.9902, acc: 69.47, test_acc: 82.41, f1: 70.09
loss: 0.7128, acc: 69.44, test_acc: 83.21, f1: 69.54
>> saved: state_dict/lcf_bert_restaurant_acc84.46
max_acc:84.46  f1:74.07
loss: 0.6629, acc: 69.87, test_acc: 84.46, f1: 74.07
>> saved: state_dict/lcf_bert_restaurant_acc85.36
max_acc:85.36  f1:77.28
loss: 0.2944, acc: 70.69, test_acc: 85.36, f1: 77.28
loss: 0.5727, acc: 70.83, test_acc: 83.39, f1: 70.72
loss: 0.2154, acc: 71.57, test_acc: 81.16, f1: 63.39
loss: 0.7889, acc: 71.48, test_acc: 84.38, f1: 72.85
>> saved: state_dict/lcf_bert_restaurant_acc85.71
max_acc:85.71  f1:77.59
loss: 0.6610, acc: 71.97, test_acc: 85.71, f1: 77.59
loss: 0.5137, acc: 72.43, test_acc: 84.20, f1: 72.57
loss: 0.5921, acc: 72.14, test_acc: 82.05, f1: 67.53
loss: 0.4702, acc: 72.22, test_acc: 84.82, f1: 75.02
loss: 0.3644, acc: 72.64, test_acc: 85.62, f1: 78.22
loss: 0.1956, acc: 73.36, test_acc: 85.09, f1: 74.04
loss: 0.5706, acc: 73.56, test_acc: 84.38, f1: 73.43
loss: 0.1873, acc: 74.06, test_acc: 83.93, f1: 73.80
loss: 0.1998, acc: 74.54, test_acc: 83.48, f1: 72.63
loss: 1.0945, acc: 74.26, test_acc: 85.54, f1: 75.94
loss: 0.2590, acc: 74.56, test_acc: 83.48, f1: 73.37
loss: 0.7321, acc: 74.43, test_acc: 85.62, f1: 78.94
>> saved: state_dict/lcf_bert_restaurant_acc86.43
max_acc:86.43  f1:77.83
loss: 0.5772, acc: 74.31, test_acc: 86.43, f1: 77.83
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.0908, acc: 100.00, test_acc: 81.70, f1: 65.44
loss: 0.2847, acc: 93.75, test_acc: 80.71, f1: 63.36
loss: 0.1119, acc: 95.83, test_acc: 82.68, f1: 66.86
loss: 0.1352, acc: 95.31, test_acc: 85.18, f1: 73.97
loss: 0.2145, acc: 95.00, test_acc: 85.71, f1: 77.35
loss: 0.4802, acc: 92.71, test_acc: 86.34, f1: 79.28
loss: 0.2692, acc: 91.96, test_acc: 85.71, f1: 76.81
loss: 0.1316, acc: 91.41, test_acc: 85.45, f1: 76.11
loss: 0.4572, acc: 90.28, test_acc: 86.16, f1: 78.69
loss: 0.4905, acc: 90.00, test_acc: 85.80, f1: 77.74
>> saved: state_dict/lcf_bert_restaurant_acc86.88
max_acc:86.88  f1:79.94
loss: 0.3110, acc: 89.20, test_acc: 86.88, f1: 79.94
loss: 0.3455, acc: 88.54, test_acc: 86.79, f1: 80.79
loss: 0.2420, acc: 88.46, test_acc: 86.88, f1: 80.85
loss: 0.1488, acc: 88.84, test_acc: 86.52, f1: 79.50
loss: 0.5000, acc: 88.75, test_acc: 85.98, f1: 77.87
loss: 0.3058, acc: 88.67, test_acc: 84.73, f1: 73.75
loss: 0.2902, acc: 88.60, test_acc: 85.45, f1: 76.37
loss: 0.1727, acc: 88.89, test_acc: 84.55, f1: 75.35
loss: 0.1092, acc: 89.47, test_acc: 85.27, f1: 76.07
loss: 0.2897, acc: 89.38, test_acc: 85.98, f1: 78.42
loss: 0.5454, acc: 88.99, test_acc: 85.54, f1: 77.19
loss: 0.2820, acc: 88.92, test_acc: 85.89, f1: 78.05
loss: 0.5635, acc: 88.59, test_acc: 83.93, f1: 74.41
loss: 0.2480, acc: 88.54, test_acc: 85.54, f1: 77.48
loss: 0.2526, acc: 88.75, test_acc: 85.36, f1: 78.40
loss: 0.6027, acc: 88.46, test_acc: 85.98, f1: 78.25
loss: 0.2024, acc: 88.66, test_acc: 85.54, f1: 75.65
loss: 0.4123, acc: 88.17, test_acc: 85.98, f1: 77.33
loss: 0.2459, acc: 88.15, test_acc: 86.34, f1: 79.42
>> saved: state_dict/lcf_bert_restaurant_acc87.14
max_acc:87.14  f1:81.02
loss: 0.5687, acc: 87.71, test_acc: 87.14, f1: 81.02
loss: 0.3014, acc: 87.50, test_acc: 85.45, f1: 75.00
loss: 0.4226, acc: 87.30, test_acc: 84.73, f1: 73.17
loss: 0.3816, acc: 87.50, test_acc: 85.98, f1: 78.35
loss: 0.3137, acc: 87.50, test_acc: 85.18, f1: 77.73
loss: 0.3550, acc: 87.14, test_acc: 86.16, f1: 78.79
loss: 0.1205, acc: 87.33, test_acc: 85.54, f1: 76.51
loss: 0.1569, acc: 87.50, test_acc: 85.89, f1: 76.95
loss: 0.2349, acc: 87.50, test_acc: 86.07, f1: 78.80
loss: 0.2602, acc: 87.50, test_acc: 85.80, f1: 77.49
loss: 0.9238, acc: 86.88, test_acc: 84.91, f1: 73.96
loss: 0.4703, acc: 86.74, test_acc: 84.20, f1: 72.84
loss: 0.1879, acc: 86.90, test_acc: 85.80, f1: 77.65
>> saved: state_dict/lcf_bert_restaurant_acc87.41
max_acc:87.41  f1:80.45
loss: 0.3324, acc: 86.92, test_acc: 87.41, f1: 80.45
loss: 0.3557, acc: 86.79, test_acc: 84.38, f1: 72.66
loss: 0.1999, acc: 86.94, test_acc: 83.93, f1: 71.12
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2353, acc: 93.75, test_acc: 86.07, f1: 77.51
loss: 0.0733, acc: 96.88, test_acc: 86.96, f1: 79.85
loss: 0.1970, acc: 95.83, test_acc: 86.88, f1: 80.96
loss: 0.0898, acc: 96.88, test_acc: 86.79, f1: 79.44
loss: 0.2815, acc: 93.75, test_acc: 86.25, f1: 77.87
loss: 0.1600, acc: 93.75, test_acc: 86.79, f1: 79.38
loss: 0.3024, acc: 92.86, test_acc: 87.23, f1: 80.87
loss: 0.1256, acc: 92.97, test_acc: 86.96, f1: 81.73
loss: 0.0875, acc: 93.06, test_acc: 87.23, f1: 80.23
loss: 0.0867, acc: 93.12, test_acc: 86.16, f1: 76.79
loss: 0.1980, acc: 93.18, test_acc: 85.98, f1: 78.41
loss: 0.2259, acc: 93.23, test_acc: 84.91, f1: 76.52
loss: 0.2718, acc: 92.79, test_acc: 86.79, f1: 81.21
loss: 0.0573, acc: 93.30, test_acc: 85.71, f1: 78.28
loss: 0.0296, acc: 93.75, test_acc: 85.89, f1: 76.49
loss: 0.1555, acc: 93.75, test_acc: 86.61, f1: 79.16
loss: 0.3584, acc: 93.38, test_acc: 87.23, f1: 80.87
loss: 0.0943, acc: 93.75, test_acc: 86.07, f1: 78.21
loss: 0.1661, acc: 93.75, test_acc: 84.91, f1: 74.94
loss: 0.5550, acc: 93.12, test_acc: 84.20, f1: 73.09
loss: 0.0907, acc: 93.15, test_acc: 84.64, f1: 75.91
loss: 0.3296, acc: 92.90, test_acc: 84.46, f1: 77.06
loss: 0.2313, acc: 92.93, test_acc: 84.38, f1: 76.16
loss: 0.0956, acc: 92.97, test_acc: 84.38, f1: 73.81
loss: 0.2008, acc: 93.00, test_acc: 85.18, f1: 75.43
loss: 0.0273, acc: 93.27, test_acc: 85.45, f1: 77.34
loss: 0.3083, acc: 92.59, test_acc: 86.34, f1: 80.01
loss: 0.2221, acc: 92.63, test_acc: 86.34, f1: 78.91
loss: 0.0884, acc: 92.89, test_acc: 86.34, f1: 77.94
loss: 0.1660, acc: 92.71, test_acc: 86.16, f1: 76.91
loss: 0.0733, acc: 92.94, test_acc: 86.88, f1: 79.67
loss: 0.4839, acc: 92.58, test_acc: 86.88, f1: 79.70
loss: 0.0880, acc: 92.80, test_acc: 86.52, f1: 79.14
loss: 0.0687, acc: 92.83, test_acc: 86.07, f1: 78.42
loss: 0.1732, acc: 92.86, test_acc: 86.43, f1: 78.72
loss: 0.2717, acc: 92.71, test_acc: 86.88, f1: 78.72
loss: 0.6013, acc: 92.06, test_acc: 87.41, f1: 79.57
>> saved: state_dict/lcf_bert_restaurant_acc87.86
max_acc:87.86  f1:81.54
loss: 0.3407, acc: 91.94, test_acc: 87.86, f1: 81.54
>> saved: state_dict/lcf_bert_restaurant_acc88.12
max_acc:88.12  f1:82.15
loss: 0.2733, acc: 91.83, test_acc: 88.12, f1: 82.15
loss: 0.2315, acc: 91.88, test_acc: 87.05, f1: 79.02
loss: 0.0411, acc: 92.07, test_acc: 85.71, f1: 74.72
loss: 0.1442, acc: 92.11, test_acc: 86.25, f1: 77.11
loss: 0.1956, acc: 92.01, test_acc: 87.32, f1: 80.90
loss: 0.1356, acc: 92.05, test_acc: 87.95, f1: 82.35
loss: 0.0361, acc: 92.22, test_acc: 86.34, f1: 78.43
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0220, acc: 100.00, test_acc: 85.89, f1: 77.45
loss: 0.0962, acc: 96.88, test_acc: 85.45, f1: 77.24
loss: 0.0446, acc: 97.92, test_acc: 86.25, f1: 78.54
loss: 0.1334, acc: 98.44, test_acc: 87.50, f1: 80.84
loss: 0.2377, acc: 97.50, test_acc: 87.68, f1: 81.15
loss: 0.0627, acc: 96.88, test_acc: 87.86, f1: 81.79
loss: 0.3010, acc: 95.54, test_acc: 87.05, f1: 80.25
loss: 0.0060, acc: 96.09, test_acc: 86.16, f1: 77.47
loss: 0.0524, acc: 96.53, test_acc: 86.25, f1: 77.81
loss: 0.0416, acc: 96.88, test_acc: 87.05, f1: 80.10
loss: 0.1146, acc: 96.59, test_acc: 87.14, f1: 80.79
loss: 0.0505, acc: 96.35, test_acc: 86.34, f1: 79.24
loss: 0.0491, acc: 96.63, test_acc: 85.89, f1: 78.33
loss: 0.0085, acc: 96.88, test_acc: 86.16, f1: 78.76
loss: 0.0456, acc: 97.08, test_acc: 87.41, f1: 80.92
loss: 0.5048, acc: 95.70, test_acc: 87.68, f1: 81.66
loss: 0.1318, acc: 95.59, test_acc: 86.43, f1: 79.01
loss: 0.0510, acc: 95.83, test_acc: 85.54, f1: 77.00
loss: 0.0873, acc: 95.72, test_acc: 85.09, f1: 75.99
loss: 0.1242, acc: 95.62, test_acc: 86.79, f1: 79.81
loss: 0.0421, acc: 95.83, test_acc: 87.59, f1: 82.03
loss: 0.1301, acc: 95.74, test_acc: 86.79, f1: 79.99
loss: 0.0232, acc: 95.92, test_acc: 85.98, f1: 77.12
loss: 0.0469, acc: 96.09, test_acc: 86.70, f1: 79.11
loss: 0.1300, acc: 96.00, test_acc: 86.52, f1: 79.60
loss: 0.0320, acc: 96.15, test_acc: 87.05, f1: 80.83
loss: 0.3036, acc: 95.83, test_acc: 87.41, f1: 81.10
loss: 0.0258, acc: 95.98, test_acc: 87.50, f1: 81.10
loss: 0.0100, acc: 96.12, test_acc: 87.32, f1: 80.56
loss: 0.0377, acc: 96.25, test_acc: 87.86, f1: 81.49
loss: 0.1957, acc: 96.17, test_acc: 87.95, f1: 82.60
loss: 0.0592, acc: 96.29, test_acc: 86.88, f1: 82.18
loss: 0.1032, acc: 96.21, test_acc: 87.50, f1: 82.15
loss: 0.1274, acc: 96.14, test_acc: 88.12, f1: 81.88
loss: 0.0281, acc: 96.25, test_acc: 87.23, f1: 79.80
loss: 0.0207, acc: 96.35, test_acc: 86.88, f1: 79.26
loss: 0.1135, acc: 96.45, test_acc: 87.50, f1: 80.86
loss: 0.0448, acc: 96.55, test_acc: 87.23, f1: 79.93
loss: 0.0045, acc: 96.63, test_acc: 86.88, f1: 79.50
loss: 0.4643, acc: 96.41, test_acc: 87.32, f1: 80.57
loss: 0.2821, acc: 96.34, test_acc: 87.77, f1: 81.99
loss: 0.1578, acc: 96.28, test_acc: 87.14, f1: 81.20
loss: 0.0164, acc: 96.37, test_acc: 86.25, f1: 79.06
loss: 0.0940, acc: 96.31, test_acc: 86.88, f1: 80.00
loss: 0.0183, acc: 96.39, test_acc: 87.14, f1: 80.54
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0215, acc: 100.00, test_acc: 86.34, f1: 79.23
loss: 0.1323, acc: 96.88, test_acc: 86.07, f1: 78.46
loss: 0.0675, acc: 97.92, test_acc: 86.07, f1: 78.90
loss: 0.0111, acc: 98.44, test_acc: 85.89, f1: 78.48
loss: 0.0071, acc: 98.75, test_acc: 86.34, f1: 79.20
loss: 0.1882, acc: 97.92, test_acc: 85.36, f1: 77.33
loss: 0.0315, acc: 98.21, test_acc: 84.20, f1: 73.81
loss: 0.0051, acc: 98.44, test_acc: 84.46, f1: 73.76
loss: 0.0013, acc: 98.61, test_acc: 85.54, f1: 76.49
loss: 0.0770, acc: 98.12, test_acc: 85.36, f1: 76.21
loss: 0.1539, acc: 97.16, test_acc: 85.98, f1: 78.27
loss: 0.0762, acc: 96.88, test_acc: 86.96, f1: 80.54
loss: 0.0473, acc: 97.12, test_acc: 86.70, f1: 80.37
loss: 0.0115, acc: 97.32, test_acc: 86.70, f1: 80.48
loss: 0.0008, acc: 97.50, test_acc: 86.61, f1: 79.97
loss: 0.0302, acc: 97.66, test_acc: 86.34, f1: 78.97
loss: 0.0199, acc: 97.79, test_acc: 86.96, f1: 80.34
loss: 0.0036, acc: 97.92, test_acc: 87.23, f1: 81.12
loss: 0.0263, acc: 98.03, test_acc: 87.32, f1: 81.13
loss: 0.0306, acc: 98.12, test_acc: 87.50, f1: 81.00
loss: 0.0447, acc: 98.21, test_acc: 87.50, f1: 80.84
loss: 0.0047, acc: 98.30, test_acc: 87.50, f1: 80.36
loss: 0.0499, acc: 98.37, test_acc: 87.50, f1: 80.52
loss: 0.0582, acc: 98.44, test_acc: 87.86, f1: 81.14
>> saved: state_dict/lcf_bert_restaurant_acc88.21
max_acc:88.21  f1:82.29
loss: 0.0102, acc: 98.50, test_acc: 88.21, f1: 82.29
>> saved: state_dict/lcf_bert_restaurant_acc88.66
max_acc:88.66  f1:83.32
loss: 0.0098, acc: 98.56, test_acc: 88.66, f1: 83.32
loss: 0.0316, acc: 98.61, test_acc: 88.48, f1: 82.99
loss: 0.0389, acc: 98.66, test_acc: 88.57, f1: 83.12
loss: 0.0181, acc: 98.71, test_acc: 86.88, f1: 79.56
loss: 0.0303, acc: 98.75, test_acc: 86.34, f1: 78.18
loss: 0.0444, acc: 98.79, test_acc: 86.16, f1: 78.20
loss: 0.0291, acc: 98.83, test_acc: 87.41, f1: 81.20
loss: 0.0316, acc: 98.86, test_acc: 87.86, f1: 82.28
loss: 0.0049, acc: 98.90, test_acc: 88.12, f1: 82.30
loss: 0.0046, acc: 98.93, test_acc: 87.41, f1: 81.08
loss: 0.0041, acc: 98.96, test_acc: 87.05, f1: 80.08
loss: 0.1726, acc: 98.82, test_acc: 87.32, f1: 81.09
loss: 0.0076, acc: 98.85, test_acc: 87.50, f1: 81.50
loss: 0.0426, acc: 98.88, test_acc: 87.41, f1: 81.32
loss: 0.0071, acc: 98.91, test_acc: 87.77, f1: 81.97
loss: 0.0655, acc: 98.93, test_acc: 87.59, f1: 81.65
loss: 0.0143, acc: 98.96, test_acc: 86.79, f1: 80.41
loss: 0.0017, acc: 98.98, test_acc: 85.71, f1: 77.75
loss: 0.0221, acc: 99.01, test_acc: 85.36, f1: 76.66
loss: 0.2313, acc: 98.89, test_acc: 85.98, f1: 77.83
loss: 0.0020, acc: 98.90, test_acc: 86.07, f1: 77.32
####################################################################################################
max_test_acc_overall:88.66071428571428
max_f1_overall:83.31761081937773
####################################################################################################
1 test_acc_overall: 89.11  f1_overall:83.95
2 test_acc_overall: 89.02  f1_overall:83.59
3 test_acc_overall: 88.93  f1_overall:83.02
4 test_acc_overall: 88.48  f1_overall:83.43
5 test_acc_overall: 88.66  f1_overall:83.32
max_acc_overall:89.11  f1_overall:83.95
mean_acc_overall:88.84  mean_f1_overall:83.46
####################################################################################################
lcf_bert - twitter - cdm - No.1 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:459274752
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 0
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc24.86
max_acc:24.86  f1:13.29
loss: 1.1484, acc: 31.25, test_acc: 24.86, f1: 13.29
>> saved: state_dict/lcf_bert_twitter_acc50.0
max_acc:50.0  f1:22.22
loss: 0.9808, acc: 43.75, test_acc: 50.00, f1: 22.22
>> saved: state_dict/lcf_bert_twitter_acc52.02
max_acc:52.02  f1:29.44
loss: 1.1674, acc: 43.75, test_acc: 52.02, f1: 29.44
loss: 1.0898, acc: 45.31, test_acc: 50.87, f1: 41.03
loss: 0.9098, acc: 47.50, test_acc: 51.16, f1: 27.63
>> saved: state_dict/lcf_bert_twitter_acc53.61
max_acc:53.61  f1:33.64
loss: 0.9297, acc: 48.96, test_acc: 53.61, f1: 33.64
>> saved: state_dict/lcf_bert_twitter_acc54.34
max_acc:54.34  f1:36.7
loss: 1.0948, acc: 46.43, test_acc: 54.34, f1: 36.70
loss: 1.0237, acc: 46.09, test_acc: 53.90, f1: 38.06
loss: 1.3833, acc: 42.36, test_acc: 51.45, f1: 26.43
loss: 1.0367, acc: 43.12, test_acc: 40.17, f1: 37.36
>> saved: state_dict/lcf_bert_twitter_acc59.39
max_acc:59.39  f1:47.11
loss: 0.9375, acc: 43.75, test_acc: 59.39, f1: 47.11
>> saved: state_dict/lcf_bert_twitter_acc61.99
max_acc:61.99  f1:51.91
loss: 0.8810, acc: 44.27, test_acc: 61.99, f1: 51.91
>> saved: state_dict/lcf_bert_twitter_acc65.03
max_acc:65.03  f1:61.65
loss: 0.8954, acc: 44.71, test_acc: 65.03, f1: 61.65
loss: 0.8209, acc: 45.98, test_acc: 61.99, f1: 61.72
loss: 0.7396, acc: 47.08, test_acc: 64.31, f1: 64.13
loss: 0.9358, acc: 47.66, test_acc: 63.87, f1: 63.46
>> saved: state_dict/lcf_bert_twitter_acc67.05
max_acc:67.05  f1:65.41
loss: 0.9389, acc: 48.16, test_acc: 67.05, f1: 65.41
>> saved: state_dict/lcf_bert_twitter_acc69.51
max_acc:69.51  f1:66.12
loss: 0.7978, acc: 48.96, test_acc: 69.51, f1: 66.12
loss: 0.7991, acc: 49.01, test_acc: 61.99, f1: 62.25
loss: 0.8720, acc: 48.75, test_acc: 62.28, f1: 52.63
loss: 0.9266, acc: 48.81, test_acc: 61.42, f1: 50.53
loss: 0.8071, acc: 49.72, test_acc: 67.20, f1: 66.10
loss: 1.0130, acc: 49.46, test_acc: 58.96, f1: 59.61
loss: 0.7057, acc: 50.00, test_acc: 63.73, f1: 61.58
loss: 0.9294, acc: 50.25, test_acc: 66.62, f1: 61.23
>> saved: state_dict/lcf_bert_twitter_acc71.1
max_acc:71.1  f1:67.74
loss: 0.4810, acc: 51.44, test_acc: 71.10, f1: 67.74
loss: 0.5585, acc: 52.31, test_acc: 68.06, f1: 67.20
loss: 0.7478, acc: 52.90, test_acc: 65.03, f1: 64.85
loss: 1.0250, acc: 53.02, test_acc: 69.08, f1: 68.07
loss: 1.0593, acc: 52.71, test_acc: 69.94, f1: 68.68
loss: 0.5983, acc: 53.63, test_acc: 69.65, f1: 68.57
loss: 0.7682, acc: 53.91, test_acc: 70.09, f1: 68.77
loss: 0.7672, acc: 54.36, test_acc: 70.23, f1: 68.50
loss: 0.8216, acc: 54.41, test_acc: 69.22, f1: 68.45
>> saved: state_dict/lcf_bert_twitter_acc71.39
max_acc:71.39  f1:69.43
loss: 0.6221, acc: 54.64, test_acc: 71.39, f1: 69.43
>> saved: state_dict/lcf_bert_twitter_acc71.53
max_acc:71.53  f1:69.93
loss: 0.8307, acc: 55.21, test_acc: 71.53, f1: 69.93
loss: 0.6277, acc: 55.41, test_acc: 68.64, f1: 68.00
loss: 0.4993, acc: 56.09, test_acc: 66.91, f1: 66.66
loss: 0.5192, acc: 56.89, test_acc: 70.52, f1: 68.20
loss: 1.0579, acc: 56.88, test_acc: 67.20, f1: 66.65
loss: 1.0902, acc: 57.16, test_acc: 63.01, f1: 63.09
>> saved: state_dict/lcf_bert_twitter_acc72.25
max_acc:72.25  f1:69.17
loss: 0.6002, acc: 57.59, test_acc: 72.25, f1: 69.17
loss: 0.6223, acc: 57.56, test_acc: 68.06, f1: 62.16
loss: 0.6753, acc: 58.10, test_acc: 70.95, f1: 70.02
loss: 0.4870, acc: 58.61, test_acc: 71.39, f1: 70.86
loss: 0.4263, acc: 59.38, test_acc: 72.11, f1: 69.22
loss: 1.2505, acc: 59.04, test_acc: 72.25, f1: 69.24
loss: 0.9131, acc: 59.24, test_acc: 65.90, f1: 66.23
loss: 0.7712, acc: 59.57, test_acc: 70.81, f1: 70.48
>> saved: state_dict/lcf_bert_twitter_acc73.27
max_acc:73.27  f1:70.95
loss: 0.6304, acc: 59.62, test_acc: 73.27, f1: 70.95
loss: 0.7283, acc: 59.93, test_acc: 71.24, f1: 68.65
loss: 0.7436, acc: 60.10, test_acc: 73.12, f1: 69.98
loss: 0.4553, acc: 60.50, test_acc: 69.80, f1: 65.81
loss: 0.5728, acc: 60.76, test_acc: 71.68, f1: 70.48
loss: 0.7602, acc: 60.80, test_acc: 71.68, f1: 70.93
loss: 0.3872, acc: 61.38, test_acc: 71.68, f1: 70.71
loss: 0.4930, acc: 61.84, test_acc: 72.98, f1: 71.74
loss: 0.7909, acc: 61.85, test_acc: 72.25, f1: 68.99
loss: 0.7943, acc: 61.97, test_acc: 68.50, f1: 66.00
loss: 0.9122, acc: 61.98, test_acc: 66.62, f1: 66.49
loss: 0.6010, acc: 62.30, test_acc: 72.25, f1: 71.57
loss: 0.6892, acc: 62.50, test_acc: 71.53, f1: 70.71
>> saved: state_dict/lcf_bert_twitter_acc75.58
max_acc:75.58  f1:74.22
loss: 1.0045, acc: 62.30, test_acc: 75.58, f1: 74.22
loss: 0.3361, acc: 62.79, test_acc: 75.43, f1: 73.71
loss: 0.6559, acc: 62.98, test_acc: 73.12, f1: 72.23
loss: 0.6516, acc: 63.16, test_acc: 68.64, f1: 68.84
loss: 0.4840, acc: 63.43, test_acc: 71.53, f1: 71.32
loss: 0.4750, acc: 63.69, test_acc: 74.42, f1: 73.34
loss: 0.6261, acc: 63.95, test_acc: 74.28, f1: 73.47
loss: 0.4848, acc: 64.11, test_acc: 72.40, f1: 71.57
loss: 0.5840, acc: 64.26, test_acc: 73.84, f1: 73.13
loss: 0.9057, acc: 64.15, test_acc: 75.00, f1: 73.39
loss: 0.4537, acc: 64.30, test_acc: 73.41, f1: 70.00
loss: 0.5172, acc: 64.36, test_acc: 73.55, f1: 72.57
loss: 0.5074, acc: 64.58, test_acc: 71.39, f1: 71.20
loss: 0.4671, acc: 64.80, test_acc: 73.70, f1: 72.85
loss: 0.7695, acc: 64.85, test_acc: 75.58, f1: 74.24
loss: 0.5747, acc: 64.90, test_acc: 75.29, f1: 73.27
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.7518, acc: 68.75, test_acc: 73.84, f1: 72.39
loss: 0.6322, acc: 68.75, test_acc: 72.25, f1: 72.40
loss: 0.7113, acc: 68.75, test_acc: 73.41, f1: 73.05
>> saved: state_dict/lcf_bert_twitter_acc76.45
max_acc:76.45  f1:74.26
loss: 0.7274, acc: 68.75, test_acc: 76.45, f1: 74.26
loss: 0.5793, acc: 68.75, test_acc: 73.41, f1: 72.43
loss: 0.7170, acc: 68.75, test_acc: 72.54, f1: 72.36
loss: 0.2336, acc: 72.32, test_acc: 75.87, f1: 75.03
loss: 0.3027, acc: 74.22, test_acc: 75.72, f1: 73.87
loss: 0.3950, acc: 75.00, test_acc: 75.14, f1: 73.72
loss: 0.5277, acc: 76.25, test_acc: 73.27, f1: 72.85
loss: 0.4066, acc: 77.84, test_acc: 73.41, f1: 72.87
loss: 0.2717, acc: 79.69, test_acc: 74.57, f1: 73.23
loss: 0.4728, acc: 80.29, test_acc: 74.57, f1: 73.68
loss: 0.6004, acc: 79.02, test_acc: 71.82, f1: 71.46
loss: 0.4265, acc: 79.58, test_acc: 72.54, f1: 72.27
loss: 0.4250, acc: 79.69, test_acc: 74.57, f1: 73.36
loss: 0.6400, acc: 79.04, test_acc: 73.55, f1: 72.89
loss: 0.3082, acc: 79.17, test_acc: 74.42, f1: 73.12
loss: 0.4363, acc: 79.61, test_acc: 74.13, f1: 72.84
loss: 0.7648, acc: 79.06, test_acc: 74.57, f1: 73.03
loss: 0.3623, acc: 79.76, test_acc: 75.43, f1: 74.20
loss: 0.2622, acc: 80.40, test_acc: 75.43, f1: 74.39
loss: 0.2284, acc: 80.98, test_acc: 70.95, f1: 71.25
loss: 0.1915, acc: 81.51, test_acc: 75.72, f1: 75.08
loss: 0.8586, acc: 81.00, test_acc: 75.58, f1: 73.50
loss: 0.4378, acc: 81.01, test_acc: 75.58, f1: 74.32
loss: 0.4379, acc: 81.25, test_acc: 73.27, f1: 73.39
loss: 0.3690, acc: 81.25, test_acc: 70.66, f1: 70.69
loss: 0.3062, acc: 81.68, test_acc: 75.72, f1: 73.86
loss: 0.5730, acc: 81.25, test_acc: 75.72, f1: 74.63
loss: 0.4919, acc: 81.25, test_acc: 73.70, f1: 73.27
loss: 0.4293, acc: 81.64, test_acc: 73.84, f1: 73.32
loss: 0.7031, acc: 81.06, test_acc: 76.01, f1: 74.75
loss: 0.4089, acc: 81.43, test_acc: 75.72, f1: 73.83
loss: 0.5582, acc: 81.07, test_acc: 75.87, f1: 74.63
loss: 0.5633, acc: 80.90, test_acc: 73.70, f1: 73.50
loss: 0.6150, acc: 80.74, test_acc: 74.57, f1: 74.44
loss: 0.4615, acc: 80.76, test_acc: 75.87, f1: 75.06
loss: 0.5500, acc: 80.61, test_acc: 73.84, f1: 71.49
loss: 0.3921, acc: 80.78, test_acc: 75.43, f1: 73.36
loss: 0.9393, acc: 80.34, test_acc: 72.83, f1: 73.04
loss: 0.6671, acc: 80.06, test_acc: 73.12, f1: 72.71
loss: 0.5949, acc: 80.09, test_acc: 75.29, f1: 73.14
loss: 0.6844, acc: 80.11, test_acc: 75.58, f1: 74.33
loss: 0.3414, acc: 80.28, test_acc: 70.95, f1: 70.91
loss: 0.3833, acc: 80.43, test_acc: 72.25, f1: 72.11
loss: 0.3945, acc: 80.45, test_acc: 72.11, f1: 72.23
loss: 0.6108, acc: 80.34, test_acc: 74.13, f1: 73.68
loss: 0.6414, acc: 79.97, test_acc: 75.58, f1: 74.68
loss: 0.3438, acc: 80.12, test_acc: 74.28, f1: 72.85
loss: 0.2486, acc: 80.39, test_acc: 75.00, f1: 74.11
loss: 0.6794, acc: 80.53, test_acc: 74.28, f1: 72.96
loss: 0.2339, acc: 80.78, test_acc: 75.14, f1: 72.66
loss: 0.3993, acc: 80.67, test_acc: 73.99, f1: 73.35
loss: 0.5483, acc: 80.57, test_acc: 72.98, f1: 72.54
loss: 0.3344, acc: 80.80, test_acc: 73.70, f1: 72.84
loss: 0.7245, acc: 80.70, test_acc: 74.28, f1: 72.09
loss: 0.2033, acc: 80.93, test_acc: 74.57, f1: 73.09
loss: 0.4835, acc: 80.93, test_acc: 71.24, f1: 71.17
loss: 0.9943, acc: 80.52, test_acc: 72.40, f1: 72.11
loss: 0.8231, acc: 80.23, test_acc: 75.14, f1: 73.73
loss: 0.3555, acc: 80.34, test_acc: 73.27, f1: 72.47
loss: 0.6017, acc: 80.36, test_acc: 72.40, f1: 71.82
loss: 0.5077, acc: 80.37, test_acc: 71.39, f1: 71.17
loss: 0.6922, acc: 80.29, test_acc: 74.42, f1: 73.51
loss: 0.6085, acc: 80.11, test_acc: 74.42, f1: 73.23
loss: 0.6324, acc: 80.04, test_acc: 75.14, f1: 73.46
loss: 0.5276, acc: 79.87, test_acc: 74.71, f1: 73.70
loss: 0.5663, acc: 79.80, test_acc: 74.71, f1: 73.74
loss: 0.2908, acc: 80.00, test_acc: 74.42, f1: 73.49
loss: 0.2857, acc: 80.11, test_acc: 74.57, f1: 73.93
loss: 0.7995, acc: 79.95, test_acc: 74.57, f1: 73.62
loss: 0.4797, acc: 79.88, test_acc: 73.55, f1: 71.81
loss: 0.8701, acc: 79.65, test_acc: 74.13, f1: 70.13
loss: 0.6147, acc: 79.58, test_acc: 74.86, f1: 74.33
loss: 0.7055, acc: 79.61, test_acc: 65.61, f1: 66.03
loss: 0.7168, acc: 79.63, test_acc: 74.42, f1: 74.07
>> saved: state_dict/lcf_bert_twitter_acc76.88
max_acc:76.88  f1:76.02
loss: 0.8681, acc: 79.49, test_acc: 76.88, f1: 76.02
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2176, acc: 93.75, test_acc: 74.13, f1: 73.93
>> saved: state_dict/lcf_bert_twitter_acc77.17
max_acc:77.17  f1:76.38
loss: 0.2062, acc: 93.75, test_acc: 77.17, f1: 76.38
loss: 0.1911, acc: 95.83, test_acc: 75.14, f1: 74.11
loss: 0.4124, acc: 90.62, test_acc: 75.00, f1: 74.58
loss: 0.3301, acc: 88.75, test_acc: 72.69, f1: 72.90
>> saved: state_dict/lcf_bert_twitter_acc77.89
max_acc:77.89  f1:77.02
loss: 0.2061, acc: 89.58, test_acc: 77.89, f1: 77.02
loss: 0.4168, acc: 89.29, test_acc: 75.72, f1: 74.18
loss: 0.1823, acc: 89.84, test_acc: 76.45, f1: 75.22
loss: 0.0606, acc: 90.97, test_acc: 75.14, f1: 74.92
loss: 0.1234, acc: 91.88, test_acc: 72.54, f1: 72.19
loss: 0.2458, acc: 91.48, test_acc: 74.86, f1: 74.68
loss: 0.0864, acc: 92.19, test_acc: 74.13, f1: 73.44
loss: 0.1163, acc: 92.79, test_acc: 75.14, f1: 73.79
loss: 0.4901, acc: 91.96, test_acc: 74.71, f1: 73.89
loss: 0.3818, acc: 91.25, test_acc: 72.98, f1: 72.53
loss: 0.4446, acc: 91.41, test_acc: 73.12, f1: 72.00
loss: 0.2491, acc: 91.54, test_acc: 73.41, f1: 71.98
loss: 0.0515, acc: 92.01, test_acc: 73.70, f1: 72.35
loss: 0.1982, acc: 92.11, test_acc: 73.99, f1: 73.32
loss: 0.2364, acc: 91.88, test_acc: 74.57, f1: 73.80
loss: 0.2078, acc: 91.96, test_acc: 75.43, f1: 74.23
loss: 0.1314, acc: 92.33, test_acc: 74.57, f1: 73.63
loss: 0.0555, acc: 92.66, test_acc: 75.00, f1: 74.03
loss: 0.3674, acc: 92.19, test_acc: 74.42, f1: 73.68
loss: 0.1330, acc: 92.25, test_acc: 74.71, f1: 73.93
loss: 0.5047, acc: 91.83, test_acc: 74.42, f1: 73.50
loss: 0.1185, acc: 91.90, test_acc: 75.00, f1: 72.89
loss: 0.5746, acc: 90.85, test_acc: 75.29, f1: 73.72
loss: 0.0625, acc: 91.16, test_acc: 67.77, f1: 67.93
loss: 0.1375, acc: 91.25, test_acc: 71.24, f1: 70.82
loss: 0.2211, acc: 91.33, test_acc: 72.83, f1: 70.44
loss: 0.3961, acc: 91.41, test_acc: 71.97, f1: 70.50
loss: 0.1519, acc: 91.48, test_acc: 72.40, f1: 71.20
loss: 0.1979, acc: 91.54, test_acc: 73.12, f1: 72.18
loss: 0.2108, acc: 91.43, test_acc: 73.12, f1: 72.34
loss: 0.3145, acc: 90.97, test_acc: 72.11, f1: 71.89
loss: 0.0635, acc: 91.22, test_acc: 73.84, f1: 72.94
loss: 0.1030, acc: 91.45, test_acc: 72.98, f1: 71.57
loss: 0.5312, acc: 91.35, test_acc: 72.98, f1: 71.59
loss: 0.4466, acc: 91.25, test_acc: 72.40, f1: 72.05
loss: 0.1401, acc: 91.31, test_acc: 73.70, f1: 72.28
loss: 0.5929, acc: 91.07, test_acc: 73.55, f1: 72.29
loss: 0.2372, acc: 90.99, test_acc: 67.92, f1: 68.34
loss: 0.2600, acc: 90.91, test_acc: 73.70, f1: 72.57
loss: 0.1484, acc: 90.97, test_acc: 74.57, f1: 72.13
loss: 0.3898, acc: 90.76, test_acc: 73.55, f1: 72.20
loss: 0.5234, acc: 90.56, test_acc: 71.39, f1: 70.69
loss: 0.2054, acc: 90.76, test_acc: 73.84, f1: 72.70
loss: 0.2426, acc: 90.69, test_acc: 74.42, f1: 72.99
loss: 0.2992, acc: 90.62, test_acc: 73.12, f1: 71.23
loss: 0.2297, acc: 90.69, test_acc: 73.55, f1: 71.90
loss: 0.1233, acc: 90.75, test_acc: 75.00, f1: 73.94
loss: 0.0564, acc: 90.92, test_acc: 72.69, f1: 72.05
loss: 0.4735, acc: 90.62, test_acc: 72.40, f1: 72.07
loss: 0.1439, acc: 90.68, test_acc: 73.99, f1: 73.07
loss: 0.1632, acc: 90.74, test_acc: 73.99, f1: 71.99
loss: 0.0617, acc: 90.90, test_acc: 73.12, f1: 71.84
loss: 0.2525, acc: 90.84, test_acc: 71.53, f1: 71.45
loss: 0.2789, acc: 90.68, test_acc: 71.24, f1: 71.30
loss: 0.3379, acc: 90.52, test_acc: 71.53, f1: 71.36
loss: 0.1087, acc: 90.68, test_acc: 72.11, f1: 71.89
loss: 0.2809, acc: 90.73, test_acc: 72.98, f1: 72.46
loss: 0.0626, acc: 90.87, test_acc: 73.41, f1: 72.47
loss: 0.3329, acc: 90.82, test_acc: 73.70, f1: 72.92
loss: 0.4264, acc: 90.77, test_acc: 72.25, f1: 71.71
loss: 0.4436, acc: 90.53, test_acc: 70.81, f1: 70.59
loss: 0.2275, acc: 90.58, test_acc: 70.95, f1: 70.52
loss: 0.1794, acc: 90.62, test_acc: 71.53, f1: 70.81
loss: 0.5130, acc: 90.49, test_acc: 72.11, f1: 71.70
loss: 0.3670, acc: 90.45, test_acc: 71.68, f1: 71.63
loss: 0.1549, acc: 90.49, test_acc: 68.93, f1: 69.05
loss: 0.2413, acc: 90.45, test_acc: 74.57, f1: 73.71
loss: 0.2821, acc: 90.41, test_acc: 73.55, f1: 72.27
loss: 0.0740, acc: 90.54, test_acc: 74.42, f1: 73.77
loss: 0.0603, acc: 90.67, test_acc: 76.01, f1: 74.99
loss: 0.1061, acc: 90.71, test_acc: 74.57, f1: 74.08
loss: 0.4736, acc: 90.42, test_acc: 75.00, f1: 74.58
loss: 0.5489, acc: 90.22, test_acc: 72.98, f1: 72.46
####################################################################################################
max_test_acc_overall:77.89017341040463
max_f1_overall:77.0236749001553
####################################################################################################
1 test_acc_overall: 77.89  f1_overall:77.02
max_acc_overall:77.89  f1_overall:77.02
mean_acc_overall:77.89  mean_f1_overall:77.02
####################################################################################################
lcf_bert - twitter - cdm - No.2 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 1
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc50.0
max_acc:50.0  f1:22.22
loss: 1.2757, acc: 37.50, test_acc: 50.00, f1: 22.22
loss: 0.9936, acc: 43.75, test_acc: 50.00, f1: 22.22
loss: 1.1698, acc: 41.67, test_acc: 50.00, f1: 22.22
loss: 1.0175, acc: 45.31, test_acc: 50.00, f1: 23.02
loss: 1.2095, acc: 46.25, test_acc: 50.00, f1: 22.22
loss: 1.1817, acc: 42.71, test_acc: 25.00, f1: 13.33
loss: 1.0643, acc: 43.75, test_acc: 50.00, f1: 22.22
loss: 1.4589, acc: 42.19, test_acc: 50.00, f1: 22.22
loss: 1.0988, acc: 41.67, test_acc: 30.49, f1: 21.14
>> saved: state_dict/lcf_bert_twitter_acc51.3
max_acc:51.3  f1:26.32
loss: 0.9381, acc: 45.00, test_acc: 51.30, f1: 26.32
loss: 0.8298, acc: 47.16, test_acc: 50.00, f1: 22.22
loss: 0.7022, acc: 49.48, test_acc: 50.00, f1: 22.22
loss: 1.0438, acc: 49.52, test_acc: 42.20, f1: 39.98
loss: 0.8570, acc: 50.00, test_acc: 50.29, f1: 23.03
>> saved: state_dict/lcf_bert_twitter_acc59.1
max_acc:59.1  f1:51.15
loss: 0.8574, acc: 50.83, test_acc: 59.10, f1: 51.15
>> saved: state_dict/lcf_bert_twitter_acc61.56
max_acc:61.56  f1:56.65
loss: 0.9620, acc: 51.56, test_acc: 61.56, f1: 56.65
loss: 0.9659, acc: 51.10, test_acc: 59.83, f1: 48.25
loss: 0.9693, acc: 51.04, test_acc: 60.98, f1: 60.23
loss: 0.6709, acc: 52.30, test_acc: 60.84, f1: 60.80
loss: 0.8971, acc: 52.50, test_acc: 56.07, f1: 57.01
>> saved: state_dict/lcf_bert_twitter_acc63.73
max_acc:63.73  f1:56.33
loss: 0.9212, acc: 52.98, test_acc: 63.73, f1: 56.33
loss: 0.5621, acc: 53.69, test_acc: 63.29, f1: 54.24
>> saved: state_dict/lcf_bert_twitter_acc67.05
max_acc:67.05  f1:64.76
loss: 0.7421, acc: 54.62, test_acc: 67.05, f1: 64.76
loss: 0.8364, acc: 54.95, test_acc: 61.42, f1: 61.90
>> saved: state_dict/lcf_bert_twitter_acc68.35
max_acc:68.35  f1:65.54
loss: 0.6512, acc: 55.75, test_acc: 68.35, f1: 65.54
loss: 0.6095, acc: 56.73, test_acc: 66.04, f1: 64.66
loss: 0.8673, acc: 57.18, test_acc: 66.62, f1: 65.71
loss: 0.6470, acc: 57.59, test_acc: 64.02, f1: 63.86
loss: 0.7968, acc: 57.76, test_acc: 65.32, f1: 64.93
>> saved: state_dict/lcf_bert_twitter_acc69.08
max_acc:69.08  f1:66.95
loss: 0.7896, acc: 57.92, test_acc: 69.08, f1: 66.95
loss: 0.6278, acc: 58.27, test_acc: 66.76, f1: 65.42
loss: 0.7131, acc: 58.01, test_acc: 60.26, f1: 60.52
loss: 0.8960, acc: 58.14, test_acc: 66.76, f1: 66.07
loss: 0.6114, acc: 58.64, test_acc: 66.18, f1: 64.99
>> saved: state_dict/lcf_bert_twitter_acc69.22
max_acc:69.22  f1:67.77
loss: 0.8449, acc: 59.11, test_acc: 69.22, f1: 67.77
loss: 0.6313, acc: 59.55, test_acc: 68.79, f1: 65.80
loss: 0.7857, acc: 59.97, test_acc: 65.61, f1: 64.97
loss: 0.8001, acc: 60.03, test_acc: 68.50, f1: 67.16
loss: 0.8992, acc: 59.94, test_acc: 68.79, f1: 65.98
loss: 0.5993, acc: 60.31, test_acc: 66.47, f1: 64.22
loss: 0.7857, acc: 60.52, test_acc: 68.93, f1: 67.56
loss: 0.9137, acc: 60.27, test_acc: 65.46, f1: 64.59
loss: 0.8405, acc: 60.32, test_acc: 66.62, f1: 65.52
loss: 0.7065, acc: 60.65, test_acc: 67.20, f1: 66.18
loss: 0.5539, acc: 61.25, test_acc: 64.02, f1: 63.00
loss: 0.6412, acc: 61.41, test_acc: 65.75, f1: 60.55
>> saved: state_dict/lcf_bert_twitter_acc70.52
max_acc:70.52  f1:68.29
loss: 0.5686, acc: 61.84, test_acc: 70.52, f1: 68.29
loss: 0.9592, acc: 61.85, test_acc: 60.55, f1: 60.79
loss: 1.1997, acc: 61.73, test_acc: 62.72, f1: 62.98
loss: 0.6222, acc: 62.12, test_acc: 66.76, f1: 65.88
loss: 0.7207, acc: 62.01, test_acc: 66.91, f1: 65.90
loss: 0.4223, acc: 62.26, test_acc: 69.36, f1: 67.80
loss: 0.4614, acc: 62.50, test_acc: 69.80, f1: 68.72
loss: 0.6875, acc: 62.50, test_acc: 63.01, f1: 63.07
loss: 0.5286, acc: 62.73, test_acc: 70.23, f1: 68.18
>> saved: state_dict/lcf_bert_twitter_acc71.82
max_acc:71.82  f1:69.77
loss: 0.5463, acc: 63.06, test_acc: 71.82, f1: 69.77
loss: 0.5737, acc: 63.38, test_acc: 66.33, f1: 65.65
loss: 0.8648, acc: 63.25, test_acc: 71.68, f1: 70.03
loss: 0.7776, acc: 63.14, test_acc: 69.36, f1: 65.33
loss: 0.7143, acc: 63.02, test_acc: 69.94, f1: 69.13
loss: 0.6075, acc: 63.32, test_acc: 69.80, f1: 68.87
loss: 0.5445, acc: 63.41, test_acc: 70.23, f1: 69.20
>> saved: state_dict/lcf_bert_twitter_acc73.84
max_acc:73.84  f1:71.76
loss: 0.6064, acc: 63.59, test_acc: 73.84, f1: 71.76
loss: 0.3864, acc: 63.96, test_acc: 72.69, f1: 71.22
loss: 0.4209, acc: 64.33, test_acc: 71.68, f1: 70.32
loss: 0.6015, acc: 64.49, test_acc: 73.84, f1: 71.65
loss: 0.7942, acc: 64.55, test_acc: 70.23, f1: 69.39
loss: 0.7076, acc: 64.52, test_acc: 67.92, f1: 67.76
loss: 0.4458, acc: 64.67, test_acc: 73.27, f1: 71.12
loss: 0.7136, acc: 64.82, test_acc: 72.98, f1: 70.43
loss: 0.7869, acc: 64.70, test_acc: 69.65, f1: 69.43
loss: 0.5464, acc: 64.84, test_acc: 66.91, f1: 67.48
>> saved: state_dict/lcf_bert_twitter_acc74.13
max_acc:74.13  f1:72.54
loss: 0.2878, acc: 65.33, test_acc: 74.13, f1: 72.54
>> saved: state_dict/lcf_bert_twitter_acc74.71
max_acc:74.71  f1:72.77
loss: 0.8868, acc: 65.29, test_acc: 74.71, f1: 72.77
loss: 0.9111, acc: 65.25, test_acc: 70.52, f1: 70.45
loss: 1.0606, acc: 65.05, test_acc: 70.09, f1: 70.11
loss: 0.7214, acc: 65.02, test_acc: 71.82, f1: 70.82
loss: 0.4630, acc: 65.30, test_acc: 73.70, f1: 71.60
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.4161, acc: 87.50, test_acc: 72.11, f1: 71.04
loss: 0.6442, acc: 81.25, test_acc: 71.39, f1: 70.49
loss: 0.5766, acc: 79.17, test_acc: 74.13, f1: 72.63
loss: 0.4173, acc: 81.25, test_acc: 70.38, f1: 70.23
loss: 0.1859, acc: 83.75, test_acc: 66.18, f1: 66.49
loss: 0.5986, acc: 84.38, test_acc: 71.97, f1: 71.34
>> saved: state_dict/lcf_bert_twitter_acc74.86
max_acc:74.86  f1:72.59
loss: 0.2057, acc: 86.61, test_acc: 74.86, f1: 72.59
loss: 0.1798, acc: 88.28, test_acc: 71.82, f1: 70.63
loss: 0.4087, acc: 87.50, test_acc: 70.66, f1: 70.49
loss: 0.4826, acc: 86.25, test_acc: 72.11, f1: 71.65
loss: 0.3967, acc: 85.80, test_acc: 71.68, f1: 70.63
loss: 0.2133, acc: 86.46, test_acc: 71.39, f1: 70.46
loss: 0.4281, acc: 85.58, test_acc: 72.54, f1: 71.03
loss: 0.3587, acc: 85.27, test_acc: 72.83, f1: 71.17
loss: 0.4252, acc: 85.42, test_acc: 70.52, f1: 70.13
loss: 0.4838, acc: 85.16, test_acc: 70.38, f1: 70.31
loss: 0.5937, acc: 84.93, test_acc: 74.42, f1: 72.73
loss: 0.4515, acc: 85.07, test_acc: 72.54, f1: 70.54
loss: 0.5555, acc: 84.54, test_acc: 72.40, f1: 72.29
loss: 0.5250, acc: 84.38, test_acc: 74.28, f1: 73.28
loss: 0.2886, acc: 84.82, test_acc: 73.84, f1: 72.46
loss: 0.4562, acc: 84.66, test_acc: 72.98, f1: 72.01
loss: 0.3867, acc: 84.51, test_acc: 68.93, f1: 69.10
loss: 0.6440, acc: 83.59, test_acc: 72.11, f1: 71.39
loss: 0.5630, acc: 83.50, test_acc: 73.55, f1: 70.49
loss: 0.5726, acc: 82.93, test_acc: 72.54, f1: 70.96
loss: 0.5144, acc: 83.10, test_acc: 71.10, f1: 71.10
loss: 0.3003, acc: 83.26, test_acc: 70.09, f1: 69.99
loss: 0.3859, acc: 83.41, test_acc: 72.54, f1: 71.79
loss: 0.7149, acc: 83.12, test_acc: 73.55, f1: 72.43
>> saved: state_dict/lcf_bert_twitter_acc75.58
max_acc:75.58  f1:74.19
loss: 0.5192, acc: 83.27, test_acc: 75.58, f1: 74.19
loss: 0.2556, acc: 83.40, test_acc: 67.49, f1: 68.15
loss: 0.3694, acc: 83.52, test_acc: 73.41, f1: 72.51
loss: 0.7000, acc: 82.90, test_acc: 74.28, f1: 71.98
loss: 0.2982, acc: 83.21, test_acc: 70.81, f1: 69.94
loss: 0.7085, acc: 83.16, test_acc: 68.35, f1: 68.19
loss: 0.4735, acc: 83.28, test_acc: 67.34, f1: 67.44
loss: 0.7524, acc: 82.73, test_acc: 68.21, f1: 67.94
loss: 0.3741, acc: 82.69, test_acc: 72.40, f1: 70.76
loss: 0.7006, acc: 82.19, test_acc: 71.82, f1: 70.82
loss: 0.5149, acc: 82.16, test_acc: 70.23, f1: 69.71
loss: 0.6283, acc: 81.55, test_acc: 73.99, f1: 72.34
loss: 0.4800, acc: 81.69, test_acc: 69.36, f1: 69.28
loss: 0.6733, acc: 81.39, test_acc: 69.22, f1: 69.07
loss: 0.3970, acc: 81.39, test_acc: 71.39, f1: 69.63
loss: 1.0406, acc: 80.84, test_acc: 71.39, f1: 68.30
loss: 0.5265, acc: 80.98, test_acc: 66.76, f1: 66.82
loss: 0.2744, acc: 81.38, test_acc: 68.06, f1: 68.05
loss: 0.5360, acc: 81.38, test_acc: 71.82, f1: 70.27
loss: 0.3256, acc: 81.38, test_acc: 71.39, f1: 69.92
loss: 0.4504, acc: 81.37, test_acc: 68.35, f1: 68.58
loss: 0.3319, acc: 81.49, test_acc: 71.97, f1: 71.46
loss: 0.9670, acc: 81.01, test_acc: 71.53, f1: 70.55
loss: 0.4572, acc: 81.13, test_acc: 70.38, f1: 69.60
loss: 0.6327, acc: 80.80, test_acc: 69.94, f1: 69.71
loss: 0.5333, acc: 80.69, test_acc: 70.81, f1: 70.50
loss: 0.3683, acc: 80.81, test_acc: 73.41, f1: 71.72
loss: 0.4140, acc: 80.93, test_acc: 71.39, f1: 70.63
loss: 0.5813, acc: 80.83, test_acc: 72.11, f1: 71.23
loss: 0.3742, acc: 80.73, test_acc: 72.40, f1: 70.84
loss: 0.2856, acc: 81.05, test_acc: 71.97, f1: 71.01
loss: 0.1989, acc: 81.35, test_acc: 72.11, f1: 71.32
loss: 0.4195, acc: 81.45, test_acc: 72.40, f1: 71.32
loss: 0.4613, acc: 81.45, test_acc: 72.54, f1: 71.02
loss: 0.5489, acc: 81.54, test_acc: 73.55, f1: 71.95
loss: 0.5652, acc: 81.44, test_acc: 72.25, f1: 71.47
loss: 0.5386, acc: 81.34, test_acc: 72.69, f1: 71.68
loss: 0.5145, acc: 81.25, test_acc: 72.98, f1: 70.95
loss: 0.8522, acc: 81.16, test_acc: 73.12, f1: 71.00
loss: 0.3354, acc: 81.16, test_acc: 74.57, f1: 72.86
loss: 0.3382, acc: 81.16, test_acc: 73.84, f1: 72.81
loss: 0.3221, acc: 81.25, test_acc: 73.70, f1: 72.54
loss: 0.7603, acc: 81.25, test_acc: 71.39, f1: 70.83
loss: 0.6168, acc: 81.17, test_acc: 73.55, f1: 72.35
loss: 0.5640, acc: 81.00, test_acc: 73.99, f1: 72.10
loss: 0.8536, acc: 81.00, test_acc: 73.27, f1: 71.35
loss: 0.3178, acc: 81.17, test_acc: 75.00, f1: 73.84
loss: 0.5597, acc: 81.01, test_acc: 73.27, f1: 72.09
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1294, acc: 100.00, test_acc: 72.54, f1: 70.91
loss: 0.3349, acc: 96.88, test_acc: 74.57, f1: 73.23
loss: 0.2285, acc: 93.75, test_acc: 73.70, f1: 72.52
loss: 0.6769, acc: 90.62, test_acc: 72.40, f1: 71.98
loss: 0.1484, acc: 91.25, test_acc: 72.69, f1: 72.02
loss: 0.0853, acc: 92.71, test_acc: 73.55, f1: 72.23
loss: 0.2364, acc: 92.86, test_acc: 72.69, f1: 71.70
loss: 0.4351, acc: 92.19, test_acc: 69.51, f1: 69.51
loss: 0.0953, acc: 93.06, test_acc: 67.05, f1: 67.69
loss: 0.0828, acc: 93.75, test_acc: 72.98, f1: 71.37
loss: 0.3182, acc: 93.75, test_acc: 72.83, f1: 72.13
loss: 0.4959, acc: 93.23, test_acc: 70.52, f1: 70.43
loss: 0.4140, acc: 92.31, test_acc: 71.97, f1: 71.40
loss: 0.3038, acc: 91.52, test_acc: 74.42, f1: 72.58
loss: 0.1087, acc: 91.67, test_acc: 74.13, f1: 72.22
loss: 0.1048, acc: 91.80, test_acc: 72.25, f1: 71.76
loss: 0.3271, acc: 91.91, test_acc: 72.40, f1: 70.99
loss: 0.3638, acc: 91.67, test_acc: 71.97, f1: 71.12
loss: 0.2301, acc: 91.78, test_acc: 72.25, f1: 71.57
loss: 0.2464, acc: 91.88, test_acc: 71.97, f1: 70.48
loss: 0.2005, acc: 91.67, test_acc: 71.82, f1: 69.60
loss: 0.3803, acc: 91.48, test_acc: 72.40, f1: 71.63
loss: 0.2562, acc: 91.30, test_acc: 67.05, f1: 67.33
loss: 0.0967, acc: 91.67, test_acc: 71.82, f1: 71.45
loss: 1.3275, acc: 90.50, test_acc: 72.98, f1: 70.52
loss: 0.5321, acc: 89.90, test_acc: 73.41, f1: 72.15
loss: 0.1980, acc: 90.05, test_acc: 72.40, f1: 71.83
loss: 0.0628, acc: 90.40, test_acc: 71.68, f1: 71.30
loss: 0.4705, acc: 90.30, test_acc: 71.39, f1: 70.43
loss: 0.1405, acc: 90.62, test_acc: 72.54, f1: 71.22
loss: 0.1181, acc: 90.93, test_acc: 73.41, f1: 72.08
loss: 0.0354, acc: 91.21, test_acc: 71.68, f1: 71.06
loss: 0.1022, acc: 91.48, test_acc: 71.53, f1: 70.71
loss: 0.3233, acc: 91.54, test_acc: 71.39, f1: 69.71
loss: 0.2602, acc: 91.43, test_acc: 71.24, f1: 69.60
loss: 0.5822, acc: 90.97, test_acc: 70.52, f1: 70.11
loss: 0.2346, acc: 90.88, test_acc: 68.93, f1: 68.85
loss: 0.0948, acc: 91.12, test_acc: 72.83, f1: 72.02
loss: 0.0665, acc: 91.35, test_acc: 71.82, f1: 70.11
loss: 0.8319, acc: 90.62, test_acc: 71.68, f1: 70.99
loss: 0.1688, acc: 90.70, test_acc: 68.50, f1: 68.70
loss: 0.3153, acc: 90.77, test_acc: 69.65, f1: 69.50
loss: 0.1605, acc: 90.84, test_acc: 71.10, f1: 69.51
loss: 0.1411, acc: 90.91, test_acc: 73.12, f1: 71.43
loss: 0.1009, acc: 91.11, test_acc: 69.51, f1: 68.87
loss: 0.3169, acc: 91.03, test_acc: 70.52, f1: 69.95
loss: 0.1827, acc: 91.09, test_acc: 71.24, f1: 69.35
loss: 0.3839, acc: 90.89, test_acc: 73.12, f1: 70.97
loss: 0.2093, acc: 90.82, test_acc: 67.92, f1: 67.83
loss: 0.2331, acc: 90.75, test_acc: 68.06, f1: 68.17
loss: 0.1392, acc: 90.81, test_acc: 72.83, f1: 70.47
loss: 0.3848, acc: 90.87, test_acc: 70.95, f1: 67.37
loss: 0.1219, acc: 91.04, test_acc: 68.93, f1: 67.77
loss: 0.2215, acc: 90.97, test_acc: 67.63, f1: 67.93
loss: 0.3196, acc: 90.91, test_acc: 72.25, f1: 70.87
loss: 0.4057, acc: 90.85, test_acc: 72.25, f1: 70.58
loss: 0.1387, acc: 90.90, test_acc: 71.24, f1: 70.45
loss: 0.3481, acc: 90.73, test_acc: 72.11, f1: 71.40
loss: 0.1907, acc: 90.78, test_acc: 70.23, f1: 69.96
loss: 0.4279, acc: 90.73, test_acc: 67.92, f1: 68.14
loss: 0.3070, acc: 90.78, test_acc: 72.54, f1: 71.84
loss: 0.1431, acc: 90.83, test_acc: 72.54, f1: 70.87
loss: 0.1331, acc: 90.87, test_acc: 72.40, f1: 70.99
loss: 0.3280, acc: 90.82, test_acc: 70.23, f1: 69.97
loss: 0.2555, acc: 90.77, test_acc: 70.95, f1: 70.67
loss: 0.5005, acc: 90.72, test_acc: 70.66, f1: 70.08
loss: 0.3373, acc: 90.76, test_acc: 70.23, f1: 69.19
loss: 0.3584, acc: 90.72, test_acc: 70.38, f1: 69.80
loss: 0.0911, acc: 90.85, test_acc: 70.23, f1: 69.91
loss: 0.0982, acc: 90.98, test_acc: 70.52, f1: 69.88
loss: 0.2835, acc: 90.93, test_acc: 72.25, f1: 70.67
loss: 0.1093, acc: 91.06, test_acc: 71.53, f1: 70.67
loss: 0.3473, acc: 91.01, test_acc: 70.52, f1: 70.07
loss: 0.5223, acc: 90.88, test_acc: 72.83, f1: 71.77
loss: 0.1990, acc: 90.83, test_acc: 73.41, f1: 71.73
loss: 0.2948, acc: 90.79, test_acc: 71.10, f1: 70.18
loss: 0.4611, acc: 90.58, test_acc: 69.51, f1: 68.90
loss: 0.5657, acc: 90.46, test_acc: 69.80, f1: 69.58
####################################################################################################
max_test_acc_overall:75.57803468208093
max_f1_overall:74.18795146688367
####################################################################################################
1 test_acc_overall: 77.89  f1_overall:77.02
2 test_acc_overall: 75.58  f1_overall:74.19
max_acc_overall:77.89  f1_overall:77.02
mean_acc_overall:76.73  mean_f1_overall:75.61
####################################################################################################
lcf_bert - twitter - cdm - No.3 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 2
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc50.0
max_acc:50.0  f1:22.22
loss: 0.9938, acc: 31.25, test_acc: 50.00, f1: 22.22
loss: 1.0269, acc: 50.00, test_acc: 50.00, f1: 22.22
loss: 1.0596, acc: 50.00, test_acc: 28.76, f1: 18.94
loss: 1.1308, acc: 48.44, test_acc: 50.00, f1: 22.22
loss: 0.9626, acc: 50.00, test_acc: 50.00, f1: 22.22
loss: 1.0433, acc: 48.96, test_acc: 33.82, f1: 24.61
>> saved: state_dict/lcf_bert_twitter_acc51.16
max_acc:51.16  f1:26.65
loss: 1.0168, acc: 50.89, test_acc: 51.16, f1: 26.65
loss: 1.1200, acc: 50.00, test_acc: 49.86, f1: 22.22
loss: 0.9876, acc: 49.31, test_acc: 50.43, f1: 23.42
loss: 1.0692, acc: 47.50, test_acc: 50.87, f1: 37.75
>> saved: state_dict/lcf_bert_twitter_acc55.06
max_acc:55.06  f1:37.47
loss: 1.0328, acc: 48.30, test_acc: 55.06, f1: 37.47
loss: 0.9351, acc: 48.96, test_acc: 52.46, f1: 28.82
loss: 1.0142, acc: 48.08, test_acc: 54.62, f1: 35.51
>> saved: state_dict/lcf_bert_twitter_acc62.28
max_acc:62.28  f1:58.41
loss: 0.8527, acc: 49.11, test_acc: 62.28, f1: 58.41
loss: 1.0957, acc: 49.17, test_acc: 58.24, f1: 47.31
loss: 1.0462, acc: 48.83, test_acc: 61.42, f1: 57.16
loss: 0.8201, acc: 49.26, test_acc: 56.50, f1: 56.83
loss: 0.7999, acc: 50.00, test_acc: 59.97, f1: 51.73
>> saved: state_dict/lcf_bert_twitter_acc65.03
max_acc:65.03  f1:61.64
loss: 0.7558, acc: 50.33, test_acc: 65.03, f1: 61.64
loss: 0.6521, acc: 50.94, test_acc: 64.31, f1: 64.11
>> saved: state_dict/lcf_bert_twitter_acc65.17
max_acc:65.17  f1:63.03
loss: 0.9785, acc: 50.89, test_acc: 65.17, f1: 63.03
loss: 0.8894, acc: 51.14, test_acc: 65.03, f1: 64.90
loss: 0.6941, acc: 51.63, test_acc: 60.40, f1: 61.33
loss: 0.7842, acc: 52.34, test_acc: 62.43, f1: 61.21
>> saved: state_dict/lcf_bert_twitter_acc68.93
max_acc:68.93  f1:65.81
loss: 0.5766, acc: 53.00, test_acc: 68.93, f1: 65.81
>> saved: state_dict/lcf_bert_twitter_acc69.36
max_acc:69.36  f1:66.73
loss: 0.7223, acc: 53.85, test_acc: 69.36, f1: 66.73
loss: 0.6826, acc: 54.63, test_acc: 67.20, f1: 66.09
loss: 0.8096, acc: 54.46, test_acc: 67.63, f1: 67.13
loss: 0.7073, acc: 54.96, test_acc: 65.32, f1: 65.87
loss: 0.5220, acc: 55.83, test_acc: 68.64, f1: 66.47
loss: 0.6717, acc: 56.65, test_acc: 67.05, f1: 59.52
loss: 0.5938, acc: 57.42, test_acc: 69.08, f1: 67.33
loss: 0.8168, acc: 57.77, test_acc: 69.22, f1: 68.20
loss: 0.2109, acc: 58.64, test_acc: 62.86, f1: 62.02
>> saved: state_dict/lcf_bert_twitter_acc70.52
max_acc:70.52  f1:69.74
loss: 0.8839, acc: 58.21, test_acc: 70.52, f1: 69.74
loss: 0.6981, acc: 58.51, test_acc: 68.21, f1: 66.66
>> saved: state_dict/lcf_bert_twitter_acc70.81
max_acc:70.81  f1:68.99
loss: 0.8635, acc: 58.45, test_acc: 70.81, f1: 68.99
loss: 0.6616, acc: 58.88, test_acc: 69.94, f1: 69.52
>> saved: state_dict/lcf_bert_twitter_acc72.4
max_acc:72.4  f1:70.92
loss: 0.7245, acc: 59.29, test_acc: 72.40, f1: 70.92
loss: 0.6549, acc: 59.84, test_acc: 72.40, f1: 71.46
loss: 0.8228, acc: 60.06, test_acc: 70.81, f1: 70.28
>> saved: state_dict/lcf_bert_twitter_acc73.12
max_acc:73.12  f1:71.62
loss: 0.6338, acc: 60.27, test_acc: 73.12, f1: 71.62
loss: 1.0962, acc: 60.32, test_acc: 69.80, f1: 65.90
loss: 0.7204, acc: 60.51, test_acc: 72.98, f1: 72.19
loss: 0.5562, acc: 60.97, test_acc: 73.12, f1: 72.36
loss: 0.8798, acc: 61.14, test_acc: 69.08, f1: 68.90
loss: 0.9726, acc: 60.77, test_acc: 70.38, f1: 67.81
loss: 0.7951, acc: 60.68, test_acc: 67.49, f1: 63.17
loss: 0.5752, acc: 61.10, test_acc: 69.51, f1: 69.15
loss: 0.4061, acc: 61.62, test_acc: 72.40, f1: 71.62
loss: 0.5678, acc: 62.01, test_acc: 72.40, f1: 71.66
loss: 0.7505, acc: 62.14, test_acc: 72.83, f1: 72.02
loss: 0.4922, acc: 62.38, test_acc: 72.98, f1: 70.64
>> saved: state_dict/lcf_bert_twitter_acc74.28
max_acc:74.28  f1:73.12
loss: 0.6271, acc: 62.38, test_acc: 74.28, f1: 73.12
loss: 0.6281, acc: 62.61, test_acc: 72.98, f1: 72.29
loss: 0.8224, acc: 62.61, test_acc: 72.40, f1: 70.69
loss: 0.5559, acc: 62.83, test_acc: 73.55, f1: 72.76
>> saved: state_dict/lcf_bert_twitter_acc74.86
max_acc:74.86  f1:73.23
loss: 0.6207, acc: 63.04, test_acc: 74.86, f1: 73.23
loss: 0.6969, acc: 63.24, test_acc: 73.27, f1: 71.13
>> saved: state_dict/lcf_bert_twitter_acc75.43
max_acc:75.43  f1:74.12
loss: 0.4815, acc: 63.54, test_acc: 75.43, f1: 74.12
loss: 0.6447, acc: 63.63, test_acc: 73.55, f1: 72.61
loss: 0.4620, acc: 64.01, test_acc: 69.80, f1: 69.71
loss: 0.6735, acc: 64.09, test_acc: 74.71, f1: 73.55
>> saved: state_dict/lcf_bert_twitter_acc75.72
max_acc:75.72  f1:74.68
loss: 0.4214, acc: 64.45, test_acc: 75.72, f1: 74.68
loss: 0.5736, acc: 64.71, test_acc: 75.14, f1: 73.99
loss: 0.5014, acc: 65.06, test_acc: 73.55, f1: 72.91
loss: 0.4730, acc: 65.39, test_acc: 75.14, f1: 73.00
loss: 0.6217, acc: 65.53, test_acc: 74.28, f1: 72.97
loss: 0.6698, acc: 65.67, test_acc: 71.82, f1: 70.88
loss: 0.7339, acc: 65.71, test_acc: 69.94, f1: 69.90
loss: 0.9479, acc: 65.67, test_acc: 70.81, f1: 70.33
loss: 0.6992, acc: 65.89, test_acc: 72.69, f1: 69.37
loss: 0.4083, acc: 66.18, test_acc: 73.99, f1: 72.26
loss: 0.5914, acc: 66.39, test_acc: 70.23, f1: 70.12
loss: 0.6419, acc: 66.42, test_acc: 63.73, f1: 64.05
loss: 0.7720, acc: 66.45, test_acc: 73.70, f1: 73.08
loss: 0.7146, acc: 66.56, test_acc: 73.70, f1: 71.14
loss: 1.0053, acc: 66.35, test_acc: 75.43, f1: 73.42
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.7813, acc: 81.25, test_acc: 68.50, f1: 68.37
loss: 0.5084, acc: 78.12, test_acc: 74.28, f1: 73.70
loss: 0.6588, acc: 77.08, test_acc: 73.12, f1: 72.58
loss: 0.1484, acc: 82.81, test_acc: 71.97, f1: 71.74
loss: 0.3469, acc: 82.50, test_acc: 74.57, f1: 73.45
>> saved: state_dict/lcf_bert_twitter_acc75.87
max_acc:75.87  f1:73.99
loss: 0.2936, acc: 84.38, test_acc: 75.87, f1: 73.99
>> saved: state_dict/lcf_bert_twitter_acc76.45
max_acc:76.45  f1:74.21
loss: 0.1859, acc: 85.71, test_acc: 76.45, f1: 74.21
loss: 0.6253, acc: 84.38, test_acc: 71.97, f1: 71.53
loss: 0.4383, acc: 84.72, test_acc: 70.66, f1: 70.55
loss: 0.3253, acc: 85.00, test_acc: 75.43, f1: 72.79
loss: 0.4004, acc: 84.66, test_acc: 76.16, f1: 74.05
loss: 0.4753, acc: 83.85, test_acc: 74.28, f1: 72.88
loss: 0.4360, acc: 83.65, test_acc: 70.52, f1: 70.27
loss: 0.2733, acc: 83.93, test_acc: 74.13, f1: 73.16
loss: 0.5637, acc: 83.75, test_acc: 74.13, f1: 73.08
loss: 0.3600, acc: 83.98, test_acc: 71.97, f1: 71.33
loss: 0.7797, acc: 83.09, test_acc: 74.71, f1: 72.57
loss: 0.3328, acc: 83.33, test_acc: 72.25, f1: 70.26
loss: 0.6852, acc: 82.57, test_acc: 68.21, f1: 68.41
loss: 0.6917, acc: 82.19, test_acc: 66.91, f1: 67.00
loss: 0.4581, acc: 81.85, test_acc: 72.98, f1: 70.87
loss: 0.5401, acc: 81.53, test_acc: 73.55, f1: 71.74
loss: 0.4783, acc: 81.52, test_acc: 71.97, f1: 70.77
loss: 0.2927, acc: 82.29, test_acc: 71.53, f1: 70.46
loss: 0.5201, acc: 82.00, test_acc: 69.36, f1: 68.92
loss: 0.4901, acc: 81.97, test_acc: 75.00, f1: 73.43
loss: 0.3832, acc: 82.18, test_acc: 71.10, f1: 70.76
loss: 0.1306, acc: 82.81, test_acc: 72.11, f1: 71.44
loss: 0.3542, acc: 83.19, test_acc: 72.25, f1: 71.26
loss: 0.2624, acc: 83.54, test_acc: 72.83, f1: 71.78
loss: 0.5684, acc: 83.27, test_acc: 72.54, f1: 72.05
loss: 0.3456, acc: 83.20, test_acc: 70.66, f1: 70.41
loss: 0.7184, acc: 82.95, test_acc: 74.42, f1: 72.35
loss: 0.5484, acc: 82.90, test_acc: 72.83, f1: 71.83
loss: 0.2801, acc: 83.21, test_acc: 68.21, f1: 68.37
loss: 0.9311, acc: 82.47, test_acc: 72.54, f1: 71.53
loss: 0.4275, acc: 82.60, test_acc: 72.98, f1: 69.41
loss: 0.5592, acc: 82.07, test_acc: 73.70, f1: 72.02
loss: 0.7452, acc: 81.57, test_acc: 68.35, f1: 68.70
loss: 0.4725, acc: 81.56, test_acc: 71.24, f1: 71.05
loss: 0.6487, acc: 81.10, test_acc: 75.14, f1: 73.64
loss: 0.4282, acc: 81.10, test_acc: 74.57, f1: 73.18
loss: 0.5300, acc: 80.81, test_acc: 72.54, f1: 72.22
loss: 0.2489, acc: 81.11, test_acc: 75.29, f1: 74.30
loss: 0.4985, acc: 81.25, test_acc: 74.57, f1: 72.86
loss: 0.4638, acc: 81.39, test_acc: 75.14, f1: 73.63
loss: 0.4887, acc: 81.25, test_acc: 74.86, f1: 73.53
loss: 0.5126, acc: 81.12, test_acc: 73.12, f1: 71.96
loss: 0.1738, acc: 81.51, test_acc: 73.41, f1: 72.33
loss: 0.3176, acc: 81.50, test_acc: 72.11, f1: 71.40
loss: 0.2465, acc: 81.74, test_acc: 73.70, f1: 72.98
loss: 0.3003, acc: 81.85, test_acc: 74.13, f1: 72.10
loss: 0.3717, acc: 81.72, test_acc: 74.28, f1: 72.56
loss: 0.3527, acc: 81.83, test_acc: 71.53, f1: 70.88
loss: 0.7339, acc: 81.70, test_acc: 73.41, f1: 72.04
loss: 0.1759, acc: 82.03, test_acc: 73.70, f1: 72.16
loss: 0.5114, acc: 81.91, test_acc: 70.09, f1: 69.51
loss: 0.2358, acc: 82.22, test_acc: 74.57, f1: 73.11
loss: 0.7588, acc: 82.10, test_acc: 75.00, f1: 73.22
loss: 0.4760, acc: 82.08, test_acc: 73.55, f1: 72.89
loss: 0.7064, acc: 81.76, test_acc: 68.50, f1: 68.83
loss: 0.7223, acc: 81.55, test_acc: 74.86, f1: 73.75
loss: 0.5915, acc: 81.55, test_acc: 75.72, f1: 74.09
loss: 0.2539, acc: 81.64, test_acc: 75.00, f1: 73.19
loss: 0.5228, acc: 81.44, test_acc: 75.72, f1: 74.30
loss: 0.4727, acc: 81.34, test_acc: 74.13, f1: 73.83
loss: 0.3918, acc: 81.44, test_acc: 75.00, f1: 74.25
loss: 0.7123, acc: 81.34, test_acc: 75.00, f1: 73.30
loss: 0.3020, acc: 81.52, test_acc: 74.28, f1: 72.40
loss: 0.3454, acc: 81.70, test_acc: 69.80, f1: 69.62
loss: 0.5422, acc: 81.69, test_acc: 71.97, f1: 71.93
loss: 0.8954, acc: 81.42, test_acc: 74.13, f1: 73.43
loss: 0.5809, acc: 81.34, test_acc: 72.54, f1: 71.85
loss: 0.3427, acc: 81.50, test_acc: 72.54, f1: 71.95
loss: 0.2253, acc: 81.67, test_acc: 71.97, f1: 71.66
loss: 0.3873, acc: 81.74, test_acc: 72.25, f1: 71.85
loss: 0.4326, acc: 81.74, test_acc: 74.71, f1: 73.39
loss: 0.2004, acc: 81.89, test_acc: 74.57, f1: 73.63
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1863, acc: 93.75, test_acc: 73.84, f1: 73.27
loss: 0.1297, acc: 96.88, test_acc: 73.99, f1: 73.11
loss: 0.3942, acc: 93.75, test_acc: 73.41, f1: 72.77
loss: 0.4134, acc: 90.62, test_acc: 74.57, f1: 73.62
loss: 0.2482, acc: 90.00, test_acc: 72.83, f1: 72.24
loss: 0.1231, acc: 90.62, test_acc: 74.28, f1: 73.45
loss: 0.2946, acc: 90.18, test_acc: 74.42, f1: 73.40
loss: 0.1417, acc: 90.62, test_acc: 74.28, f1: 73.00
loss: 0.0559, acc: 91.67, test_acc: 73.70, f1: 72.80
loss: 0.2061, acc: 91.88, test_acc: 71.53, f1: 71.42
loss: 0.0546, acc: 92.61, test_acc: 73.99, f1: 73.18
loss: 0.2971, acc: 92.19, test_acc: 73.12, f1: 72.02
loss: 0.1923, acc: 92.31, test_acc: 74.57, f1: 73.14
loss: 0.1959, acc: 92.41, test_acc: 70.81, f1: 70.40
loss: 0.1777, acc: 92.50, test_acc: 70.38, f1: 70.29
loss: 0.0941, acc: 92.97, test_acc: 73.99, f1: 72.54
loss: 0.1084, acc: 93.38, test_acc: 74.71, f1: 72.99
loss: 0.2366, acc: 93.40, test_acc: 71.68, f1: 71.47
loss: 0.0986, acc: 93.75, test_acc: 69.94, f1: 70.29
loss: 0.2538, acc: 93.75, test_acc: 71.10, f1: 70.89
loss: 0.2091, acc: 93.75, test_acc: 74.86, f1: 73.25
loss: 0.1734, acc: 93.75, test_acc: 74.42, f1: 72.73
loss: 0.3059, acc: 93.75, test_acc: 70.52, f1: 70.49
loss: 0.5881, acc: 92.97, test_acc: 70.66, f1: 70.47
loss: 0.4251, acc: 92.00, test_acc: 72.98, f1: 69.98
loss: 0.5074, acc: 91.59, test_acc: 74.86, f1: 73.32
loss: 0.3888, acc: 91.44, test_acc: 73.27, f1: 72.61
loss: 0.1306, acc: 91.52, test_acc: 73.99, f1: 72.23
loss: 0.1222, acc: 91.81, test_acc: 73.99, f1: 72.69
loss: 0.4714, acc: 91.25, test_acc: 75.14, f1: 74.02
loss: 0.1220, acc: 91.33, test_acc: 75.43, f1: 74.50
loss: 0.1089, acc: 91.60, test_acc: 72.54, f1: 72.30
loss: 0.2084, acc: 91.67, test_acc: 74.57, f1: 73.20
loss: 0.2033, acc: 91.54, test_acc: 74.28, f1: 73.15
loss: 0.4956, acc: 91.25, test_acc: 74.13, f1: 72.75
loss: 0.2098, acc: 91.32, test_acc: 71.82, f1: 71.18
loss: 0.1389, acc: 91.39, test_acc: 72.83, f1: 72.15
loss: 0.2805, acc: 90.95, test_acc: 72.11, f1: 71.65
loss: 0.2877, acc: 91.03, test_acc: 72.83, f1: 72.16
loss: 0.2022, acc: 90.94, test_acc: 74.57, f1: 73.36
loss: 0.3241, acc: 91.01, test_acc: 75.00, f1: 73.54
loss: 0.1506, acc: 91.07, test_acc: 74.71, f1: 73.63
loss: 0.6216, acc: 90.84, test_acc: 75.72, f1: 74.26
loss: 0.5764, acc: 90.91, test_acc: 73.99, f1: 73.39
loss: 0.2746, acc: 90.83, test_acc: 73.84, f1: 72.67
loss: 0.1042, acc: 91.03, test_acc: 74.57, f1: 73.74
loss: 0.3991, acc: 90.69, test_acc: 72.40, f1: 72.04
loss: 0.2326, acc: 90.49, test_acc: 74.71, f1: 73.48
loss: 0.2188, acc: 90.56, test_acc: 72.98, f1: 72.15
loss: 0.1905, acc: 90.50, test_acc: 72.54, f1: 72.11
loss: 0.1193, acc: 90.69, test_acc: 71.68, f1: 71.28
loss: 0.5012, acc: 90.62, test_acc: 73.70, f1: 72.64
loss: 0.4720, acc: 90.45, test_acc: 72.98, f1: 72.08
loss: 0.0496, acc: 90.62, test_acc: 69.65, f1: 69.03
loss: 0.2245, acc: 90.57, test_acc: 73.70, f1: 72.61
loss: 0.3543, acc: 90.40, test_acc: 75.00, f1: 73.51
loss: 0.2598, acc: 90.46, test_acc: 73.55, f1: 72.76
loss: 0.2143, acc: 90.41, test_acc: 73.27, f1: 72.69
loss: 0.0341, acc: 90.57, test_acc: 73.12, f1: 70.96
loss: 0.2142, acc: 90.52, test_acc: 73.70, f1: 71.24
loss: 0.3246, acc: 90.37, test_acc: 73.84, f1: 72.36
loss: 0.3780, acc: 90.22, test_acc: 70.81, f1: 70.61
loss: 0.2921, acc: 90.08, test_acc: 69.08, f1: 69.12
loss: 0.1366, acc: 90.23, test_acc: 73.84, f1: 71.62
loss: 0.6150, acc: 90.10, test_acc: 72.98, f1: 70.20
loss: 0.0783, acc: 90.25, test_acc: 73.41, f1: 72.40
loss: 0.2828, acc: 90.21, test_acc: 70.38, f1: 70.02
loss: 0.2325, acc: 90.26, test_acc: 71.68, f1: 71.07
loss: 0.0263, acc: 90.40, test_acc: 73.99, f1: 72.39
loss: 0.3767, acc: 90.27, test_acc: 73.27, f1: 72.01
loss: 0.8594, acc: 90.05, test_acc: 73.12, f1: 71.34
loss: 0.5477, acc: 90.10, test_acc: 71.97, f1: 70.22
loss: 0.1859, acc: 90.15, test_acc: 73.84, f1: 72.41
loss: 0.5005, acc: 89.95, test_acc: 72.83, f1: 71.13
loss: 0.2352, acc: 89.92, test_acc: 72.11, f1: 70.44
loss: 0.1693, acc: 90.05, test_acc: 74.42, f1: 73.47
loss: 0.2570, acc: 90.02, test_acc: 74.28, f1: 73.55
loss: 0.0711, acc: 90.14, test_acc: 74.86, f1: 74.12
####################################################################################################
max_test_acc_overall:76.44508670520231
max_f1_overall:74.67586515664907
####################################################################################################
1 test_acc_overall: 77.89  f1_overall:77.02
2 test_acc_overall: 75.58  f1_overall:74.19
3 test_acc_overall: 76.45  f1_overall:74.68
max_acc_overall:77.89  f1_overall:77.02
mean_acc_overall:76.64  mean_f1_overall:75.3
####################################################################################################
lcf_bert - twitter - cdm - No.4 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 3
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc46.97
max_acc:46.97  f1:29.95
loss: 1.2910, acc: 37.50, test_acc: 46.97, f1: 29.95
>> saved: state_dict/lcf_bert_twitter_acc50.0
max_acc:50.0  f1:22.22
loss: 0.9147, acc: 46.88, test_acc: 50.00, f1: 22.22
loss: 1.1411, acc: 47.92, test_acc: 50.00, f1: 22.22
loss: 0.8614, acc: 51.56, test_acc: 50.00, f1: 22.22
>> saved: state_dict/lcf_bert_twitter_acc50.14
max_acc:50.14  f1:22.63
loss: 0.8434, acc: 53.75, test_acc: 50.14, f1: 22.63
>> saved: state_dict/lcf_bert_twitter_acc51.16
max_acc:51.16  f1:27.43
loss: 1.0481, acc: 50.00, test_acc: 51.16, f1: 27.43
loss: 0.9682, acc: 51.79, test_acc: 49.71, f1: 22.14
loss: 1.0357, acc: 52.34, test_acc: 50.00, f1: 22.22
>> saved: state_dict/lcf_bert_twitter_acc51.73
max_acc:51.73  f1:28.56
loss: 1.0707, acc: 51.39, test_acc: 51.73, f1: 28.56
>> saved: state_dict/lcf_bert_twitter_acc55.49
max_acc:55.49  f1:43.58
loss: 1.0228, acc: 52.50, test_acc: 55.49, f1: 43.58
loss: 0.9896, acc: 52.27, test_acc: 50.14, f1: 22.99
loss: 0.9919, acc: 52.60, test_acc: 52.75, f1: 33.13
loss: 1.0819, acc: 50.96, test_acc: 55.49, f1: 44.22
>> saved: state_dict/lcf_bert_twitter_acc57.8
max_acc:57.8  f1:45.15
loss: 1.0224, acc: 50.89, test_acc: 57.80, f1: 45.15
loss: 1.2816, acc: 49.58, test_acc: 56.50, f1: 41.44
>> saved: state_dict/lcf_bert_twitter_acc58.67
max_acc:58.67  f1:58.97
loss: 0.8225, acc: 51.56, test_acc: 58.67, f1: 58.97
>> saved: state_dict/lcf_bert_twitter_acc61.42
max_acc:61.42  f1:59.56
loss: 0.7137, acc: 52.57, test_acc: 61.42, f1: 59.56
>> saved: state_dict/lcf_bert_twitter_acc63.15
max_acc:63.15  f1:57.34
loss: 0.6599, acc: 54.17, test_acc: 63.15, f1: 57.34
loss: 0.9208, acc: 53.95, test_acc: 61.71, f1: 61.04
loss: 0.9850, acc: 53.75, test_acc: 60.12, f1: 58.33
>> saved: state_dict/lcf_bert_twitter_acc64.31
max_acc:64.31  f1:60.53
loss: 0.8169, acc: 54.17, test_acc: 64.31, f1: 60.53
loss: 0.7949, acc: 54.83, test_acc: 58.67, f1: 59.34
loss: 0.9943, acc: 54.62, test_acc: 54.91, f1: 55.05
loss: 0.8710, acc: 54.95, test_acc: 58.38, f1: 45.85
loss: 0.8940, acc: 54.75, test_acc: 62.86, f1: 53.93
>> saved: state_dict/lcf_bert_twitter_acc66.33
max_acc:66.33  f1:65.09
loss: 0.7601, acc: 55.77, test_acc: 66.33, f1: 65.09
loss: 0.4479, acc: 57.18, test_acc: 66.04, f1: 62.54
>> saved: state_dict/lcf_bert_twitter_acc67.05
max_acc:67.05  f1:61.93
loss: 0.7452, acc: 57.37, test_acc: 67.05, f1: 61.93
loss: 1.0963, acc: 57.54, test_acc: 63.15, f1: 62.66
loss: 1.0094, acc: 57.29, test_acc: 58.82, f1: 59.87
>> saved: state_dict/lcf_bert_twitter_acc68.93
max_acc:68.93  f1:66.23
loss: 0.8635, acc: 57.66, test_acc: 68.93, f1: 66.23
loss: 1.0247, acc: 57.42, test_acc: 66.33, f1: 58.98
loss: 0.5443, acc: 58.33, test_acc: 68.64, f1: 67.00
loss: 0.8270, acc: 58.09, test_acc: 63.01, f1: 63.42
loss: 0.6336, acc: 58.04, test_acc: 68.50, f1: 67.16
>> saved: state_dict/lcf_bert_twitter_acc71.39
max_acc:71.39  f1:68.58
loss: 0.6913, acc: 58.33, test_acc: 71.39, f1: 68.58
loss: 0.8391, acc: 58.28, test_acc: 70.23, f1: 68.75
loss: 0.8020, acc: 58.55, test_acc: 67.34, f1: 67.43
loss: 0.7051, acc: 58.97, test_acc: 68.35, f1: 67.18
loss: 0.4718, acc: 59.53, test_acc: 71.39, f1: 68.80
>> saved: state_dict/lcf_bert_twitter_acc72.25
max_acc:72.25  f1:70.6
loss: 0.4910, acc: 60.06, test_acc: 72.25, f1: 70.60
loss: 0.6443, acc: 60.12, test_acc: 67.20, f1: 67.31
loss: 0.5056, acc: 60.61, test_acc: 67.49, f1: 67.68
loss: 0.8559, acc: 60.51, test_acc: 71.97, f1: 70.39
loss: 0.5987, acc: 60.83, test_acc: 70.23, f1: 69.44
loss: 0.5259, acc: 61.28, test_acc: 71.68, f1: 70.63
loss: 0.5362, acc: 61.70, test_acc: 71.39, f1: 70.06
loss: 1.0478, acc: 61.46, test_acc: 71.24, f1: 70.55
loss: 0.9227, acc: 61.48, test_acc: 67.63, f1: 67.74
loss: 0.7954, acc: 61.75, test_acc: 68.64, f1: 68.41
loss: 0.9128, acc: 61.76, test_acc: 70.38, f1: 69.48
loss: 0.9001, acc: 61.66, test_acc: 71.68, f1: 70.09
loss: 0.6090, acc: 61.79, test_acc: 72.25, f1: 70.89
loss: 0.6589, acc: 62.15, test_acc: 71.39, f1: 70.64
loss: 0.5838, acc: 62.50, test_acc: 70.81, f1: 69.75
loss: 0.5231, acc: 62.95, test_acc: 70.66, f1: 69.63
loss: 0.6848, acc: 63.05, test_acc: 71.68, f1: 68.46
>> saved: state_dict/lcf_bert_twitter_acc72.54
max_acc:72.54  f1:70.47
loss: 0.8869, acc: 63.25, test_acc: 72.54, f1: 70.47
loss: 0.8640, acc: 63.24, test_acc: 68.93, f1: 68.69
loss: 0.7169, acc: 63.44, test_acc: 68.35, f1: 68.41
loss: 0.5463, acc: 63.73, test_acc: 72.54, f1: 69.35
>> saved: state_dict/lcf_bert_twitter_acc72.83
max_acc:72.83  f1:70.0
loss: 0.7528, acc: 63.81, test_acc: 72.83, f1: 70.00
loss: 0.5862, acc: 63.99, test_acc: 64.74, f1: 65.43
loss: 0.9912, acc: 63.57, test_acc: 67.63, f1: 68.28
>> saved: state_dict/lcf_bert_twitter_acc73.12
max_acc:73.12  f1:70.24
loss: 0.5659, acc: 63.75, test_acc: 73.12, f1: 70.24
>> saved: state_dict/lcf_bert_twitter_acc73.84
max_acc:73.84  f1:70.91
loss: 0.3153, acc: 64.11, test_acc: 73.84, f1: 70.91
>> saved: state_dict/lcf_bert_twitter_acc74.28
max_acc:74.28  f1:72.43
loss: 0.7713, acc: 64.18, test_acc: 74.28, f1: 72.43
loss: 0.3960, acc: 64.43, test_acc: 70.23, f1: 70.33
loss: 0.7969, acc: 64.31, test_acc: 70.09, f1: 70.26
>> saved: state_dict/lcf_bert_twitter_acc74.57
max_acc:74.57  f1:72.65
loss: 0.4016, acc: 64.55, test_acc: 74.57, f1: 72.65
loss: 0.8715, acc: 64.44, test_acc: 73.84, f1: 71.83
loss: 0.5027, acc: 64.67, test_acc: 71.24, f1: 70.08
loss: 0.6369, acc: 64.81, test_acc: 73.99, f1: 72.23
loss: 0.5745, acc: 65.03, test_acc: 73.12, f1: 70.88
loss: 0.6170, acc: 65.25, test_acc: 70.09, f1: 69.68
loss: 0.7785, acc: 65.05, test_acc: 66.18, f1: 66.78
>> saved: state_dict/lcf_bert_twitter_acc74.86
max_acc:74.86  f1:73.11
loss: 0.7650, acc: 65.10, test_acc: 74.86, f1: 73.11
loss: 0.4726, acc: 65.22, test_acc: 72.11, f1: 68.52
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.4263, acc: 81.25, test_acc: 72.11, f1: 70.64
loss: 0.3480, acc: 81.25, test_acc: 66.33, f1: 66.25
loss: 0.8280, acc: 77.08, test_acc: 67.92, f1: 67.22
loss: 0.4292, acc: 78.12, test_acc: 70.95, f1: 69.78
loss: 0.3364, acc: 80.00, test_acc: 71.68, f1: 70.49
loss: 0.1918, acc: 83.33, test_acc: 72.98, f1: 71.83
loss: 0.2271, acc: 84.82, test_acc: 71.53, f1: 70.90
loss: 0.3501, acc: 85.16, test_acc: 68.50, f1: 68.75
loss: 0.1976, acc: 86.81, test_acc: 71.68, f1: 71.31
loss: 0.6744, acc: 85.62, test_acc: 74.13, f1: 72.74
loss: 0.2464, acc: 86.36, test_acc: 70.95, f1: 70.74
loss: 0.3646, acc: 85.94, test_acc: 71.53, f1: 71.36
loss: 0.6144, acc: 85.10, test_acc: 72.54, f1: 71.50
loss: 0.3726, acc: 84.82, test_acc: 70.66, f1: 70.31
loss: 0.5973, acc: 84.58, test_acc: 67.92, f1: 67.89
loss: 0.3600, acc: 84.77, test_acc: 70.38, f1: 70.04
loss: 0.4611, acc: 84.56, test_acc: 72.40, f1: 70.50
loss: 0.6434, acc: 83.68, test_acc: 72.54, f1: 71.06
loss: 0.2217, acc: 84.21, test_acc: 72.54, f1: 71.92
loss: 0.7183, acc: 83.44, test_acc: 71.39, f1: 70.77
loss: 0.3087, acc: 83.93, test_acc: 70.66, f1: 70.62
loss: 0.6564, acc: 83.52, test_acc: 74.57, f1: 73.15
loss: 0.5413, acc: 83.70, test_acc: 74.42, f1: 73.14
>> saved: state_dict/lcf_bert_twitter_acc75.0
max_acc:75.0  f1:73.72
loss: 0.1668, acc: 84.38, test_acc: 75.00, f1: 73.72
loss: 0.2684, acc: 85.00, test_acc: 68.21, f1: 68.08
loss: 0.3099, acc: 85.10, test_acc: 69.65, f1: 69.44
loss: 1.0014, acc: 84.03, test_acc: 71.97, f1: 71.76
loss: 0.4134, acc: 83.93, test_acc: 73.70, f1: 72.51
loss: 0.3348, acc: 84.27, test_acc: 74.13, f1: 71.25
loss: 0.2779, acc: 84.58, test_acc: 74.57, f1: 72.77
loss: 0.4865, acc: 84.27, test_acc: 68.64, f1: 68.90
loss: 0.3023, acc: 84.57, test_acc: 70.38, f1: 70.13
loss: 0.5942, acc: 84.09, test_acc: 74.57, f1: 72.28
loss: 0.5847, acc: 84.19, test_acc: 71.97, f1: 69.95
loss: 0.3701, acc: 84.11, test_acc: 73.12, f1: 72.39
loss: 0.6137, acc: 83.85, test_acc: 71.82, f1: 71.21
loss: 0.2413, acc: 84.12, test_acc: 74.42, f1: 73.32
loss: 0.5848, acc: 83.88, test_acc: 74.28, f1: 73.53
loss: 0.8064, acc: 83.49, test_acc: 74.71, f1: 73.74
loss: 0.4752, acc: 83.59, test_acc: 74.28, f1: 72.95
loss: 0.7091, acc: 83.54, test_acc: 73.55, f1: 72.88
loss: 0.4860, acc: 83.33, test_acc: 72.40, f1: 71.98
loss: 0.5815, acc: 82.99, test_acc: 73.70, f1: 72.51
loss: 0.6327, acc: 82.67, test_acc: 73.12, f1: 72.25
loss: 0.4251, acc: 82.78, test_acc: 73.12, f1: 72.47
loss: 0.2769, acc: 83.02, test_acc: 73.99, f1: 72.98
loss: 0.4824, acc: 82.98, test_acc: 74.28, f1: 72.97
loss: 0.3861, acc: 82.94, test_acc: 73.41, f1: 72.15
loss: 0.7699, acc: 82.65, test_acc: 71.97, f1: 71.52
loss: 0.6365, acc: 82.50, test_acc: 72.25, f1: 71.44
loss: 0.6005, acc: 82.48, test_acc: 73.27, f1: 72.43
loss: 0.8114, acc: 82.09, test_acc: 71.68, f1: 71.20
loss: 0.4133, acc: 81.84, test_acc: 73.84, f1: 72.21
loss: 0.3074, acc: 82.06, test_acc: 74.57, f1: 72.57
loss: 0.7276, acc: 81.82, test_acc: 73.55, f1: 71.29
loss: 1.2093, acc: 81.36, test_acc: 72.11, f1: 71.08
loss: 0.4596, acc: 81.47, test_acc: 73.70, f1: 72.35
loss: 0.3740, acc: 81.47, test_acc: 74.28, f1: 73.00
loss: 0.2789, acc: 81.67, test_acc: 73.84, f1: 72.59
loss: 0.7384, acc: 81.56, test_acc: 74.28, f1: 72.41
loss: 0.7840, acc: 81.25, test_acc: 71.68, f1: 70.97
loss: 0.6855, acc: 81.25, test_acc: 71.24, f1: 70.22
loss: 0.3964, acc: 81.15, test_acc: 73.12, f1: 71.68
loss: 0.7502, acc: 81.05, test_acc: 71.24, f1: 70.81
loss: 0.4975, acc: 81.06, test_acc: 67.63, f1: 67.56
loss: 0.4483, acc: 81.06, test_acc: 70.52, f1: 70.51
loss: 0.6864, acc: 81.06, test_acc: 73.12, f1: 71.19
loss: 0.4658, acc: 81.16, test_acc: 74.28, f1: 72.04
loss: 0.5380, acc: 80.98, test_acc: 71.53, f1: 71.46
loss: 0.4187, acc: 80.98, test_acc: 68.93, f1: 69.16
>> saved: state_dict/lcf_bert_twitter_acc75.29
max_acc:75.29  f1:74.55
loss: 0.3685, acc: 80.99, test_acc: 75.29, f1: 74.55
loss: 0.5009, acc: 80.82, test_acc: 73.99, f1: 71.64
loss: 0.4361, acc: 80.91, test_acc: 74.71, f1: 73.30
>> saved: state_dict/lcf_bert_twitter_acc75.87
max_acc:75.87  f1:74.68
loss: 0.4573, acc: 80.83, test_acc: 75.87, f1: 74.68
loss: 0.5545, acc: 80.83, test_acc: 75.72, f1: 74.84
loss: 0.4800, acc: 80.84, test_acc: 75.58, f1: 74.75
loss: 0.6588, acc: 80.60, test_acc: 73.12, f1: 72.57
loss: 0.5180, acc: 80.61, test_acc: 68.06, f1: 68.41
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.6188, acc: 87.50, test_acc: 73.70, f1: 72.33
loss: 0.3974, acc: 87.50, test_acc: 73.41, f1: 71.80
loss: 0.2503, acc: 89.58, test_acc: 71.68, f1: 70.99
loss: 0.2148, acc: 90.62, test_acc: 72.40, f1: 71.52
loss: 0.0940, acc: 92.50, test_acc: 72.83, f1: 71.60
loss: 0.1177, acc: 92.71, test_acc: 73.84, f1: 72.16
loss: 0.2466, acc: 92.86, test_acc: 72.54, f1: 71.62
loss: 0.1969, acc: 92.97, test_acc: 72.54, f1: 72.03
loss: 0.5011, acc: 92.36, test_acc: 71.68, f1: 71.25
loss: 0.3146, acc: 91.88, test_acc: 72.54, f1: 71.90
loss: 0.2329, acc: 91.48, test_acc: 75.00, f1: 72.93
loss: 0.2914, acc: 91.67, test_acc: 72.69, f1: 71.91
loss: 0.2037, acc: 91.83, test_acc: 72.25, f1: 71.83
loss: 0.1472, acc: 91.96, test_acc: 74.71, f1: 72.98
loss: 0.1090, acc: 92.50, test_acc: 70.95, f1: 69.86
loss: 0.3646, acc: 92.19, test_acc: 71.97, f1: 71.84
loss: 0.4750, acc: 91.18, test_acc: 73.12, f1: 71.47
loss: 0.0961, acc: 91.32, test_acc: 75.14, f1: 73.00
loss: 0.2268, acc: 91.12, test_acc: 74.57, f1: 73.33
loss: 0.2490, acc: 90.94, test_acc: 71.82, f1: 71.62
loss: 0.1030, acc: 91.37, test_acc: 72.11, f1: 71.42
loss: 0.3236, acc: 91.19, test_acc: 71.68, f1: 70.87
loss: 0.1412, acc: 91.30, test_acc: 72.40, f1: 71.67
loss: 0.1761, acc: 91.41, test_acc: 71.68, f1: 71.46
loss: 0.3818, acc: 91.25, test_acc: 72.83, f1: 72.12
loss: 0.0350, acc: 91.59, test_acc: 73.99, f1: 73.31
loss: 0.2354, acc: 91.67, test_acc: 70.09, f1: 69.84
loss: 0.3610, acc: 91.29, test_acc: 71.39, f1: 71.28
loss: 0.1144, acc: 91.59, test_acc: 74.13, f1: 73.20
loss: 0.0601, acc: 91.88, test_acc: 75.00, f1: 73.62
loss: 0.3796, acc: 91.94, test_acc: 74.57, f1: 73.56
loss: 0.2570, acc: 91.99, test_acc: 71.97, f1: 71.73
loss: 0.1277, acc: 92.05, test_acc: 72.54, f1: 71.22
loss: 0.3324, acc: 91.91, test_acc: 75.29, f1: 73.66
loss: 0.2756, acc: 91.79, test_acc: 73.84, f1: 73.13
loss: 0.1613, acc: 92.01, test_acc: 73.27, f1: 72.87
loss: 0.0947, acc: 92.23, test_acc: 74.86, f1: 73.76
loss: 0.3372, acc: 92.11, test_acc: 74.42, f1: 73.32
loss: 0.1381, acc: 92.15, test_acc: 74.13, f1: 73.75
loss: 0.4844, acc: 91.88, test_acc: 75.58, f1: 75.01
loss: 0.2388, acc: 91.62, test_acc: 75.72, f1: 74.60
loss: 0.2014, acc: 91.67, test_acc: 73.12, f1: 72.21
loss: 0.4456, acc: 91.28, test_acc: 75.14, f1: 74.49
loss: 0.3176, acc: 91.05, test_acc: 72.40, f1: 72.15
loss: 0.2860, acc: 90.97, test_acc: 73.12, f1: 72.49
loss: 0.2017, acc: 91.03, test_acc: 70.38, f1: 70.44
loss: 0.1606, acc: 91.22, test_acc: 70.09, f1: 69.53
loss: 0.2440, acc: 91.28, test_acc: 73.99, f1: 71.26
loss: 0.3078, acc: 91.07, test_acc: 73.84, f1: 70.93
loss: 0.1364, acc: 91.25, test_acc: 73.41, f1: 72.51
loss: 0.2495, acc: 91.30, test_acc: 71.82, f1: 71.47
loss: 0.2857, acc: 91.35, test_acc: 72.98, f1: 71.71
loss: 0.1255, acc: 91.39, test_acc: 74.28, f1: 72.50
loss: 0.3273, acc: 91.32, test_acc: 73.84, f1: 72.53
loss: 0.6215, acc: 91.14, test_acc: 68.06, f1: 68.53
loss: 0.1780, acc: 91.07, test_acc: 72.25, f1: 71.78
loss: 0.2751, acc: 91.01, test_acc: 73.55, f1: 72.44
loss: 0.1384, acc: 91.06, test_acc: 72.83, f1: 72.28
loss: 0.2168, acc: 91.10, test_acc: 72.11, f1: 71.69
loss: 0.3128, acc: 91.04, test_acc: 72.98, f1: 72.40
loss: 0.5761, acc: 90.78, test_acc: 72.98, f1: 72.36
loss: 0.4319, acc: 90.62, test_acc: 71.97, f1: 71.39
loss: 0.1713, acc: 90.58, test_acc: 69.22, f1: 69.12
loss: 0.4604, acc: 90.43, test_acc: 73.84, f1: 73.04
loss: 0.4987, acc: 90.29, test_acc: 72.98, f1: 71.75
loss: 0.4630, acc: 90.15, test_acc: 73.41, f1: 71.55
loss: 0.1826, acc: 90.21, test_acc: 73.84, f1: 72.99
loss: 0.2631, acc: 90.17, test_acc: 71.97, f1: 71.71
loss: 0.1181, acc: 90.31, test_acc: 73.27, f1: 71.98
loss: 0.1940, acc: 90.36, test_acc: 73.41, f1: 72.51
loss: 0.2631, acc: 90.40, test_acc: 68.50, f1: 68.31
loss: 0.1409, acc: 90.45, test_acc: 72.11, f1: 71.45
loss: 0.2064, acc: 90.50, test_acc: 72.83, f1: 71.90
loss: 0.3305, acc: 90.46, test_acc: 72.40, f1: 70.62
loss: 0.2062, acc: 90.42, test_acc: 73.70, f1: 72.61
loss: 0.7023, acc: 90.38, test_acc: 71.53, f1: 71.01
loss: 0.1438, acc: 90.34, test_acc: 73.12, f1: 72.59
loss: 0.2549, acc: 90.38, test_acc: 72.11, f1: 71.80
####################################################################################################
max_test_acc_overall:75.86705202312139
max_f1_overall:75.0109759801688
####################################################################################################
1 test_acc_overall: 77.89  f1_overall:77.02
2 test_acc_overall: 75.58  f1_overall:74.19
3 test_acc_overall: 76.45  f1_overall:74.68
4 test_acc_overall: 75.87  f1_overall:75.01
max_acc_overall:77.89  f1_overall:77.02
mean_acc_overall:76.45  mean_f1_overall:75.22
####################################################################################################
lcf_bert - twitter - cdm - No.5 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdm
>>> device: cuda:0
>>> seed: 4
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc50.0
max_acc:50.0  f1:22.22
loss: 1.4988, acc: 31.25, test_acc: 50.00, f1: 22.22
loss: 1.0914, acc: 34.38, test_acc: 42.92, f1: 31.23
loss: 1.1938, acc: 41.67, test_acc: 50.00, f1: 22.22
loss: 1.0871, acc: 43.75, test_acc: 50.00, f1: 22.22
loss: 1.1814, acc: 43.75, test_acc: 47.25, f1: 33.29
loss: 0.8149, acc: 47.92, test_acc: 50.00, f1: 22.22
loss: 1.1914, acc: 48.21, test_acc: 50.00, f1: 22.22
>> saved: state_dict/lcf_bert_twitter_acc52.6
max_acc:52.6  f1:31.36
loss: 0.9074, acc: 50.78, test_acc: 52.60, f1: 31.36
loss: 1.0001, acc: 49.31, test_acc: 47.98, f1: 35.56
loss: 1.2270, acc: 48.12, test_acc: 50.00, f1: 22.24
>> saved: state_dict/lcf_bert_twitter_acc54.48
max_acc:54.48  f1:37.26
loss: 0.9166, acc: 48.86, test_acc: 54.48, f1: 37.26
>> saved: state_dict/lcf_bert_twitter_acc55.92
max_acc:55.92  f1:39.5
loss: 0.9478, acc: 47.40, test_acc: 55.92, f1: 39.50
>> saved: state_dict/lcf_bert_twitter_acc57.95
max_acc:57.95  f1:44.7
loss: 0.8215, acc: 48.56, test_acc: 57.95, f1: 44.70
>> saved: state_dict/lcf_bert_twitter_acc60.98
max_acc:60.98  f1:53.9
loss: 0.9969, acc: 47.77, test_acc: 60.98, f1: 53.90
loss: 0.7941, acc: 48.75, test_acc: 55.49, f1: 54.34
loss: 0.9403, acc: 49.61, test_acc: 57.80, f1: 43.90
>> saved: state_dict/lcf_bert_twitter_acc62.43
max_acc:62.43  f1:61.65
loss: 0.7566, acc: 50.37, test_acc: 62.43, f1: 61.65
>> saved: state_dict/lcf_bert_twitter_acc65.32
max_acc:65.32  f1:63.51
loss: 1.0270, acc: 51.74, test_acc: 65.32, f1: 63.51
loss: 0.6362, acc: 52.63, test_acc: 64.31, f1: 60.59
loss: 0.8870, acc: 53.12, test_acc: 64.45, f1: 61.07
loss: 0.9411, acc: 53.87, test_acc: 58.09, f1: 58.63
loss: 0.8919, acc: 54.55, test_acc: 63.01, f1: 59.43
>> saved: state_dict/lcf_bert_twitter_acc65.46
max_acc:65.46  f1:59.02
loss: 0.9254, acc: 55.16, test_acc: 65.46, f1: 59.02
loss: 0.9507, acc: 55.21, test_acc: 59.97, f1: 58.15
loss: 1.0433, acc: 55.00, test_acc: 64.88, f1: 63.86
loss: 0.7980, acc: 56.01, test_acc: 65.03, f1: 63.93
>> saved: state_dict/lcf_bert_twitter_acc67.92
max_acc:67.92  f1:62.11
loss: 0.7510, acc: 56.25, test_acc: 67.92, f1: 62.11
loss: 0.9505, acc: 56.25, test_acc: 67.49, f1: 64.24
loss: 0.7346, acc: 56.90, test_acc: 63.44, f1: 63.51
loss: 0.9752, acc: 56.88, test_acc: 58.38, f1: 58.71
>> saved: state_dict/lcf_bert_twitter_acc70.38
max_acc:70.38  f1:67.71
loss: 0.6239, acc: 57.26, test_acc: 70.38, f1: 67.71
loss: 0.6069, acc: 57.81, test_acc: 69.80, f1: 66.78
loss: 0.7472, acc: 58.14, test_acc: 67.63, f1: 67.09
loss: 0.5590, acc: 58.82, test_acc: 68.21, f1: 67.25
loss: 0.8783, acc: 58.93, test_acc: 69.80, f1: 66.77
loss: 0.6587, acc: 59.38, test_acc: 69.36, f1: 67.68
>> saved: state_dict/lcf_bert_twitter_acc70.81
max_acc:70.81  f1:68.75
loss: 0.5529, acc: 60.14, test_acc: 70.81, f1: 68.75
loss: 0.9016, acc: 59.70, test_acc: 70.66, f1: 68.57
loss: 1.0855, acc: 59.62, test_acc: 66.76, f1: 66.01
>> saved: state_dict/lcf_bert_twitter_acc71.1
max_acc:71.1  f1:67.59
loss: 0.6802, acc: 60.00, test_acc: 71.10, f1: 67.59
loss: 0.4945, acc: 60.67, test_acc: 70.95, f1: 68.58
loss: 0.8347, acc: 60.71, test_acc: 70.23, f1: 69.32
loss: 0.5775, acc: 60.90, test_acc: 65.32, f1: 64.93
loss: 0.5229, acc: 61.36, test_acc: 68.64, f1: 67.56
loss: 0.5152, acc: 61.39, test_acc: 68.93, f1: 66.94
loss: 0.8934, acc: 61.68, test_acc: 69.80, f1: 68.25
loss: 0.6546, acc: 61.84, test_acc: 65.90, f1: 66.48
loss: 0.7833, acc: 61.98, test_acc: 66.18, f1: 66.27
>> saved: state_dict/lcf_bert_twitter_acc71.97
max_acc:71.97  f1:70.72
loss: 0.8558, acc: 62.12, test_acc: 71.97, f1: 70.72
loss: 0.5886, acc: 62.25, test_acc: 69.22, f1: 68.82
loss: 0.9802, acc: 62.01, test_acc: 67.63, f1: 67.58
>> saved: state_dict/lcf_bert_twitter_acc73.41
max_acc:73.41  f1:71.9
loss: 0.7072, acc: 62.02, test_acc: 73.41, f1: 71.90
loss: 1.0901, acc: 61.91, test_acc: 70.95, f1: 68.15
loss: 0.5295, acc: 62.27, test_acc: 70.38, f1: 69.64
loss: 0.6677, acc: 62.73, test_acc: 68.21, f1: 68.03
loss: 0.5515, acc: 63.06, test_acc: 72.25, f1: 71.50
>> saved: state_dict/lcf_bert_twitter_acc74.42
max_acc:74.42  f1:73.34
loss: 0.6455, acc: 63.38, test_acc: 74.42, f1: 73.34
loss: 0.8641, acc: 63.47, test_acc: 71.24, f1: 70.32
loss: 1.0319, acc: 63.14, test_acc: 73.55, f1: 71.19
loss: 0.8904, acc: 63.02, test_acc: 73.70, f1: 71.90
loss: 1.0656, acc: 62.81, test_acc: 64.45, f1: 64.52
loss: 0.5878, acc: 63.00, test_acc: 66.91, f1: 66.39
loss: 0.6277, acc: 63.10, test_acc: 72.54, f1: 71.14
loss: 0.5023, acc: 63.28, test_acc: 73.55, f1: 72.40
loss: 0.5144, acc: 63.56, test_acc: 65.90, f1: 65.99
loss: 0.4912, acc: 63.83, test_acc: 73.12, f1: 72.31
loss: 0.7317, acc: 63.71, test_acc: 73.41, f1: 71.91
loss: 0.5632, acc: 63.88, test_acc: 72.83, f1: 70.63
loss: 1.0811, acc: 63.77, test_acc: 66.62, f1: 66.59
loss: 0.3991, acc: 64.11, test_acc: 69.08, f1: 69.08
loss: 0.9026, acc: 64.08, test_acc: 66.47, f1: 66.42
loss: 0.6640, acc: 64.24, test_acc: 69.80, f1: 69.53
loss: 0.7419, acc: 64.30, test_acc: 71.53, f1: 69.82
loss: 0.7067, acc: 64.36, test_acc: 72.69, f1: 70.98
loss: 1.0002, acc: 64.25, test_acc: 73.12, f1: 71.89
loss: 0.8449, acc: 64.31, test_acc: 72.11, f1: 71.10
loss: 0.6383, acc: 64.61, test_acc: 74.13, f1: 72.71
loss: 0.5668, acc: 64.90, test_acc: 71.82, f1: 70.13
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.7548, acc: 75.00, test_acc: 72.83, f1: 70.10
loss: 0.3767, acc: 84.38, test_acc: 73.12, f1: 72.24
loss: 0.5378, acc: 79.17, test_acc: 69.08, f1: 69.06
loss: 0.3075, acc: 79.69, test_acc: 70.09, f1: 69.77
loss: 0.7757, acc: 80.00, test_acc: 71.53, f1: 71.18
loss: 0.4126, acc: 80.21, test_acc: 72.54, f1: 71.68
loss: 0.1483, acc: 83.04, test_acc: 72.83, f1: 72.04
>> saved: state_dict/lcf_bert_twitter_acc74.71
max_acc:74.71  f1:72.69
loss: 0.2388, acc: 85.16, test_acc: 74.71, f1: 72.69
loss: 0.4858, acc: 84.03, test_acc: 74.71, f1: 73.50
loss: 0.2129, acc: 84.38, test_acc: 73.41, f1: 72.61
loss: 0.2519, acc: 85.23, test_acc: 72.69, f1: 71.83
loss: 0.4674, acc: 84.90, test_acc: 74.13, f1: 73.00
loss: 0.5018, acc: 84.62, test_acc: 73.12, f1: 72.30
loss: 0.3294, acc: 84.82, test_acc: 73.12, f1: 72.22
>> saved: state_dict/lcf_bert_twitter_acc75.14
max_acc:75.14  f1:73.31
loss: 0.2488, acc: 85.42, test_acc: 75.14, f1: 73.31
loss: 0.5784, acc: 85.16, test_acc: 71.97, f1: 70.97
loss: 0.3397, acc: 85.29, test_acc: 73.84, f1: 72.65
loss: 0.4091, acc: 85.42, test_acc: 74.28, f1: 72.98
loss: 0.5953, acc: 84.87, test_acc: 70.38, f1: 70.60
loss: 0.5785, acc: 84.38, test_acc: 75.14, f1: 73.95
loss: 0.3696, acc: 84.52, test_acc: 72.25, f1: 70.81
loss: 0.7127, acc: 83.24, test_acc: 71.24, f1: 70.57
loss: 0.5317, acc: 82.88, test_acc: 69.51, f1: 69.57
loss: 0.2454, acc: 83.07, test_acc: 71.10, f1: 70.18
loss: 0.6020, acc: 82.75, test_acc: 69.80, f1: 69.71
loss: 0.5672, acc: 82.45, test_acc: 70.23, f1: 70.38
loss: 0.5948, acc: 82.18, test_acc: 73.84, f1: 72.60
loss: 0.7026, acc: 81.25, test_acc: 74.57, f1: 72.72
loss: 0.3812, acc: 81.25, test_acc: 73.99, f1: 72.34
loss: 0.4300, acc: 81.25, test_acc: 71.68, f1: 70.76
loss: 0.5464, acc: 80.85, test_acc: 72.54, f1: 71.44
loss: 0.4494, acc: 80.66, test_acc: 74.28, f1: 73.12
loss: 0.6517, acc: 80.30, test_acc: 74.86, f1: 73.43
loss: 0.3815, acc: 80.51, test_acc: 70.66, f1: 70.36
loss: 0.3229, acc: 80.89, test_acc: 70.38, f1: 70.22
loss: 0.3397, acc: 81.08, test_acc: 73.41, f1: 72.91
loss: 0.4474, acc: 81.25, test_acc: 72.54, f1: 70.34
loss: 0.1915, acc: 81.58, test_acc: 71.68, f1: 70.97
loss: 0.4997, acc: 81.57, test_acc: 68.79, f1: 68.64
loss: 0.3029, acc: 81.88, test_acc: 71.97, f1: 71.08
loss: 0.6637, acc: 81.71, test_acc: 74.28, f1: 72.68
loss: 0.3067, acc: 81.99, test_acc: 70.81, f1: 70.77
loss: 0.4388, acc: 81.98, test_acc: 67.49, f1: 67.46
loss: 0.7054, acc: 81.82, test_acc: 72.11, f1: 71.30
loss: 0.4656, acc: 81.81, test_acc: 70.52, f1: 70.41
>> saved: state_dict/lcf_bert_twitter_acc75.58
max_acc:75.58  f1:74.21
loss: 0.6018, acc: 81.66, test_acc: 75.58, f1: 74.21
loss: 0.6379, acc: 81.52, test_acc: 73.99, f1: 72.86
loss: 0.5578, acc: 81.38, test_acc: 72.11, f1: 71.78
loss: 0.4943, acc: 81.25, test_acc: 71.68, f1: 70.92
loss: 0.8624, acc: 81.12, test_acc: 74.28, f1: 73.15
loss: 0.2204, acc: 81.25, test_acc: 73.99, f1: 73.33
loss: 0.7713, acc: 81.01, test_acc: 73.27, f1: 73.25
loss: 0.3894, acc: 80.90, test_acc: 74.42, f1: 73.46
loss: 0.4433, acc: 80.79, test_acc: 75.00, f1: 73.33
loss: 0.4556, acc: 80.80, test_acc: 72.54, f1: 71.75
loss: 0.5150, acc: 80.69, test_acc: 71.68, f1: 71.66
loss: 0.3952, acc: 80.81, test_acc: 74.28, f1: 73.38
loss: 0.4378, acc: 80.82, test_acc: 75.43, f1: 74.55
loss: 0.1984, acc: 81.04, test_acc: 71.39, f1: 70.87
loss: 0.5157, acc: 80.83, test_acc: 73.27, f1: 72.90
loss: 0.4082, acc: 80.94, test_acc: 75.14, f1: 73.81
>> saved: state_dict/lcf_bert_twitter_acc76.16
max_acc:76.16  f1:75.07
loss: 0.2905, acc: 81.05, test_acc: 76.16, f1: 75.07
loss: 0.9392, acc: 80.75, test_acc: 75.87, f1: 74.82
loss: 0.5066, acc: 80.57, test_acc: 74.13, f1: 73.63
loss: 0.4027, acc: 80.58, test_acc: 74.13, f1: 73.31
loss: 0.1949, acc: 80.78, test_acc: 71.97, f1: 71.44
loss: 0.2354, acc: 81.06, test_acc: 68.21, f1: 68.23
loss: 1.0667, acc: 80.88, test_acc: 74.71, f1: 72.90
loss: 0.4264, acc: 80.89, test_acc: 73.70, f1: 71.25
loss: 0.4079, acc: 80.89, test_acc: 72.54, f1: 71.83
loss: 0.6599, acc: 80.81, test_acc: 72.25, f1: 71.90
loss: 0.7942, acc: 80.64, test_acc: 71.82, f1: 70.93
loss: 0.3516, acc: 80.82, test_acc: 72.40, f1: 70.28
loss: 0.4685, acc: 80.83, test_acc: 73.99, f1: 73.16
loss: 0.6395, acc: 80.67, test_acc: 70.23, f1: 70.34
loss: 0.6613, acc: 80.59, test_acc: 74.86, f1: 73.74
loss: 0.7667, acc: 80.52, test_acc: 73.12, f1: 70.49
loss: 0.5353, acc: 80.69, test_acc: 72.54, f1: 69.99
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1524, acc: 100.00, test_acc: 74.28, f1: 72.81
loss: 0.2916, acc: 96.88, test_acc: 72.11, f1: 71.78
loss: 0.3274, acc: 93.75, test_acc: 72.54, f1: 72.22
loss: 0.1907, acc: 93.75, test_acc: 72.98, f1: 72.41
loss: 0.2098, acc: 92.50, test_acc: 73.84, f1: 73.06
loss: 0.2201, acc: 91.67, test_acc: 73.27, f1: 72.64
loss: 0.2176, acc: 91.07, test_acc: 72.54, f1: 72.06
loss: 0.2622, acc: 91.41, test_acc: 70.81, f1: 70.21
loss: 0.1025, acc: 91.67, test_acc: 71.39, f1: 70.74
loss: 0.0797, acc: 92.50, test_acc: 73.99, f1: 73.04
loss: 0.2363, acc: 92.05, test_acc: 73.55, f1: 72.75
loss: 0.3288, acc: 92.19, test_acc: 69.51, f1: 69.15
loss: 0.6231, acc: 90.87, test_acc: 68.21, f1: 68.14
loss: 0.1360, acc: 91.52, test_acc: 72.40, f1: 70.89
loss: 0.2487, acc: 91.67, test_acc: 72.54, f1: 71.07
loss: 0.3965, acc: 91.80, test_acc: 72.25, f1: 71.17
loss: 0.2356, acc: 91.91, test_acc: 70.81, f1: 70.29
loss: 0.2074, acc: 92.01, test_acc: 73.41, f1: 72.10
loss: 0.2436, acc: 92.11, test_acc: 72.98, f1: 71.57
loss: 0.1103, acc: 92.50, test_acc: 72.69, f1: 71.68
loss: 0.4421, acc: 92.26, test_acc: 72.69, f1: 71.84
loss: 0.4676, acc: 91.76, test_acc: 74.13, f1: 72.87
loss: 0.1289, acc: 91.85, test_acc: 73.55, f1: 71.47
loss: 0.1858, acc: 91.93, test_acc: 71.97, f1: 71.29
loss: 0.3826, acc: 91.75, test_acc: 69.51, f1: 69.44
loss: 0.1686, acc: 91.83, test_acc: 69.51, f1: 65.74
loss: 0.2487, acc: 91.90, test_acc: 72.69, f1: 71.43
loss: 0.2889, acc: 91.74, test_acc: 72.40, f1: 71.13
loss: 0.3033, acc: 91.59, test_acc: 69.94, f1: 68.83
loss: 0.2498, acc: 91.67, test_acc: 71.39, f1: 70.29
loss: 0.4778, acc: 91.13, test_acc: 72.83, f1: 71.56
loss: 0.2390, acc: 91.02, test_acc: 71.53, f1: 69.34
loss: 0.2985, acc: 90.72, test_acc: 73.70, f1: 72.99
loss: 0.3933, acc: 90.44, test_acc: 66.91, f1: 66.90
loss: 0.3085, acc: 90.36, test_acc: 71.53, f1: 71.04
loss: 0.2499, acc: 90.10, test_acc: 72.98, f1: 70.89
loss: 0.1644, acc: 90.37, test_acc: 71.82, f1: 71.22
loss: 0.2298, acc: 90.62, test_acc: 69.08, f1: 68.77
loss: 0.2022, acc: 90.54, test_acc: 68.79, f1: 68.66
loss: 0.0733, acc: 90.78, test_acc: 71.68, f1: 69.54
loss: 0.3208, acc: 90.85, test_acc: 72.69, f1: 71.48
loss: 0.1760, acc: 90.77, test_acc: 70.95, f1: 70.87
loss: 0.3796, acc: 90.55, test_acc: 71.39, f1: 71.24
loss: 0.2756, acc: 90.48, test_acc: 70.52, f1: 69.99
loss: 0.3526, acc: 90.56, test_acc: 72.98, f1: 71.60
loss: 0.5249, acc: 90.35, test_acc: 72.11, f1: 71.07
loss: 0.1775, acc: 90.56, test_acc: 71.24, f1: 71.23
loss: 0.1516, acc: 90.76, test_acc: 69.94, f1: 70.08
loss: 0.2971, acc: 90.82, test_acc: 72.40, f1: 71.62
loss: 0.1272, acc: 90.88, test_acc: 72.25, f1: 71.03
loss: 0.1470, acc: 90.93, test_acc: 72.69, f1: 72.03
loss: 0.2854, acc: 90.99, test_acc: 71.24, f1: 70.95
loss: 0.3280, acc: 90.80, test_acc: 70.66, f1: 70.08
loss: 0.0501, acc: 90.97, test_acc: 70.95, f1: 70.89
loss: 0.3697, acc: 90.80, test_acc: 72.11, f1: 71.37
loss: 0.3254, acc: 90.74, test_acc: 74.57, f1: 72.37
loss: 0.1344, acc: 90.79, test_acc: 71.82, f1: 71.09
loss: 0.1498, acc: 90.84, test_acc: 69.08, f1: 68.89
loss: 0.3176, acc: 90.89, test_acc: 71.53, f1: 70.90
loss: 0.8716, acc: 90.73, test_acc: 72.40, f1: 71.66
loss: 0.2407, acc: 90.57, test_acc: 70.95, f1: 70.74
loss: 0.1732, acc: 90.62, test_acc: 73.55, f1: 72.46
loss: 0.1208, acc: 90.77, test_acc: 74.13, f1: 72.94
loss: 0.0498, acc: 90.92, test_acc: 74.13, f1: 73.56
loss: 0.2832, acc: 90.87, test_acc: 73.99, f1: 73.41
loss: 0.4472, acc: 90.91, test_acc: 73.27, f1: 71.77
loss: 0.2307, acc: 90.86, test_acc: 72.69, f1: 72.22
loss: 0.1615, acc: 90.90, test_acc: 72.11, f1: 70.99
loss: 0.2383, acc: 90.85, test_acc: 72.40, f1: 71.29
loss: 0.3808, acc: 90.80, test_acc: 72.11, f1: 71.27
loss: 0.2598, acc: 90.67, test_acc: 72.54, f1: 71.63
loss: 0.4072, acc: 90.62, test_acc: 73.27, f1: 72.24
loss: 0.0496, acc: 90.75, test_acc: 73.27, f1: 72.09
loss: 0.4768, acc: 90.62, test_acc: 73.41, f1: 72.22
loss: 0.1444, acc: 90.67, test_acc: 72.83, f1: 72.00
loss: 0.1680, acc: 90.71, test_acc: 70.66, f1: 70.63
loss: 0.3216, acc: 90.67, test_acc: 70.52, f1: 69.97
loss: 0.4916, acc: 90.46, test_acc: 73.84, f1: 71.67
####################################################################################################
max_test_acc_overall:76.15606936416185
max_f1_overall:75.06633541142338
####################################################################################################
1 test_acc_overall: 77.89  f1_overall:77.02
2 test_acc_overall: 75.58  f1_overall:74.19
3 test_acc_overall: 76.45  f1_overall:74.68
4 test_acc_overall: 75.87  f1_overall:75.01
5 test_acc_overall: 76.16  f1_overall:75.07
max_acc_overall:77.89  f1_overall:77.02
mean_acc_overall:76.39  mean_f1_overall:75.19
####################################################################################################
lcf_bert - laptop - cdw - No.1 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:0
>>> seed: 0
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc53.45
max_acc:53.45  f1:23.22
loss: 1.3139, acc: 50.00, test_acc: 53.45, f1: 23.22
>> saved: state_dict/lcf_bert_laptop_acc54.23
max_acc:54.23  f1:25.9
loss: 1.1007, acc: 43.75, test_acc: 54.23, f1: 25.90
loss: 1.0077, acc: 52.08, test_acc: 24.61, f1: 17.92
>> saved: state_dict/lcf_bert_laptop_acc54.39
max_acc:54.39  f1:26.87
loss: 0.9865, acc: 51.56, test_acc: 54.39, f1: 26.87
>> saved: state_dict/lcf_bert_laptop_acc65.05
max_acc:65.05  f1:50.05
loss: 0.9475, acc: 55.00, test_acc: 65.05, f1: 50.05
>> saved: state_dict/lcf_bert_laptop_acc65.2
max_acc:65.2  f1:49.2
loss: 0.9512, acc: 54.17, test_acc: 65.20, f1: 49.20
>> saved: state_dict/lcf_bert_laptop_acc69.44
max_acc:69.44  f1:54.79
loss: 0.6953, acc: 58.04, test_acc: 69.44, f1: 54.79
>> saved: state_dict/lcf_bert_laptop_acc73.04
max_acc:73.04  f1:63.13
loss: 0.5858, acc: 60.94, test_acc: 73.04, f1: 63.13
loss: 0.7212, acc: 62.50, test_acc: 71.16, f1: 62.84
>> saved: state_dict/lcf_bert_laptop_acc73.82
max_acc:73.82  f1:64.41
loss: 0.8199, acc: 62.50, test_acc: 73.82, f1: 64.41
>> saved: state_dict/lcf_bert_laptop_acc74.29
max_acc:74.29  f1:66.8
loss: 0.5409, acc: 63.64, test_acc: 74.29, f1: 66.80
>> saved: state_dict/lcf_bert_laptop_acc76.8
max_acc:76.8  f1:71.53
loss: 0.3811, acc: 65.10, test_acc: 76.80, f1: 71.53
loss: 0.7235, acc: 65.38, test_acc: 76.49, f1: 70.55
loss: 0.9398, acc: 65.18, test_acc: 70.38, f1: 63.86
>> saved: state_dict/lcf_bert_laptop_acc77.9
max_acc:77.9  f1:73.93
loss: 0.6317, acc: 66.25, test_acc: 77.90, f1: 73.93
loss: 0.4891, acc: 67.19, test_acc: 76.96, f1: 70.79
loss: 0.5325, acc: 67.65, test_acc: 73.82, f1: 63.28
loss: 0.4541, acc: 68.40, test_acc: 72.88, f1: 62.07
loss: 0.2900, acc: 69.74, test_acc: 76.65, f1: 71.43
loss: 0.7087, acc: 69.69, test_acc: 76.65, f1: 71.22
loss: 0.6081, acc: 69.94, test_acc: 76.33, f1: 70.38
loss: 0.5344, acc: 69.89, test_acc: 76.02, f1: 69.35
loss: 0.4433, acc: 70.65, test_acc: 77.12, f1: 72.60
loss: 0.3040, acc: 71.61, test_acc: 76.65, f1: 73.23
loss: 0.5513, acc: 72.00, test_acc: 77.90, f1: 73.18
>> saved: state_dict/lcf_bert_laptop_acc78.21
max_acc:78.21  f1:73.44
loss: 0.4715, acc: 72.12, test_acc: 78.21, f1: 73.44
>> saved: state_dict/lcf_bert_laptop_acc78.68
max_acc:78.68  f1:74.58
loss: 0.3320, acc: 72.92, test_acc: 78.68, f1: 74.58
loss: 0.5459, acc: 73.21, test_acc: 77.74, f1: 71.20
loss: 0.5419, acc: 73.49, test_acc: 77.74, f1: 71.67
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.7094, acc: 62.50, test_acc: 77.43, f1: 72.11
loss: 0.2878, acc: 78.12, test_acc: 76.65, f1: 72.98
loss: 0.4465, acc: 77.08, test_acc: 76.65, f1: 70.96
loss: 0.4502, acc: 79.69, test_acc: 76.96, f1: 71.22
loss: 0.7250, acc: 78.75, test_acc: 78.21, f1: 73.48
loss: 0.2156, acc: 81.25, test_acc: 77.12, f1: 72.04
loss: 0.5222, acc: 81.25, test_acc: 76.80, f1: 69.64
loss: 0.3781, acc: 81.25, test_acc: 78.06, f1: 74.30
loss: 0.8978, acc: 78.47, test_acc: 78.53, f1: 75.51
loss: 0.5073, acc: 77.50, test_acc: 77.90, f1: 74.68
loss: 0.3269, acc: 78.41, test_acc: 78.21, f1: 74.93
loss: 0.3031, acc: 78.65, test_acc: 77.27, f1: 73.70
loss: 0.6248, acc: 78.37, test_acc: 75.71, f1: 69.98
loss: 0.8051, acc: 77.68, test_acc: 76.18, f1: 71.71
loss: 0.2416, acc: 79.17, test_acc: 75.24, f1: 72.04
loss: 0.2758, acc: 79.69, test_acc: 77.12, f1: 72.64
loss: 0.6487, acc: 80.15, test_acc: 76.33, f1: 70.48
loss: 0.6395, acc: 79.86, test_acc: 78.53, f1: 74.91
>> saved: state_dict/lcf_bert_laptop_acc78.84
max_acc:78.84  f1:75.64
loss: 0.6368, acc: 79.93, test_acc: 78.84, f1: 75.64
loss: 0.4218, acc: 80.31, test_acc: 78.68, f1: 73.10
loss: 0.3821, acc: 80.36, test_acc: 76.33, f1: 68.15
loss: 0.5766, acc: 80.11, test_acc: 75.24, f1: 65.55
loss: 0.4341, acc: 80.16, test_acc: 76.65, f1: 72.15
loss: 0.5666, acc: 80.47, test_acc: 77.74, f1: 73.19
loss: 0.2607, acc: 80.75, test_acc: 78.06, f1: 71.88
>> saved: state_dict/lcf_bert_laptop_acc79.31
max_acc:79.31  f1:74.7
loss: 0.4082, acc: 80.53, test_acc: 79.31, f1: 74.70
>> saved: state_dict/lcf_bert_laptop_acc79.78
max_acc:79.78  f1:76.48
loss: 0.4269, acc: 80.56, test_acc: 79.78, f1: 76.48
loss: 0.4004, acc: 80.36, test_acc: 78.84, f1: 76.31
loss: 0.6236, acc: 80.39, test_acc: 77.12, f1: 73.56
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.3391, acc: 75.00, test_acc: 76.65, f1: 68.12
loss: 0.2967, acc: 78.12, test_acc: 74.14, f1: 63.08
loss: 0.1577, acc: 83.33, test_acc: 78.84, f1: 74.02
loss: 0.2632, acc: 85.94, test_acc: 79.31, f1: 76.87
loss: 0.0497, acc: 88.75, test_acc: 78.21, f1: 74.76
loss: 0.4604, acc: 87.50, test_acc: 77.27, f1: 73.37
loss: 0.3780, acc: 87.50, test_acc: 78.37, f1: 75.77
loss: 0.2010, acc: 87.50, test_acc: 79.78, f1: 75.92
loss: 0.1451, acc: 88.19, test_acc: 78.68, f1: 73.56
loss: 0.1177, acc: 88.75, test_acc: 79.78, f1: 75.99
loss: 0.4610, acc: 88.07, test_acc: 79.00, f1: 76.20
loss: 0.2237, acc: 88.02, test_acc: 77.90, f1: 74.53
loss: 0.3862, acc: 88.46, test_acc: 77.74, f1: 73.09
loss: 0.2392, acc: 88.39, test_acc: 79.00, f1: 74.62
>> saved: state_dict/lcf_bert_laptop_acc82.13
max_acc:82.13  f1:79.17
loss: 0.1268, acc: 89.17, test_acc: 82.13, f1: 79.17
loss: 0.2593, acc: 89.06, test_acc: 81.19, f1: 78.41
loss: 0.4286, acc: 88.97, test_acc: 80.56, f1: 75.83
loss: 0.4497, acc: 88.54, test_acc: 79.31, f1: 75.58
loss: 0.8067, acc: 86.84, test_acc: 79.00, f1: 75.90
loss: 0.3919, acc: 86.88, test_acc: 79.94, f1: 76.04
loss: 0.6339, acc: 86.31, test_acc: 77.90, f1: 72.02
loss: 0.2225, acc: 86.65, test_acc: 79.15, f1: 74.16
loss: 0.3359, acc: 86.68, test_acc: 79.15, f1: 75.02
loss: 0.1347, acc: 86.98, test_acc: 78.84, f1: 75.96
loss: 0.4781, acc: 87.00, test_acc: 79.00, f1: 75.88
loss: 0.3227, acc: 87.02, test_acc: 77.59, f1: 71.54
loss: 0.1808, acc: 87.04, test_acc: 77.27, f1: 71.03
loss: 0.4213, acc: 86.83, test_acc: 78.21, f1: 72.74
loss: 0.2962, acc: 86.85, test_acc: 79.94, f1: 76.59
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.2367, acc: 93.75, test_acc: 81.03, f1: 77.51
loss: 0.0442, acc: 96.88, test_acc: 77.43, f1: 70.23
loss: 0.4880, acc: 93.75, test_acc: 77.90, f1: 71.10
loss: 0.3758, acc: 92.19, test_acc: 78.68, f1: 73.73
loss: 0.2683, acc: 90.00, test_acc: 79.62, f1: 76.07
loss: 0.0613, acc: 91.67, test_acc: 79.78, f1: 76.26
loss: 0.5161, acc: 89.29, test_acc: 77.12, f1: 71.08
loss: 0.5903, acc: 87.50, test_acc: 78.68, f1: 73.61
loss: 0.1269, acc: 88.19, test_acc: 78.37, f1: 75.90
loss: 0.2581, acc: 88.75, test_acc: 80.56, f1: 78.01
loss: 0.2008, acc: 89.20, test_acc: 79.15, f1: 73.73
loss: 0.0569, acc: 90.10, test_acc: 79.00, f1: 74.06
loss: 0.0894, acc: 90.87, test_acc: 78.53, f1: 74.53
loss: 0.0915, acc: 91.07, test_acc: 77.12, f1: 72.89
loss: 0.5207, acc: 90.00, test_acc: 78.37, f1: 74.31
loss: 0.3705, acc: 89.84, test_acc: 80.09, f1: 75.92
loss: 0.3160, acc: 89.71, test_acc: 80.25, f1: 76.36
loss: 0.2069, acc: 89.93, test_acc: 80.25, f1: 75.72
loss: 0.5216, acc: 88.82, test_acc: 79.15, f1: 74.10
loss: 0.1542, acc: 89.06, test_acc: 78.06, f1: 72.88
loss: 0.0915, acc: 89.58, test_acc: 79.62, f1: 76.64
loss: 0.2372, acc: 89.49, test_acc: 78.37, f1: 73.83
loss: 0.0908, acc: 89.95, test_acc: 76.49, f1: 70.35
loss: 0.1088, acc: 90.10, test_acc: 76.65, f1: 70.42
loss: 0.1417, acc: 90.25, test_acc: 79.62, f1: 75.65
loss: 0.2014, acc: 90.14, test_acc: 80.72, f1: 77.22
loss: 0.1654, acc: 90.28, test_acc: 77.90, f1: 71.56
loss: 0.3876, acc: 90.18, test_acc: 79.47, f1: 75.33
loss: 0.4036, acc: 89.87, test_acc: 80.41, f1: 76.80
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0723, acc: 100.00, test_acc: 78.37, f1: 73.27
loss: 0.2151, acc: 96.88, test_acc: 77.74, f1: 71.59
loss: 0.0859, acc: 97.92, test_acc: 79.31, f1: 74.62
loss: 0.0846, acc: 98.44, test_acc: 80.09, f1: 76.41
loss: 0.3217, acc: 96.25, test_acc: 80.72, f1: 77.31
loss: 0.1349, acc: 95.83, test_acc: 80.09, f1: 75.83
loss: 0.1722, acc: 95.54, test_acc: 79.62, f1: 75.78
loss: 0.2125, acc: 95.31, test_acc: 80.25, f1: 76.07
loss: 0.0251, acc: 95.83, test_acc: 78.21, f1: 72.17
loss: 0.0162, acc: 96.25, test_acc: 79.47, f1: 75.58
>> saved: state_dict/lcf_bert_laptop_acc82.6
max_acc:82.6  f1:79.93
loss: 0.0800, acc: 96.59, test_acc: 82.60, f1: 79.93
loss: 0.0347, acc: 96.88, test_acc: 81.97, f1: 78.87
loss: 0.1253, acc: 96.63, test_acc: 80.09, f1: 76.04
loss: 0.0774, acc: 96.88, test_acc: 79.62, f1: 75.19
loss: 0.0654, acc: 97.08, test_acc: 81.03, f1: 77.35
loss: 0.2205, acc: 96.88, test_acc: 81.03, f1: 77.65
loss: 0.0733, acc: 97.06, test_acc: 79.47, f1: 74.42
loss: 0.5786, acc: 96.53, test_acc: 78.53, f1: 72.66
loss: 0.1139, acc: 96.38, test_acc: 79.00, f1: 74.71
loss: 0.0668, acc: 96.56, test_acc: 79.15, f1: 75.33
loss: 0.3824, acc: 96.13, test_acc: 79.62, f1: 76.05
loss: 0.0145, acc: 96.31, test_acc: 81.50, f1: 78.24
loss: 0.1469, acc: 96.20, test_acc: 81.35, f1: 77.78
loss: 0.0920, acc: 96.35, test_acc: 77.90, f1: 71.40
loss: 0.0847, acc: 96.50, test_acc: 77.74, f1: 71.09
loss: 0.1988, acc: 96.15, test_acc: 78.37, f1: 73.08
loss: 0.4089, acc: 95.60, test_acc: 79.31, f1: 75.20
loss: 0.0508, acc: 95.76, test_acc: 79.47, f1: 75.51
loss: 0.3477, acc: 95.47, test_acc: 79.00, f1: 74.38
loss: 0.0060, acc: 95.55, test_acc: 81.03, f1: 77.38
####################################################################################################
max_test_acc_overall:82.60188087774296
max_f1_overall:79.92524355179508
####################################################################################################
1 test_acc_overall: 82.6  f1_overall:79.93
max_acc_overall:82.6  f1_overall:79.93
mean_acc_overall:82.6  mean_f1_overall:79.93
####################################################################################################
lcf_bert - laptop - cdw - No.2 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:0
>>> seed: 1
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc53.61
max_acc:53.61  f1:24.0
loss: 1.0274, acc: 31.25, test_acc: 53.61, f1: 24.00
loss: 1.1410, acc: 25.00, test_acc: 20.53, f1: 15.20
>> saved: state_dict/lcf_bert_laptop_acc57.84
max_acc:57.84  f1:35.81
loss: 0.8694, acc: 37.50, test_acc: 57.84, f1: 35.81
>> saved: state_dict/lcf_bert_laptop_acc66.61
max_acc:66.61  f1:48.73
loss: 0.7896, acc: 48.44, test_acc: 66.61, f1: 48.73
>> saved: state_dict/lcf_bert_laptop_acc68.03
max_acc:68.03  f1:51.67
loss: 0.9089, acc: 53.75, test_acc: 68.03, f1: 51.67
>> saved: state_dict/lcf_bert_laptop_acc69.44
max_acc:69.44  f1:53.84
loss: 0.8998, acc: 55.21, test_acc: 69.44, f1: 53.84
>> saved: state_dict/lcf_bert_laptop_acc70.22
max_acc:70.22  f1:54.97
loss: 0.8707, acc: 56.25, test_acc: 70.22, f1: 54.97
>> saved: state_dict/lcf_bert_laptop_acc72.73
max_acc:72.73  f1:62.53
loss: 0.6589, acc: 57.03, test_acc: 72.73, f1: 62.53
>> saved: state_dict/lcf_bert_laptop_acc73.2
max_acc:73.2  f1:63.82
loss: 0.7945, acc: 57.64, test_acc: 73.20, f1: 63.82
loss: 0.5584, acc: 59.38, test_acc: 71.94, f1: 63.88
loss: 0.7448, acc: 59.09, test_acc: 69.91, f1: 56.75
>> saved: state_dict/lcf_bert_laptop_acc74.61
max_acc:74.61  f1:67.55
loss: 0.6617, acc: 60.94, test_acc: 74.61, f1: 67.55
loss: 0.6892, acc: 61.06, test_acc: 73.04, f1: 67.56
loss: 0.7109, acc: 61.16, test_acc: 73.04, f1: 61.63
>> saved: state_dict/lcf_bert_laptop_acc74.92
max_acc:74.92  f1:67.55
loss: 0.5603, acc: 62.08, test_acc: 74.92, f1: 67.55
>> saved: state_dict/lcf_bert_laptop_acc76.18
max_acc:76.18  f1:70.11
loss: 1.1835, acc: 61.33, test_acc: 76.18, f1: 70.11
loss: 0.6792, acc: 61.76, test_acc: 70.53, f1: 57.53
loss: 0.8792, acc: 61.81, test_acc: 73.82, f1: 65.15
loss: 0.3881, acc: 62.50, test_acc: 75.71, f1: 69.16
loss: 0.6389, acc: 62.81, test_acc: 72.26, f1: 59.64
loss: 0.2616, acc: 63.99, test_acc: 75.08, f1: 66.23
>> saved: state_dict/lcf_bert_laptop_acc77.74
max_acc:77.74  f1:73.69
loss: 0.6518, acc: 64.49, test_acc: 77.74, f1: 73.69
loss: 0.1608, acc: 66.03, test_acc: 75.71, f1: 68.61
loss: 0.4789, acc: 66.41, test_acc: 75.39, f1: 67.57
>> saved: state_dict/lcf_bert_laptop_acc78.06
max_acc:78.06  f1:72.81
loss: 0.6756, acc: 66.50, test_acc: 78.06, f1: 72.81
loss: 0.5240, acc: 67.07, test_acc: 76.65, f1: 69.60
>> saved: state_dict/lcf_bert_laptop_acc79.31
max_acc:79.31  f1:73.76
loss: 0.4603, acc: 67.82, test_acc: 79.31, f1: 73.76
loss: 0.4074, acc: 68.53, test_acc: 78.68, f1: 73.79
loss: 0.7309, acc: 68.75, test_acc: 78.53, f1: 73.49
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.6922, acc: 68.75, test_acc: 79.15, f1: 74.15
loss: 0.3476, acc: 78.12, test_acc: 79.15, f1: 75.08
loss: 0.2484, acc: 81.25, test_acc: 78.53, f1: 74.65
loss: 0.7136, acc: 79.69, test_acc: 79.15, f1: 73.63
loss: 0.1808, acc: 82.50, test_acc: 78.53, f1: 73.83
loss: 0.4409, acc: 83.33, test_acc: 79.00, f1: 74.22
loss: 0.3196, acc: 83.93, test_acc: 77.59, f1: 72.23
loss: 0.5186, acc: 83.59, test_acc: 76.02, f1: 67.48
loss: 0.2066, acc: 84.03, test_acc: 76.96, f1: 70.45
loss: 0.5359, acc: 83.75, test_acc: 75.08, f1: 72.17
loss: 0.9558, acc: 81.25, test_acc: 77.12, f1: 72.54
loss: 0.4295, acc: 81.25, test_acc: 77.43, f1: 71.61
loss: 0.5716, acc: 79.81, test_acc: 74.45, f1: 65.50
loss: 0.5339, acc: 80.36, test_acc: 75.86, f1: 68.28
loss: 0.3168, acc: 80.42, test_acc: 76.80, f1: 72.41
loss: 0.7197, acc: 80.08, test_acc: 76.18, f1: 72.64
loss: 0.1745, acc: 80.88, test_acc: 78.21, f1: 74.38
loss: 0.4329, acc: 80.90, test_acc: 76.33, f1: 68.91
loss: 0.6338, acc: 80.92, test_acc: 77.59, f1: 72.14
loss: 0.1587, acc: 81.56, test_acc: 78.21, f1: 75.15
loss: 0.3546, acc: 81.55, test_acc: 78.06, f1: 72.13
loss: 0.4236, acc: 81.25, test_acc: 75.55, f1: 67.56
loss: 0.1964, acc: 82.07, test_acc: 78.53, f1: 74.93
loss: 0.1838, acc: 82.55, test_acc: 77.59, f1: 71.72
loss: 0.0930, acc: 83.25, test_acc: 76.49, f1: 69.30
loss: 0.4087, acc: 83.17, test_acc: 77.90, f1: 74.06
loss: 0.5192, acc: 83.10, test_acc: 79.31, f1: 74.60
loss: 0.4056, acc: 83.04, test_acc: 78.21, f1: 72.03
loss: 0.3579, acc: 82.97, test_acc: 78.37, f1: 72.71
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1549, acc: 100.00, test_acc: 78.53, f1: 74.92
loss: 0.4482, acc: 90.62, test_acc: 77.59, f1: 73.23
loss: 0.4101, acc: 89.58, test_acc: 77.43, f1: 71.36
loss: 0.0764, acc: 92.19, test_acc: 77.74, f1: 71.11
loss: 0.4277, acc: 90.00, test_acc: 79.00, f1: 74.53
loss: 0.2596, acc: 90.62, test_acc: 78.68, f1: 73.20
loss: 0.1428, acc: 91.07, test_acc: 78.37, f1: 72.56
loss: 0.0526, acc: 92.19, test_acc: 78.06, f1: 71.76
>> saved: state_dict/lcf_bert_laptop_acc80.25
max_acc:80.25  f1:75.76
loss: 0.2870, acc: 92.36, test_acc: 80.25, f1: 75.76
loss: 0.0974, acc: 93.12, test_acc: 80.09, f1: 76.14
loss: 0.1912, acc: 93.18, test_acc: 80.09, f1: 75.97
loss: 0.0712, acc: 93.75, test_acc: 77.59, f1: 73.27
loss: 0.2244, acc: 92.79, test_acc: 78.37, f1: 72.66
loss: 0.3003, acc: 92.41, test_acc: 76.49, f1: 69.86
loss: 0.5629, acc: 91.25, test_acc: 77.43, f1: 71.22
loss: 0.3234, acc: 91.02, test_acc: 78.84, f1: 74.37
loss: 0.3318, acc: 91.18, test_acc: 76.02, f1: 72.81
loss: 0.4438, acc: 90.97, test_acc: 77.59, f1: 73.24
loss: 0.2867, acc: 90.79, test_acc: 78.37, f1: 72.87
loss: 0.5165, acc: 90.31, test_acc: 79.31, f1: 74.35
loss: 0.4829, acc: 89.88, test_acc: 79.62, f1: 75.56
loss: 0.1689, acc: 90.06, test_acc: 76.80, f1: 73.22
loss: 0.1948, acc: 90.22, test_acc: 78.21, f1: 73.25
loss: 0.8087, acc: 89.84, test_acc: 77.74, f1: 72.71
loss: 0.0774, acc: 90.25, test_acc: 78.06, f1: 72.48
loss: 0.4042, acc: 89.90, test_acc: 77.74, f1: 72.27
loss: 0.1297, acc: 90.05, test_acc: 79.00, f1: 74.48
loss: 0.1903, acc: 90.40, test_acc: 77.43, f1: 70.44
loss: 0.3052, acc: 90.09, test_acc: 76.33, f1: 68.40
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.2521, acc: 87.50, test_acc: 75.71, f1: 67.61
loss: 0.1249, acc: 90.62, test_acc: 79.31, f1: 75.08
loss: 0.1429, acc: 91.67, test_acc: 80.25, f1: 76.54
>> saved: state_dict/lcf_bert_laptop_acc80.41
max_acc:80.41  f1:76.91
loss: 0.0821, acc: 93.75, test_acc: 80.41, f1: 76.91
loss: 0.1368, acc: 95.00, test_acc: 80.41, f1: 77.16
loss: 0.3083, acc: 92.71, test_acc: 79.31, f1: 74.67
loss: 0.5115, acc: 91.96, test_acc: 79.47, f1: 74.03
loss: 0.1448, acc: 92.19, test_acc: 79.00, f1: 75.17
>> saved: state_dict/lcf_bert_laptop_acc80.88
max_acc:80.88  f1:77.7
loss: 0.2469, acc: 92.36, test_acc: 80.88, f1: 77.70
loss: 0.5641, acc: 90.62, test_acc: 77.74, f1: 72.32
loss: 0.1264, acc: 90.91, test_acc: 76.02, f1: 68.68
loss: 0.1068, acc: 91.15, test_acc: 78.37, f1: 73.37
loss: 0.0596, acc: 91.83, test_acc: 77.74, f1: 74.44
loss: 0.2143, acc: 91.52, test_acc: 80.25, f1: 76.26
loss: 0.5648, acc: 90.42, test_acc: 75.55, f1: 67.41
loss: 0.3412, acc: 90.23, test_acc: 75.39, f1: 67.46
loss: 0.2195, acc: 90.44, test_acc: 78.37, f1: 73.44
loss: 0.3574, acc: 89.93, test_acc: 79.78, f1: 75.99
loss: 0.1352, acc: 90.13, test_acc: 78.21, f1: 73.12
loss: 0.4954, acc: 90.00, test_acc: 77.12, f1: 71.05
loss: 0.1802, acc: 90.18, test_acc: 79.31, f1: 75.06
loss: 0.2534, acc: 90.06, test_acc: 79.15, f1: 75.55
loss: 0.2020, acc: 90.22, test_acc: 78.37, f1: 73.06
loss: 0.1660, acc: 90.36, test_acc: 77.74, f1: 70.92
loss: 0.5905, acc: 90.00, test_acc: 79.00, f1: 74.17
loss: 0.4013, acc: 89.90, test_acc: 75.39, f1: 72.51
loss: 0.5133, acc: 89.58, test_acc: 76.80, f1: 73.90
loss: 0.0332, acc: 89.96, test_acc: 79.15, f1: 73.72
loss: 0.0581, acc: 90.30, test_acc: 76.18, f1: 68.18
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0711, acc: 100.00, test_acc: 77.27, f1: 70.75
loss: 0.1367, acc: 96.88, test_acc: 80.09, f1: 75.54
loss: 0.1763, acc: 95.83, test_acc: 80.56, f1: 76.27
loss: 0.1030, acc: 95.31, test_acc: 79.78, f1: 75.09
loss: 0.1833, acc: 95.00, test_acc: 79.31, f1: 74.43
loss: 0.0542, acc: 95.83, test_acc: 79.78, f1: 75.41
loss: 0.3384, acc: 94.64, test_acc: 79.78, f1: 75.18
loss: 0.1893, acc: 94.53, test_acc: 79.15, f1: 74.32
loss: 0.2125, acc: 93.75, test_acc: 79.00, f1: 74.03
loss: 0.0944, acc: 93.75, test_acc: 79.62, f1: 75.31
loss: 0.0591, acc: 94.32, test_acc: 78.68, f1: 73.21
loss: 0.0690, acc: 94.79, test_acc: 77.27, f1: 70.91
loss: 0.1096, acc: 94.71, test_acc: 78.37, f1: 73.71
loss: 0.0092, acc: 95.09, test_acc: 77.74, f1: 72.28
loss: 0.1616, acc: 95.00, test_acc: 77.74, f1: 72.35
loss: 0.1993, acc: 94.92, test_acc: 78.06, f1: 72.57
loss: 0.0496, acc: 95.22, test_acc: 77.59, f1: 71.70
loss: 0.1164, acc: 95.14, test_acc: 79.15, f1: 74.81
loss: 0.1431, acc: 95.07, test_acc: 80.09, f1: 75.90
loss: 0.2069, acc: 95.00, test_acc: 77.27, f1: 71.53
loss: 0.1739, acc: 94.94, test_acc: 76.65, f1: 70.13
loss: 0.0344, acc: 95.17, test_acc: 77.43, f1: 71.99
loss: 0.0125, acc: 95.38, test_acc: 79.47, f1: 75.70
loss: 0.0811, acc: 95.31, test_acc: 79.47, f1: 75.74
loss: 0.2074, acc: 95.25, test_acc: 78.53, f1: 73.69
loss: 0.4456, acc: 94.71, test_acc: 78.53, f1: 73.77
loss: 0.3328, acc: 94.44, test_acc: 79.62, f1: 75.31
loss: 0.0667, acc: 94.42, test_acc: 79.00, f1: 74.21
loss: 0.1214, acc: 94.40, test_acc: 78.53, f1: 73.16
loss: 0.1967, acc: 94.28, test_acc: 79.15, f1: 74.30
####################################################################################################
max_test_acc_overall:80.87774294670847
max_f1_overall:77.70209291935593
####################################################################################################
1 test_acc_overall: 82.6  f1_overall:79.93
2 test_acc_overall: 80.88  f1_overall:77.7
max_acc_overall:82.6  f1_overall:79.93
mean_acc_overall:81.74  mean_f1_overall:78.81
####################################################################################################
lcf_bert - laptop - cdw - No.3 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:0
>>> seed: 2
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc53.92
max_acc:53.92  f1:29.07
loss: 1.1545, acc: 18.75, test_acc: 53.92, f1: 29.07
loss: 1.0624, acc: 31.25, test_acc: 53.92, f1: 29.46
>> saved: state_dict/lcf_bert_laptop_acc55.49
max_acc:55.49  f1:32.02
loss: 0.9711, acc: 35.42, test_acc: 55.49, f1: 32.02
>> saved: state_dict/lcf_bert_laptop_acc66.46
max_acc:66.46  f1:48.74
loss: 0.8608, acc: 40.62, test_acc: 66.46, f1: 48.74
>> saved: state_dict/lcf_bert_laptop_acc71.0
max_acc:71.0  f1:60.52
loss: 0.6282, acc: 47.50, test_acc: 71.00, f1: 60.52
loss: 0.8389, acc: 51.04, test_acc: 70.38, f1: 58.51
>> saved: state_dict/lcf_bert_laptop_acc74.76
max_acc:74.76  f1:69.88
loss: 0.6883, acc: 53.57, test_acc: 74.76, f1: 69.88
loss: 0.8681, acc: 55.47, test_acc: 74.29, f1: 65.53
loss: 0.6649, acc: 56.94, test_acc: 74.14, f1: 66.11
>> saved: state_dict/lcf_bert_laptop_acc76.96
max_acc:76.96  f1:73.37
loss: 0.4367, acc: 59.38, test_acc: 76.96, f1: 73.37
loss: 0.6798, acc: 60.23, test_acc: 71.63, f1: 60.43
>> saved: state_dict/lcf_bert_laptop_acc77.74
max_acc:77.74  f1:73.22
loss: 1.0141, acc: 58.85, test_acc: 77.74, f1: 73.22
loss: 0.8206, acc: 59.62, test_acc: 77.74, f1: 73.16
loss: 0.6361, acc: 61.16, test_acc: 77.74, f1: 71.21
loss: 0.4336, acc: 62.50, test_acc: 74.45, f1: 64.50
>> saved: state_dict/lcf_bert_laptop_acc77.9
max_acc:77.9  f1:72.36
loss: 0.5395, acc: 63.67, test_acc: 77.90, f1: 72.36
loss: 0.9264, acc: 63.24, test_acc: 77.12, f1: 73.47
loss: 0.3996, acc: 64.58, test_acc: 76.33, f1: 67.86
loss: 0.7707, acc: 64.80, test_acc: 74.14, f1: 62.72
loss: 0.7206, acc: 65.31, test_acc: 74.92, f1: 67.80
loss: 0.7099, acc: 65.48, test_acc: 76.65, f1: 71.95
>> saved: state_dict/lcf_bert_laptop_acc79.31
max_acc:79.31  f1:74.69
loss: 0.6165, acc: 65.62, test_acc: 79.31, f1: 74.69
loss: 0.5189, acc: 66.30, test_acc: 79.15, f1: 73.99
loss: 0.4157, acc: 67.19, test_acc: 79.00, f1: 72.96
loss: 0.7411, acc: 67.50, test_acc: 79.15, f1: 73.79
>> saved: state_dict/lcf_bert_laptop_acc79.94
max_acc:79.94  f1:77.17
loss: 0.5411, acc: 68.03, test_acc: 79.94, f1: 77.17
loss: 0.2740, acc: 68.75, test_acc: 78.53, f1: 72.55
loss: 0.3671, acc: 69.42, test_acc: 74.14, f1: 63.60
loss: 0.5615, acc: 70.04, test_acc: 78.68, f1: 74.30
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.1658, acc: 100.00, test_acc: 77.74, f1: 71.82
loss: 0.3133, acc: 93.75, test_acc: 78.21, f1: 74.08
loss: 0.7725, acc: 83.33, test_acc: 79.78, f1: 75.90
loss: 0.2089, acc: 85.94, test_acc: 74.45, f1: 65.79
loss: 0.4281, acc: 85.00, test_acc: 76.18, f1: 69.24
loss: 0.4042, acc: 85.42, test_acc: 78.84, f1: 75.79
loss: 0.4294, acc: 85.71, test_acc: 76.80, f1: 73.64
loss: 0.2573, acc: 85.94, test_acc: 74.29, f1: 69.38
loss: 0.6747, acc: 84.72, test_acc: 77.43, f1: 73.97
loss: 0.4178, acc: 84.38, test_acc: 77.27, f1: 74.28
loss: 0.1412, acc: 85.23, test_acc: 79.31, f1: 75.24
loss: 0.1615, acc: 85.94, test_acc: 76.96, f1: 69.83
loss: 0.6683, acc: 85.10, test_acc: 75.86, f1: 66.85
loss: 0.4243, acc: 84.38, test_acc: 77.27, f1: 69.90
loss: 0.5623, acc: 84.17, test_acc: 79.62, f1: 75.13
loss: 0.4516, acc: 84.38, test_acc: 79.15, f1: 75.15
loss: 0.3819, acc: 84.56, test_acc: 74.45, f1: 70.14
loss: 0.3632, acc: 84.38, test_acc: 76.02, f1: 69.80
loss: 0.2028, acc: 84.87, test_acc: 79.47, f1: 74.85
>> saved: state_dict/lcf_bert_laptop_acc80.56
max_acc:80.56  f1:76.89
loss: 0.4745, acc: 84.69, test_acc: 80.56, f1: 76.89
loss: 0.4167, acc: 84.82, test_acc: 79.62, f1: 75.55
loss: 0.3180, acc: 84.66, test_acc: 79.00, f1: 75.09
loss: 0.4831, acc: 84.51, test_acc: 79.00, f1: 74.51
loss: 0.1959, acc: 84.90, test_acc: 78.37, f1: 73.64
loss: 0.3644, acc: 85.00, test_acc: 78.68, f1: 74.55
loss: 0.5066, acc: 84.86, test_acc: 77.74, f1: 74.80
loss: 0.4214, acc: 84.72, test_acc: 78.53, f1: 73.48
loss: 0.2563, acc: 84.82, test_acc: 76.33, f1: 68.86
loss: 0.3545, acc: 84.91, test_acc: 76.02, f1: 67.89
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1881, acc: 100.00, test_acc: 77.74, f1: 72.77
loss: 0.3347, acc: 93.75, test_acc: 78.06, f1: 74.08
loss: 0.1740, acc: 91.67, test_acc: 77.74, f1: 73.21
loss: 0.1869, acc: 90.62, test_acc: 77.59, f1: 72.99
loss: 0.2371, acc: 90.00, test_acc: 77.90, f1: 74.12
loss: 0.2132, acc: 90.62, test_acc: 78.53, f1: 74.18
loss: 0.1827, acc: 90.18, test_acc: 79.47, f1: 75.35
loss: 0.2989, acc: 89.84, test_acc: 79.00, f1: 74.66
loss: 0.1760, acc: 90.28, test_acc: 79.15, f1: 74.81
loss: 0.2679, acc: 90.62, test_acc: 79.47, f1: 75.16
loss: 0.1476, acc: 90.91, test_acc: 79.78, f1: 75.39
loss: 0.2996, acc: 90.62, test_acc: 79.78, f1: 75.10
loss: 0.2737, acc: 90.87, test_acc: 79.00, f1: 73.97
loss: 0.3927, acc: 90.62, test_acc: 79.47, f1: 75.42
loss: 0.2798, acc: 90.42, test_acc: 78.84, f1: 75.40
loss: 0.2643, acc: 90.62, test_acc: 79.31, f1: 75.06
loss: 0.3822, acc: 90.44, test_acc: 76.33, f1: 70.40
loss: 0.3919, acc: 89.93, test_acc: 79.15, f1: 74.78
loss: 0.1235, acc: 90.46, test_acc: 80.09, f1: 76.57
loss: 0.2400, acc: 90.00, test_acc: 80.56, f1: 77.14
loss: 0.1112, acc: 90.48, test_acc: 79.47, f1: 74.73
loss: 0.4270, acc: 90.06, test_acc: 79.00, f1: 75.26
loss: 0.0853, acc: 90.49, test_acc: 78.68, f1: 75.02
loss: 0.2029, acc: 90.62, test_acc: 79.78, f1: 75.61
loss: 0.3929, acc: 90.25, test_acc: 79.78, f1: 75.46
>> saved: state_dict/lcf_bert_laptop_acc82.76
max_acc:82.76  f1:79.66
loss: 0.4490, acc: 89.90, test_acc: 82.76, f1: 79.66
loss: 0.1636, acc: 90.05, test_acc: 82.29, f1: 78.84
loss: 0.5997, acc: 89.73, test_acc: 80.56, f1: 76.73
loss: 0.3414, acc: 89.44, test_acc: 81.66, f1: 78.32
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.1983, acc: 93.75, test_acc: 81.19, f1: 77.68
loss: 0.2224, acc: 90.62, test_acc: 80.41, f1: 76.29
loss: 0.1270, acc: 91.67, test_acc: 78.37, f1: 72.64
loss: 0.1660, acc: 92.19, test_acc: 79.31, f1: 74.31
loss: 0.2878, acc: 91.25, test_acc: 79.47, f1: 75.51
loss: 0.2294, acc: 90.62, test_acc: 80.09, f1: 76.85
loss: 0.0444, acc: 91.96, test_acc: 80.41, f1: 76.83
loss: 0.3191, acc: 91.41, test_acc: 77.90, f1: 72.09
loss: 0.0561, acc: 91.67, test_acc: 78.84, f1: 73.89
loss: 0.3154, acc: 91.25, test_acc: 81.03, f1: 77.40
loss: 0.3298, acc: 90.91, test_acc: 78.84, f1: 74.99
loss: 0.1950, acc: 90.62, test_acc: 78.84, f1: 74.39
loss: 0.1637, acc: 90.87, test_acc: 76.96, f1: 70.73
loss: 0.0953, acc: 91.52, test_acc: 79.00, f1: 74.52
loss: 0.0665, acc: 92.08, test_acc: 79.47, f1: 75.25
loss: 0.1365, acc: 92.58, test_acc: 78.68, f1: 75.01
loss: 0.5087, acc: 91.91, test_acc: 78.68, f1: 74.42
loss: 0.1124, acc: 92.01, test_acc: 78.68, f1: 74.37
loss: 0.0524, acc: 92.43, test_acc: 78.53, f1: 72.72
loss: 0.1380, acc: 92.81, test_acc: 76.80, f1: 69.47
loss: 0.0490, acc: 93.15, test_acc: 77.43, f1: 71.93
loss: 0.1430, acc: 93.18, test_acc: 73.82, f1: 70.02
loss: 0.0448, acc: 93.48, test_acc: 77.59, f1: 72.75
loss: 0.2592, acc: 93.23, test_acc: 79.31, f1: 74.35
loss: 0.0847, acc: 93.25, test_acc: 79.15, f1: 75.10
loss: 0.3383, acc: 93.03, test_acc: 79.47, f1: 75.86
loss: 0.0507, acc: 93.29, test_acc: 78.84, f1: 73.79
loss: 0.2359, acc: 93.30, test_acc: 78.06, f1: 72.67
loss: 0.1500, acc: 93.10, test_acc: 79.00, f1: 74.44
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.1874, acc: 93.75, test_acc: 79.62, f1: 76.14
loss: 0.0852, acc: 96.88, test_acc: 79.94, f1: 76.34
loss: 0.1581, acc: 93.75, test_acc: 78.37, f1: 73.56
loss: 0.3985, acc: 90.62, test_acc: 79.00, f1: 74.93
loss: 0.0319, acc: 92.50, test_acc: 81.03, f1: 77.97
loss: 0.0401, acc: 93.75, test_acc: 79.62, f1: 75.92
loss: 0.1408, acc: 93.75, test_acc: 79.94, f1: 76.01
loss: 0.4826, acc: 92.97, test_acc: 79.78, f1: 75.76
loss: 0.0109, acc: 93.75, test_acc: 80.09, f1: 76.31
loss: 0.1188, acc: 93.75, test_acc: 80.25, f1: 76.65
loss: 0.1805, acc: 93.18, test_acc: 79.47, f1: 75.75
loss: 0.1843, acc: 92.71, test_acc: 80.56, f1: 77.10
loss: 0.3367, acc: 91.83, test_acc: 80.41, f1: 76.26
loss: 0.0644, acc: 92.41, test_acc: 80.72, f1: 76.63
loss: 0.0633, acc: 92.92, test_acc: 79.15, f1: 76.34
loss: 0.2764, acc: 92.97, test_acc: 77.59, f1: 75.16
loss: 0.0227, acc: 93.38, test_acc: 78.84, f1: 74.43
loss: 0.0967, acc: 93.40, test_acc: 78.84, f1: 73.43
loss: 0.0744, acc: 93.75, test_acc: 79.78, f1: 74.28
loss: 0.1491, acc: 93.75, test_acc: 80.41, f1: 75.69
loss: 0.1374, acc: 93.75, test_acc: 81.19, f1: 77.11
loss: 0.0213, acc: 94.03, test_acc: 81.03, f1: 77.45
loss: 0.0377, acc: 94.29, test_acc: 81.19, f1: 77.92
loss: 0.0483, acc: 94.53, test_acc: 80.88, f1: 76.83
loss: 0.0068, acc: 94.75, test_acc: 80.88, f1: 76.24
loss: 0.0751, acc: 94.95, test_acc: 81.35, f1: 76.79
loss: 0.2979, acc: 94.68, test_acc: 81.50, f1: 78.00
loss: 0.2897, acc: 94.42, test_acc: 81.03, f1: 77.96
loss: 0.0366, acc: 94.61, test_acc: 81.50, f1: 78.02
loss: 0.2528, acc: 94.49, test_acc: 77.74, f1: 72.02
####################################################################################################
max_test_acc_overall:82.75862068965517
max_f1_overall:79.65579779708229
####################################################################################################
1 test_acc_overall: 82.6  f1_overall:79.93
2 test_acc_overall: 80.88  f1_overall:77.7
3 test_acc_overall: 82.76  f1_overall:79.66
max_acc_overall:82.76  f1_overall:79.66
mean_acc_overall:82.08  mean_f1_overall:79.09
####################################################################################################
lcf_bert - laptop - cdw - No.4 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:0
>>> seed: 3
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc51.41
max_acc:51.41  f1:32.57
loss: 1.0202, acc: 50.00, test_acc: 51.41, f1: 32.57
>> saved: state_dict/lcf_bert_laptop_acc54.55
max_acc:54.55  f1:30.37
loss: 0.9919, acc: 53.12, test_acc: 54.55, f1: 30.37
loss: 1.0524, acc: 41.67, test_acc: 24.14, f1: 19.31
>> saved: state_dict/lcf_bert_laptop_acc56.9
max_acc:56.9  f1:37.11
loss: 1.0238, acc: 42.19, test_acc: 56.90, f1: 37.11
loss: 1.1170, acc: 41.25, test_acc: 56.74, f1: 33.06
>> saved: state_dict/lcf_bert_laptop_acc69.12
max_acc:69.12  f1:57.66
loss: 1.0530, acc: 43.75, test_acc: 69.12, f1: 57.66
loss: 0.8594, acc: 45.54, test_acc: 65.52, f1: 49.81
loss: 0.7440, acc: 47.66, test_acc: 66.93, f1: 52.40
>> saved: state_dict/lcf_bert_laptop_acc70.69
max_acc:70.69  f1:59.5
loss: 0.6927, acc: 50.00, test_acc: 70.69, f1: 59.50
>> saved: state_dict/lcf_bert_laptop_acc70.85
max_acc:70.85  f1:57.0
loss: 0.6152, acc: 52.50, test_acc: 70.85, f1: 57.00
>> saved: state_dict/lcf_bert_laptop_acc73.2
max_acc:73.2  f1:63.88
loss: 0.4131, acc: 55.11, test_acc: 73.20, f1: 63.88
>> saved: state_dict/lcf_bert_laptop_acc76.02
max_acc:76.02  f1:69.14
loss: 0.7273, acc: 56.77, test_acc: 76.02, f1: 69.14
loss: 0.5833, acc: 58.17, test_acc: 75.86, f1: 72.80
loss: 0.6567, acc: 58.93, test_acc: 73.67, f1: 62.87
loss: 0.5144, acc: 60.00, test_acc: 73.82, f1: 63.63
>> saved: state_dict/lcf_bert_laptop_acc77.74
max_acc:77.74  f1:72.41
loss: 0.5458, acc: 60.55, test_acc: 77.74, f1: 72.41
>> saved: state_dict/lcf_bert_laptop_acc78.53
max_acc:78.53  f1:73.01
loss: 1.0191, acc: 61.03, test_acc: 78.53, f1: 73.01
loss: 0.6825, acc: 61.46, test_acc: 75.55, f1: 71.27
loss: 0.5872, acc: 62.17, test_acc: 76.33, f1: 73.77
>> saved: state_dict/lcf_bert_laptop_acc79.78
max_acc:79.78  f1:74.69
loss: 0.6733, acc: 62.19, test_acc: 79.78, f1: 74.69
loss: 0.7168, acc: 62.50, test_acc: 72.10, f1: 59.14
loss: 0.5899, acc: 63.07, test_acc: 71.63, f1: 61.02
loss: 0.4589, acc: 64.13, test_acc: 76.33, f1: 68.68
>> saved: state_dict/lcf_bert_laptop_acc80.41
max_acc:80.41  f1:76.36
loss: 0.4856, acc: 64.58, test_acc: 80.41, f1: 76.36
loss: 0.6910, acc: 64.75, test_acc: 79.00, f1: 73.77
loss: 0.4474, acc: 65.38, test_acc: 78.68, f1: 74.16
loss: 0.4506, acc: 65.97, test_acc: 75.55, f1: 70.58
loss: 0.6813, acc: 66.07, test_acc: 77.59, f1: 70.44
loss: 0.7986, acc: 65.95, test_acc: 76.96, f1: 70.49
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.5931, acc: 68.75, test_acc: 78.37, f1: 73.20
loss: 0.4903, acc: 75.00, test_acc: 77.74, f1: 74.32
loss: 0.6047, acc: 77.08, test_acc: 77.27, f1: 70.67
loss: 0.5302, acc: 75.00, test_acc: 74.76, f1: 65.69
loss: 0.5919, acc: 77.50, test_acc: 76.80, f1: 70.32
loss: 0.0959, acc: 81.25, test_acc: 77.90, f1: 72.54
loss: 0.2909, acc: 82.14, test_acc: 78.37, f1: 73.08
loss: 0.5337, acc: 82.03, test_acc: 80.41, f1: 76.48
>> saved: state_dict/lcf_bert_laptop_acc81.97
max_acc:81.97  f1:79.27
loss: 0.6343, acc: 81.94, test_acc: 81.97, f1: 79.27
loss: 0.4381, acc: 81.88, test_acc: 78.37, f1: 72.12
loss: 0.1593, acc: 82.95, test_acc: 76.02, f1: 67.79
loss: 0.5600, acc: 82.29, test_acc: 77.59, f1: 71.39
loss: 0.3689, acc: 83.17, test_acc: 80.56, f1: 77.08
loss: 0.4222, acc: 83.48, test_acc: 80.72, f1: 76.55
loss: 0.2898, acc: 84.17, test_acc: 78.84, f1: 72.99
loss: 0.5649, acc: 83.59, test_acc: 77.90, f1: 72.73
loss: 0.4692, acc: 83.82, test_acc: 79.31, f1: 74.47
loss: 0.3822, acc: 83.68, test_acc: 81.19, f1: 77.14
loss: 0.6492, acc: 83.22, test_acc: 80.09, f1: 75.02
loss: 0.3621, acc: 83.44, test_acc: 79.47, f1: 74.15
loss: 0.2648, acc: 83.63, test_acc: 79.00, f1: 76.53
loss: 0.3405, acc: 83.52, test_acc: 77.27, f1: 74.09
loss: 0.7303, acc: 82.88, test_acc: 77.27, f1: 73.89
loss: 0.4264, acc: 82.55, test_acc: 78.84, f1: 73.88
loss: 0.9389, acc: 82.00, test_acc: 77.12, f1: 71.26
loss: 0.2719, acc: 82.45, test_acc: 76.49, f1: 70.51
loss: 0.5236, acc: 82.41, test_acc: 75.24, f1: 67.72
loss: 0.4468, acc: 82.14, test_acc: 76.65, f1: 70.37
loss: 0.4481, acc: 82.11, test_acc: 77.74, f1: 73.94
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1165, acc: 100.00, test_acc: 78.53, f1: 74.29
loss: 0.5710, acc: 90.62, test_acc: 77.74, f1: 72.08
loss: 0.7311, acc: 83.33, test_acc: 78.21, f1: 73.58
loss: 0.3440, acc: 81.25, test_acc: 77.90, f1: 74.47
loss: 0.2461, acc: 82.50, test_acc: 78.84, f1: 76.09
loss: 0.1893, acc: 84.38, test_acc: 79.47, f1: 75.77
loss: 0.2999, acc: 84.82, test_acc: 78.68, f1: 74.52
loss: 0.3756, acc: 84.38, test_acc: 79.62, f1: 75.82
loss: 0.6219, acc: 83.33, test_acc: 77.27, f1: 72.14
loss: 0.3840, acc: 83.75, test_acc: 77.43, f1: 71.82
loss: 0.2841, acc: 83.52, test_acc: 79.78, f1: 75.72
loss: 0.1426, acc: 84.38, test_acc: 79.78, f1: 75.05
loss: 0.1616, acc: 84.62, test_acc: 78.84, f1: 74.00
loss: 0.3899, acc: 84.82, test_acc: 79.47, f1: 75.03
loss: 0.2783, acc: 84.58, test_acc: 80.56, f1: 76.58
loss: 0.3219, acc: 85.16, test_acc: 79.15, f1: 75.45
loss: 0.0921, acc: 85.66, test_acc: 78.21, f1: 72.85
loss: 0.1628, acc: 86.11, test_acc: 75.24, f1: 68.32
loss: 0.2618, acc: 86.51, test_acc: 76.02, f1: 70.68
loss: 0.4093, acc: 86.56, test_acc: 79.15, f1: 75.95
loss: 0.1942, acc: 86.90, test_acc: 81.97, f1: 78.31
>> saved: state_dict/lcf_bert_laptop_acc82.29
max_acc:82.29  f1:79.15
loss: 0.3966, acc: 86.65, test_acc: 82.29, f1: 79.15
loss: 0.1478, acc: 86.96, test_acc: 80.88, f1: 77.50
loss: 0.1624, acc: 87.24, test_acc: 78.84, f1: 73.48
loss: 0.0847, acc: 87.75, test_acc: 78.21, f1: 72.85
loss: 0.2381, acc: 87.74, test_acc: 78.37, f1: 73.16
loss: 0.1616, acc: 87.96, test_acc: 79.47, f1: 75.53
loss: 0.5343, acc: 87.28, test_acc: 79.94, f1: 76.24
loss: 0.2698, acc: 87.28, test_acc: 79.62, f1: 76.26
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.3867, acc: 81.25, test_acc: 77.27, f1: 72.20
loss: 0.1980, acc: 87.50, test_acc: 78.37, f1: 72.58
loss: 0.1419, acc: 87.50, test_acc: 79.15, f1: 73.74
loss: 0.0944, acc: 90.62, test_acc: 80.56, f1: 77.25
loss: 0.0458, acc: 92.50, test_acc: 79.62, f1: 75.49
loss: 0.2355, acc: 92.71, test_acc: 79.94, f1: 74.98
loss: 0.9146, acc: 90.18, test_acc: 79.47, f1: 74.16
loss: 0.1125, acc: 90.62, test_acc: 79.15, f1: 75.62
loss: 0.1332, acc: 90.97, test_acc: 79.47, f1: 76.15
loss: 0.4663, acc: 89.38, test_acc: 80.25, f1: 76.52
loss: 0.0177, acc: 90.34, test_acc: 79.78, f1: 74.77
loss: 0.3734, acc: 90.62, test_acc: 80.88, f1: 76.74
loss: 0.1641, acc: 90.87, test_acc: 78.21, f1: 75.10
loss: 0.2089, acc: 91.07, test_acc: 79.31, f1: 76.77
loss: 0.1227, acc: 91.25, test_acc: 78.53, f1: 72.76
loss: 0.3060, acc: 91.02, test_acc: 78.06, f1: 71.92
loss: 0.0967, acc: 91.54, test_acc: 77.90, f1: 73.55
loss: 0.0297, acc: 92.01, test_acc: 78.21, f1: 74.89
loss: 0.0499, acc: 92.43, test_acc: 78.68, f1: 74.66
loss: 0.1093, acc: 92.81, test_acc: 82.13, f1: 78.54
loss: 0.0484, acc: 93.15, test_acc: 79.62, f1: 74.71
loss: 0.1913, acc: 93.18, test_acc: 80.72, f1: 76.61
loss: 0.1024, acc: 93.21, test_acc: 78.06, f1: 73.29
loss: 0.1130, acc: 93.23, test_acc: 77.43, f1: 72.89
loss: 0.3647, acc: 93.00, test_acc: 77.59, f1: 73.26
loss: 0.0323, acc: 93.27, test_acc: 79.62, f1: 74.97
loss: 0.4732, acc: 93.06, test_acc: 81.35, f1: 77.18
loss: 0.2477, acc: 93.08, test_acc: 75.55, f1: 67.63
loss: 0.4757, acc: 92.89, test_acc: 76.02, f1: 67.78
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0532, acc: 100.00, test_acc: 79.47, f1: 75.24
loss: 0.3284, acc: 93.75, test_acc: 79.47, f1: 76.39
loss: 0.0570, acc: 95.83, test_acc: 79.47, f1: 76.23
loss: 0.0542, acc: 96.88, test_acc: 80.09, f1: 76.38
loss: 0.2515, acc: 95.00, test_acc: 79.00, f1: 73.82
loss: 0.0422, acc: 95.83, test_acc: 79.00, f1: 73.50
loss: 0.0195, acc: 96.43, test_acc: 78.68, f1: 74.03
loss: 0.0297, acc: 96.88, test_acc: 79.47, f1: 75.80
loss: 0.0772, acc: 97.22, test_acc: 79.78, f1: 76.23
loss: 0.1810, acc: 96.88, test_acc: 77.59, f1: 72.79
loss: 0.0081, acc: 97.16, test_acc: 78.21, f1: 72.53
loss: 0.2173, acc: 96.35, test_acc: 79.15, f1: 74.81
loss: 0.0566, acc: 96.63, test_acc: 80.41, f1: 76.66
loss: 0.1112, acc: 96.43, test_acc: 81.19, f1: 78.06
loss: 0.0571, acc: 96.67, test_acc: 80.56, f1: 77.21
loss: 0.0998, acc: 96.48, test_acc: 80.88, f1: 77.47
loss: 0.0373, acc: 96.69, test_acc: 79.62, f1: 76.08
loss: 0.0399, acc: 96.88, test_acc: 79.62, f1: 75.77
loss: 0.1392, acc: 96.71, test_acc: 78.37, f1: 72.69
loss: 0.0155, acc: 96.88, test_acc: 79.47, f1: 73.45
loss: 0.0737, acc: 97.02, test_acc: 81.35, f1: 77.46
loss: 0.0758, acc: 97.16, test_acc: 82.29, f1: 79.11
loss: 0.1002, acc: 97.01, test_acc: 81.50, f1: 78.70
loss: 0.1636, acc: 96.88, test_acc: 79.62, f1: 74.76
loss: 0.3541, acc: 96.50, test_acc: 78.84, f1: 72.14
loss: 0.2193, acc: 96.39, test_acc: 78.84, f1: 74.00
loss: 0.2986, acc: 96.06, test_acc: 81.82, f1: 79.09
loss: 0.3154, acc: 95.76, test_acc: 80.41, f1: 76.64
loss: 0.2476, acc: 95.69, test_acc: 77.43, f1: 71.52
loss: 0.0545, acc: 95.76, test_acc: 80.56, f1: 75.91
####################################################################################################
max_test_acc_overall:82.2884012539185
max_f1_overall:79.2748615423034
####################################################################################################
1 test_acc_overall: 82.6  f1_overall:79.93
2 test_acc_overall: 80.88  f1_overall:77.7
3 test_acc_overall: 82.76  f1_overall:79.66
4 test_acc_overall: 82.29  f1_overall:79.27
max_acc_overall:82.76  f1_overall:79.66
mean_acc_overall:82.13  mean_f1_overall:79.14
####################################################################################################
lcf_bert - laptop - cdw - No.5 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:0
>>> seed: 4
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc20.85
max_acc:20.85  f1:12.62
loss: 1.2063, acc: 25.00, test_acc: 20.85, f1: 12.62
>> saved: state_dict/lcf_bert_laptop_acc50.31
max_acc:50.31  f1:36.24
loss: 1.0519, acc: 31.25, test_acc: 50.31, f1: 36.24
>> saved: state_dict/lcf_bert_laptop_acc54.39
max_acc:54.39  f1:28.93
loss: 0.8740, acc: 50.00, test_acc: 54.39, f1: 28.93
>> saved: state_dict/lcf_bert_laptop_acc59.09
max_acc:59.09  f1:39.81
loss: 0.9440, acc: 53.12, test_acc: 59.09, f1: 39.81
loss: 1.0124, acc: 51.25, test_acc: 24.76, f1: 21.48
>> saved: state_dict/lcf_bert_laptop_acc68.65
max_acc:68.65  f1:56.75
loss: 0.7761, acc: 56.25, test_acc: 68.65, f1: 56.75
>> saved: state_dict/lcf_bert_laptop_acc68.97
max_acc:68.97  f1:51.52
loss: 0.5754, acc: 59.82, test_acc: 68.97, f1: 51.52
loss: 0.3483, acc: 64.06, test_acc: 68.97, f1: 51.57
>> saved: state_dict/lcf_bert_laptop_acc70.38
max_acc:70.38  f1:58.74
loss: 0.7041, acc: 63.89, test_acc: 70.38, f1: 58.74
>> saved: state_dict/lcf_bert_laptop_acc73.98
max_acc:73.98  f1:69.36
loss: 0.7492, acc: 65.00, test_acc: 73.98, f1: 69.36
loss: 0.6965, acc: 64.77, test_acc: 70.22, f1: 54.87
loss: 0.5655, acc: 65.62, test_acc: 69.59, f1: 55.91
loss: 0.5080, acc: 66.83, test_acc: 69.44, f1: 56.31
loss: 0.6151, acc: 66.96, test_acc: 71.79, f1: 61.78
>> saved: state_dict/lcf_bert_laptop_acc74.76
max_acc:74.76  f1:69.02
loss: 0.7865, acc: 67.50, test_acc: 74.76, f1: 69.02
loss: 0.5489, acc: 68.36, test_acc: 74.14, f1: 65.25
loss: 1.1460, acc: 67.28, test_acc: 73.82, f1: 64.53
loss: 0.7408, acc: 67.36, test_acc: 74.29, f1: 65.85
>> saved: state_dict/lcf_bert_laptop_acc76.8
max_acc:76.8  f1:70.53
loss: 0.4442, acc: 68.09, test_acc: 76.80, f1: 70.53
loss: 0.5019, acc: 68.44, test_acc: 73.35, f1: 62.38
loss: 0.7214, acc: 68.45, test_acc: 71.32, f1: 56.95
loss: 0.4698, acc: 68.75, test_acc: 74.29, f1: 66.08
loss: 0.6172, acc: 68.48, test_acc: 74.76, f1: 66.84
>> saved: state_dict/lcf_bert_laptop_acc77.59
max_acc:77.59  f1:72.5
loss: 0.1629, acc: 69.53, test_acc: 77.59, f1: 72.50
loss: 0.8898, acc: 69.25, test_acc: 76.65, f1: 70.04
loss: 0.6758, acc: 69.23, test_acc: 74.45, f1: 64.90
>> saved: state_dict/lcf_bert_laptop_acc77.74
max_acc:77.74  f1:72.36
loss: 0.7998, acc: 69.44, test_acc: 77.74, f1: 72.36
loss: 0.6785, acc: 69.64, test_acc: 75.08, f1: 72.19
>> saved: state_dict/lcf_bert_laptop_acc78.84
max_acc:78.84  f1:73.12
loss: 0.4207, acc: 70.26, test_acc: 78.84, f1: 73.12
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.3274, acc: 87.50, test_acc: 76.49, f1: 68.17
loss: 0.4043, acc: 84.38, test_acc: 77.27, f1: 69.96
loss: 0.1939, acc: 89.58, test_acc: 78.21, f1: 71.98
loss: 0.5987, acc: 87.50, test_acc: 78.21, f1: 72.44
loss: 0.2132, acc: 88.75, test_acc: 78.68, f1: 72.86
loss: 0.4358, acc: 86.46, test_acc: 78.53, f1: 72.64
loss: 0.3036, acc: 87.50, test_acc: 78.53, f1: 74.10
loss: 0.4985, acc: 85.94, test_acc: 78.06, f1: 71.54
loss: 0.6201, acc: 85.42, test_acc: 77.27, f1: 70.44
loss: 0.6688, acc: 83.12, test_acc: 78.37, f1: 72.55
loss: 0.4118, acc: 82.95, test_acc: 78.06, f1: 74.75
loss: 0.2761, acc: 83.33, test_acc: 75.24, f1: 67.29
loss: 0.3101, acc: 84.13, test_acc: 74.14, f1: 63.13
loss: 0.4327, acc: 83.93, test_acc: 73.51, f1: 64.08
loss: 0.4027, acc: 83.75, test_acc: 76.96, f1: 72.50
loss: 0.7879, acc: 82.03, test_acc: 73.98, f1: 71.09
loss: 0.5030, acc: 82.35, test_acc: 78.21, f1: 73.04
loss: 0.5737, acc: 81.94, test_acc: 75.55, f1: 67.63
loss: 0.4632, acc: 81.91, test_acc: 76.18, f1: 68.86
loss: 0.5954, acc: 82.50, test_acc: 76.18, f1: 73.00
loss: 0.8207, acc: 81.55, test_acc: 77.59, f1: 73.82
loss: 0.3039, acc: 81.82, test_acc: 76.18, f1: 68.79
>> saved: state_dict/lcf_bert_laptop_acc79.0
max_acc:79.0  f1:73.36
loss: 0.3368, acc: 81.79, test_acc: 79.00, f1: 73.36
loss: 0.7436, acc: 81.51, test_acc: 78.84, f1: 74.07
loss: 0.5299, acc: 81.75, test_acc: 76.33, f1: 68.90
loss: 0.6463, acc: 81.73, test_acc: 74.45, f1: 65.87
loss: 0.2591, acc: 81.94, test_acc: 76.80, f1: 71.89
loss: 0.5034, acc: 81.92, test_acc: 75.71, f1: 68.29
loss: 0.5683, acc: 81.68, test_acc: 73.98, f1: 64.12
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.4395, acc: 81.25, test_acc: 76.49, f1: 70.45
loss: 0.1673, acc: 87.50, test_acc: 78.06, f1: 73.72
loss: 0.1542, acc: 89.58, test_acc: 78.84, f1: 74.29
loss: 0.1705, acc: 92.19, test_acc: 78.68, f1: 73.77
loss: 0.0649, acc: 93.75, test_acc: 78.53, f1: 74.68
loss: 0.4413, acc: 91.67, test_acc: 78.84, f1: 74.97
loss: 0.2634, acc: 91.07, test_acc: 76.80, f1: 71.11
loss: 0.4349, acc: 89.06, test_acc: 77.43, f1: 72.09
>> saved: state_dict/lcf_bert_laptop_acc79.47
max_acc:79.47  f1:75.98
loss: 0.3515, acc: 88.89, test_acc: 79.47, f1: 75.98
loss: 0.3569, acc: 88.75, test_acc: 77.27, f1: 71.00
loss: 0.2183, acc: 88.64, test_acc: 75.55, f1: 66.07
loss: 0.2781, acc: 88.02, test_acc: 78.37, f1: 72.98
loss: 0.4074, acc: 87.02, test_acc: 74.61, f1: 72.14
loss: 0.2949, acc: 87.50, test_acc: 77.27, f1: 72.50
loss: 0.1360, acc: 88.33, test_acc: 79.31, f1: 73.51
loss: 0.4040, acc: 87.89, test_acc: 78.53, f1: 74.53
loss: 0.4234, acc: 87.87, test_acc: 79.00, f1: 74.96
loss: 0.2886, acc: 87.85, test_acc: 78.21, f1: 72.55
loss: 0.3186, acc: 88.16, test_acc: 76.80, f1: 70.80
>> saved: state_dict/lcf_bert_laptop_acc79.62
max_acc:79.62  f1:74.45
loss: 0.1710, acc: 88.44, test_acc: 79.62, f1: 74.45
loss: 0.3765, acc: 88.10, test_acc: 78.84, f1: 73.03
>> saved: state_dict/lcf_bert_laptop_acc80.09
max_acc:80.09  f1:75.9
loss: 0.3070, acc: 87.78, test_acc: 80.09, f1: 75.90
loss: 0.3521, acc: 87.77, test_acc: 79.31, f1: 74.29
loss: 0.2717, acc: 87.50, test_acc: 78.21, f1: 72.63
loss: 0.1755, acc: 87.50, test_acc: 79.62, f1: 75.00
loss: 0.4741, acc: 87.74, test_acc: 78.53, f1: 73.66
loss: 0.4604, acc: 87.04, test_acc: 78.06, f1: 73.24
loss: 0.1876, acc: 87.05, test_acc: 76.80, f1: 70.52
loss: 0.5221, acc: 86.42, test_acc: 76.65, f1: 69.35
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.1562, acc: 93.75, test_acc: 78.53, f1: 73.53
loss: 0.1911, acc: 90.62, test_acc: 78.53, f1: 73.76
loss: 0.1409, acc: 91.67, test_acc: 77.43, f1: 70.88
loss: 0.0764, acc: 93.75, test_acc: 77.12, f1: 70.46
loss: 0.4463, acc: 92.50, test_acc: 77.90, f1: 72.98
loss: 0.2341, acc: 92.71, test_acc: 77.74, f1: 74.23
loss: 0.1318, acc: 92.86, test_acc: 79.15, f1: 74.91
loss: 0.1926, acc: 92.97, test_acc: 78.53, f1: 73.62
loss: 0.3577, acc: 91.67, test_acc: 78.53, f1: 73.90
loss: 0.1914, acc: 91.25, test_acc: 78.21, f1: 73.61
loss: 0.0311, acc: 92.05, test_acc: 77.43, f1: 71.95
loss: 0.1149, acc: 92.19, test_acc: 76.49, f1: 70.36
loss: 0.5584, acc: 90.87, test_acc: 76.02, f1: 69.60
loss: 0.2494, acc: 91.07, test_acc: 79.15, f1: 75.08
loss: 0.1054, acc: 91.25, test_acc: 79.78, f1: 76.01
loss: 0.2714, acc: 91.02, test_acc: 77.74, f1: 72.48
loss: 0.2924, acc: 90.81, test_acc: 76.96, f1: 72.31
loss: 0.5001, acc: 90.28, test_acc: 78.37, f1: 74.77
loss: 0.4106, acc: 89.80, test_acc: 77.59, f1: 71.27
loss: 0.2442, acc: 89.69, test_acc: 77.27, f1: 70.33
loss: 0.0474, acc: 90.18, test_acc: 77.43, f1: 71.49
loss: 0.2230, acc: 90.06, test_acc: 79.94, f1: 75.75
loss: 0.2719, acc: 90.22, test_acc: 76.49, f1: 73.90
loss: 0.3036, acc: 90.10, test_acc: 78.84, f1: 73.75
loss: 0.5226, acc: 90.00, test_acc: 75.08, f1: 67.17
>> saved: state_dict/lcf_bert_laptop_acc81.19
max_acc:81.19  f1:77.65
loss: 0.0725, acc: 90.38, test_acc: 81.19, f1: 77.65
loss: 0.2641, acc: 90.51, test_acc: 79.47, f1: 75.53
loss: 0.4519, acc: 89.96, test_acc: 77.90, f1: 72.89
loss: 0.2864, acc: 89.87, test_acc: 78.06, f1: 72.84
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0321, acc: 100.00, test_acc: 76.80, f1: 70.43
loss: 0.0608, acc: 96.88, test_acc: 78.53, f1: 72.24
loss: 0.1620, acc: 93.75, test_acc: 80.09, f1: 75.48
>> saved: state_dict/lcf_bert_laptop_acc81.35
max_acc:81.35  f1:77.43
loss: 0.0519, acc: 95.31, test_acc: 81.35, f1: 77.43
loss: 0.0292, acc: 96.25, test_acc: 79.00, f1: 74.22
loss: 0.2971, acc: 94.79, test_acc: 78.53, f1: 73.93
loss: 0.1632, acc: 94.64, test_acc: 80.25, f1: 76.80
loss: 0.0461, acc: 95.31, test_acc: 81.19, f1: 77.36
loss: 0.1732, acc: 95.14, test_acc: 79.94, f1: 75.69
loss: 0.1331, acc: 95.00, test_acc: 80.09, f1: 75.51
loss: 0.1990, acc: 94.89, test_acc: 79.62, f1: 75.81
loss: 0.3620, acc: 94.79, test_acc: 79.78, f1: 76.51
loss: 0.1048, acc: 94.71, test_acc: 79.94, f1: 76.20
loss: 0.0645, acc: 94.64, test_acc: 78.84, f1: 73.89
loss: 0.0390, acc: 95.00, test_acc: 78.84, f1: 73.78
loss: 0.0501, acc: 95.31, test_acc: 79.31, f1: 74.67
loss: 0.0719, acc: 95.22, test_acc: 79.47, f1: 74.23
loss: 0.4366, acc: 94.44, test_acc: 78.68, f1: 73.01
loss: 0.2710, acc: 94.08, test_acc: 80.88, f1: 76.54
loss: 0.2393, acc: 94.06, test_acc: 80.25, f1: 75.43
loss: 0.0698, acc: 94.35, test_acc: 80.25, f1: 75.63
loss: 0.0165, acc: 94.60, test_acc: 80.56, f1: 76.56
loss: 0.2480, acc: 94.29, test_acc: 80.56, f1: 76.31
loss: 0.1595, acc: 94.27, test_acc: 77.43, f1: 71.21
loss: 0.0329, acc: 94.50, test_acc: 77.43, f1: 71.31
loss: 0.0886, acc: 94.71, test_acc: 78.06, f1: 72.62
loss: 0.1255, acc: 94.68, test_acc: 78.68, f1: 73.52
loss: 0.1132, acc: 94.64, test_acc: 80.88, f1: 76.82
loss: 0.1534, acc: 94.61, test_acc: 79.78, f1: 75.22
loss: 0.0131, acc: 94.70, test_acc: 77.74, f1: 70.94
####################################################################################################
max_test_acc_overall:81.34796238244513
max_f1_overall:77.64856855003957
####################################################################################################
1 test_acc_overall: 82.6  f1_overall:79.93
2 test_acc_overall: 80.88  f1_overall:77.7
3 test_acc_overall: 82.76  f1_overall:79.66
4 test_acc_overall: 82.29  f1_overall:79.27
5 test_acc_overall: 81.35  f1_overall:77.65
max_acc_overall:82.76  f1_overall:79.66
mean_acc_overall:81.97  mean_f1_overall:78.84
####################################################################################################
lcf_bert - restaurant - cdw - No.1 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:0
>>> seed: 0
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc63.21
max_acc:63.21  f1:26.73
loss: 0.7429, acc: 87.50, test_acc: 63.21, f1: 26.73
>> saved: state_dict/lcf_bert_restaurant_acc65.0
max_acc:65.0  f1:26.26
loss: 0.8136, acc: 78.12, test_acc: 65.00, f1: 26.26
loss: 1.0441, acc: 68.75, test_acc: 65.00, f1: 26.26
loss: 0.8671, acc: 67.19, test_acc: 65.00, f1: 26.26
loss: 0.8304, acc: 68.75, test_acc: 65.00, f1: 26.26
>> saved: state_dict/lcf_bert_restaurant_acc66.79
max_acc:66.79  f1:34.79
loss: 0.8609, acc: 67.71, test_acc: 66.79, f1: 34.79
loss: 0.7765, acc: 66.07, test_acc: 65.45, f1: 28.32
>> saved: state_dict/lcf_bert_restaurant_acc77.86
max_acc:77.86  f1:64.12
loss: 0.7139, acc: 69.53, test_acc: 77.86, f1: 64.12
>> saved: state_dict/lcf_bert_restaurant_acc78.66
max_acc:78.66  f1:57.63
loss: 0.8517, acc: 69.44, test_acc: 78.66, f1: 57.63
>> saved: state_dict/lcf_bert_restaurant_acc78.93
max_acc:78.93  f1:57.16
loss: 0.8116, acc: 68.12, test_acc: 78.93, f1: 57.16
>> saved: state_dict/lcf_bert_restaurant_acc80.0
max_acc:80.0  f1:67.52
loss: 0.4984, acc: 69.32, test_acc: 80.00, f1: 67.52
loss: 0.6502, acc: 68.75, test_acc: 79.29, f1: 59.03
>> saved: state_dict/lcf_bert_restaurant_acc80.09
max_acc:80.09  f1:61.91
loss: 0.5822, acc: 69.71, test_acc: 80.09, f1: 61.91
>> saved: state_dict/lcf_bert_restaurant_acc81.43
max_acc:81.43  f1:70.73
loss: 0.5532, acc: 70.09, test_acc: 81.43, f1: 70.73
loss: 0.5458, acc: 70.83, test_acc: 79.82, f1: 64.79
loss: 1.1419, acc: 69.14, test_acc: 78.84, f1: 61.35
loss: 0.6999, acc: 69.49, test_acc: 79.91, f1: 63.28
loss: 0.5488, acc: 70.14, test_acc: 78.75, f1: 59.91
loss: 0.7552, acc: 70.07, test_acc: 78.84, f1: 63.34
loss: 0.5510, acc: 70.62, test_acc: 78.12, f1: 63.50
loss: 0.3690, acc: 71.43, test_acc: 80.80, f1: 68.43
loss: 0.2856, acc: 72.44, test_acc: 79.64, f1: 60.54
loss: 0.4364, acc: 72.55, test_acc: 79.55, f1: 59.06
loss: 0.3885, acc: 73.18, test_acc: 79.91, f1: 64.76
loss: 0.8004, acc: 72.75, test_acc: 81.16, f1: 67.66
loss: 0.4478, acc: 73.32, test_acc: 80.18, f1: 62.85
loss: 0.5859, acc: 73.38, test_acc: 78.57, f1: 59.02
loss: 0.6230, acc: 73.66, test_acc: 79.82, f1: 60.37
loss: 0.7938, acc: 73.28, test_acc: 80.80, f1: 69.30
loss: 0.3505, acc: 73.75, test_acc: 79.02, f1: 68.04
>> saved: state_dict/lcf_bert_restaurant_acc82.68
max_acc:82.68  f1:71.6
loss: 0.4408, acc: 74.19, test_acc: 82.68, f1: 71.60
loss: 0.6548, acc: 74.41, test_acc: 79.91, f1: 60.82
loss: 0.4521, acc: 74.43, test_acc: 79.64, f1: 58.83
loss: 0.6244, acc: 74.45, test_acc: 82.41, f1: 67.95
>> saved: state_dict/lcf_bert_restaurant_acc83.66
max_acc:83.66  f1:77.2
loss: 0.5950, acc: 74.29, test_acc: 83.66, f1: 77.20
loss: 0.5367, acc: 74.31, test_acc: 81.70, f1: 67.88
loss: 0.7349, acc: 73.99, test_acc: 79.02, f1: 58.76
loss: 0.3937, acc: 74.18, test_acc: 81.16, f1: 65.43
>> saved: state_dict/lcf_bert_restaurant_acc84.11
max_acc:84.11  f1:74.71
loss: 0.6286, acc: 74.20, test_acc: 84.11, f1: 74.71
loss: 0.2958, acc: 74.53, test_acc: 83.84, f1: 74.61
loss: 0.5479, acc: 74.85, test_acc: 81.96, f1: 69.52
loss: 0.4340, acc: 74.85, test_acc: 80.71, f1: 64.74
loss: 0.5726, acc: 75.00, test_acc: 82.50, f1: 69.48
loss: 0.3021, acc: 75.43, test_acc: 83.48, f1: 72.45
>> saved: state_dict/lcf_bert_restaurant_acc84.73
max_acc:84.73  f1:75.68
loss: 0.5511, acc: 75.42, test_acc: 84.73, f1: 75.68
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.7572, acc: 75.00, test_acc: 84.02, f1: 75.11
loss: 0.3529, acc: 84.38, test_acc: 83.30, f1: 73.42
loss: 0.3266, acc: 83.33, test_acc: 83.21, f1: 70.49
loss: 0.6907, acc: 81.25, test_acc: 83.04, f1: 70.21
loss: 0.5510, acc: 80.00, test_acc: 84.64, f1: 76.00
loss: 0.4481, acc: 80.21, test_acc: 82.95, f1: 75.16
loss: 0.5048, acc: 79.46, test_acc: 82.50, f1: 73.29
loss: 0.4414, acc: 78.91, test_acc: 82.77, f1: 71.06
loss: 0.2617, acc: 80.56, test_acc: 82.23, f1: 70.45
loss: 0.2698, acc: 80.62, test_acc: 83.57, f1: 73.00
loss: 0.4288, acc: 80.68, test_acc: 82.50, f1: 73.00
loss: 0.2790, acc: 81.77, test_acc: 84.11, f1: 73.04
loss: 0.4566, acc: 81.73, test_acc: 83.48, f1: 72.46
loss: 0.2268, acc: 82.14, test_acc: 83.39, f1: 74.68
loss: 0.3473, acc: 82.08, test_acc: 83.12, f1: 72.15
loss: 0.0905, acc: 83.20, test_acc: 81.16, f1: 64.30
loss: 0.1102, acc: 83.82, test_acc: 80.71, f1: 63.79
loss: 0.1179, acc: 84.38, test_acc: 83.93, f1: 73.93
loss: 0.5181, acc: 84.21, test_acc: 83.84, f1: 76.24
loss: 0.4049, acc: 83.75, test_acc: 81.96, f1: 71.09
loss: 0.3606, acc: 83.63, test_acc: 82.32, f1: 69.85
loss: 0.6865, acc: 83.52, test_acc: 84.02, f1: 73.55
loss: 0.4215, acc: 83.42, test_acc: 84.55, f1: 74.89
>> saved: state_dict/lcf_bert_restaurant_acc85.71
max_acc:85.71  f1:77.38
loss: 0.4350, acc: 83.33, test_acc: 85.71, f1: 77.38
>> saved: state_dict/lcf_bert_restaurant_acc86.07
max_acc:86.07  f1:78.35
loss: 0.5178, acc: 83.00, test_acc: 86.07, f1: 78.35
loss: 0.3566, acc: 83.17, test_acc: 85.27, f1: 76.38
>> saved: state_dict/lcf_bert_restaurant_acc86.43
max_acc:86.43  f1:78.54
loss: 0.3237, acc: 83.33, test_acc: 86.43, f1: 78.54
loss: 0.9088, acc: 82.59, test_acc: 86.43, f1: 78.91
>> saved: state_dict/lcf_bert_restaurant_acc86.88
max_acc:86.88  f1:80.49
loss: 0.3187, acc: 82.76, test_acc: 86.88, f1: 80.49
loss: 0.4222, acc: 82.50, test_acc: 85.09, f1: 75.44
loss: 0.5571, acc: 82.46, test_acc: 85.18, f1: 75.41
loss: 0.2838, acc: 82.42, test_acc: 84.82, f1: 75.06
loss: 0.2889, acc: 82.58, test_acc: 85.71, f1: 77.66
loss: 0.5140, acc: 82.54, test_acc: 85.36, f1: 76.28
loss: 0.3555, acc: 82.50, test_acc: 84.73, f1: 76.34
loss: 0.5863, acc: 82.64, test_acc: 84.64, f1: 77.27
loss: 0.3759, acc: 82.77, test_acc: 83.12, f1: 74.01
loss: 0.7688, acc: 82.40, test_acc: 84.64, f1: 74.58
loss: 0.4222, acc: 82.37, test_acc: 86.25, f1: 79.21
loss: 0.2422, acc: 82.66, test_acc: 86.61, f1: 80.11
>> saved: state_dict/lcf_bert_restaurant_acc87.05
max_acc:87.05  f1:80.78
loss: 0.2952, acc: 82.77, test_acc: 87.05, f1: 80.78
>> saved: state_dict/lcf_bert_restaurant_acc87.77
max_acc:87.77  f1:82.03
loss: 0.2201, acc: 83.04, test_acc: 87.77, f1: 82.03
loss: 0.3385, acc: 83.14, test_acc: 86.07, f1: 78.20
loss: 0.2372, acc: 83.24, test_acc: 86.96, f1: 79.56
loss: 0.1931, acc: 83.47, test_acc: 86.79, f1: 78.24
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2751, acc: 81.25, test_acc: 86.52, f1: 77.12
loss: 0.1006, acc: 87.50, test_acc: 87.68, f1: 81.13
loss: 0.1514, acc: 89.58, test_acc: 87.23, f1: 80.46
loss: 0.1454, acc: 90.62, test_acc: 86.88, f1: 80.30
loss: 0.2452, acc: 88.75, test_acc: 86.16, f1: 78.47
loss: 0.4324, acc: 88.54, test_acc: 85.80, f1: 77.58
loss: 0.0740, acc: 90.18, test_acc: 86.61, f1: 80.65
loss: 0.2584, acc: 90.62, test_acc: 87.50, f1: 81.13
loss: 0.1845, acc: 90.28, test_acc: 86.79, f1: 78.94
>> saved: state_dict/lcf_bert_restaurant_acc87.86
max_acc:87.86  f1:82.0
loss: 0.1896, acc: 90.62, test_acc: 87.86, f1: 82.00
>> saved: state_dict/lcf_bert_restaurant_acc88.66
max_acc:88.66  f1:82.89
loss: 0.0980, acc: 91.48, test_acc: 88.66, f1: 82.89
loss: 0.4075, acc: 90.62, test_acc: 87.41, f1: 79.85
loss: 0.1383, acc: 90.87, test_acc: 87.23, f1: 80.02
loss: 0.8467, acc: 89.73, test_acc: 87.50, f1: 81.38
loss: 0.3675, acc: 89.17, test_acc: 87.05, f1: 81.17
loss: 0.2236, acc: 89.45, test_acc: 86.96, f1: 80.12
loss: 0.1050, acc: 90.07, test_acc: 87.59, f1: 81.13
loss: 0.1007, acc: 90.62, test_acc: 87.23, f1: 79.37
loss: 0.2829, acc: 90.46, test_acc: 87.32, f1: 80.40
loss: 0.1188, acc: 90.94, test_acc: 87.14, f1: 80.10
loss: 0.2269, acc: 90.77, test_acc: 85.98, f1: 78.29
loss: 0.2076, acc: 90.91, test_acc: 86.96, f1: 79.33
loss: 0.0655, acc: 91.30, test_acc: 87.23, f1: 80.59
loss: 0.1921, acc: 90.89, test_acc: 87.14, f1: 81.07
loss: 0.3143, acc: 90.75, test_acc: 87.14, f1: 79.91
loss: 0.1243, acc: 90.87, test_acc: 84.46, f1: 75.09
loss: 0.4006, acc: 90.74, test_acc: 87.68, f1: 81.96
loss: 0.0837, acc: 91.07, test_acc: 87.68, f1: 81.50
loss: 0.2829, acc: 91.16, test_acc: 87.14, f1: 79.39
loss: 0.6286, acc: 91.04, test_acc: 87.50, f1: 80.31
loss: 0.6099, acc: 90.32, test_acc: 88.04, f1: 81.40
loss: 0.5626, acc: 89.65, test_acc: 87.23, f1: 79.95
loss: 0.4008, acc: 89.58, test_acc: 86.61, f1: 77.97
loss: 0.3123, acc: 89.71, test_acc: 86.70, f1: 78.85
loss: 0.2948, acc: 89.64, test_acc: 85.54, f1: 77.48
loss: 0.3117, acc: 89.76, test_acc: 85.98, f1: 77.88
loss: 0.3552, acc: 89.53, test_acc: 85.62, f1: 76.49
loss: 0.2639, acc: 89.31, test_acc: 86.70, f1: 78.61
loss: 0.4326, acc: 89.26, test_acc: 87.32, f1: 80.46
loss: 0.0755, acc: 89.53, test_acc: 88.04, f1: 82.05
loss: 0.0984, acc: 89.63, test_acc: 88.48, f1: 82.54
loss: 0.1828, acc: 89.73, test_acc: 88.12, f1: 81.27
loss: 0.1868, acc: 89.68, test_acc: 87.32, f1: 79.12
loss: 0.2068, acc: 89.77, test_acc: 87.05, f1: 79.27
loss: 0.1551, acc: 89.86, test_acc: 87.59, f1: 80.58
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.1004, acc: 100.00, test_acc: 87.14, f1: 79.14
loss: 0.2627, acc: 90.62, test_acc: 86.70, f1: 78.68
loss: 0.2443, acc: 91.67, test_acc: 87.68, f1: 80.53
loss: 0.0658, acc: 93.75, test_acc: 87.95, f1: 81.15
loss: 0.0697, acc: 95.00, test_acc: 88.12, f1: 81.07
loss: 0.0371, acc: 95.83, test_acc: 87.95, f1: 81.25
loss: 0.0820, acc: 95.54, test_acc: 88.48, f1: 81.92
loss: 0.2100, acc: 95.31, test_acc: 88.04, f1: 82.03
loss: 0.2066, acc: 94.44, test_acc: 88.39, f1: 82.26
loss: 0.1143, acc: 94.38, test_acc: 88.48, f1: 82.65
loss: 0.3821, acc: 93.75, test_acc: 87.86, f1: 82.34
loss: 0.0125, acc: 94.27, test_acc: 88.04, f1: 81.23
loss: 0.0998, acc: 94.71, test_acc: 86.96, f1: 79.10
loss: 0.0871, acc: 94.64, test_acc: 88.21, f1: 81.39
loss: 0.1292, acc: 94.58, test_acc: 88.66, f1: 82.63
loss: 0.0508, acc: 94.92, test_acc: 88.66, f1: 82.47
>> saved: state_dict/lcf_bert_restaurant_acc89.02
max_acc:89.02  f1:83.52
loss: 0.2210, acc: 94.49, test_acc: 89.02, f1: 83.52
loss: 0.0266, acc: 94.79, test_acc: 88.75, f1: 83.15
loss: 0.0512, acc: 95.07, test_acc: 89.02, f1: 83.75
loss: 0.1598, acc: 95.00, test_acc: 88.57, f1: 82.59
loss: 0.1362, acc: 94.64, test_acc: 88.84, f1: 82.74
loss: 0.5374, acc: 93.75, test_acc: 89.02, f1: 84.00
loss: 0.0942, acc: 93.75, test_acc: 87.95, f1: 83.22
loss: 0.0984, acc: 93.75, test_acc: 87.23, f1: 80.55
loss: 0.1385, acc: 93.75, test_acc: 88.48, f1: 82.84
loss: 0.0713, acc: 93.99, test_acc: 88.75, f1: 84.11
loss: 0.6413, acc: 93.75, test_acc: 88.93, f1: 83.70
loss: 0.0194, acc: 93.97, test_acc: 87.95, f1: 81.15
loss: 0.3287, acc: 93.97, test_acc: 88.30, f1: 82.08
loss: 0.0180, acc: 94.17, test_acc: 88.30, f1: 82.16
loss: 0.1448, acc: 94.15, test_acc: 88.75, f1: 83.41
loss: 0.0684, acc: 94.34, test_acc: 88.75, f1: 83.41
loss: 0.0898, acc: 94.51, test_acc: 88.12, f1: 81.79
loss: 0.0326, acc: 94.67, test_acc: 87.59, f1: 80.96
loss: 0.0393, acc: 94.82, test_acc: 88.04, f1: 81.47
loss: 0.0560, acc: 94.97, test_acc: 88.75, f1: 82.78
loss: 0.2682, acc: 94.76, test_acc: 89.02, f1: 83.31
loss: 0.0301, acc: 94.90, test_acc: 88.75, f1: 82.35
loss: 0.1360, acc: 94.87, test_acc: 88.21, f1: 81.28
loss: 0.0447, acc: 95.00, test_acc: 88.39, f1: 82.11
loss: 0.2649, acc: 94.97, test_acc: 87.68, f1: 80.64
loss: 0.0186, acc: 95.09, test_acc: 86.70, f1: 79.37
loss: 0.1587, acc: 95.06, test_acc: 86.07, f1: 77.54
loss: 0.2264, acc: 94.89, test_acc: 86.25, f1: 78.21
loss: 0.1424, acc: 94.86, test_acc: 86.70, f1: 79.66
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0840, acc: 100.00, test_acc: 86.70, f1: 80.11
loss: 0.0571, acc: 100.00, test_acc: 87.77, f1: 81.29
loss: 0.0099, acc: 100.00, test_acc: 88.66, f1: 82.47
loss: 0.0870, acc: 100.00, test_acc: 88.66, f1: 82.24
>> saved: state_dict/lcf_bert_restaurant_acc89.11
max_acc:89.11  f1:82.83
loss: 0.0112, acc: 100.00, test_acc: 89.11, f1: 82.83
loss: 0.1725, acc: 98.96, test_acc: 89.02, f1: 82.18
loss: 0.0370, acc: 99.11, test_acc: 88.93, f1: 82.45
loss: 0.0061, acc: 99.22, test_acc: 88.12, f1: 81.63
loss: 0.0038, acc: 99.31, test_acc: 87.95, f1: 81.53
loss: 0.0536, acc: 99.38, test_acc: 88.04, f1: 81.59
loss: 0.0170, acc: 99.43, test_acc: 88.75, f1: 82.60
loss: 0.0051, acc: 99.48, test_acc: 87.59, f1: 80.11
loss: 0.0557, acc: 99.52, test_acc: 88.12, f1: 81.46
loss: 0.0369, acc: 99.55, test_acc: 88.21, f1: 82.05
loss: 0.0299, acc: 99.58, test_acc: 86.96, f1: 79.25
loss: 0.2014, acc: 98.83, test_acc: 86.96, f1: 78.76
loss: 0.0358, acc: 98.90, test_acc: 88.66, f1: 82.70
loss: 0.0451, acc: 98.96, test_acc: 87.41, f1: 81.87
loss: 0.0078, acc: 99.01, test_acc: 88.75, f1: 82.48
loss: 0.0902, acc: 98.75, test_acc: 88.30, f1: 81.40
loss: 0.0363, acc: 98.81, test_acc: 88.04, f1: 82.10
loss: 0.0380, acc: 98.86, test_acc: 86.96, f1: 80.90
loss: 0.0148, acc: 98.91, test_acc: 87.41, f1: 80.98
loss: 0.0209, acc: 98.96, test_acc: 86.25, f1: 78.78
loss: 0.0115, acc: 99.00, test_acc: 86.61, f1: 79.31
loss: 0.0395, acc: 99.04, test_acc: 86.43, f1: 78.95
loss: 0.0584, acc: 99.07, test_acc: 86.79, f1: 79.56
loss: 0.0158, acc: 99.11, test_acc: 86.79, f1: 79.21
loss: 0.0337, acc: 99.14, test_acc: 88.12, f1: 82.24
loss: 0.0129, acc: 99.17, test_acc: 87.68, f1: 81.75
loss: 0.0269, acc: 99.19, test_acc: 87.32, f1: 80.77
loss: 0.0148, acc: 99.22, test_acc: 87.50, f1: 80.33
loss: 0.1755, acc: 99.05, test_acc: 88.04, f1: 81.17
loss: 0.2362, acc: 98.90, test_acc: 88.30, f1: 82.90
loss: 0.1442, acc: 98.75, test_acc: 87.77, f1: 82.52
loss: 0.0162, acc: 98.78, test_acc: 88.04, f1: 81.81
loss: 0.3920, acc: 98.48, test_acc: 86.70, f1: 78.81
loss: 0.2553, acc: 98.19, test_acc: 86.79, f1: 78.78
loss: 0.0016, acc: 98.24, test_acc: 88.84, f1: 82.99
loss: 0.0178, acc: 98.28, test_acc: 87.95, f1: 82.35
loss: 0.1765, acc: 98.17, test_acc: 88.21, f1: 82.73
loss: 0.0709, acc: 98.07, test_acc: 89.11, f1: 83.19
loss: 0.0636, acc: 98.11, test_acc: 88.84, f1: 82.65
loss: 0.1898, acc: 98.01, test_acc: 87.77, f1: 81.09
loss: 0.1599, acc: 97.92, test_acc: 87.32, f1: 80.54
loss: 0.0025, acc: 97.94, test_acc: 87.05, f1: 79.71
####################################################################################################
max_test_acc_overall:89.10714285714286
max_f1_overall:84.10501035597572
####################################################################################################
1 test_acc_overall: 89.11  f1_overall:84.11
max_acc_overall:89.11  f1_overall:84.11
mean_acc_overall:89.11  mean_f1_overall:84.11
####################################################################################################
lcf_bert - restaurant - cdw - No.2 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:0
>>> seed: 1
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc20.45
max_acc:20.45  f1:13.16
loss: 1.0777, acc: 43.75, test_acc: 20.45, f1: 13.16
>> saved: state_dict/lcf_bert_restaurant_acc65.27
max_acc:65.27  f1:27.31
loss: 0.6821, acc: 59.38, test_acc: 65.27, f1: 27.31
loss: 0.8280, acc: 62.50, test_acc: 65.27, f1: 27.63
>> saved: state_dict/lcf_bert_restaurant_acc69.29
max_acc:69.29  f1:42.14
loss: 0.9295, acc: 62.50, test_acc: 69.29, f1: 42.14
loss: 0.6086, acc: 66.25, test_acc: 65.62, f1: 29.25
>> saved: state_dict/lcf_bert_restaurant_acc73.3
max_acc:73.3  f1:47.72
loss: 0.7481, acc: 65.62, test_acc: 73.30, f1: 47.72
>> saved: state_dict/lcf_bert_restaurant_acc76.34
max_acc:76.34  f1:57.97
loss: 0.6861, acc: 66.07, test_acc: 76.34, f1: 57.97
>> saved: state_dict/lcf_bert_restaurant_acc77.05
max_acc:77.05  f1:63.85
loss: 0.8300, acc: 66.41, test_acc: 77.05, f1: 63.85
>> saved: state_dict/lcf_bert_restaurant_acc77.86
max_acc:77.86  f1:56.34
loss: 1.0856, acc: 65.97, test_acc: 77.86, f1: 56.34
>> saved: state_dict/lcf_bert_restaurant_acc78.84
max_acc:78.84  f1:56.93
loss: 0.7029, acc: 66.88, test_acc: 78.84, f1: 56.93
>> saved: state_dict/lcf_bert_restaurant_acc79.02
max_acc:79.02  f1:57.96
loss: 0.5478, acc: 68.75, test_acc: 79.02, f1: 57.96
loss: 0.5403, acc: 69.27, test_acc: 78.48, f1: 54.79
loss: 0.7310, acc: 69.23, test_acc: 77.59, f1: 59.67
>> saved: state_dict/lcf_bert_restaurant_acc79.64
max_acc:79.64  f1:69.3
loss: 0.4487, acc: 70.54, test_acc: 79.64, f1: 69.30
>> saved: state_dict/lcf_bert_restaurant_acc81.07
max_acc:81.07  f1:69.33
loss: 0.8901, acc: 69.58, test_acc: 81.07, f1: 69.33
loss: 0.3489, acc: 70.70, test_acc: 78.93, f1: 57.69
loss: 1.0848, acc: 70.22, test_acc: 80.62, f1: 62.20
>> saved: state_dict/lcf_bert_restaurant_acc81.61
max_acc:81.61  f1:73.58
loss: 0.5349, acc: 70.49, test_acc: 81.61, f1: 73.58
loss: 0.6787, acc: 71.05, test_acc: 80.62, f1: 66.81
loss: 0.5436, acc: 71.56, test_acc: 79.64, f1: 61.02
>> saved: state_dict/lcf_bert_restaurant_acc82.41
max_acc:82.41  f1:68.5
loss: 0.5296, acc: 71.73, test_acc: 82.41, f1: 68.50
>> saved: state_dict/lcf_bert_restaurant_acc83.04
max_acc:83.04  f1:71.0
loss: 0.8206, acc: 70.74, test_acc: 83.04, f1: 71.00
loss: 1.1760, acc: 70.11, test_acc: 80.80, f1: 61.93
loss: 0.8158, acc: 70.31, test_acc: 81.25, f1: 65.17
loss: 0.3339, acc: 71.00, test_acc: 81.70, f1: 68.41
loss: 1.3785, acc: 70.19, test_acc: 80.36, f1: 65.09
loss: 0.3336, acc: 70.60, test_acc: 81.96, f1: 70.85
loss: 1.2581, acc: 69.87, test_acc: 81.70, f1: 71.16
loss: 0.7147, acc: 69.61, test_acc: 82.50, f1: 74.69
loss: 0.4103, acc: 70.21, test_acc: 81.07, f1: 67.20
loss: 0.7101, acc: 70.16, test_acc: 79.73, f1: 62.66
loss: 0.5505, acc: 70.31, test_acc: 79.55, f1: 62.11
loss: 0.2459, acc: 71.02, test_acc: 80.89, f1: 65.73
loss: 0.7075, acc: 70.96, test_acc: 82.59, f1: 72.17
loss: 0.5636, acc: 71.07, test_acc: 82.14, f1: 70.14
loss: 0.7222, acc: 71.18, test_acc: 80.45, f1: 64.21
loss: 0.4215, acc: 71.45, test_acc: 80.09, f1: 62.43
loss: 0.5194, acc: 71.71, test_acc: 82.05, f1: 67.90
loss: 0.7045, acc: 71.63, test_acc: 82.14, f1: 70.03
loss: 0.6963, acc: 71.56, test_acc: 81.52, f1: 70.00
>> saved: state_dict/lcf_bert_restaurant_acc83.57
max_acc:83.57  f1:72.97
loss: 0.2712, acc: 71.95, test_acc: 83.57, f1: 72.97
loss: 0.6048, acc: 71.88, test_acc: 83.30, f1: 72.34
loss: 0.5680, acc: 71.95, test_acc: 82.95, f1: 71.78
loss: 0.4636, acc: 72.16, test_acc: 82.41, f1: 70.99
loss: 0.4577, acc: 72.22, test_acc: 81.96, f1: 70.98
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.4952, acc: 75.00, test_acc: 82.77, f1: 71.87
loss: 0.1300, acc: 84.38, test_acc: 83.21, f1: 73.97
loss: 0.6345, acc: 81.25, test_acc: 82.86, f1: 71.79
loss: 0.3788, acc: 82.81, test_acc: 82.86, f1: 70.57
loss: 0.2528, acc: 86.25, test_acc: 83.12, f1: 71.87
>> saved: state_dict/lcf_bert_restaurant_acc83.75
max_acc:83.75  f1:74.14
loss: 0.7234, acc: 82.29, test_acc: 83.75, f1: 74.14
loss: 0.4731, acc: 82.14, test_acc: 81.96, f1: 74.22
loss: 0.7943, acc: 80.47, test_acc: 83.48, f1: 71.71
loss: 0.2763, acc: 81.94, test_acc: 82.77, f1: 70.31
loss: 0.4195, acc: 81.88, test_acc: 83.30, f1: 73.03
loss: 0.4936, acc: 81.82, test_acc: 82.59, f1: 72.88
loss: 0.2078, acc: 82.81, test_acc: 83.57, f1: 74.63
loss: 0.7392, acc: 81.25, test_acc: 82.14, f1: 68.93
loss: 0.7078, acc: 80.36, test_acc: 82.05, f1: 67.97
>> saved: state_dict/lcf_bert_restaurant_acc83.84
max_acc:83.84  f1:74.12
loss: 0.2811, acc: 80.42, test_acc: 83.84, f1: 74.12
>> saved: state_dict/lcf_bert_restaurant_acc84.2
max_acc:84.2  f1:75.3
loss: 0.6697, acc: 79.30, test_acc: 84.20, f1: 75.30
loss: 0.4435, acc: 80.15, test_acc: 84.11, f1: 73.67
loss: 0.3588, acc: 80.56, test_acc: 84.11, f1: 74.23
>> saved: state_dict/lcf_bert_restaurant_acc84.82
max_acc:84.82  f1:77.37
loss: 0.4597, acc: 80.26, test_acc: 84.82, f1: 77.37
>> saved: state_dict/lcf_bert_restaurant_acc85.0
max_acc:85.0  f1:77.07
loss: 0.3256, acc: 80.62, test_acc: 85.00, f1: 77.07
loss: 0.5374, acc: 80.95, test_acc: 83.93, f1: 72.67
>> saved: state_dict/lcf_bert_restaurant_acc85.54
max_acc:85.54  f1:77.28
loss: 0.4947, acc: 80.97, test_acc: 85.54, f1: 77.28
loss: 0.5571, acc: 80.98, test_acc: 84.46, f1: 73.99
loss: 0.4082, acc: 80.99, test_acc: 84.91, f1: 74.91
loss: 0.7276, acc: 80.50, test_acc: 84.02, f1: 72.90
loss: 0.3247, acc: 80.53, test_acc: 84.38, f1: 74.95
loss: 0.4058, acc: 80.32, test_acc: 83.04, f1: 70.77
loss: 0.1647, acc: 81.03, test_acc: 81.70, f1: 66.55
loss: 0.3873, acc: 81.25, test_acc: 83.48, f1: 72.43
loss: 0.7845, acc: 80.83, test_acc: 84.64, f1: 77.02
loss: 0.3739, acc: 81.05, test_acc: 83.84, f1: 75.01
loss: 0.4940, acc: 80.86, test_acc: 82.95, f1: 70.38
loss: 0.1943, acc: 81.25, test_acc: 83.48, f1: 74.66
loss: 0.6552, acc: 81.25, test_acc: 83.39, f1: 75.42
loss: 0.3225, acc: 81.43, test_acc: 82.41, f1: 67.71
loss: 0.4145, acc: 81.42, test_acc: 83.21, f1: 71.47
loss: 0.4003, acc: 81.42, test_acc: 83.75, f1: 74.40
loss: 0.2471, acc: 81.74, test_acc: 83.84, f1: 74.07
loss: 0.2243, acc: 81.89, test_acc: 83.12, f1: 71.65
loss: 0.3789, acc: 81.72, test_acc: 83.75, f1: 77.17
loss: 0.8329, acc: 81.25, test_acc: 84.38, f1: 75.90
loss: 0.4589, acc: 81.25, test_acc: 83.04, f1: 67.64
loss: 0.1608, acc: 81.54, test_acc: 83.84, f1: 71.06
>> saved: state_dict/lcf_bert_restaurant_acc85.8
max_acc:85.8  f1:78.71
loss: 0.3668, acc: 81.68, test_acc: 85.80, f1: 78.71
>> saved: state_dict/lcf_bert_restaurant_acc85.89
max_acc:85.89  f1:78.74
loss: 0.4372, acc: 81.67, test_acc: 85.89, f1: 78.74
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
>> saved: state_dict/lcf_bert_restaurant_acc86.79
max_acc:86.79  f1:79.72
loss: 0.3992, acc: 87.50, test_acc: 86.79, f1: 79.72
loss: 0.2946, acc: 87.50, test_acc: 85.89, f1: 78.13
loss: 0.3081, acc: 89.58, test_acc: 85.54, f1: 76.34
loss: 0.0449, acc: 92.19, test_acc: 84.91, f1: 74.14
>> saved: state_dict/lcf_bert_restaurant_acc86.88
max_acc:86.88  f1:79.18
loss: 0.2828, acc: 91.25, test_acc: 86.88, f1: 79.18
>> saved: state_dict/lcf_bert_restaurant_acc87.32
max_acc:87.32  f1:80.54
loss: 0.0668, acc: 92.71, test_acc: 87.32, f1: 80.54
loss: 0.2342, acc: 91.96, test_acc: 86.43, f1: 78.18
loss: 0.2445, acc: 91.41, test_acc: 85.89, f1: 77.63
loss: 0.1387, acc: 91.67, test_acc: 86.61, f1: 80.87
loss: 0.0541, acc: 92.50, test_acc: 86.96, f1: 81.26
loss: 0.2614, acc: 92.05, test_acc: 84.91, f1: 73.96
loss: 0.5351, acc: 91.67, test_acc: 85.00, f1: 74.58
loss: 0.2596, acc: 91.35, test_acc: 86.61, f1: 79.98
loss: 0.3288, acc: 91.07, test_acc: 86.96, f1: 80.33
loss: 0.2027, acc: 91.25, test_acc: 84.73, f1: 72.52
loss: 0.4567, acc: 90.62, test_acc: 85.36, f1: 74.86
loss: 0.3564, acc: 90.07, test_acc: 86.16, f1: 78.48
loss: 0.1873, acc: 90.62, test_acc: 86.96, f1: 80.42
loss: 0.2833, acc: 90.46, test_acc: 87.05, f1: 80.42
loss: 1.2120, acc: 89.06, test_acc: 84.11, f1: 70.63
loss: 0.2668, acc: 89.29, test_acc: 84.82, f1: 75.18
loss: 0.1981, acc: 89.49, test_acc: 85.54, f1: 78.02
loss: 0.3773, acc: 89.67, test_acc: 85.89, f1: 78.25
loss: 0.3315, acc: 89.84, test_acc: 85.80, f1: 77.92
loss: 0.0753, acc: 90.25, test_acc: 86.43, f1: 79.71
loss: 0.4333, acc: 89.66, test_acc: 86.43, f1: 79.47
loss: 0.1090, acc: 90.05, test_acc: 85.09, f1: 76.31
loss: 0.7090, acc: 89.51, test_acc: 85.09, f1: 75.28
loss: 0.0970, acc: 89.66, test_acc: 85.00, f1: 76.37
loss: 0.1057, acc: 90.00, test_acc: 85.18, f1: 76.73
loss: 0.1535, acc: 90.12, test_acc: 86.16, f1: 78.62
loss: 0.3764, acc: 89.84, test_acc: 86.43, f1: 79.53
loss: 0.4200, acc: 89.77, test_acc: 85.98, f1: 78.48
loss: 0.3677, acc: 89.71, test_acc: 86.79, f1: 79.98
loss: 0.2494, acc: 89.82, test_acc: 86.52, f1: 78.97
loss: 0.2856, acc: 89.76, test_acc: 85.98, f1: 77.85
loss: 0.2840, acc: 89.70, test_acc: 86.43, f1: 78.55
loss: 0.0871, acc: 89.80, test_acc: 86.79, f1: 79.18
loss: 0.2657, acc: 89.58, test_acc: 86.07, f1: 76.53
loss: 0.3828, acc: 89.69, test_acc: 86.70, f1: 79.77
loss: 0.1950, acc: 89.79, test_acc: 85.89, f1: 78.52
loss: 0.2079, acc: 89.88, test_acc: 87.05, f1: 80.22
loss: 0.5266, acc: 89.68, test_acc: 87.32, f1: 79.80
loss: 0.5380, acc: 89.63, test_acc: 86.52, f1: 77.72
loss: 0.1164, acc: 89.72, test_acc: 86.79, f1: 78.62
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
>> saved: state_dict/lcf_bert_restaurant_acc87.77
max_acc:87.77  f1:80.94
loss: 0.0277, acc: 100.00, test_acc: 87.77, f1: 80.94
loss: 0.0385, acc: 100.00, test_acc: 86.34, f1: 77.68
loss: 0.0070, acc: 100.00, test_acc: 86.25, f1: 78.08
loss: 0.0109, acc: 100.00, test_acc: 86.79, f1: 79.37
loss: 0.2045, acc: 98.75, test_acc: 87.14, f1: 79.73
>> saved: state_dict/lcf_bert_restaurant_acc87.95
max_acc:87.95  f1:81.43
loss: 0.0399, acc: 98.96, test_acc: 87.95, f1: 81.43
loss: 0.0131, acc: 99.11, test_acc: 87.32, f1: 80.06
loss: 0.0393, acc: 99.22, test_acc: 87.32, f1: 80.48
loss: 0.1029, acc: 98.61, test_acc: 87.50, f1: 80.69
loss: 0.0703, acc: 98.75, test_acc: 87.14, f1: 79.30
loss: 0.2523, acc: 97.16, test_acc: 87.32, f1: 80.23
>> saved: state_dict/lcf_bert_restaurant_acc88.57
max_acc:88.57  f1:82.97
loss: 0.0509, acc: 97.40, test_acc: 88.57, f1: 82.97
loss: 0.0277, acc: 97.60, test_acc: 88.21, f1: 82.28
loss: 0.0603, acc: 97.77, test_acc: 86.88, f1: 79.64
loss: 0.0329, acc: 97.92, test_acc: 85.80, f1: 76.76
loss: 0.0640, acc: 97.66, test_acc: 86.25, f1: 77.78
loss: 0.3825, acc: 96.69, test_acc: 86.70, f1: 79.59
loss: 0.3444, acc: 96.18, test_acc: 86.96, f1: 80.18
loss: 0.1306, acc: 96.38, test_acc: 86.61, f1: 78.58
loss: 0.1742, acc: 96.25, test_acc: 86.16, f1: 77.09
loss: 0.1889, acc: 96.13, test_acc: 86.96, f1: 79.41
loss: 0.0144, acc: 96.31, test_acc: 86.88, f1: 80.05
loss: 0.3716, acc: 95.92, test_acc: 86.70, f1: 78.70
loss: 0.4987, acc: 95.05, test_acc: 85.71, f1: 77.11
loss: 0.1986, acc: 95.00, test_acc: 87.14, f1: 80.61
loss: 0.0789, acc: 95.19, test_acc: 87.95, f1: 81.92
loss: 0.1362, acc: 95.14, test_acc: 86.61, f1: 78.66
loss: 0.0553, acc: 95.31, test_acc: 86.52, f1: 78.68
loss: 0.1434, acc: 95.26, test_acc: 87.86, f1: 81.56
loss: 0.0220, acc: 95.42, test_acc: 86.88, f1: 79.92
loss: 0.0861, acc: 95.36, test_acc: 86.61, f1: 78.78
loss: 0.4465, acc: 94.92, test_acc: 86.79, f1: 78.92
loss: 0.0215, acc: 95.08, test_acc: 88.04, f1: 81.95
loss: 0.0310, acc: 95.22, test_acc: 87.32, f1: 80.63
loss: 0.2053, acc: 95.18, test_acc: 87.14, f1: 80.05
loss: 0.0244, acc: 95.31, test_acc: 86.34, f1: 77.82
loss: 0.0773, acc: 95.27, test_acc: 86.79, f1: 78.57
loss: 0.1261, acc: 95.23, test_acc: 86.43, f1: 78.03
loss: 0.2976, acc: 95.03, test_acc: 87.23, f1: 80.00
loss: 0.2473, acc: 94.84, test_acc: 86.88, f1: 80.50
loss: 0.1221, acc: 94.97, test_acc: 86.96, f1: 80.13
loss: 0.2515, acc: 94.79, test_acc: 85.98, f1: 76.64
loss: 0.2505, acc: 94.77, test_acc: 85.54, f1: 76.39
loss: 0.1833, acc: 94.74, test_acc: 85.80, f1: 78.15
loss: 0.0939, acc: 94.86, test_acc: 86.16, f1: 78.99
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0440, acc: 100.00, test_acc: 86.16, f1: 78.76
loss: 0.0103, acc: 100.00, test_acc: 87.23, f1: 80.39
loss: 0.0127, acc: 100.00, test_acc: 87.32, f1: 80.36
loss: 0.0154, acc: 100.00, test_acc: 87.41, f1: 80.74
loss: 0.0908, acc: 98.75, test_acc: 87.59, f1: 81.65
loss: 0.0213, acc: 98.96, test_acc: 87.68, f1: 82.10
loss: 0.0640, acc: 99.11, test_acc: 87.41, f1: 81.00
loss: 0.0404, acc: 99.22, test_acc: 85.98, f1: 77.40
loss: 0.0497, acc: 99.31, test_acc: 86.16, f1: 77.42
loss: 0.0177, acc: 99.38, test_acc: 86.25, f1: 78.09
loss: 0.0054, acc: 99.43, test_acc: 86.70, f1: 78.84
loss: 0.0336, acc: 99.48, test_acc: 87.14, f1: 79.46
loss: 0.0500, acc: 99.52, test_acc: 87.50, f1: 80.59
loss: 0.1033, acc: 99.11, test_acc: 87.23, f1: 79.71
loss: 0.0233, acc: 99.17, test_acc: 87.95, f1: 81.41
loss: 0.0459, acc: 99.22, test_acc: 87.68, f1: 80.96
loss: 0.0194, acc: 99.26, test_acc: 86.88, f1: 78.85
loss: 0.0277, acc: 99.31, test_acc: 86.70, f1: 78.39
loss: 0.0044, acc: 99.34, test_acc: 87.68, f1: 81.10
loss: 0.0671, acc: 99.38, test_acc: 87.41, f1: 81.13
loss: 0.2472, acc: 99.11, test_acc: 87.23, f1: 80.97
loss: 0.1454, acc: 99.15, test_acc: 87.41, f1: 80.77
loss: 0.0564, acc: 99.18, test_acc: 86.61, f1: 78.56
loss: 0.0440, acc: 99.22, test_acc: 86.07, f1: 76.92
loss: 0.1187, acc: 99.00, test_acc: 86.43, f1: 77.89
loss: 0.0182, acc: 99.04, test_acc: 87.41, f1: 80.90
loss: 0.0719, acc: 99.07, test_acc: 88.04, f1: 81.91
loss: 0.0186, acc: 99.11, test_acc: 86.79, f1: 79.26
loss: 0.0061, acc: 99.14, test_acc: 86.07, f1: 77.68
loss: 0.0321, acc: 99.17, test_acc: 87.05, f1: 80.14
loss: 0.0162, acc: 99.19, test_acc: 87.32, f1: 80.83
loss: 0.0886, acc: 99.02, test_acc: 87.23, f1: 80.30
loss: 0.1662, acc: 98.67, test_acc: 87.14, f1: 80.45
loss: 0.2551, acc: 98.35, test_acc: 86.79, f1: 81.59
loss: 0.1502, acc: 98.21, test_acc: 86.96, f1: 80.90
loss: 0.1337, acc: 98.09, test_acc: 86.52, f1: 78.76
loss: 0.1486, acc: 97.97, test_acc: 84.11, f1: 72.55
loss: 0.1136, acc: 97.86, test_acc: 85.89, f1: 76.29
loss: 0.0073, acc: 97.92, test_acc: 87.50, f1: 80.37
loss: 0.0131, acc: 97.97, test_acc: 88.04, f1: 81.74
loss: 0.0478, acc: 98.02, test_acc: 88.04, f1: 81.91
loss: 0.0051, acc: 98.07, test_acc: 88.30, f1: 82.11
>> saved: state_dict/lcf_bert_restaurant_acc88.66
max_acc:88.66  f1:82.57
loss: 0.1450, acc: 97.97, test_acc: 88.66, f1: 82.57
>> saved: state_dict/lcf_bert_restaurant_acc88.75
max_acc:88.75  f1:83.14
loss: 0.1449, acc: 97.87, test_acc: 88.75, f1: 83.14
loss: 0.4687, acc: 97.64, test_acc: 88.30, f1: 82.44
loss: 0.0640, acc: 97.66, test_acc: 88.39, f1: 82.15
####################################################################################################
max_test_acc_overall:88.75
max_f1_overall:83.14432638080123
####################################################################################################
1 test_acc_overall: 89.11  f1_overall:84.11
2 test_acc_overall: 88.75  f1_overall:83.14
max_acc_overall:89.11  f1_overall:84.11
mean_acc_overall:88.93  mean_f1_overall:83.62
####################################################################################################
lcf_bert - restaurant - cdw - No.3 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:0
>>> seed: 2
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc64.55
max_acc:64.55  f1:26.15
loss: 0.8575, acc: 62.50, test_acc: 64.55, f1: 26.15
loss: 0.9517, acc: 59.38, test_acc: 26.43, f1: 18.96
>> saved: state_dict/lcf_bert_restaurant_acc65.0
max_acc:65.0  f1:26.26
loss: 0.8393, acc: 62.50, test_acc: 65.00, f1: 26.26
loss: 1.1626, acc: 54.69, test_acc: 43.04, f1: 28.92
>> saved: state_dict/lcf_bert_restaurant_acc65.09
max_acc:65.09  f1:26.62
loss: 1.0392, acc: 53.75, test_acc: 65.09, f1: 26.62
>> saved: state_dict/lcf_bert_restaurant_acc66.7
max_acc:66.7  f1:33.63
loss: 0.9133, acc: 55.21, test_acc: 66.70, f1: 33.63
>> saved: state_dict/lcf_bert_restaurant_acc68.04
max_acc:68.04  f1:38.7
loss: 0.8066, acc: 57.14, test_acc: 68.04, f1: 38.70
>> saved: state_dict/lcf_bert_restaurant_acc69.38
max_acc:69.38  f1:40.35
loss: 0.9856, acc: 56.25, test_acc: 69.38, f1: 40.35
>> saved: state_dict/lcf_bert_restaurant_acc75.45
max_acc:75.45  f1:51.05
loss: 0.5108, acc: 58.33, test_acc: 75.45, f1: 51.05
>> saved: state_dict/lcf_bert_restaurant_acc76.61
max_acc:76.61  f1:53.13
loss: 0.4865, acc: 60.00, test_acc: 76.61, f1: 53.13
loss: 0.9296, acc: 59.66, test_acc: 70.36, f1: 43.99
loss: 0.7314, acc: 60.94, test_acc: 69.20, f1: 39.84
loss: 0.6741, acc: 61.06, test_acc: 74.38, f1: 56.18
>> saved: state_dict/lcf_bert_restaurant_acc77.23
max_acc:77.23  f1:53.47
loss: 0.7302, acc: 62.05, test_acc: 77.23, f1: 53.47
>> saved: state_dict/lcf_bert_restaurant_acc77.86
max_acc:77.86  f1:55.33
loss: 0.5985, acc: 63.33, test_acc: 77.86, f1: 55.33
>> saved: state_dict/lcf_bert_restaurant_acc78.04
max_acc:78.04  f1:55.09
loss: 0.8120, acc: 63.28, test_acc: 78.04, f1: 55.09
>> saved: state_dict/lcf_bert_restaurant_acc78.57
max_acc:78.57  f1:60.44
loss: 0.6217, acc: 63.60, test_acc: 78.57, f1: 60.44
>> saved: state_dict/lcf_bert_restaurant_acc79.38
max_acc:79.38  f1:63.23
loss: 0.4839, acc: 64.58, test_acc: 79.38, f1: 63.23
loss: 0.5478, acc: 65.13, test_acc: 79.29, f1: 59.21
loss: 0.4690, acc: 65.62, test_acc: 77.59, f1: 61.73
>> saved: state_dict/lcf_bert_restaurant_acc81.16
max_acc:81.16  f1:71.44
loss: 0.2581, acc: 66.67, test_acc: 81.16, f1: 71.44
>> saved: state_dict/lcf_bert_restaurant_acc81.34
max_acc:81.34  f1:69.58
loss: 0.3984, acc: 67.61, test_acc: 81.34, f1: 69.58
loss: 0.7011, acc: 67.66, test_acc: 78.93, f1: 57.72
loss: 0.7302, acc: 67.71, test_acc: 78.75, f1: 56.30
loss: 0.6863, acc: 67.75, test_acc: 80.71, f1: 63.91
loss: 0.6409, acc: 68.03, test_acc: 81.34, f1: 70.05
loss: 0.4755, acc: 68.29, test_acc: 81.16, f1: 65.52
loss: 0.4298, acc: 68.75, test_acc: 81.25, f1: 65.89
>> saved: state_dict/lcf_bert_restaurant_acc81.79
max_acc:81.79  f1:70.21
loss: 0.7417, acc: 68.53, test_acc: 81.79, f1: 70.21
>> saved: state_dict/lcf_bert_restaurant_acc83.48
max_acc:83.48  f1:74.02
loss: 0.6701, acc: 68.54, test_acc: 83.48, f1: 74.02
loss: 0.8809, acc: 68.55, test_acc: 83.39, f1: 73.71
loss: 0.5616, acc: 68.75, test_acc: 82.50, f1: 68.12
loss: 0.6329, acc: 69.13, test_acc: 80.71, f1: 62.22
loss: 0.6693, acc: 69.49, test_acc: 81.52, f1: 65.84
>> saved: state_dict/lcf_bert_restaurant_acc84.2
max_acc:84.2  f1:73.62
loss: 0.6836, acc: 69.46, test_acc: 84.20, f1: 73.62
loss: 0.5551, acc: 69.62, test_acc: 83.84, f1: 74.77
loss: 0.8701, acc: 69.59, test_acc: 80.36, f1: 67.23
loss: 0.6768, acc: 69.57, test_acc: 82.41, f1: 73.99
loss: 0.3521, acc: 70.03, test_acc: 81.88, f1: 69.95
loss: 0.3123, acc: 70.47, test_acc: 82.32, f1: 67.52
loss: 0.3646, acc: 70.73, test_acc: 81.25, f1: 68.35
loss: 0.3580, acc: 70.98, test_acc: 80.71, f1: 68.87
loss: 0.5525, acc: 70.93, test_acc: 83.48, f1: 73.00
loss: 0.4004, acc: 71.16, test_acc: 82.68, f1: 69.23
loss: 0.9696, acc: 70.97, test_acc: 82.68, f1: 68.85
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.3337, acc: 87.50, test_acc: 84.02, f1: 74.99
loss: 0.2949, acc: 87.50, test_acc: 82.95, f1: 72.42
loss: 0.2829, acc: 89.58, test_acc: 83.39, f1: 71.43
loss: 0.6306, acc: 87.50, test_acc: 83.21, f1: 71.48
loss: 0.6101, acc: 85.00, test_acc: 83.04, f1: 73.09
loss: 0.5440, acc: 82.29, test_acc: 83.39, f1: 73.59
loss: 0.1454, acc: 83.93, test_acc: 83.57, f1: 72.92
loss: 0.3651, acc: 84.38, test_acc: 83.30, f1: 72.55
loss: 0.3585, acc: 84.03, test_acc: 83.04, f1: 73.62
loss: 0.4104, acc: 83.75, test_acc: 83.21, f1: 72.05
loss: 0.8311, acc: 82.95, test_acc: 82.68, f1: 70.19
loss: 0.1554, acc: 83.85, test_acc: 81.25, f1: 64.85
loss: 0.5290, acc: 83.65, test_acc: 81.61, f1: 66.72
loss: 0.5625, acc: 83.04, test_acc: 83.12, f1: 73.25
loss: 0.2754, acc: 83.75, test_acc: 83.57, f1: 72.91
loss: 0.4065, acc: 83.59, test_acc: 83.57, f1: 73.19
loss: 0.2839, acc: 84.19, test_acc: 83.75, f1: 73.77
loss: 0.4074, acc: 84.38, test_acc: 83.48, f1: 74.36
loss: 0.1896, acc: 84.87, test_acc: 83.57, f1: 74.28
loss: 0.0923, acc: 85.62, test_acc: 82.86, f1: 71.48
loss: 0.7039, acc: 85.12, test_acc: 83.04, f1: 72.05
loss: 0.2960, acc: 85.51, test_acc: 83.39, f1: 74.47
loss: 0.3551, acc: 85.60, test_acc: 83.21, f1: 74.65
loss: 0.5328, acc: 85.16, test_acc: 83.39, f1: 73.81
loss: 0.3248, acc: 85.50, test_acc: 82.86, f1: 72.07
loss: 0.5760, acc: 85.34, test_acc: 83.12, f1: 72.58
loss: 0.5170, acc: 85.19, test_acc: 83.48, f1: 72.79
loss: 0.4838, acc: 85.04, test_acc: 83.30, f1: 71.89
loss: 0.2724, acc: 85.13, test_acc: 84.02, f1: 74.81
loss: 0.5829, acc: 84.79, test_acc: 83.57, f1: 75.69
>> saved: state_dict/lcf_bert_restaurant_acc84.55
max_acc:84.55  f1:74.59
loss: 0.5383, acc: 84.27, test_acc: 84.55, f1: 74.59
loss: 0.4209, acc: 84.18, test_acc: 84.38, f1: 73.27
>> saved: state_dict/lcf_bert_restaurant_acc85.09
max_acc:85.09  f1:74.7
loss: 0.6138, acc: 83.90, test_acc: 85.09, f1: 74.70
>> saved: state_dict/lcf_bert_restaurant_acc85.45
max_acc:85.45  f1:76.6
loss: 0.4423, acc: 83.82, test_acc: 85.45, f1: 76.60
loss: 0.6933, acc: 83.57, test_acc: 85.00, f1: 75.63
loss: 0.5748, acc: 83.33, test_acc: 83.93, f1: 72.28
loss: 0.4486, acc: 83.28, test_acc: 85.27, f1: 76.62
loss: 0.5280, acc: 83.06, test_acc: 83.39, f1: 72.95
loss: 0.3943, acc: 83.17, test_acc: 83.39, f1: 72.54
loss: 0.4237, acc: 83.12, test_acc: 84.29, f1: 74.05
loss: 0.2421, acc: 83.38, test_acc: 84.20, f1: 73.45
loss: 0.5490, acc: 83.18, test_acc: 84.46, f1: 75.27
loss: 0.7218, acc: 82.70, test_acc: 84.46, f1: 74.50
loss: 0.5458, acc: 82.53, test_acc: 83.93, f1: 73.44
loss: 0.5774, acc: 82.22, test_acc: 83.75, f1: 71.69
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.4035, acc: 81.25, test_acc: 83.48, f1: 71.19
loss: 0.2991, acc: 84.38, test_acc: 83.39, f1: 72.07
loss: 0.3552, acc: 85.42, test_acc: 85.36, f1: 76.10
loss: 0.0897, acc: 89.06, test_acc: 82.68, f1: 68.34
loss: 0.2172, acc: 90.00, test_acc: 82.95, f1: 69.21
loss: 0.1861, acc: 90.62, test_acc: 83.30, f1: 72.40
loss: 0.1741, acc: 91.07, test_acc: 84.02, f1: 75.10
loss: 0.0887, acc: 92.19, test_acc: 85.27, f1: 78.34
>> saved: state_dict/lcf_bert_restaurant_acc85.54
max_acc:85.54  f1:75.46
loss: 0.1755, acc: 92.36, test_acc: 85.54, f1: 75.46
>> saved: state_dict/lcf_bert_restaurant_acc86.07
max_acc:86.07  f1:77.49
loss: 0.3927, acc: 92.50, test_acc: 86.07, f1: 77.49
loss: 0.2877, acc: 92.05, test_acc: 84.91, f1: 77.32
loss: 0.6999, acc: 90.62, test_acc: 84.82, f1: 75.73
loss: 0.3394, acc: 89.42, test_acc: 85.27, f1: 77.53
loss: 0.2317, acc: 89.73, test_acc: 85.80, f1: 77.56
loss: 0.3831, acc: 89.17, test_acc: 85.36, f1: 75.74
loss: 0.4361, acc: 89.06, test_acc: 84.73, f1: 72.72
>> saved: state_dict/lcf_bert_restaurant_acc86.52
max_acc:86.52  f1:79.94
loss: 0.3294, acc: 88.60, test_acc: 86.52, f1: 79.94
loss: 0.5351, acc: 87.85, test_acc: 85.71, f1: 77.84
loss: 0.1257, acc: 88.16, test_acc: 86.16, f1: 78.56
>> saved: state_dict/lcf_bert_restaurant_acc86.7
max_acc:86.7  f1:79.95
loss: 0.1803, acc: 88.44, test_acc: 86.70, f1: 79.95
loss: 0.2922, acc: 88.39, test_acc: 86.43, f1: 78.97
loss: 0.0826, acc: 88.92, test_acc: 86.43, f1: 79.77
loss: 0.2331, acc: 88.86, test_acc: 85.54, f1: 78.35
loss: 0.3335, acc: 88.54, test_acc: 86.07, f1: 79.11
loss: 0.0955, acc: 89.00, test_acc: 86.25, f1: 80.35
loss: 0.1994, acc: 89.18, test_acc: 86.07, f1: 77.44
loss: 0.2605, acc: 89.12, test_acc: 85.45, f1: 75.78
loss: 0.1290, acc: 89.51, test_acc: 85.71, f1: 77.84
loss: 0.3774, acc: 89.22, test_acc: 85.18, f1: 77.42
loss: 0.1080, acc: 89.38, test_acc: 85.71, f1: 78.48
>> saved: state_dict/lcf_bert_restaurant_acc87.59
max_acc:87.59  f1:81.43
loss: 0.3037, acc: 89.31, test_acc: 87.59, f1: 81.43
>> saved: state_dict/lcf_bert_restaurant_acc88.39
max_acc:88.39  f1:82.32
loss: 0.3079, acc: 89.26, test_acc: 88.39, f1: 82.32
loss: 0.3149, acc: 89.39, test_acc: 87.32, f1: 80.44
loss: 0.2594, acc: 89.34, test_acc: 85.98, f1: 76.98
loss: 0.2016, acc: 89.46, test_acc: 86.07, f1: 78.01
loss: 0.3581, acc: 89.24, test_acc: 87.23, f1: 80.86
loss: 0.1663, acc: 89.36, test_acc: 86.34, f1: 78.73
loss: 0.2752, acc: 89.31, test_acc: 85.27, f1: 75.27
loss: 0.2735, acc: 89.42, test_acc: 84.38, f1: 71.09
loss: 0.3130, acc: 89.22, test_acc: 86.61, f1: 79.19
loss: 0.1551, acc: 89.33, test_acc: 86.79, f1: 81.90
loss: 0.5890, acc: 88.84, test_acc: 86.96, f1: 81.25
loss: 0.3127, acc: 88.81, test_acc: 88.12, f1: 81.33
loss: 0.3900, acc: 88.78, test_acc: 86.61, f1: 78.81
loss: 0.1996, acc: 88.75, test_acc: 86.70, f1: 80.61
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.2030, acc: 93.75, test_acc: 87.14, f1: 79.64
loss: 0.1980, acc: 93.75, test_acc: 86.07, f1: 75.25
loss: 0.3864, acc: 89.58, test_acc: 86.07, f1: 76.05
>> saved: state_dict/lcf_bert_restaurant_acc88.48
max_acc:88.48  f1:82.8
loss: 0.1250, acc: 90.62, test_acc: 88.48, f1: 82.80
loss: 0.1655, acc: 91.25, test_acc: 88.39, f1: 82.46
loss: 0.0391, acc: 92.71, test_acc: 85.00, f1: 75.00
loss: 0.1357, acc: 92.86, test_acc: 87.41, f1: 79.93
loss: 0.0669, acc: 93.75, test_acc: 86.96, f1: 82.04
>> saved: state_dict/lcf_bert_restaurant_acc89.38
max_acc:89.38  f1:84.02
loss: 0.0326, acc: 94.44, test_acc: 89.38, f1: 84.02
loss: 0.0864, acc: 94.38, test_acc: 88.04, f1: 81.26
loss: 0.0480, acc: 94.89, test_acc: 86.88, f1: 78.34
loss: 0.0376, acc: 95.31, test_acc: 88.30, f1: 81.79
loss: 0.0323, acc: 95.67, test_acc: 87.77, f1: 81.05
loss: 0.1423, acc: 95.54, test_acc: 86.61, f1: 78.52
loss: 0.0181, acc: 95.83, test_acc: 86.43, f1: 78.14
loss: 0.1981, acc: 95.31, test_acc: 86.25, f1: 78.21
loss: 0.0879, acc: 95.22, test_acc: 86.70, f1: 79.66
loss: 0.0716, acc: 95.49, test_acc: 86.88, f1: 80.90
loss: 0.0940, acc: 95.39, test_acc: 87.14, f1: 80.98
loss: 0.4233, acc: 95.00, test_acc: 87.50, f1: 80.98
loss: 0.0912, acc: 94.94, test_acc: 87.86, f1: 80.79
loss: 0.2038, acc: 94.89, test_acc: 88.04, f1: 82.13
loss: 0.0802, acc: 94.84, test_acc: 87.77, f1: 81.76
loss: 0.0392, acc: 95.05, test_acc: 87.32, f1: 80.56
loss: 0.0218, acc: 95.25, test_acc: 86.70, f1: 77.86
loss: 0.2963, acc: 94.95, test_acc: 86.43, f1: 77.93
loss: 0.1595, acc: 94.91, test_acc: 86.52, f1: 79.90
loss: 0.2756, acc: 94.64, test_acc: 86.43, f1: 80.41
loss: 0.0647, acc: 94.83, test_acc: 87.41, f1: 81.07
loss: 0.3480, acc: 94.58, test_acc: 87.68, f1: 81.05
loss: 0.4018, acc: 94.56, test_acc: 87.68, f1: 80.84
loss: 0.0585, acc: 94.73, test_acc: 87.59, f1: 80.81
loss: 0.0674, acc: 94.70, test_acc: 86.96, f1: 79.79
loss: 0.2904, acc: 94.49, test_acc: 87.86, f1: 80.74
loss: 0.6310, acc: 94.11, test_acc: 87.77, f1: 81.27
loss: 0.2401, acc: 93.92, test_acc: 85.54, f1: 77.20
loss: 0.3917, acc: 93.75, test_acc: 85.09, f1: 76.37
loss: 0.1426, acc: 93.75, test_acc: 86.07, f1: 77.47
loss: 0.2669, acc: 93.75, test_acc: 86.96, f1: 80.55
loss: 0.0636, acc: 93.91, test_acc: 87.50, f1: 81.68
loss: 0.0223, acc: 94.05, test_acc: 88.04, f1: 82.06
loss: 0.1592, acc: 94.05, test_acc: 87.95, f1: 80.63
loss: 0.0441, acc: 94.19, test_acc: 87.41, f1: 78.75
loss: 0.3186, acc: 94.03, test_acc: 87.59, f1: 79.07
loss: 0.0843, acc: 94.03, test_acc: 88.39, f1: 81.50
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0299, acc: 100.00, test_acc: 89.02, f1: 83.43
loss: 0.1497, acc: 96.88, test_acc: 89.02, f1: 83.44
loss: 0.0873, acc: 97.92, test_acc: 88.30, f1: 81.61
loss: 0.0330, acc: 98.44, test_acc: 88.21, f1: 81.04
loss: 0.0189, acc: 98.75, test_acc: 88.48, f1: 81.74
loss: 0.0193, acc: 98.96, test_acc: 88.39, f1: 81.83
loss: 0.0510, acc: 99.11, test_acc: 88.39, f1: 82.08
loss: 0.0449, acc: 99.22, test_acc: 88.30, f1: 81.63
loss: 0.0137, acc: 99.31, test_acc: 88.12, f1: 81.35
loss: 0.0615, acc: 98.75, test_acc: 87.95, f1: 81.36
loss: 0.0465, acc: 98.86, test_acc: 87.59, f1: 81.92
loss: 0.0716, acc: 98.44, test_acc: 86.96, f1: 81.81
loss: 0.1026, acc: 98.08, test_acc: 86.88, f1: 80.02
loss: 0.1735, acc: 97.77, test_acc: 86.25, f1: 78.62
loss: 0.0872, acc: 97.50, test_acc: 85.62, f1: 77.23
loss: 0.0832, acc: 97.27, test_acc: 85.80, f1: 78.94
loss: 0.2954, acc: 96.69, test_acc: 86.79, f1: 80.69
loss: 0.2858, acc: 96.53, test_acc: 87.05, f1: 79.39
loss: 0.1778, acc: 96.38, test_acc: 87.50, f1: 81.99
loss: 0.2391, acc: 96.25, test_acc: 88.84, f1: 82.93
loss: 0.0390, acc: 96.43, test_acc: 88.48, f1: 81.29
loss: 0.4221, acc: 95.74, test_acc: 88.21, f1: 81.15
loss: 0.0581, acc: 95.92, test_acc: 88.57, f1: 82.76
loss: 0.0727, acc: 95.83, test_acc: 88.57, f1: 83.09
loss: 0.0341, acc: 96.00, test_acc: 86.96, f1: 79.70
loss: 0.0063, acc: 96.15, test_acc: 86.70, f1: 78.90
loss: 0.0111, acc: 96.30, test_acc: 86.43, f1: 78.17
loss: 0.0035, acc: 96.43, test_acc: 86.79, f1: 79.34
loss: 0.0270, acc: 96.55, test_acc: 86.61, f1: 79.85
loss: 0.0869, acc: 96.46, test_acc: 86.96, f1: 79.72
loss: 0.0562, acc: 96.57, test_acc: 85.62, f1: 75.87
loss: 0.0682, acc: 96.48, test_acc: 86.34, f1: 77.62
loss: 0.1829, acc: 96.40, test_acc: 87.23, f1: 79.91
loss: 0.0125, acc: 96.51, test_acc: 87.86, f1: 81.51
loss: 0.0716, acc: 96.43, test_acc: 88.04, f1: 81.38
loss: 0.2082, acc: 96.35, test_acc: 87.14, f1: 78.77
loss: 0.1072, acc: 96.28, test_acc: 87.32, f1: 79.80
loss: 0.1346, acc: 96.05, test_acc: 87.05, f1: 79.81
loss: 0.0076, acc: 96.15, test_acc: 86.61, f1: 79.41
loss: 0.2118, acc: 95.94, test_acc: 86.96, f1: 80.24
loss: 0.1344, acc: 95.88, test_acc: 87.59, f1: 81.20
loss: 0.1370, acc: 95.83, test_acc: 87.95, f1: 81.71
loss: 0.1041, acc: 95.78, test_acc: 88.57, f1: 82.82
loss: 0.2746, acc: 95.74, test_acc: 88.30, f1: 82.07
loss: 0.0836, acc: 95.69, test_acc: 87.68, f1: 79.79
loss: 0.4481, acc: 95.60, test_acc: 87.86, f1: 80.03
####################################################################################################
max_test_acc_overall:89.375
max_f1_overall:84.01501171832399
####################################################################################################
1 test_acc_overall: 89.11  f1_overall:84.11
2 test_acc_overall: 88.75  f1_overall:83.14
3 test_acc_overall: 89.38  f1_overall:84.02
max_acc_overall:89.38  f1_overall:84.02
mean_acc_overall:89.08  mean_f1_overall:83.75
####################################################################################################
lcf_bert - restaurant - cdw - No.4 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:0
>>> seed: 3
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc65.09
max_acc:65.09  f1:26.62
loss: 0.9666, acc: 62.50, test_acc: 65.09, f1: 26.62
loss: 0.6780, acc: 68.75, test_acc: 65.00, f1: 26.26
>> saved: state_dict/lcf_bert_restaurant_acc66.34
max_acc:66.34  f1:33.73
loss: 1.3337, acc: 60.42, test_acc: 66.34, f1: 33.73
loss: 0.8732, acc: 60.94, test_acc: 65.71, f1: 29.28
loss: 0.7583, acc: 62.50, test_acc: 65.80, f1: 29.60
>> saved: state_dict/lcf_bert_restaurant_acc75.54
max_acc:75.54  f1:51.01
loss: 0.6572, acc: 66.67, test_acc: 75.54, f1: 51.01
loss: 0.5919, acc: 68.75, test_acc: 75.36, f1: 50.58
>> saved: state_dict/lcf_bert_restaurant_acc77.95
max_acc:77.95  f1:60.95
loss: 0.6842, acc: 68.75, test_acc: 77.95, f1: 60.95
>> saved: state_dict/lcf_bert_restaurant_acc79.55
max_acc:79.55  f1:63.45
loss: 0.5766, acc: 69.44, test_acc: 79.55, f1: 63.45
loss: 0.8070, acc: 68.75, test_acc: 79.29, f1: 64.05
loss: 0.4256, acc: 69.89, test_acc: 79.20, f1: 61.98
loss: 0.3205, acc: 70.83, test_acc: 78.21, f1: 65.83
loss: 0.7472, acc: 71.63, test_acc: 78.48, f1: 63.27
loss: 0.5589, acc: 72.32, test_acc: 76.88, f1: 55.31
>> saved: state_dict/lcf_bert_restaurant_acc80.71
max_acc:80.71  f1:63.54
loss: 0.5455, acc: 72.50, test_acc: 80.71, f1: 63.54
loss: 0.8500, acc: 72.66, test_acc: 79.73, f1: 61.74
>> saved: state_dict/lcf_bert_restaurant_acc81.16
max_acc:81.16  f1:67.98
loss: 0.6379, acc: 72.79, test_acc: 81.16, f1: 67.98
>> saved: state_dict/lcf_bert_restaurant_acc81.61
max_acc:81.61  f1:68.12
loss: 0.6779, acc: 73.26, test_acc: 81.61, f1: 68.12
>> saved: state_dict/lcf_bert_restaurant_acc82.05
max_acc:82.05  f1:69.51
loss: 0.4887, acc: 73.68, test_acc: 82.05, f1: 69.51
>> saved: state_dict/lcf_bert_restaurant_acc82.23
max_acc:82.23  f1:69.05
loss: 0.7038, acc: 73.44, test_acc: 82.23, f1: 69.05
>> saved: state_dict/lcf_bert_restaurant_acc82.32
max_acc:82.32  f1:69.78
loss: 0.4696, acc: 73.51, test_acc: 82.32, f1: 69.78
loss: 0.9149, acc: 72.73, test_acc: 80.09, f1: 65.38
loss: 0.8546, acc: 72.01, test_acc: 81.52, f1: 69.62
loss: 0.6600, acc: 72.14, test_acc: 81.70, f1: 70.04
>> saved: state_dict/lcf_bert_restaurant_acc82.41
max_acc:82.41  f1:70.99
loss: 0.5782, acc: 72.75, test_acc: 82.41, f1: 70.99
loss: 0.4474, acc: 73.08, test_acc: 81.52, f1: 65.77
loss: 0.6883, acc: 72.92, test_acc: 82.32, f1: 71.88
>> saved: state_dict/lcf_bert_restaurant_acc82.5
max_acc:82.5  f1:72.99
loss: 0.7434, acc: 72.54, test_acc: 82.50, f1: 72.99
>> saved: state_dict/lcf_bert_restaurant_acc82.68
max_acc:82.68  f1:70.45
loss: 0.9090, acc: 72.41, test_acc: 82.68, f1: 70.45
>> saved: state_dict/lcf_bert_restaurant_acc82.86
max_acc:82.86  f1:70.73
loss: 0.5612, acc: 72.71, test_acc: 82.86, f1: 70.73
loss: 0.4560, acc: 73.19, test_acc: 82.77, f1: 69.43
>> saved: state_dict/lcf_bert_restaurant_acc83.12
max_acc:83.12  f1:71.42
loss: 0.6107, acc: 73.63, test_acc: 83.12, f1: 71.42
>> saved: state_dict/lcf_bert_restaurant_acc84.11
max_acc:84.11  f1:74.37
loss: 0.2560, acc: 74.05, test_acc: 84.11, f1: 74.37
loss: 0.1896, acc: 74.82, test_acc: 83.66, f1: 73.56
loss: 0.3965, acc: 75.00, test_acc: 84.02, f1: 75.21
>> saved: state_dict/lcf_bert_restaurant_acc84.91
max_acc:84.91  f1:76.66
loss: 0.4213, acc: 75.00, test_acc: 84.91, f1: 76.66
loss: 0.5873, acc: 75.00, test_acc: 84.73, f1: 77.26
loss: 0.5502, acc: 75.16, test_acc: 82.95, f1: 70.96
loss: 0.3967, acc: 75.32, test_acc: 82.95, f1: 69.12
loss: 0.2338, acc: 75.62, test_acc: 83.84, f1: 73.09
loss: 0.6017, acc: 75.61, test_acc: 84.46, f1: 75.96
loss: 0.4403, acc: 75.74, test_acc: 83.48, f1: 74.49
loss: 0.8070, acc: 75.58, test_acc: 83.66, f1: 74.83
loss: 0.6647, acc: 75.14, test_acc: 83.84, f1: 73.89
loss: 0.5318, acc: 75.28, test_acc: 84.02, f1: 73.89
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.2482, acc: 87.50, test_acc: 84.20, f1: 72.96
loss: 0.6503, acc: 84.38, test_acc: 82.05, f1: 68.65
loss: 0.7375, acc: 81.25, test_acc: 84.38, f1: 73.16
loss: 0.3002, acc: 82.81, test_acc: 83.66, f1: 72.39
loss: 0.8206, acc: 78.75, test_acc: 83.93, f1: 74.69
loss: 0.8189, acc: 76.04, test_acc: 84.46, f1: 77.99
loss: 0.4586, acc: 76.79, test_acc: 82.77, f1: 69.53
loss: 0.4379, acc: 78.12, test_acc: 81.79, f1: 65.69
loss: 0.3762, acc: 78.47, test_acc: 84.82, f1: 75.31
>> saved: state_dict/lcf_bert_restaurant_acc86.16
max_acc:86.16  f1:78.42
loss: 0.1833, acc: 80.00, test_acc: 86.16, f1: 78.42
loss: 0.4036, acc: 80.68, test_acc: 85.36, f1: 76.02
loss: 0.4507, acc: 80.73, test_acc: 84.91, f1: 75.39
loss: 0.5315, acc: 80.29, test_acc: 85.45, f1: 77.56
loss: 0.2528, acc: 80.80, test_acc: 80.71, f1: 70.18
loss: 0.1774, acc: 81.67, test_acc: 84.38, f1: 75.59
loss: 0.9519, acc: 80.47, test_acc: 83.48, f1: 69.65
loss: 0.5410, acc: 80.15, test_acc: 84.73, f1: 74.37
loss: 0.3911, acc: 80.56, test_acc: 85.80, f1: 77.59
loss: 0.3972, acc: 80.59, test_acc: 84.11, f1: 73.59
loss: 0.6531, acc: 80.94, test_acc: 85.09, f1: 75.31
loss: 0.3431, acc: 80.95, test_acc: 85.00, f1: 77.77
loss: 0.3628, acc: 80.97, test_acc: 85.45, f1: 76.29
loss: 0.8230, acc: 80.71, test_acc: 85.27, f1: 74.77
>> saved: state_dict/lcf_bert_restaurant_acc86.25
max_acc:86.25  f1:78.52
loss: 0.3070, acc: 80.73, test_acc: 86.25, f1: 78.52
>> saved: state_dict/lcf_bert_restaurant_acc86.43
max_acc:86.43  f1:79.34
loss: 0.7978, acc: 80.25, test_acc: 86.43, f1: 79.34
>> saved: state_dict/lcf_bert_restaurant_acc86.79
max_acc:86.79  f1:80.02
loss: 0.4425, acc: 80.53, test_acc: 86.79, f1: 80.02
>> saved: state_dict/lcf_bert_restaurant_acc87.14
max_acc:87.14  f1:80.01
loss: 0.2299, acc: 80.79, test_acc: 87.14, f1: 80.01
loss: 0.2493, acc: 81.25, test_acc: 87.05, f1: 78.17
>> saved: state_dict/lcf_bert_restaurant_acc87.5
max_acc:87.5  f1:80.06
loss: 0.6338, acc: 81.25, test_acc: 87.50, f1: 80.06
loss: 0.2888, acc: 81.67, test_acc: 86.88, f1: 79.33
loss: 0.2892, acc: 82.06, test_acc: 87.23, f1: 79.15
>> saved: state_dict/lcf_bert_restaurant_acc88.04
max_acc:88.04  f1:81.39
loss: 0.5192, acc: 82.03, test_acc: 88.04, f1: 81.39
loss: 0.5324, acc: 82.20, test_acc: 86.07, f1: 78.24
loss: 0.4190, acc: 82.35, test_acc: 86.16, f1: 78.66
loss: 0.1053, acc: 82.86, test_acc: 85.62, f1: 73.99
loss: 0.7577, acc: 82.81, test_acc: 84.91, f1: 71.66
loss: 0.1052, acc: 83.28, test_acc: 87.05, f1: 78.33
loss: 0.5605, acc: 83.22, test_acc: 87.41, f1: 80.03
loss: 0.1899, acc: 83.49, test_acc: 87.14, f1: 79.88
>> saved: state_dict/lcf_bert_restaurant_acc88.12
max_acc:88.12  f1:81.27
loss: 0.2736, acc: 83.59, test_acc: 88.12, f1: 81.27
>> saved: state_dict/lcf_bert_restaurant_acc88.93
max_acc:88.93  f1:82.16
loss: 0.2947, acc: 83.69, test_acc: 88.93, f1: 82.16
loss: 0.8360, acc: 83.33, test_acc: 87.95, f1: 81.66
loss: 0.1170, acc: 83.72, test_acc: 86.88, f1: 79.78
loss: 0.5803, acc: 83.66, test_acc: 86.61, f1: 78.73
loss: 0.2920, acc: 83.75, test_acc: 86.79, f1: 78.25
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.3357, acc: 87.50, test_acc: 85.00, f1: 72.98
loss: 0.1103, acc: 93.75, test_acc: 85.98, f1: 75.54
loss: 0.0924, acc: 95.83, test_acc: 87.77, f1: 82.00
loss: 0.1599, acc: 95.31, test_acc: 87.77, f1: 82.40
loss: 0.0877, acc: 96.25, test_acc: 87.05, f1: 79.69
loss: 0.0851, acc: 96.88, test_acc: 85.80, f1: 75.58
loss: 0.3388, acc: 93.75, test_acc: 85.89, f1: 75.91
loss: 0.2006, acc: 92.97, test_acc: 87.59, f1: 80.82
loss: 0.2573, acc: 92.36, test_acc: 87.95, f1: 81.94
loss: 0.2251, acc: 91.88, test_acc: 87.68, f1: 81.27
loss: 0.0916, acc: 92.61, test_acc: 87.59, f1: 81.65
loss: 0.0853, acc: 92.71, test_acc: 87.41, f1: 81.60
loss: 0.3593, acc: 92.31, test_acc: 86.96, f1: 80.38
loss: 0.0315, acc: 92.86, test_acc: 87.68, f1: 81.12
loss: 0.1525, acc: 92.92, test_acc: 86.70, f1: 79.07
loss: 0.2295, acc: 92.97, test_acc: 87.41, f1: 80.11
loss: 0.3682, acc: 92.65, test_acc: 87.86, f1: 81.45
loss: 0.0468, acc: 93.06, test_acc: 87.23, f1: 78.59
loss: 0.3066, acc: 92.43, test_acc: 87.32, f1: 79.11
loss: 0.0844, acc: 92.50, test_acc: 87.05, f1: 80.43
loss: 0.4125, acc: 92.26, test_acc: 86.79, f1: 79.91
loss: 0.1947, acc: 92.05, test_acc: 86.70, f1: 76.85
loss: 0.4231, acc: 91.85, test_acc: 86.43, f1: 76.32
loss: 0.1459, acc: 91.67, test_acc: 87.77, f1: 81.01
loss: 0.4820, acc: 91.00, test_acc: 88.21, f1: 82.54
loss: 0.2646, acc: 90.87, test_acc: 88.12, f1: 81.65
loss: 0.1359, acc: 90.97, test_acc: 87.68, f1: 80.13
loss: 0.1256, acc: 91.07, test_acc: 86.25, f1: 78.47
loss: 0.4076, acc: 90.95, test_acc: 84.64, f1: 75.96
loss: 0.3285, acc: 90.83, test_acc: 85.89, f1: 78.39
loss: 0.2784, acc: 90.73, test_acc: 87.59, f1: 80.92
loss: 0.0546, acc: 91.02, test_acc: 87.05, f1: 78.98
loss: 0.0404, acc: 91.29, test_acc: 87.41, f1: 81.03
loss: 0.3158, acc: 91.18, test_acc: 87.50, f1: 81.21
loss: 0.0750, acc: 91.43, test_acc: 87.32, f1: 80.40
loss: 0.1109, acc: 91.49, test_acc: 88.04, f1: 81.91
loss: 0.2459, acc: 91.55, test_acc: 87.95, f1: 82.34
loss: 0.1111, acc: 91.61, test_acc: 88.21, f1: 81.93
loss: 0.2477, acc: 91.35, test_acc: 87.23, f1: 80.01
loss: 0.5308, acc: 91.09, test_acc: 87.14, f1: 79.80
loss: 0.3057, acc: 91.01, test_acc: 87.41, f1: 81.46
loss: 0.1627, acc: 91.07, test_acc: 86.61, f1: 80.31
loss: 0.3612, acc: 90.99, test_acc: 86.96, f1: 79.16
loss: 0.0911, acc: 91.05, test_acc: 86.79, f1: 79.54
loss: 0.4439, acc: 90.83, test_acc: 86.79, f1: 78.81
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0776, acc: 100.00, test_acc: 87.14, f1: 79.80
loss: 0.1775, acc: 96.88, test_acc: 87.32, f1: 80.58
loss: 0.0978, acc: 95.83, test_acc: 86.16, f1: 78.03
loss: 0.0740, acc: 95.31, test_acc: 85.62, f1: 76.15
loss: 0.1570, acc: 95.00, test_acc: 86.43, f1: 77.85
loss: 0.0955, acc: 95.83, test_acc: 87.05, f1: 79.92
loss: 0.0883, acc: 96.43, test_acc: 87.23, f1: 80.17
loss: 0.0998, acc: 96.09, test_acc: 87.14, f1: 79.66
loss: 0.2386, acc: 95.83, test_acc: 86.96, f1: 79.53
loss: 0.1799, acc: 95.00, test_acc: 86.52, f1: 78.81
loss: 0.0879, acc: 94.89, test_acc: 87.59, f1: 80.79
loss: 0.6597, acc: 93.75, test_acc: 87.86, f1: 82.30
loss: 0.0762, acc: 94.23, test_acc: 88.04, f1: 82.49
loss: 0.1102, acc: 94.20, test_acc: 87.50, f1: 80.14
loss: 0.0950, acc: 94.17, test_acc: 87.23, f1: 79.12
loss: 0.5203, acc: 93.36, test_acc: 87.86, f1: 80.52
loss: 0.0754, acc: 93.75, test_acc: 88.57, f1: 82.38
loss: 0.0253, acc: 94.10, test_acc: 88.30, f1: 82.25
loss: 0.0082, acc: 94.41, test_acc: 87.86, f1: 80.66
loss: 0.1139, acc: 94.38, test_acc: 87.59, f1: 79.65
loss: 0.1211, acc: 94.35, test_acc: 87.86, f1: 80.49
loss: 0.0456, acc: 94.60, test_acc: 87.41, f1: 81.01
loss: 0.0387, acc: 94.84, test_acc: 86.34, f1: 79.15
loss: 0.3114, acc: 94.79, test_acc: 87.05, f1: 80.38
loss: 0.0633, acc: 95.00, test_acc: 87.77, f1: 81.56
loss: 0.0698, acc: 94.95, test_acc: 87.95, f1: 81.43
loss: 0.0197, acc: 95.14, test_acc: 88.04, f1: 82.72
loss: 0.0435, acc: 95.31, test_acc: 87.23, f1: 79.53
loss: 0.0336, acc: 95.47, test_acc: 86.70, f1: 79.15
loss: 0.1237, acc: 95.42, test_acc: 87.05, f1: 80.57
loss: 0.1058, acc: 95.36, test_acc: 86.79, f1: 79.27
loss: 0.1762, acc: 95.31, test_acc: 86.61, f1: 77.49
loss: 0.1379, acc: 95.27, test_acc: 87.77, f1: 80.87
loss: 0.3062, acc: 95.22, test_acc: 87.14, f1: 79.85
loss: 0.0688, acc: 95.18, test_acc: 87.32, f1: 79.98
loss: 0.3141, acc: 95.14, test_acc: 87.05, f1: 80.40
loss: 0.0578, acc: 95.27, test_acc: 87.23, f1: 80.71
loss: 0.0355, acc: 95.39, test_acc: 86.88, f1: 80.03
loss: 0.0151, acc: 95.51, test_acc: 86.88, f1: 79.55
loss: 0.0038, acc: 95.62, test_acc: 87.05, f1: 79.62
loss: 0.1413, acc: 95.58, test_acc: 87.68, f1: 81.69
loss: 0.0492, acc: 95.68, test_acc: 87.68, f1: 81.86
loss: 0.0627, acc: 95.78, test_acc: 87.86, f1: 81.77
loss: 0.3197, acc: 95.74, test_acc: 88.39, f1: 82.42
loss: 0.0517, acc: 95.83, test_acc: 87.50, f1: 81.16
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.1085, acc: 93.75, test_acc: 86.70, f1: 79.70
loss: 0.0092, acc: 96.88, test_acc: 87.32, f1: 80.57
loss: 0.0064, acc: 97.92, test_acc: 87.41, f1: 80.65
loss: 0.0070, acc: 98.44, test_acc: 88.04, f1: 81.36
loss: 0.0091, acc: 98.75, test_acc: 88.57, f1: 82.28
loss: 0.0337, acc: 98.96, test_acc: 87.50, f1: 80.28
loss: 0.0526, acc: 99.11, test_acc: 86.52, f1: 78.36
loss: 0.0337, acc: 99.22, test_acc: 86.96, f1: 80.10
loss: 0.0557, acc: 99.31, test_acc: 86.79, f1: 79.93
loss: 0.1767, acc: 98.75, test_acc: 87.95, f1: 82.25
loss: 0.0894, acc: 98.86, test_acc: 88.39, f1: 82.90
loss: 0.0445, acc: 98.96, test_acc: 88.30, f1: 81.87
loss: 0.0116, acc: 99.04, test_acc: 87.86, f1: 80.57
loss: 0.0015, acc: 99.11, test_acc: 88.12, f1: 81.84
loss: 0.0172, acc: 99.17, test_acc: 88.93, f1: 83.58
loss: 0.0203, acc: 99.22, test_acc: 88.39, f1: 82.74
loss: 0.0020, acc: 99.26, test_acc: 88.39, f1: 82.39
loss: 0.0026, acc: 99.31, test_acc: 87.68, f1: 80.73
loss: 0.0074, acc: 99.34, test_acc: 87.05, f1: 79.34
loss: 0.0108, acc: 99.38, test_acc: 87.05, f1: 78.82
loss: 0.0021, acc: 99.40, test_acc: 87.77, f1: 81.10
loss: 0.3603, acc: 99.15, test_acc: 86.96, f1: 81.38
loss: 0.1385, acc: 98.91, test_acc: 87.32, f1: 80.32
loss: 0.0042, acc: 98.96, test_acc: 85.98, f1: 77.99
loss: 0.0217, acc: 99.00, test_acc: 85.54, f1: 77.20
loss: 0.0183, acc: 99.04, test_acc: 85.80, f1: 77.80
loss: 0.1270, acc: 98.84, test_acc: 87.32, f1: 80.30
loss: 0.0073, acc: 98.88, test_acc: 86.61, f1: 79.00
loss: 0.1358, acc: 98.71, test_acc: 87.32, f1: 80.43
loss: 0.0467, acc: 98.75, test_acc: 87.14, f1: 79.74
loss: 0.0479, acc: 98.79, test_acc: 87.23, f1: 80.10
loss: 0.0469, acc: 98.83, test_acc: 87.14, f1: 80.13
loss: 0.1874, acc: 98.48, test_acc: 86.70, f1: 79.56
loss: 0.3924, acc: 98.35, test_acc: 87.05, f1: 79.88
loss: 0.0228, acc: 98.39, test_acc: 86.70, f1: 78.67
loss: 0.0147, acc: 98.44, test_acc: 87.23, f1: 79.83
loss: 0.1564, acc: 98.31, test_acc: 87.05, f1: 79.60
loss: 0.1331, acc: 98.19, test_acc: 87.23, f1: 80.06
loss: 0.1507, acc: 98.08, test_acc: 87.05, f1: 79.41
loss: 0.0790, acc: 98.12, test_acc: 86.96, f1: 78.66
loss: 0.0284, acc: 98.17, test_acc: 86.70, f1: 78.28
loss: 0.1212, acc: 98.07, test_acc: 87.05, f1: 78.77
loss: 0.0033, acc: 98.11, test_acc: 87.86, f1: 80.70
loss: 0.0114, acc: 98.15, test_acc: 88.39, f1: 82.30
loss: 0.0111, acc: 98.19, test_acc: 88.12, f1: 81.91
loss: 0.1429, acc: 98.08, test_acc: 87.95, f1: 81.07
####################################################################################################
max_test_acc_overall:88.92857142857142
max_f1_overall:83.58346817575047
####################################################################################################
1 test_acc_overall: 89.11  f1_overall:84.11
2 test_acc_overall: 88.75  f1_overall:83.14
3 test_acc_overall: 89.38  f1_overall:84.02
4 test_acc_overall: 88.93  f1_overall:83.58
max_acc_overall:89.38  f1_overall:84.02
mean_acc_overall:89.04  mean_f1_overall:83.71
####################################################################################################
lcf_bert - restaurant - cdw - No.5 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:460140032
n_trainable_params: 114797571, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> use_single_bert: False
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8da05091e0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:0
>>> seed: 4
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc64.73
max_acc:64.73  f1:27.5
loss: 1.1152, acc: 62.50, test_acc: 64.73, f1: 27.50
>> saved: state_dict/lcf_bert_restaurant_acc65.27
max_acc:65.27  f1:27.62
loss: 1.0755, acc: 56.25, test_acc: 65.27, f1: 27.62
>> saved: state_dict/lcf_bert_restaurant_acc65.8
max_acc:65.8  f1:37.25
loss: 1.0607, acc: 58.33, test_acc: 65.80, f1: 37.25
loss: 1.0903, acc: 53.12, test_acc: 65.36, f1: 27.96
loss: 0.6794, acc: 56.25, test_acc: 65.36, f1: 27.96
loss: 0.8948, acc: 58.33, test_acc: 54.64, f1: 36.92
>> saved: state_dict/lcf_bert_restaurant_acc68.04
max_acc:68.04  f1:37.71
loss: 0.7159, acc: 62.50, test_acc: 68.04, f1: 37.71
loss: 0.9463, acc: 62.50, test_acc: 66.79, f1: 33.26
>> saved: state_dict/lcf_bert_restaurant_acc71.25
max_acc:71.25  f1:51.55
loss: 0.8890, acc: 62.50, test_acc: 71.25, f1: 51.55
loss: 0.8083, acc: 62.50, test_acc: 70.98, f1: 43.39
>> saved: state_dict/lcf_bert_restaurant_acc77.95
max_acc:77.95  f1:54.19
loss: 1.2116, acc: 61.36, test_acc: 77.95, f1: 54.19
>> saved: state_dict/lcf_bert_restaurant_acc78.3
max_acc:78.3  f1:54.68
loss: 0.6491, acc: 62.50, test_acc: 78.30, f1: 54.68
>> saved: state_dict/lcf_bert_restaurant_acc79.2
max_acc:79.2  f1:57.99
loss: 0.7770, acc: 62.98, test_acc: 79.20, f1: 57.99
>> saved: state_dict/lcf_bert_restaurant_acc79.38
max_acc:79.38  f1:58.08
loss: 0.6562, acc: 63.39, test_acc: 79.38, f1: 58.08
>> saved: state_dict/lcf_bert_restaurant_acc80.36
max_acc:80.36  f1:66.54
loss: 0.6722, acc: 63.33, test_acc: 80.36, f1: 66.54
>> saved: state_dict/lcf_bert_restaurant_acc80.8
max_acc:80.8  f1:66.37
loss: 0.2792, acc: 65.23, test_acc: 80.80, f1: 66.37
loss: 0.6602, acc: 65.44, test_acc: 80.45, f1: 61.65
loss: 0.4472, acc: 66.67, test_acc: 77.86, f1: 55.46
loss: 0.8479, acc: 66.12, test_acc: 79.91, f1: 59.81
>> saved: state_dict/lcf_bert_restaurant_acc81.34
max_acc:81.34  f1:68.22
loss: 0.7217, acc: 66.25, test_acc: 81.34, f1: 68.22
loss: 0.6746, acc: 65.77, test_acc: 80.98, f1: 69.36
loss: 0.5723, acc: 66.19, test_acc: 79.38, f1: 59.48
loss: 0.5265, acc: 67.12, test_acc: 79.02, f1: 58.02
loss: 0.4397, acc: 67.71, test_acc: 80.89, f1: 69.06
>> saved: state_dict/lcf_bert_restaurant_acc82.59
max_acc:82.59  f1:72.67
loss: 0.6593, acc: 67.75, test_acc: 82.59, f1: 72.67
loss: 1.0914, acc: 67.31, test_acc: 80.62, f1: 67.08
loss: 0.7555, acc: 67.59, test_acc: 82.32, f1: 68.53
>> saved: state_dict/lcf_bert_restaurant_acc82.86
max_acc:82.86  f1:71.27
loss: 0.6777, acc: 67.86, test_acc: 82.86, f1: 71.27
>> saved: state_dict/lcf_bert_restaurant_acc83.48
max_acc:83.48  f1:72.69
loss: 0.2614, acc: 68.75, test_acc: 83.48, f1: 72.69
loss: 0.6534, acc: 68.96, test_acc: 80.89, f1: 64.92
loss: 0.2199, acc: 69.56, test_acc: 80.54, f1: 62.86
>> saved: state_dict/lcf_bert_restaurant_acc83.84
max_acc:83.84  f1:73.66
loss: 0.8306, acc: 69.14, test_acc: 83.84, f1: 73.66
>> saved: state_dict/lcf_bert_restaurant_acc84.46
max_acc:84.46  f1:75.34
loss: 0.6627, acc: 69.51, test_acc: 84.46, f1: 75.34
loss: 0.4133, acc: 70.04, test_acc: 81.79, f1: 66.77
loss: 0.6532, acc: 69.82, test_acc: 81.34, f1: 65.22
loss: 0.4784, acc: 70.14, test_acc: 84.46, f1: 75.11
loss: 0.5550, acc: 70.44, test_acc: 84.11, f1: 76.32
loss: 0.2260, acc: 71.05, test_acc: 83.66, f1: 72.03
loss: 0.5721, acc: 71.15, test_acc: 83.75, f1: 73.33
loss: 0.2326, acc: 71.56, test_acc: 82.59, f1: 71.31
loss: 0.2401, acc: 71.95, test_acc: 83.12, f1: 71.39
loss: 1.2565, acc: 71.58, test_acc: 83.12, f1: 71.35
loss: 0.4055, acc: 71.95, test_acc: 83.30, f1: 72.35
loss: 0.8896, acc: 71.88, test_acc: 84.38, f1: 76.67
loss: 0.6339, acc: 71.81, test_acc: 83.93, f1: 73.15
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.1128, acc: 100.00, test_acc: 81.07, f1: 63.52
loss: 0.4553, acc: 90.62, test_acc: 81.07, f1: 63.65
loss: 0.2152, acc: 93.75, test_acc: 81.96, f1: 65.94
loss: 0.1913, acc: 93.75, test_acc: 83.57, f1: 71.42
>> saved: state_dict/lcf_bert_restaurant_acc84.82
max_acc:84.82  f1:75.64
loss: 0.7697, acc: 90.00, test_acc: 84.82, f1: 75.64
loss: 0.5492, acc: 88.54, test_acc: 84.64, f1: 75.73
loss: 0.4212, acc: 87.50, test_acc: 84.46, f1: 74.08
loss: 0.2526, acc: 87.50, test_acc: 83.84, f1: 72.63
>> saved: state_dict/lcf_bert_restaurant_acc84.91
max_acc:84.91  f1:76.9
loss: 0.5579, acc: 86.11, test_acc: 84.91, f1: 76.90
>> saved: state_dict/lcf_bert_restaurant_acc85.27
max_acc:85.27  f1:76.47
loss: 0.5567, acc: 86.25, test_acc: 85.27, f1: 76.47
loss: 0.4618, acc: 84.66, test_acc: 85.18, f1: 76.65
loss: 0.5052, acc: 83.85, test_acc: 84.38, f1: 77.73
loss: 0.3280, acc: 83.65, test_acc: 83.84, f1: 74.17
loss: 0.1500, acc: 84.38, test_acc: 84.02, f1: 72.53
loss: 0.4459, acc: 84.58, test_acc: 83.39, f1: 72.11
loss: 0.4485, acc: 84.77, test_acc: 83.30, f1: 70.91
loss: 0.3155, acc: 84.93, test_acc: 83.30, f1: 71.32
loss: 0.2737, acc: 85.07, test_acc: 83.21, f1: 71.22
loss: 0.2078, acc: 85.53, test_acc: 83.39, f1: 70.92
loss: 0.3009, acc: 85.31, test_acc: 84.29, f1: 73.96
loss: 0.5967, acc: 85.12, test_acc: 84.64, f1: 76.27
loss: 0.3473, acc: 84.94, test_acc: 84.91, f1: 75.64
loss: 0.5206, acc: 84.78, test_acc: 83.66, f1: 73.16
loss: 0.2223, acc: 85.16, test_acc: 85.27, f1: 75.77
loss: 0.5685, acc: 84.25, test_acc: 84.46, f1: 77.71
loss: 0.4980, acc: 84.13, test_acc: 85.09, f1: 76.55
loss: 0.2983, acc: 84.26, test_acc: 84.29, f1: 73.45
loss: 0.5628, acc: 83.71, test_acc: 85.27, f1: 76.47
>> saved: state_dict/lcf_bert_restaurant_acc85.45
max_acc:85.45  f1:78.23
loss: 0.3593, acc: 83.62, test_acc: 85.45, f1: 78.23
loss: 0.5973, acc: 83.33, test_acc: 85.27, f1: 78.63
loss: 0.3242, acc: 83.47, test_acc: 83.57, f1: 72.56
loss: 0.4269, acc: 83.40, test_acc: 83.12, f1: 70.79
loss: 0.6510, acc: 82.95, test_acc: 83.30, f1: 73.07
loss: 0.5035, acc: 82.90, test_acc: 82.95, f1: 73.19
>> saved: state_dict/lcf_bert_restaurant_acc85.54
max_acc:85.54  f1:78.55
loss: 0.5543, acc: 82.68, test_acc: 85.54, f1: 78.55
loss: 0.1516, acc: 83.16, test_acc: 84.82, f1: 75.26
loss: 0.4434, acc: 83.11, test_acc: 83.21, f1: 70.68
loss: 0.1360, acc: 83.55, test_acc: 83.75, f1: 71.95
loss: 0.2693, acc: 83.65, test_acc: 85.09, f1: 76.22
loss: 0.8834, acc: 83.44, test_acc: 84.02, f1: 73.65
loss: 0.4501, acc: 83.38, test_acc: 82.68, f1: 68.62
loss: 0.2497, acc: 83.63, test_acc: 83.66, f1: 71.09
loss: 0.4434, acc: 83.58, test_acc: 85.00, f1: 75.10
loss: 0.1634, acc: 83.95, test_acc: 85.27, f1: 75.40
loss: 0.2080, acc: 84.03, test_acc: 84.73, f1: 74.03
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.4078, acc: 87.50, test_acc: 85.45, f1: 76.31
loss: 0.1302, acc: 90.62, test_acc: 85.45, f1: 76.96
>> saved: state_dict/lcf_bert_restaurant_acc85.71
max_acc:85.71  f1:78.81
loss: 0.2770, acc: 89.58, test_acc: 85.71, f1: 78.81
loss: 0.2277, acc: 90.62, test_acc: 85.62, f1: 78.11
>> saved: state_dict/lcf_bert_restaurant_acc86.34
max_acc:86.34  f1:78.38
loss: 0.3181, acc: 88.75, test_acc: 86.34, f1: 78.38
>> saved: state_dict/lcf_bert_restaurant_acc86.79
max_acc:86.79  f1:79.41
loss: 0.0906, acc: 89.58, test_acc: 86.79, f1: 79.41
>> saved: state_dict/lcf_bert_restaurant_acc87.14
max_acc:87.14  f1:80.91
loss: 0.3051, acc: 88.39, test_acc: 87.14, f1: 80.91
loss: 0.2398, acc: 89.06, test_acc: 85.54, f1: 80.52
loss: 0.2070, acc: 89.58, test_acc: 86.16, f1: 79.02
loss: 0.1832, acc: 90.00, test_acc: 84.91, f1: 74.24
loss: 0.3052, acc: 89.77, test_acc: 85.62, f1: 77.16
loss: 0.3022, acc: 90.10, test_acc: 85.36, f1: 76.88
loss: 0.3536, acc: 89.90, test_acc: 85.80, f1: 79.78
loss: 0.1409, acc: 90.62, test_acc: 86.16, f1: 78.28
loss: 0.0618, acc: 91.25, test_acc: 85.36, f1: 75.06
loss: 0.1572, acc: 91.41, test_acc: 85.80, f1: 77.92
loss: 0.5730, acc: 90.44, test_acc: 85.45, f1: 76.87
loss: 0.2183, acc: 90.62, test_acc: 84.46, f1: 74.73
loss: 0.3431, acc: 90.46, test_acc: 84.20, f1: 73.78
loss: 0.6763, acc: 89.69, test_acc: 84.46, f1: 74.16
loss: 0.2282, acc: 89.29, test_acc: 84.29, f1: 74.55
loss: 0.2489, acc: 89.20, test_acc: 84.73, f1: 75.67
loss: 0.2015, acc: 89.40, test_acc: 84.64, f1: 75.46
loss: 0.2477, acc: 89.32, test_acc: 84.82, f1: 75.03
loss: 0.1999, acc: 89.50, test_acc: 85.36, f1: 75.59
loss: 0.0450, acc: 89.90, test_acc: 85.36, f1: 75.55
loss: 0.1653, acc: 90.05, test_acc: 85.71, f1: 77.53
loss: 0.2783, acc: 89.73, test_acc: 85.62, f1: 76.45
loss: 0.1713, acc: 89.87, test_acc: 85.36, f1: 76.33
loss: 0.1800, acc: 89.79, test_acc: 85.09, f1: 74.63
loss: 0.2238, acc: 89.92, test_acc: 85.18, f1: 76.61
loss: 0.6298, acc: 89.65, test_acc: 85.98, f1: 77.77
loss: 0.1418, acc: 89.77, test_acc: 86.61, f1: 79.42
loss: 0.1090, acc: 89.89, test_acc: 86.16, f1: 78.44
loss: 0.2087, acc: 90.00, test_acc: 85.89, f1: 77.86
loss: 0.3774, acc: 89.93, test_acc: 86.07, f1: 76.79
loss: 0.7198, acc: 89.53, test_acc: 86.25, f1: 76.30
loss: 0.2939, acc: 89.47, test_acc: 87.05, f1: 80.22
loss: 0.2357, acc: 89.42, test_acc: 87.05, f1: 80.39
loss: 0.2006, acc: 89.53, test_acc: 86.25, f1: 76.95
loss: 0.1760, acc: 89.63, test_acc: 85.00, f1: 72.93
loss: 0.2262, acc: 89.73, test_acc: 85.98, f1: 76.13
>> saved: state_dict/lcf_bert_restaurant_acc87.32
max_acc:87.32  f1:81.18
loss: 0.1645, acc: 89.68, test_acc: 87.32, f1: 81.18
loss: 0.1332, acc: 89.77, test_acc: 86.52, f1: 80.48
loss: 0.0714, acc: 90.00, test_acc: 86.52, f1: 77.68
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0924, acc: 100.00, test_acc: 85.71, f1: 74.96
loss: 0.0281, acc: 100.00, test_acc: 86.52, f1: 77.60
loss: 0.0447, acc: 100.00, test_acc: 86.43, f1: 78.69
>> saved: state_dict/lcf_bert_restaurant_acc87.5
max_acc:87.5  f1:81.32
loss: 0.3494, acc: 98.44, test_acc: 87.50, f1: 81.32
loss: 0.2360, acc: 96.25, test_acc: 86.61, f1: 79.37
loss: 0.0886, acc: 95.83, test_acc: 86.70, f1: 79.07
loss: 0.2379, acc: 94.64, test_acc: 86.07, f1: 77.69
loss: 0.0037, acc: 95.31, test_acc: 85.89, f1: 76.47
loss: 0.0853, acc: 95.14, test_acc: 85.80, f1: 76.12
loss: 0.0713, acc: 95.00, test_acc: 86.34, f1: 78.28
loss: 0.2308, acc: 94.89, test_acc: 87.23, f1: 80.76
loss: 0.0790, acc: 95.31, test_acc: 87.05, f1: 80.53
loss: 0.1344, acc: 95.19, test_acc: 86.07, f1: 78.26
loss: 0.0260, acc: 95.54, test_acc: 87.14, f1: 79.23
loss: 0.0396, acc: 95.83, test_acc: 87.23, f1: 79.52
>> saved: state_dict/lcf_bert_restaurant_acc87.59
max_acc:87.59  f1:80.54
loss: 0.5735, acc: 94.92, test_acc: 87.59, f1: 80.54
loss: 0.1079, acc: 94.85, test_acc: 86.79, f1: 79.65
loss: 0.1614, acc: 94.79, test_acc: 85.36, f1: 77.01
loss: 0.3644, acc: 94.41, test_acc: 85.36, f1: 76.72
loss: 0.1586, acc: 94.38, test_acc: 86.61, f1: 78.81
loss: 0.1290, acc: 94.35, test_acc: 87.59, f1: 81.10
loss: 0.3035, acc: 94.03, test_acc: 86.88, f1: 79.14
loss: 0.0335, acc: 94.29, test_acc: 86.70, f1: 78.48
loss: 0.0835, acc: 94.53, test_acc: 86.96, f1: 79.31
loss: 0.1425, acc: 94.50, test_acc: 87.14, f1: 79.90
>> saved: state_dict/lcf_bert_restaurant_acc87.77
max_acc:87.77  f1:81.39
loss: 0.0065, acc: 94.71, test_acc: 87.77, f1: 81.39
loss: 0.5114, acc: 94.44, test_acc: 87.41, f1: 81.29
loss: 0.1290, acc: 94.42, test_acc: 87.41, f1: 80.94
loss: 0.0565, acc: 94.40, test_acc: 87.05, f1: 80.23
loss: 0.1987, acc: 94.17, test_acc: 87.14, f1: 80.32
loss: 0.1073, acc: 94.35, test_acc: 87.23, f1: 80.46
loss: 0.0698, acc: 94.34, test_acc: 87.77, f1: 82.26
loss: 0.1507, acc: 94.13, test_acc: 87.32, f1: 81.44
loss: 0.4293, acc: 93.93, test_acc: 87.14, f1: 80.50
loss: 0.1207, acc: 93.93, test_acc: 86.16, f1: 78.12
loss: 0.1061, acc: 93.92, test_acc: 86.43, f1: 78.69
loss: 0.2098, acc: 93.75, test_acc: 87.68, f1: 81.30
loss: 0.2147, acc: 93.75, test_acc: 87.05, f1: 79.74
loss: 0.0985, acc: 93.75, test_acc: 86.70, f1: 78.72
loss: 0.3780, acc: 93.59, test_acc: 87.59, f1: 80.42
loss: 0.2258, acc: 93.45, test_acc: 87.23, f1: 80.27
loss: 0.0769, acc: 93.60, test_acc: 86.96, f1: 79.66
loss: 0.0683, acc: 93.60, test_acc: 86.88, f1: 79.62
loss: 0.1191, acc: 93.61, test_acc: 86.70, f1: 79.50
loss: 0.1436, acc: 93.61, test_acc: 86.70, f1: 79.49
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0381, acc: 100.00, test_acc: 87.41, f1: 80.25
loss: 0.0858, acc: 96.88, test_acc: 86.79, f1: 79.00
loss: 0.0164, acc: 97.92, test_acc: 87.23, f1: 80.03
loss: 0.0482, acc: 96.88, test_acc: 87.32, f1: 80.31
loss: 0.0097, acc: 97.50, test_acc: 87.14, f1: 80.24
loss: 0.2090, acc: 96.88, test_acc: 86.96, f1: 79.54
loss: 0.2314, acc: 96.43, test_acc: 85.62, f1: 76.15
loss: 0.0282, acc: 96.88, test_acc: 85.62, f1: 76.24
loss: 0.0051, acc: 97.22, test_acc: 86.79, f1: 79.23
loss: 0.0717, acc: 96.88, test_acc: 86.96, f1: 79.06
loss: 0.3994, acc: 96.02, test_acc: 87.14, f1: 80.03
loss: 0.1003, acc: 95.83, test_acc: 87.14, f1: 80.13
loss: 0.0967, acc: 95.67, test_acc: 86.96, f1: 80.24
loss: 0.1914, acc: 95.54, test_acc: 87.05, f1: 80.22
loss: 0.0252, acc: 95.83, test_acc: 86.34, f1: 78.00
loss: 0.0384, acc: 96.09, test_acc: 86.70, f1: 78.29
>> saved: state_dict/lcf_bert_restaurant_acc88.21
max_acc:88.21  f1:81.74
loss: 0.0355, acc: 96.32, test_acc: 88.21, f1: 81.74
>> saved: state_dict/lcf_bert_restaurant_acc89.02
max_acc:89.02  f1:83.45
loss: 0.0086, acc: 96.53, test_acc: 89.02, f1: 83.45
loss: 0.2045, acc: 96.05, test_acc: 87.86, f1: 81.55
loss: 0.0598, acc: 95.94, test_acc: 85.89, f1: 78.13
loss: 0.0833, acc: 95.83, test_acc: 86.61, f1: 79.35
loss: 0.0183, acc: 96.02, test_acc: 86.07, f1: 77.95
loss: 0.0753, acc: 96.20, test_acc: 87.32, f1: 79.76
loss: 0.3168, acc: 96.09, test_acc: 87.68, f1: 80.29
loss: 0.0372, acc: 96.25, test_acc: 88.21, f1: 82.05
loss: 0.0167, acc: 96.39, test_acc: 88.48, f1: 83.33
loss: 0.1370, acc: 96.30, test_acc: 88.39, f1: 83.29
loss: 0.1509, acc: 96.21, test_acc: 88.48, f1: 82.69
loss: 0.0872, acc: 96.12, test_acc: 87.86, f1: 80.89
loss: 0.0400, acc: 96.25, test_acc: 86.16, f1: 77.65
loss: 0.0812, acc: 96.17, test_acc: 87.95, f1: 81.36
loss: 0.1238, acc: 96.09, test_acc: 88.48, f1: 82.70
loss: 0.0242, acc: 96.21, test_acc: 88.21, f1: 82.11
loss: 0.0152, acc: 96.32, test_acc: 88.66, f1: 82.77
loss: 0.1086, acc: 96.25, test_acc: 88.75, f1: 82.95
loss: 0.0687, acc: 96.35, test_acc: 87.95, f1: 81.51
loss: 0.1132, acc: 96.28, test_acc: 87.68, f1: 80.81
loss: 0.0930, acc: 96.38, test_acc: 87.14, f1: 80.64
loss: 0.0698, acc: 96.47, test_acc: 87.32, f1: 80.48
loss: 0.1068, acc: 96.41, test_acc: 87.59, f1: 80.33
loss: 0.1740, acc: 96.34, test_acc: 87.41, f1: 80.09
loss: 0.0238, acc: 96.43, test_acc: 87.41, f1: 80.81
loss: 0.0129, acc: 96.51, test_acc: 86.34, f1: 78.93
loss: 0.0644, acc: 96.45, test_acc: 85.89, f1: 77.58
loss: 0.1598, acc: 96.39, test_acc: 86.52, f1: 78.48
loss: 0.0260, acc: 96.43, test_acc: 85.98, f1: 76.90
####################################################################################################
max_test_acc_overall:89.01785714285714
max_f1_overall:83.45014910250771
####################################################################################################
1 test_acc_overall: 89.11  f1_overall:84.11
2 test_acc_overall: 88.75  f1_overall:83.14
3 test_acc_overall: 89.38  f1_overall:84.02
4 test_acc_overall: 88.93  f1_overall:83.58
5 test_acc_overall: 89.02  f1_overall:83.45
max_acc_overall:89.38  f1_overall:84.02
mean_acc_overall:89.04  mean_f1_overall:83.66
####################################################################################################
lcf_bert - twitter - cdw - No.1 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:897287680
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:1
>>> seed: 0
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc50.0
max_acc:50.0  f1:22.22
loss: 1.8714, acc: 31.25, test_acc: 50.00, f1: 22.22
loss: 1.0906, acc: 31.25, test_acc: 39.02, f1: 29.12
loss: 1.1485, acc: 35.42, test_acc: 50.00, f1: 22.22
loss: 0.9282, acc: 42.19, test_acc: 39.16, f1: 29.78
loss: 0.9427, acc: 45.00, test_acc: 50.00, f1: 22.22
loss: 0.9415, acc: 50.00, test_acc: 43.35, f1: 34.07
>> saved: state_dict/lcf_bert_twitter_acc52.17
max_acc:52.17  f1:30.33
loss: 1.1069, acc: 47.32, test_acc: 52.17, f1: 30.33
loss: 0.9823, acc: 50.00, test_acc: 50.87, f1: 24.92
>> saved: state_dict/lcf_bert_twitter_acc52.31
max_acc:52.31  f1:30.53
loss: 1.4632, acc: 45.83, test_acc: 52.31, f1: 30.53
loss: 1.3101, acc: 43.75, test_acc: 34.10, f1: 30.33
loss: 0.9357, acc: 44.32, test_acc: 51.45, f1: 26.96
>> saved: state_dict/lcf_bert_twitter_acc56.5
max_acc:56.5  f1:40.36
loss: 0.9507, acc: 44.79, test_acc: 56.50, f1: 40.36
>> saved: state_dict/lcf_bert_twitter_acc59.25
max_acc:59.25  f1:58.39
loss: 0.9496, acc: 45.67, test_acc: 59.25, f1: 58.39
>> saved: state_dict/lcf_bert_twitter_acc65.32
max_acc:65.32  f1:62.38
loss: 0.9004, acc: 46.43, test_acc: 65.32, f1: 62.38
loss: 0.9207, acc: 46.25, test_acc: 62.72, f1: 60.01
loss: 0.8274, acc: 46.88, test_acc: 59.97, f1: 59.94
loss: 0.8335, acc: 47.79, test_acc: 62.86, f1: 62.38
>> saved: state_dict/lcf_bert_twitter_acc65.46
max_acc:65.46  f1:61.06
loss: 0.7652, acc: 48.61, test_acc: 65.46, f1: 61.06
loss: 0.7813, acc: 49.01, test_acc: 56.94, f1: 57.39
loss: 1.0008, acc: 48.44, test_acc: 58.67, f1: 45.73
loss: 0.9962, acc: 48.21, test_acc: 62.14, f1: 52.78
loss: 0.8112, acc: 48.86, test_acc: 59.39, f1: 59.83
loss: 1.0930, acc: 48.37, test_acc: 58.96, f1: 59.70
loss: 0.6858, acc: 48.96, test_acc: 64.60, f1: 58.26
>> saved: state_dict/lcf_bert_twitter_acc67.63
max_acc:67.63  f1:63.26
loss: 0.8985, acc: 49.25, test_acc: 67.63, f1: 63.26
loss: 0.5786, acc: 50.72, test_acc: 66.62, f1: 65.29
loss: 0.5116, acc: 52.08, test_acc: 65.61, f1: 65.25
loss: 0.7896, acc: 52.01, test_acc: 65.46, f1: 65.07
loss: 1.1798, acc: 51.51, test_acc: 66.62, f1: 66.04
loss: 1.0290, acc: 51.46, test_acc: 67.05, f1: 66.18
loss: 0.5786, acc: 52.42, test_acc: 67.34, f1: 66.78
>> saved: state_dict/lcf_bert_twitter_acc69.08
max_acc:69.08  f1:68.43
loss: 0.7747, acc: 52.93, test_acc: 69.08, f1: 68.43
loss: 0.8422, acc: 53.22, test_acc: 65.90, f1: 63.14
loss: 0.8366, acc: 53.68, test_acc: 68.21, f1: 67.74
>> saved: state_dict/lcf_bert_twitter_acc71.24
max_acc:71.24  f1:68.92
loss: 0.7161, acc: 53.57, test_acc: 71.24, f1: 68.92
>> saved: state_dict/lcf_bert_twitter_acc71.82
max_acc:71.82  f1:70.14
loss: 0.8286, acc: 54.17, test_acc: 71.82, f1: 70.14
loss: 0.7090, acc: 54.73, test_acc: 68.64, f1: 68.04
loss: 0.5401, acc: 55.26, test_acc: 68.35, f1: 67.95
loss: 0.6094, acc: 55.93, test_acc: 69.08, f1: 66.37
loss: 0.9413, acc: 55.94, test_acc: 68.50, f1: 68.45
loss: 1.0672, acc: 55.79, test_acc: 57.66, f1: 57.85
loss: 0.5624, acc: 56.25, test_acc: 68.06, f1: 63.61
loss: 0.7344, acc: 56.40, test_acc: 64.02, f1: 54.97
loss: 0.6196, acc: 56.82, test_acc: 71.24, f1: 70.62
loss: 0.5537, acc: 57.22, test_acc: 69.51, f1: 68.84
loss: 0.4365, acc: 58.02, test_acc: 69.94, f1: 65.37
>> saved: state_dict/lcf_bert_twitter_acc72.25
max_acc:72.25  f1:69.27
loss: 1.1202, acc: 57.71, test_acc: 72.25, f1: 69.27
loss: 0.9327, acc: 57.81, test_acc: 60.84, f1: 61.28
loss: 0.7146, acc: 58.29, test_acc: 71.24, f1: 70.29
loss: 0.7270, acc: 58.50, test_acc: 71.97, f1: 68.39
loss: 0.7913, acc: 58.70, test_acc: 67.92, f1: 66.12
loss: 0.7131, acc: 58.89, test_acc: 72.11, f1: 69.67
loss: 0.4589, acc: 59.43, test_acc: 65.75, f1: 60.14
>> saved: state_dict/lcf_bert_twitter_acc73.27
max_acc:73.27  f1:71.27
loss: 0.6312, acc: 59.49, test_acc: 73.27, f1: 71.27
loss: 0.6817, acc: 59.66, test_acc: 70.66, f1: 68.62
loss: 0.4151, acc: 60.04, test_acc: 71.68, f1: 70.81
loss: 0.5675, acc: 60.53, test_acc: 72.25, f1: 71.32
loss: 0.8501, acc: 60.56, test_acc: 72.40, f1: 68.98
loss: 0.8269, acc: 60.81, test_acc: 68.06, f1: 65.87
loss: 0.9531, acc: 60.83, test_acc: 67.20, f1: 67.80
loss: 0.5959, acc: 61.07, test_acc: 69.94, f1: 69.12
loss: 0.6659, acc: 61.29, test_acc: 72.25, f1: 71.12
>> saved: state_dict/lcf_bert_twitter_acc74.42
max_acc:74.42  f1:73.1
loss: 1.0460, acc: 61.11, test_acc: 74.42, f1: 73.10
>> saved: state_dict/lcf_bert_twitter_acc74.71
max_acc:74.71  f1:73.3
loss: 0.3307, acc: 61.62, test_acc: 74.71, f1: 73.30
loss: 0.5842, acc: 61.83, test_acc: 72.69, f1: 71.97
loss: 0.7337, acc: 61.74, test_acc: 67.63, f1: 68.03
loss: 0.5459, acc: 62.03, test_acc: 74.13, f1: 73.27
loss: 0.5531, acc: 62.32, test_acc: 73.99, f1: 72.42
loss: 0.5345, acc: 62.50, test_acc: 71.10, f1: 70.94
loss: 0.5645, acc: 62.50, test_acc: 70.52, f1: 69.53
>> saved: state_dict/lcf_bert_twitter_acc75.14
max_acc:75.14  f1:74.0
loss: 0.5069, acc: 62.59, test_acc: 75.14, f1: 74.00
loss: 0.8818, acc: 62.41, test_acc: 75.00, f1: 73.70
loss: 0.3757, acc: 62.84, test_acc: 74.42, f1: 72.01
loss: 0.4018, acc: 63.18, test_acc: 71.82, f1: 71.43
loss: 0.5118, acc: 63.42, test_acc: 71.53, f1: 71.42
>> saved: state_dict/lcf_bert_twitter_acc75.29
max_acc:75.29  f1:74.2
loss: 0.4246, acc: 63.57, test_acc: 75.29, f1: 74.20
loss: 0.7454, acc: 63.64, test_acc: 73.12, f1: 71.92
loss: 0.5643, acc: 63.78, test_acc: 75.14, f1: 73.43
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.7538, acc: 75.00, test_acc: 72.54, f1: 70.70
loss: 0.5999, acc: 75.00, test_acc: 72.69, f1: 72.45
loss: 0.7322, acc: 75.00, test_acc: 75.14, f1: 74.48
>> saved: state_dict/lcf_bert_twitter_acc75.58
max_acc:75.58  f1:73.59
loss: 0.8367, acc: 73.44, test_acc: 75.58, f1: 73.59
loss: 0.5137, acc: 73.75, test_acc: 73.55, f1: 72.95
loss: 0.7490, acc: 71.88, test_acc: 72.25, f1: 72.00
>> saved: state_dict/lcf_bert_twitter_acc76.88
max_acc:76.88  f1:75.84
loss: 0.2635, acc: 74.11, test_acc: 76.88, f1: 75.84
loss: 0.3398, acc: 74.22, test_acc: 76.59, f1: 75.02
>> saved: state_dict/lcf_bert_twitter_acc77.17
max_acc:77.17  f1:76.12
loss: 0.5065, acc: 74.31, test_acc: 77.17, f1: 76.12
loss: 0.5161, acc: 75.62, test_acc: 73.55, f1: 73.28
loss: 0.4821, acc: 76.14, test_acc: 73.99, f1: 73.56
loss: 0.2867, acc: 78.12, test_acc: 74.86, f1: 73.68
loss: 0.5592, acc: 78.37, test_acc: 73.70, f1: 72.86
loss: 0.6316, acc: 77.23, test_acc: 74.28, f1: 73.84
loss: 0.3540, acc: 77.92, test_acc: 72.40, f1: 71.87
loss: 0.3728, acc: 78.12, test_acc: 74.42, f1: 73.10
loss: 0.6175, acc: 77.21, test_acc: 73.84, f1: 73.07
loss: 0.3057, acc: 78.12, test_acc: 72.54, f1: 71.31
loss: 0.5429, acc: 78.29, test_acc: 71.97, f1: 70.95
loss: 0.7791, acc: 78.44, test_acc: 74.28, f1: 72.77
loss: 0.2835, acc: 79.17, test_acc: 74.42, f1: 72.74
loss: 0.2523, acc: 79.83, test_acc: 73.12, f1: 72.50
loss: 0.2436, acc: 80.43, test_acc: 70.09, f1: 70.62
loss: 0.1052, acc: 81.25, test_acc: 73.70, f1: 72.84
loss: 0.9553, acc: 80.25, test_acc: 73.99, f1: 71.72
loss: 0.3947, acc: 80.53, test_acc: 74.28, f1: 73.60
loss: 0.5479, acc: 80.32, test_acc: 72.98, f1: 73.02
loss: 0.3842, acc: 80.36, test_acc: 72.25, f1: 71.74
loss: 0.4437, acc: 80.60, test_acc: 74.42, f1: 71.89
loss: 0.6297, acc: 80.00, test_acc: 73.55, f1: 72.76
loss: 0.4033, acc: 80.04, test_acc: 72.98, f1: 72.84
loss: 0.5278, acc: 80.27, test_acc: 74.57, f1: 73.83
loss: 0.6733, acc: 79.92, test_acc: 75.00, f1: 73.10
loss: 0.4973, acc: 79.96, test_acc: 75.43, f1: 73.86
loss: 0.4556, acc: 79.82, test_acc: 73.12, f1: 72.21
loss: 0.4550, acc: 80.03, test_acc: 71.82, f1: 71.59
loss: 0.4308, acc: 80.07, test_acc: 73.41, f1: 73.08
loss: 0.5091, acc: 80.10, test_acc: 74.71, f1: 73.75
loss: 0.5673, acc: 79.97, test_acc: 75.00, f1: 72.93
loss: 0.3245, acc: 80.16, test_acc: 74.13, f1: 72.47
loss: 0.9241, acc: 79.57, test_acc: 71.68, f1: 72.00
loss: 0.4996, acc: 79.32, test_acc: 72.69, f1: 72.09
loss: 0.6629, acc: 79.36, test_acc: 75.14, f1: 73.59
loss: 0.4098, acc: 79.40, test_acc: 73.41, f1: 72.68
loss: 0.3483, acc: 79.58, test_acc: 71.53, f1: 71.05
loss: 0.3111, acc: 79.76, test_acc: 73.12, f1: 72.67
loss: 0.4473, acc: 79.92, test_acc: 69.94, f1: 70.20
loss: 0.6030, acc: 79.69, test_acc: 72.54, f1: 72.03
loss: 0.7290, acc: 79.34, test_acc: 75.00, f1: 73.42
loss: 0.3514, acc: 79.50, test_acc: 75.43, f1: 73.89
loss: 0.2171, acc: 79.78, test_acc: 72.83, f1: 72.13
loss: 0.6827, acc: 79.57, test_acc: 74.28, f1: 72.57
loss: 0.3843, acc: 79.72, test_acc: 72.98, f1: 69.16
loss: 0.4282, acc: 79.51, test_acc: 72.69, f1: 71.90
loss: 0.4034, acc: 79.55, test_acc: 71.97, f1: 71.78
loss: 0.3475, acc: 79.58, test_acc: 73.41, f1: 72.41
loss: 0.8708, acc: 79.28, test_acc: 75.14, f1: 73.27
loss: 0.1951, acc: 79.53, test_acc: 74.42, f1: 72.86
loss: 0.6107, acc: 79.56, test_acc: 70.66, f1: 70.76
loss: 1.0375, acc: 79.06, test_acc: 72.69, f1: 72.17
loss: 0.7743, acc: 78.69, test_acc: 75.87, f1: 74.06
loss: 0.3438, acc: 78.83, test_acc: 74.28, f1: 73.28
loss: 0.5935, acc: 78.77, test_acc: 73.41, f1: 72.85
loss: 0.5731, acc: 78.61, test_acc: 72.69, f1: 72.39
loss: 0.5430, acc: 78.56, test_acc: 72.98, f1: 72.39
loss: 0.6419, acc: 78.41, test_acc: 75.58, f1: 74.54
loss: 0.6309, acc: 78.36, test_acc: 76.30, f1: 74.77
loss: 0.5111, acc: 78.40, test_acc: 74.13, f1: 73.42
loss: 0.5917, acc: 78.26, test_acc: 75.00, f1: 74.09
loss: 0.2795, acc: 78.39, test_acc: 75.43, f1: 74.17
loss: 0.2858, acc: 78.52, test_acc: 75.72, f1: 74.80
loss: 0.7278, acc: 78.39, test_acc: 73.99, f1: 73.05
loss: 0.4214, acc: 78.34, test_acc: 73.12, f1: 71.45
loss: 0.8593, acc: 78.21, test_acc: 74.42, f1: 71.25
loss: 0.6498, acc: 78.08, test_acc: 74.28, f1: 74.17
loss: 0.6858, acc: 78.04, test_acc: 65.61, f1: 65.93
loss: 0.8838, acc: 77.76, test_acc: 74.71, f1: 73.50
loss: 0.9115, acc: 77.64, test_acc: 75.00, f1: 74.29
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2339, acc: 93.75, test_acc: 69.22, f1: 69.66
loss: 0.2034, acc: 93.75, test_acc: 76.30, f1: 75.32
loss: 0.2764, acc: 91.67, test_acc: 75.43, f1: 74.12
loss: 0.4229, acc: 89.06, test_acc: 74.42, f1: 74.28
loss: 0.3161, acc: 90.00, test_acc: 68.79, f1: 69.35
loss: 0.3542, acc: 88.54, test_acc: 75.87, f1: 75.30
loss: 0.4754, acc: 88.39, test_acc: 75.87, f1: 73.66
loss: 0.1648, acc: 89.84, test_acc: 76.59, f1: 75.41
loss: 0.1003, acc: 90.97, test_acc: 73.84, f1: 73.78
loss: 0.1203, acc: 91.88, test_acc: 74.42, f1: 74.03
loss: 0.2979, acc: 91.48, test_acc: 72.98, f1: 73.09
loss: 0.0799, acc: 92.19, test_acc: 73.99, f1: 73.80
loss: 0.1641, acc: 92.31, test_acc: 75.72, f1: 74.57
loss: 0.3623, acc: 91.96, test_acc: 74.57, f1: 73.28
loss: 0.4126, acc: 91.25, test_acc: 73.12, f1: 73.03
loss: 0.4140, acc: 91.41, test_acc: 71.24, f1: 70.58
loss: 0.1111, acc: 91.54, test_acc: 73.27, f1: 72.15
loss: 0.1024, acc: 91.67, test_acc: 75.14, f1: 73.78
loss: 0.1568, acc: 92.11, test_acc: 73.99, f1: 73.23
loss: 0.1949, acc: 92.19, test_acc: 75.00, f1: 74.69
loss: 0.2876, acc: 91.96, test_acc: 74.86, f1: 74.21
loss: 0.1201, acc: 92.33, test_acc: 74.28, f1: 73.66
loss: 0.0890, acc: 92.66, test_acc: 74.86, f1: 73.21
loss: 0.3587, acc: 92.45, test_acc: 73.41, f1: 72.23
loss: 0.2472, acc: 92.00, test_acc: 73.12, f1: 72.45
loss: 0.4593, acc: 91.83, test_acc: 72.98, f1: 72.77
loss: 0.1810, acc: 91.90, test_acc: 75.14, f1: 73.34
loss: 0.7563, acc: 91.29, test_acc: 74.71, f1: 72.97
loss: 0.1242, acc: 91.38, test_acc: 71.82, f1: 71.53
loss: 0.1719, acc: 91.46, test_acc: 70.38, f1: 70.46
loss: 0.3638, acc: 91.13, test_acc: 76.01, f1: 74.92
loss: 0.2370, acc: 91.21, test_acc: 75.29, f1: 73.99
loss: 0.1464, acc: 91.10, test_acc: 75.29, f1: 73.85
loss: 0.1255, acc: 91.18, test_acc: 76.16, f1: 75.36
loss: 0.1194, acc: 91.43, test_acc: 75.58, f1: 75.18
loss: 0.2981, acc: 91.15, test_acc: 74.57, f1: 73.98
loss: 0.2403, acc: 91.05, test_acc: 75.87, f1: 74.66
loss: 0.1072, acc: 91.12, test_acc: 73.99, f1: 73.76
loss: 0.4080, acc: 91.03, test_acc: 75.58, f1: 74.69
loss: 0.3681, acc: 90.94, test_acc: 72.69, f1: 72.35
loss: 0.1299, acc: 91.01, test_acc: 74.13, f1: 72.42
loss: 0.6876, acc: 90.77, test_acc: 75.14, f1: 74.40
loss: 0.5292, acc: 90.55, test_acc: 65.46, f1: 66.05
loss: 0.2526, acc: 90.48, test_acc: 74.71, f1: 72.79
loss: 0.2192, acc: 90.56, test_acc: 72.83, f1: 69.23
loss: 0.3023, acc: 90.62, test_acc: 76.16, f1: 75.34
loss: 0.4451, acc: 90.43, test_acc: 71.10, f1: 71.24
loss: 0.1821, acc: 90.49, test_acc: 74.42, f1: 73.64
loss: 0.2116, acc: 90.56, test_acc: 75.43, f1: 74.02
loss: 0.2491, acc: 90.50, test_acc: 74.71, f1: 73.23
loss: 0.1883, acc: 90.56, test_acc: 73.99, f1: 73.24
loss: 0.0668, acc: 90.75, test_acc: 75.00, f1: 74.20
loss: 0.0847, acc: 90.92, test_acc: 72.98, f1: 72.80
loss: 0.4003, acc: 90.74, test_acc: 72.11, f1: 72.24
loss: 0.1662, acc: 90.91, test_acc: 76.01, f1: 74.97
loss: 0.1280, acc: 91.07, test_acc: 75.43, f1: 73.67
loss: 0.0815, acc: 91.23, test_acc: 75.58, f1: 74.15
loss: 0.3335, acc: 91.16, test_acc: 71.68, f1: 71.63
loss: 0.2772, acc: 91.10, test_acc: 68.93, f1: 69.25
loss: 0.3509, acc: 90.94, test_acc: 72.83, f1: 72.53
loss: 0.0676, acc: 91.09, test_acc: 73.12, f1: 72.64
loss: 0.0905, acc: 91.23, test_acc: 72.11, f1: 72.04
loss: 0.2002, acc: 91.27, test_acc: 73.12, f1: 72.54
loss: 0.2842, acc: 91.21, test_acc: 72.98, f1: 72.43
loss: 0.3337, acc: 91.15, test_acc: 72.25, f1: 72.24
loss: 0.3957, acc: 91.10, test_acc: 70.38, f1: 70.04
loss: 0.3605, acc: 91.14, test_acc: 71.39, f1: 71.11
loss: 0.3652, acc: 91.18, test_acc: 70.95, f1: 69.93
loss: 0.2773, acc: 91.12, test_acc: 72.98, f1: 72.31
loss: 0.5819, acc: 91.07, test_acc: 71.39, f1: 71.52
loss: 0.1795, acc: 91.11, test_acc: 68.93, f1: 68.98
loss: 0.1649, acc: 91.15, test_acc: 72.98, f1: 71.95
loss: 0.3911, acc: 91.01, test_acc: 73.12, f1: 72.30
loss: 0.0877, acc: 91.13, test_acc: 72.69, f1: 72.36
loss: 0.1112, acc: 91.25, test_acc: 74.86, f1: 74.20
loss: 0.0803, acc: 91.37, test_acc: 75.43, f1: 74.48
loss: 0.4728, acc: 91.15, test_acc: 74.42, f1: 73.96
loss: 0.6051, acc: 90.95, test_acc: 73.27, f1: 73.16
####################################################################################################
max_test_acc_overall:77.16763005780348
max_f1_overall:76.11958757547224
####################################################################################################
1 test_acc_overall: 77.17  f1_overall:76.12
max_acc_overall:77.17  f1_overall:76.12
mean_acc_overall:77.17  mean_f1_overall:76.12
####################################################################################################
lcf_bert - twitter - cdw - No.2 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:1
>>> seed: 1
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc25.14
max_acc:25.14  f1:13.54
loss: 1.0427, acc: 37.50, test_acc: 25.14, f1: 13.54
>> saved: state_dict/lcf_bert_twitter_acc50.0
max_acc:50.0  f1:22.22
loss: 1.0843, acc: 43.75, test_acc: 50.00, f1: 22.22
>> saved: state_dict/lcf_bert_twitter_acc51.16
max_acc:51.16  f1:27.32
loss: 1.1142, acc: 43.75, test_acc: 51.16, f1: 27.32
loss: 0.9599, acc: 48.44, test_acc: 50.00, f1: 22.22
loss: 1.1828, acc: 48.75, test_acc: 50.00, f1: 22.22
loss: 1.1592, acc: 44.79, test_acc: 27.46, f1: 17.10
loss: 1.2034, acc: 45.54, test_acc: 50.00, f1: 22.22
loss: 1.2196, acc: 44.53, test_acc: 50.43, f1: 37.54
>> saved: state_dict/lcf_bert_twitter_acc51.88
max_acc:51.88  f1:51.52
loss: 1.0432, acc: 44.44, test_acc: 51.88, f1: 51.52
>> saved: state_dict/lcf_bert_twitter_acc54.19
max_acc:54.19  f1:32.83
loss: 0.7404, acc: 48.12, test_acc: 54.19, f1: 32.83
loss: 0.7977, acc: 50.00, test_acc: 50.72, f1: 24.53
>> saved: state_dict/lcf_bert_twitter_acc59.25
max_acc:59.25  f1:49.49
loss: 0.7283, acc: 51.56, test_acc: 59.25, f1: 49.49
>> saved: state_dict/lcf_bert_twitter_acc59.68
max_acc:59.68  f1:56.85
loss: 0.9124, acc: 52.40, test_acc: 59.68, f1: 56.85
loss: 0.6878, acc: 53.12, test_acc: 57.95, f1: 44.92
loss: 0.7229, acc: 55.00, test_acc: 55.49, f1: 55.86
>> saved: state_dict/lcf_bert_twitter_acc63.44
max_acc:63.44  f1:58.07
loss: 1.0608, acc: 54.69, test_acc: 63.44, f1: 58.07
loss: 1.0489, acc: 54.41, test_acc: 60.12, f1: 51.38
loss: 0.8857, acc: 54.51, test_acc: 59.54, f1: 59.64
>> saved: state_dict/lcf_bert_twitter_acc63.58
max_acc:63.58  f1:62.96
loss: 0.6463, acc: 55.26, test_acc: 63.58, f1: 62.96
loss: 0.8977, acc: 55.00, test_acc: 62.28, f1: 62.71
>> saved: state_dict/lcf_bert_twitter_acc66.62
max_acc:66.62  f1:61.97
loss: 1.0328, acc: 55.06, test_acc: 66.62, f1: 61.97
loss: 0.4942, acc: 56.25, test_acc: 66.47, f1: 62.37
loss: 0.6421, acc: 57.07, test_acc: 64.16, f1: 63.28
loss: 0.7498, acc: 57.29, test_acc: 64.31, f1: 63.72
loss: 0.7500, acc: 57.75, test_acc: 65.61, f1: 61.31
loss: 0.6156, acc: 58.65, test_acc: 63.73, f1: 63.69
loss: 0.8732, acc: 58.56, test_acc: 66.18, f1: 65.10
loss: 0.5824, acc: 59.15, test_acc: 65.32, f1: 64.16
loss: 0.7627, acc: 59.05, test_acc: 64.16, f1: 64.01
>> saved: state_dict/lcf_bert_twitter_acc69.94
max_acc:69.94  f1:67.44
loss: 0.7568, acc: 59.58, test_acc: 69.94, f1: 67.44
loss: 0.6541, acc: 60.28, test_acc: 66.33, f1: 63.59
loss: 0.7242, acc: 60.16, test_acc: 63.15, f1: 63.33
loss: 0.8063, acc: 60.23, test_acc: 67.20, f1: 66.05
loss: 0.6003, acc: 60.66, test_acc: 67.92, f1: 66.41
loss: 0.7855, acc: 60.71, test_acc: 68.64, f1: 67.34
loss: 0.6383, acc: 60.94, test_acc: 69.80, f1: 66.70
loss: 0.7057, acc: 61.49, test_acc: 62.86, f1: 63.19
loss: 0.9011, acc: 61.51, test_acc: 68.93, f1: 67.34
loss: 1.0167, acc: 61.22, test_acc: 69.80, f1: 66.60
loss: 0.6032, acc: 61.56, test_acc: 65.17, f1: 63.96
>> saved: state_dict/lcf_bert_twitter_acc72.11
max_acc:72.11  f1:70.36
loss: 0.7896, acc: 61.74, test_acc: 72.11, f1: 70.36
loss: 0.9376, acc: 61.46, test_acc: 64.88, f1: 63.93
loss: 0.8174, acc: 61.34, test_acc: 68.79, f1: 67.51
loss: 0.6645, acc: 61.65, test_acc: 68.21, f1: 67.92
loss: 0.5305, acc: 62.08, test_acc: 66.04, f1: 63.14
loss: 0.6325, acc: 62.23, test_acc: 67.63, f1: 62.23
loss: 0.5648, acc: 62.50, test_acc: 69.08, f1: 68.09
loss: 0.9251, acc: 62.76, test_acc: 66.18, f1: 65.74
loss: 1.1145, acc: 62.50, test_acc: 64.16, f1: 64.18
loss: 0.6527, acc: 62.62, test_acc: 67.05, f1: 67.54
loss: 0.6858, acc: 62.50, test_acc: 69.22, f1: 67.41
loss: 0.4527, acc: 62.98, test_acc: 70.66, f1: 69.09
loss: 0.4562, acc: 63.21, test_acc: 70.23, f1: 69.59
loss: 0.9024, acc: 63.08, test_acc: 64.31, f1: 64.57
loss: 0.5890, acc: 63.18, test_acc: 70.52, f1: 67.38
>> saved: state_dict/lcf_bert_twitter_acc72.54
max_acc:72.54  f1:71.4
loss: 0.6276, acc: 63.39, test_acc: 72.54, f1: 71.40
loss: 0.5548, acc: 63.71, test_acc: 63.87, f1: 63.79
loss: 0.7140, acc: 63.79, test_acc: 70.23, f1: 67.05
loss: 0.9074, acc: 63.56, test_acc: 65.75, f1: 60.37
loss: 0.6957, acc: 63.54, test_acc: 68.21, f1: 68.51
loss: 0.5273, acc: 63.83, test_acc: 70.23, f1: 69.18
loss: 0.4518, acc: 63.91, test_acc: 72.11, f1: 69.78
>> saved: state_dict/lcf_bert_twitter_acc73.55
max_acc:73.55  f1:71.52
loss: 0.7486, acc: 63.99, test_acc: 73.55, f1: 71.52
loss: 0.3249, acc: 64.45, test_acc: 70.66, f1: 70.10
loss: 0.4570, acc: 64.90, test_acc: 70.66, f1: 69.43
loss: 0.6419, acc: 64.96, test_acc: 73.41, f1: 70.46
loss: 0.8226, acc: 64.93, test_acc: 71.97, f1: 71.27
loss: 0.6869, acc: 64.98, test_acc: 70.66, f1: 70.27
loss: 0.4699, acc: 65.22, test_acc: 71.24, f1: 68.65
loss: 0.7318, acc: 65.36, test_acc: 72.25, f1: 69.54
loss: 0.7600, acc: 65.32, test_acc: 72.11, f1: 71.88
loss: 0.5010, acc: 65.54, test_acc: 66.47, f1: 66.91
>> saved: state_dict/lcf_bert_twitter_acc73.84
max_acc:73.84  f1:71.85
loss: 0.3027, acc: 65.92, test_acc: 73.84, f1: 71.85
loss: 0.8663, acc: 65.96, test_acc: 73.55, f1: 71.59
loss: 0.7566, acc: 66.08, test_acc: 71.39, f1: 71.46
>> saved: state_dict/lcf_bert_twitter_acc74.28
max_acc:74.28  f1:73.64
loss: 0.9867, acc: 65.79, test_acc: 74.28, f1: 73.64
>> saved: state_dict/lcf_bert_twitter_acc74.42
max_acc:74.42  f1:72.41
loss: 0.6890, acc: 65.75, test_acc: 74.42, f1: 72.41
loss: 0.4612, acc: 66.03, test_acc: 73.55, f1: 71.86
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.4240, acc: 93.75, test_acc: 73.12, f1: 72.39
>> saved: state_dict/lcf_bert_twitter_acc74.71
max_acc:74.71  f1:72.96
loss: 0.5878, acc: 87.50, test_acc: 74.71, f1: 72.96
>> saved: state_dict/lcf_bert_twitter_acc76.16
max_acc:76.16  f1:74.5
loss: 0.5692, acc: 85.42, test_acc: 76.16, f1: 74.50
loss: 0.4429, acc: 84.38, test_acc: 69.36, f1: 69.62
loss: 0.2714, acc: 86.25, test_acc: 67.49, f1: 67.69
loss: 0.5634, acc: 84.38, test_acc: 75.00, f1: 73.88
loss: 0.2253, acc: 85.71, test_acc: 72.83, f1: 70.08
loss: 0.2590, acc: 87.50, test_acc: 70.95, f1: 70.36
loss: 0.4751, acc: 86.11, test_acc: 72.69, f1: 72.05
loss: 0.5183, acc: 85.00, test_acc: 73.27, f1: 71.98
loss: 0.4030, acc: 84.66, test_acc: 73.27, f1: 72.68
loss: 0.2802, acc: 84.38, test_acc: 71.82, f1: 71.03
loss: 0.4702, acc: 83.17, test_acc: 74.71, f1: 72.75
loss: 0.4098, acc: 83.04, test_acc: 75.14, f1: 73.40
loss: 0.5913, acc: 82.50, test_acc: 73.12, f1: 72.58
loss: 0.4320, acc: 82.81, test_acc: 71.10, f1: 70.94
loss: 0.6012, acc: 82.72, test_acc: 75.43, f1: 73.48
loss: 0.3886, acc: 82.64, test_acc: 75.58, f1: 73.48
loss: 0.5389, acc: 82.89, test_acc: 72.69, f1: 72.38
loss: 0.4114, acc: 82.81, test_acc: 73.99, f1: 71.68
loss: 0.2387, acc: 83.33, test_acc: 74.42, f1: 72.50
loss: 0.4422, acc: 82.95, test_acc: 72.11, f1: 71.52
loss: 0.4880, acc: 82.88, test_acc: 70.66, f1: 70.70
loss: 0.5462, acc: 81.77, test_acc: 73.84, f1: 72.31
loss: 0.6003, acc: 81.50, test_acc: 70.23, f1: 65.35
loss: 0.5466, acc: 81.01, test_acc: 74.28, f1: 73.22
loss: 0.5273, acc: 81.25, test_acc: 68.93, f1: 69.28
loss: 0.3885, acc: 81.25, test_acc: 73.41, f1: 72.84
loss: 0.3326, acc: 81.47, test_acc: 75.14, f1: 74.16
loss: 0.6791, acc: 81.25, test_acc: 74.42, f1: 73.19
loss: 0.4702, acc: 81.45, test_acc: 75.00, f1: 73.61
loss: 0.1372, acc: 81.84, test_acc: 68.50, f1: 68.89
loss: 0.3221, acc: 82.01, test_acc: 75.00, f1: 73.85
loss: 0.8335, acc: 81.43, test_acc: 73.41, f1: 70.98
loss: 0.3096, acc: 81.61, test_acc: 73.27, f1: 72.97
loss: 0.6567, acc: 81.60, test_acc: 71.97, f1: 71.65
loss: 0.4727, acc: 81.76, test_acc: 71.53, f1: 70.64
loss: 0.5331, acc: 81.41, test_acc: 70.38, f1: 69.93
loss: 0.3978, acc: 81.41, test_acc: 71.68, f1: 70.26
loss: 0.7419, acc: 80.78, test_acc: 71.82, f1: 71.01
loss: 0.5533, acc: 80.64, test_acc: 72.98, f1: 72.23
loss: 0.5410, acc: 80.36, test_acc: 74.13, f1: 72.22
loss: 0.4814, acc: 80.38, test_acc: 68.64, f1: 68.80
loss: 0.5516, acc: 80.26, test_acc: 72.69, f1: 72.11
loss: 0.4592, acc: 80.28, test_acc: 72.69, f1: 70.22
loss: 0.9704, acc: 79.62, test_acc: 72.98, f1: 70.69
loss: 0.5303, acc: 79.65, test_acc: 66.91, f1: 67.23
loss: 0.2870, acc: 79.95, test_acc: 72.11, f1: 71.32
loss: 0.6707, acc: 79.72, test_acc: 72.98, f1: 70.59
loss: 0.2871, acc: 79.75, test_acc: 74.28, f1: 73.34
loss: 0.5121, acc: 79.78, test_acc: 68.50, f1: 68.93
loss: 0.3065, acc: 79.93, test_acc: 74.42, f1: 73.27
loss: 1.1172, acc: 79.36, test_acc: 73.70, f1: 72.27
loss: 0.4742, acc: 79.40, test_acc: 70.66, f1: 70.50
loss: 0.5328, acc: 79.32, test_acc: 73.41, f1: 73.08
loss: 0.4590, acc: 79.35, test_acc: 73.84, f1: 72.42
loss: 0.3196, acc: 79.50, test_acc: 74.71, f1: 73.05
loss: 0.4071, acc: 79.63, test_acc: 73.27, f1: 72.81
loss: 0.5249, acc: 79.66, test_acc: 73.99, f1: 73.12
loss: 0.4428, acc: 79.58, test_acc: 75.58, f1: 74.04
loss: 0.2870, acc: 79.71, test_acc: 74.71, f1: 73.80
loss: 0.2039, acc: 79.94, test_acc: 73.99, f1: 73.37
loss: 0.3323, acc: 79.96, test_acc: 73.99, f1: 73.01
loss: 0.5541, acc: 79.88, test_acc: 74.86, f1: 73.44
loss: 0.4083, acc: 79.90, test_acc: 75.00, f1: 74.06
loss: 0.6267, acc: 79.73, test_acc: 69.65, f1: 69.48
loss: 0.6450, acc: 79.57, test_acc: 74.42, f1: 73.34
loss: 0.3954, acc: 79.60, test_acc: 75.72, f1: 73.53
>> saved: state_dict/lcf_bert_twitter_acc76.88
max_acc:76.88  f1:75.5
loss: 0.7873, acc: 79.62, test_acc: 76.88, f1: 75.50
loss: 0.3736, acc: 79.64, test_acc: 74.42, f1: 73.54
loss: 0.2864, acc: 79.75, test_acc: 75.72, f1: 74.47
loss: 0.3791, acc: 79.77, test_acc: 75.87, f1: 74.52
loss: 0.7509, acc: 79.62, test_acc: 69.80, f1: 69.76
loss: 0.6413, acc: 79.56, test_acc: 75.72, f1: 75.05
loss: 0.4910, acc: 79.42, test_acc: 74.28, f1: 71.87
loss: 0.8289, acc: 79.36, test_acc: 74.28, f1: 72.40
>> saved: state_dict/lcf_bert_twitter_acc77.17
max_acc:77.17  f1:76.39
loss: 0.3890, acc: 79.46, test_acc: 77.17, f1: 76.39
loss: 0.5238, acc: 79.33, test_acc: 74.42, f1: 73.67
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1685, acc: 100.00, test_acc: 76.16, f1: 74.51
loss: 0.3337, acc: 93.75, test_acc: 76.45, f1: 75.13
loss: 0.2027, acc: 93.75, test_acc: 74.57, f1: 73.25
loss: 0.7166, acc: 90.62, test_acc: 73.70, f1: 73.19
loss: 0.2128, acc: 91.25, test_acc: 74.28, f1: 73.80
loss: 0.0968, acc: 92.71, test_acc: 75.00, f1: 73.49
loss: 0.1619, acc: 92.86, test_acc: 74.42, f1: 73.58
loss: 0.2995, acc: 91.41, test_acc: 73.55, f1: 73.27
loss: 0.1005, acc: 92.36, test_acc: 71.10, f1: 70.86
loss: 0.1023, acc: 93.12, test_acc: 75.58, f1: 74.36
loss: 0.2667, acc: 93.18, test_acc: 73.55, f1: 73.17
loss: 0.4785, acc: 92.71, test_acc: 72.25, f1: 72.14
loss: 0.3879, acc: 91.35, test_acc: 74.57, f1: 73.92
loss: 0.2655, acc: 90.62, test_acc: 76.30, f1: 75.09
loss: 0.1234, acc: 91.25, test_acc: 76.01, f1: 75.28
loss: 0.1421, acc: 91.41, test_acc: 74.57, f1: 74.13
loss: 0.3654, acc: 91.18, test_acc: 75.00, f1: 73.82
loss: 0.4263, acc: 90.97, test_acc: 71.97, f1: 71.66
loss: 0.1361, acc: 91.45, test_acc: 73.27, f1: 72.85
loss: 0.2189, acc: 91.56, test_acc: 73.55, f1: 71.68
loss: 0.3400, acc: 91.07, test_acc: 73.41, f1: 71.06
loss: 0.3653, acc: 90.91, test_acc: 72.54, f1: 72.47
loss: 0.5662, acc: 89.95, test_acc: 66.91, f1: 67.38
loss: 0.0861, acc: 90.36, test_acc: 74.71, f1: 74.01
loss: 1.2240, acc: 89.25, test_acc: 74.57, f1: 72.75
loss: 0.4882, acc: 88.94, test_acc: 73.99, f1: 73.39
loss: 0.2270, acc: 89.12, test_acc: 68.79, f1: 68.93
loss: 0.0912, acc: 89.29, test_acc: 71.97, f1: 71.76
loss: 0.4948, acc: 88.79, test_acc: 73.41, f1: 72.05
loss: 0.2054, acc: 88.96, test_acc: 75.00, f1: 73.82
loss: 0.1277, acc: 89.31, test_acc: 73.84, f1: 72.82
loss: 0.0336, acc: 89.65, test_acc: 70.81, f1: 70.20
loss: 0.2763, acc: 89.77, test_acc: 73.55, f1: 72.34
loss: 0.4697, acc: 89.71, test_acc: 71.53, f1: 69.15
loss: 0.1851, acc: 89.82, test_acc: 73.70, f1: 73.40
loss: 0.4471, acc: 89.41, test_acc: 73.27, f1: 71.81
loss: 0.1704, acc: 89.70, test_acc: 73.55, f1: 72.83
loss: 0.0934, acc: 89.97, test_acc: 72.83, f1: 72.65
loss: 0.1922, acc: 89.90, test_acc: 72.83, f1: 71.69
loss: 0.5215, acc: 89.22, test_acc: 72.83, f1: 71.97
loss: 0.1508, acc: 89.33, test_acc: 68.21, f1: 68.44
loss: 0.4419, acc: 89.29, test_acc: 70.38, f1: 70.34
loss: 0.2182, acc: 89.24, test_acc: 74.28, f1: 72.25
loss: 0.2120, acc: 89.20, test_acc: 73.84, f1: 72.37
loss: 0.1120, acc: 89.31, test_acc: 72.11, f1: 72.16
loss: 0.3067, acc: 89.27, test_acc: 72.69, f1: 71.99
loss: 0.1687, acc: 89.36, test_acc: 72.25, f1: 69.38
loss: 0.3548, acc: 89.19, test_acc: 72.40, f1: 70.84
loss: 0.2675, acc: 89.16, test_acc: 63.87, f1: 64.69
loss: 0.4357, acc: 89.12, test_acc: 66.47, f1: 66.92
loss: 0.1208, acc: 89.34, test_acc: 73.55, f1: 70.76
loss: 0.3448, acc: 89.42, test_acc: 71.39, f1: 67.97
loss: 0.1014, acc: 89.62, test_acc: 68.79, f1: 68.82
loss: 0.3568, acc: 89.47, test_acc: 68.50, f1: 68.61
loss: 0.2704, acc: 89.32, test_acc: 73.41, f1: 71.06
loss: 0.4288, acc: 89.06, test_acc: 73.12, f1: 71.52
loss: 0.1325, acc: 89.14, test_acc: 70.23, f1: 69.88
loss: 0.3502, acc: 89.12, test_acc: 72.11, f1: 71.24
loss: 0.1399, acc: 89.19, test_acc: 70.95, f1: 70.17
loss: 0.4644, acc: 89.06, test_acc: 69.22, f1: 69.06
loss: 0.2466, acc: 89.14, test_acc: 71.39, f1: 70.65
loss: 0.1846, acc: 89.31, test_acc: 72.54, f1: 71.19
loss: 0.0533, acc: 89.48, test_acc: 73.84, f1: 72.36
loss: 0.3536, acc: 89.55, test_acc: 70.81, f1: 70.42
loss: 0.3404, acc: 89.33, test_acc: 70.38, f1: 69.94
loss: 0.6130, acc: 89.20, test_acc: 73.27, f1: 72.37
loss: 0.3182, acc: 89.18, test_acc: 72.69, f1: 71.53
loss: 0.2822, acc: 89.15, test_acc: 71.97, f1: 70.75
loss: 0.1392, acc: 89.31, test_acc: 72.25, f1: 70.80
loss: 0.1322, acc: 89.38, test_acc: 70.66, f1: 70.50
loss: 0.2137, acc: 89.44, test_acc: 71.82, f1: 71.01
loss: 0.0965, acc: 89.58, test_acc: 73.41, f1: 71.88
loss: 0.3250, acc: 89.64, test_acc: 74.13, f1: 72.86
loss: 0.4292, acc: 89.61, test_acc: 73.55, f1: 73.06
loss: 0.2111, acc: 89.58, test_acc: 69.94, f1: 69.33
loss: 0.1137, acc: 89.72, test_acc: 71.39, f1: 70.09
loss: 0.3564, acc: 89.61, test_acc: 71.97, f1: 71.14
loss: 0.5417, acc: 89.50, test_acc: 65.90, f1: 66.35
####################################################################################################
max_test_acc_overall:77.16763005780348
max_f1_overall:76.38610357437771
####################################################################################################
1 test_acc_overall: 77.17  f1_overall:76.12
2 test_acc_overall: 77.17  f1_overall:76.39
max_acc_overall:77.17  f1_overall:76.12
mean_acc_overall:77.17  mean_f1_overall:76.25
####################################################################################################
lcf_bert - twitter - cdw - No.3 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:1
>>> seed: 2
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc50.0
max_acc:50.0  f1:22.22
loss: 0.9981, acc: 43.75, test_acc: 50.00, f1: 22.22
loss: 1.0679, acc: 56.25, test_acc: 50.00, f1: 22.22
loss: 1.1901, acc: 45.83, test_acc: 25.00, f1: 13.48
loss: 1.0626, acc: 45.31, test_acc: 50.00, f1: 22.22
loss: 0.9472, acc: 47.50, test_acc: 50.00, f1: 22.58
loss: 1.0581, acc: 46.88, test_acc: 46.24, f1: 43.73
>> saved: state_dict/lcf_bert_twitter_acc50.87
max_acc:50.87  f1:26.77
loss: 0.9802, acc: 49.11, test_acc: 50.87, f1: 26.77
loss: 1.0976, acc: 48.44, test_acc: 50.14, f1: 22.63
loss: 1.0622, acc: 47.92, test_acc: 46.10, f1: 35.29
>> saved: state_dict/lcf_bert_twitter_acc54.77
max_acc:54.77  f1:36.56
loss: 1.0858, acc: 46.25, test_acc: 54.77, f1: 36.56
>> saved: state_dict/lcf_bert_twitter_acc55.2
max_acc:55.2  f1:37.47
loss: 0.9424, acc: 46.59, test_acc: 55.20, f1: 37.47
loss: 1.0452, acc: 46.88, test_acc: 53.76, f1: 36.90
loss: 1.0431, acc: 46.15, test_acc: 54.91, f1: 36.16
>> saved: state_dict/lcf_bert_twitter_acc61.85
max_acc:61.85  f1:56.96
loss: 0.8929, acc: 46.88, test_acc: 61.85, f1: 56.96
loss: 1.1857, acc: 47.08, test_acc: 53.18, f1: 39.57
loss: 1.0729, acc: 46.88, test_acc: 61.85, f1: 54.66
loss: 0.9799, acc: 47.06, test_acc: 51.01, f1: 51.51
loss: 0.8041, acc: 47.92, test_acc: 57.51, f1: 42.88
loss: 0.8106, acc: 48.36, test_acc: 55.20, f1: 47.07
loss: 0.7502, acc: 49.06, test_acc: 61.56, f1: 60.60
>> saved: state_dict/lcf_bert_twitter_acc65.32
max_acc:65.32  f1:61.47
loss: 1.0434, acc: 49.40, test_acc: 65.32, f1: 61.47
loss: 0.9403, acc: 49.15, test_acc: 61.13, f1: 60.63
loss: 0.6975, acc: 50.27, test_acc: 58.82, f1: 59.69
loss: 0.8049, acc: 51.04, test_acc: 63.73, f1: 61.92
>> saved: state_dict/lcf_bert_twitter_acc68.93
max_acc:68.93  f1:65.4
loss: 0.5713, acc: 51.50, test_acc: 68.93, f1: 65.40
loss: 0.8107, acc: 52.16, test_acc: 68.21, f1: 65.56
loss: 0.7459, acc: 52.55, test_acc: 67.20, f1: 65.53
loss: 0.9109, acc: 52.46, test_acc: 68.35, f1: 67.73
loss: 0.6994, acc: 53.23, test_acc: 65.03, f1: 65.50
loss: 0.4928, acc: 54.17, test_acc: 68.50, f1: 65.03
loss: 0.7680, acc: 54.44, test_acc: 66.33, f1: 58.81
loss: 0.5762, acc: 55.27, test_acc: 67.63, f1: 65.98
loss: 0.8794, acc: 55.49, test_acc: 66.47, f1: 63.82
loss: 0.2544, acc: 56.43, test_acc: 60.84, f1: 59.83
loss: 0.7846, acc: 56.25, test_acc: 68.93, f1: 67.59
loss: 0.8491, acc: 56.60, test_acc: 66.04, f1: 63.62
>> saved: state_dict/lcf_bert_twitter_acc70.23
max_acc:70.23  f1:68.64
loss: 0.8483, acc: 56.42, test_acc: 70.23, f1: 68.64
loss: 0.6942, acc: 56.91, test_acc: 64.74, f1: 65.25
>> saved: state_dict/lcf_bert_twitter_acc70.95
max_acc:70.95  f1:68.16
loss: 0.7567, acc: 57.05, test_acc: 70.95, f1: 68.16
loss: 0.5944, acc: 57.81, test_acc: 70.52, f1: 69.54
loss: 0.8176, acc: 57.62, test_acc: 68.21, f1: 68.11
loss: 0.5675, acc: 58.04, test_acc: 69.08, f1: 66.76
loss: 1.2059, acc: 58.14, test_acc: 68.35, f1: 64.26
loss: 0.8343, acc: 58.10, test_acc: 66.76, f1: 66.73
>> saved: state_dict/lcf_bert_twitter_acc73.27
max_acc:73.27  f1:72.37
loss: 0.6351, acc: 58.47, test_acc: 73.27, f1: 72.37
loss: 0.7967, acc: 58.83, test_acc: 71.68, f1: 70.83
loss: 0.9616, acc: 58.64, test_acc: 69.65, f1: 67.10
loss: 0.7550, acc: 58.72, test_acc: 68.06, f1: 64.09
loss: 0.5391, acc: 59.18, test_acc: 70.38, f1: 69.67
loss: 0.4304, acc: 59.75, test_acc: 72.11, f1: 71.02
loss: 0.5968, acc: 60.17, test_acc: 71.24, f1: 70.20
loss: 0.7600, acc: 60.34, test_acc: 72.98, f1: 72.24
loss: 0.4838, acc: 60.73, test_acc: 70.09, f1: 67.10
loss: 0.5991, acc: 60.76, test_acc: 72.40, f1: 70.58
loss: 0.6634, acc: 61.02, test_acc: 72.69, f1: 71.49
loss: 0.8707, acc: 60.83, test_acc: 71.10, f1: 68.58
loss: 0.6689, acc: 60.96, test_acc: 71.82, f1: 70.93
loss: 0.6054, acc: 61.31, test_acc: 73.27, f1: 71.65
loss: 0.7217, acc: 61.44, test_acc: 71.24, f1: 68.52
>> saved: state_dict/lcf_bert_twitter_acc73.84
max_acc:73.84  f1:72.65
loss: 0.4847, acc: 61.67, test_acc: 73.84, f1: 72.65
loss: 0.6320, acc: 61.89, test_acc: 71.53, f1: 70.89
loss: 0.4932, acc: 62.00, test_acc: 69.80, f1: 69.66
loss: 0.6760, acc: 62.20, test_acc: 72.69, f1: 71.53
loss: 0.5321, acc: 62.40, test_acc: 71.82, f1: 70.99
loss: 0.5838, acc: 62.69, test_acc: 73.84, f1: 72.58
loss: 0.5399, acc: 62.97, test_acc: 72.54, f1: 71.94
loss: 0.5076, acc: 63.34, test_acc: 73.84, f1: 71.66
loss: 0.5414, acc: 63.60, test_acc: 72.69, f1: 71.69
loss: 0.7625, acc: 63.68, test_acc: 70.52, f1: 69.53
loss: 0.7346, acc: 63.75, test_acc: 69.80, f1: 69.73
loss: 0.9597, acc: 63.64, test_acc: 70.38, f1: 70.07
loss: 0.7337, acc: 63.89, test_acc: 70.09, f1: 65.98
loss: 0.4092, acc: 64.21, test_acc: 72.98, f1: 71.44
loss: 0.5261, acc: 64.44, test_acc: 67.34, f1: 67.45
loss: 0.7228, acc: 64.50, test_acc: 65.03, f1: 65.25
loss: 0.7381, acc: 64.47, test_acc: 71.68, f1: 70.15
loss: 0.7241, acc: 64.61, test_acc: 70.23, f1: 68.36
loss: 0.9158, acc: 64.50, test_acc: 72.98, f1: 71.76
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.7351, acc: 68.75, test_acc: 67.63, f1: 67.75
loss: 0.5687, acc: 68.75, test_acc: 73.84, f1: 72.81
loss: 0.6009, acc: 70.83, test_acc: 68.64, f1: 68.77
loss: 0.1664, acc: 78.12, test_acc: 69.80, f1: 70.12
>> saved: state_dict/lcf_bert_twitter_acc74.57
max_acc:74.57  f1:72.98
loss: 0.3985, acc: 78.75, test_acc: 74.57, f1: 72.98
loss: 0.3874, acc: 80.21, test_acc: 74.42, f1: 71.68
loss: 0.1881, acc: 82.14, test_acc: 74.28, f1: 72.47
loss: 0.7303, acc: 81.25, test_acc: 68.93, f1: 69.18
loss: 0.3312, acc: 82.64, test_acc: 71.97, f1: 71.47
loss: 0.3674, acc: 83.12, test_acc: 74.42, f1: 71.31
loss: 0.4270, acc: 82.95, test_acc: 73.84, f1: 71.63
loss: 0.4537, acc: 82.29, test_acc: 70.95, f1: 70.25
loss: 0.4662, acc: 82.21, test_acc: 70.23, f1: 70.13
loss: 0.3195, acc: 82.14, test_acc: 73.84, f1: 72.36
loss: 0.5535, acc: 81.67, test_acc: 73.12, f1: 72.04
loss: 0.4540, acc: 81.64, test_acc: 70.52, f1: 70.02
loss: 0.7853, acc: 80.15, test_acc: 73.99, f1: 72.42
loss: 0.2741, acc: 80.56, test_acc: 71.10, f1: 70.26
loss: 0.8904, acc: 79.93, test_acc: 70.09, f1: 70.18
loss: 0.6184, acc: 79.69, test_acc: 68.50, f1: 68.67
loss: 0.3913, acc: 80.06, test_acc: 73.99, f1: 72.02
loss: 0.5697, acc: 80.11, test_acc: 71.82, f1: 70.85
loss: 0.5562, acc: 79.89, test_acc: 71.68, f1: 71.15
loss: 0.2382, acc: 80.73, test_acc: 71.82, f1: 71.21
loss: 0.6047, acc: 80.50, test_acc: 69.65, f1: 69.36
loss: 0.4088, acc: 80.77, test_acc: 73.84, f1: 72.18
loss: 0.3670, acc: 81.25, test_acc: 72.40, f1: 71.81
loss: 0.1590, acc: 81.92, test_acc: 70.66, f1: 70.44
loss: 0.3624, acc: 82.11, test_acc: 72.25, f1: 71.53
loss: 0.2697, acc: 82.29, test_acc: 72.25, f1: 70.97
loss: 0.5525, acc: 82.06, test_acc: 71.39, f1: 71.03
loss: 0.3484, acc: 82.23, test_acc: 69.65, f1: 69.53
loss: 0.6924, acc: 81.82, test_acc: 71.53, f1: 69.65
loss: 0.6247, acc: 81.43, test_acc: 72.69, f1: 72.09
loss: 0.4564, acc: 81.25, test_acc: 65.75, f1: 66.10
loss: 0.8470, acc: 80.90, test_acc: 73.99, f1: 72.43
loss: 0.3528, acc: 80.91, test_acc: 71.68, f1: 67.73
loss: 0.6222, acc: 80.92, test_acc: 71.68, f1: 70.83
loss: 0.8969, acc: 80.29, test_acc: 69.36, f1: 69.36
loss: 0.5010, acc: 80.31, test_acc: 72.98, f1: 72.02
>> saved: state_dict/lcf_bert_twitter_acc74.71
max_acc:74.71  f1:73.04
loss: 0.6173, acc: 79.88, test_acc: 74.71, f1: 73.04
loss: 0.4336, acc: 80.06, test_acc: 73.70, f1: 72.88
loss: 0.6390, acc: 79.80, test_acc: 71.68, f1: 71.69
loss: 0.2825, acc: 79.97, test_acc: 74.57, f1: 73.35
loss: 0.4503, acc: 80.14, test_acc: 73.12, f1: 71.16
loss: 0.4189, acc: 80.30, test_acc: 74.71, f1: 73.34
loss: 0.5259, acc: 80.05, test_acc: 74.28, f1: 73.33
loss: 0.5591, acc: 80.08, test_acc: 73.84, f1: 72.79
loss: 0.1557, acc: 80.48, test_acc: 73.41, f1: 72.15
loss: 0.3317, acc: 80.62, test_acc: 72.40, f1: 71.86
loss: 0.2391, acc: 81.00, test_acc: 72.98, f1: 72.12
loss: 0.3354, acc: 81.13, test_acc: 73.70, f1: 71.95
loss: 0.3645, acc: 81.25, test_acc: 73.27, f1: 72.25
loss: 0.3552, acc: 81.37, test_acc: 71.53, f1: 71.12
loss: 0.7408, acc: 81.48, test_acc: 72.98, f1: 71.32
loss: 0.1485, acc: 81.81, test_acc: 73.41, f1: 71.92
loss: 0.6045, acc: 81.69, test_acc: 70.23, f1: 70.12
loss: 0.2622, acc: 81.90, test_acc: 73.70, f1: 72.13
loss: 0.8432, acc: 81.67, test_acc: 73.12, f1: 70.73
loss: 0.4300, acc: 81.67, test_acc: 72.54, f1: 72.36
loss: 0.8357, acc: 81.35, test_acc: 69.65, f1: 69.89
loss: 0.6188, acc: 81.25, test_acc: 74.28, f1: 72.60
>> saved: state_dict/lcf_bert_twitter_acc75.0
max_acc:75.0  f1:73.73
loss: 0.6957, acc: 81.15, test_acc: 75.00, f1: 73.73
loss: 0.2960, acc: 81.35, test_acc: 74.57, f1: 73.59
loss: 0.5427, acc: 81.25, test_acc: 74.71, f1: 73.44
loss: 0.5166, acc: 81.16, test_acc: 73.55, f1: 72.80
loss: 0.3900, acc: 81.25, test_acc: 75.00, f1: 73.52
loss: 0.5411, acc: 81.34, test_acc: 74.86, f1: 72.79
>> saved: state_dict/lcf_bert_twitter_acc75.14
max_acc:75.14  f1:73.5
loss: 0.2744, acc: 81.52, test_acc: 75.14, f1: 73.50
loss: 0.3852, acc: 81.70, test_acc: 70.38, f1: 70.19
loss: 0.3506, acc: 81.78, test_acc: 71.10, f1: 71.11
loss: 0.9404, acc: 81.42, test_acc: 71.97, f1: 70.95
loss: 0.5479, acc: 81.42, test_acc: 73.27, f1: 72.25
loss: 0.3685, acc: 81.59, test_acc: 72.83, f1: 72.16
loss: 0.2841, acc: 81.75, test_acc: 70.95, f1: 70.80
loss: 0.4309, acc: 81.83, test_acc: 72.69, f1: 71.89
>> saved: state_dict/lcf_bert_twitter_acc75.29
max_acc:75.29  f1:73.27
loss: 0.4618, acc: 81.82, test_acc: 75.29, f1: 73.27
loss: 0.2350, acc: 81.97, test_acc: 73.41, f1: 72.38
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2284, acc: 100.00, test_acc: 74.42, f1: 73.60
loss: 0.1095, acc: 100.00, test_acc: 74.42, f1: 73.28
loss: 0.3704, acc: 95.83, test_acc: 74.13, f1: 73.65
loss: 0.3689, acc: 93.75, test_acc: 74.13, f1: 73.75
loss: 0.3021, acc: 92.50, test_acc: 74.71, f1: 74.20
loss: 0.1793, acc: 92.71, test_acc: 73.99, f1: 73.22
loss: 0.3969, acc: 91.96, test_acc: 73.41, f1: 72.49
loss: 0.1331, acc: 92.19, test_acc: 74.13, f1: 73.04
loss: 0.1096, acc: 93.06, test_acc: 72.11, f1: 71.66
loss: 0.3251, acc: 93.12, test_acc: 67.77, f1: 68.21
loss: 0.0867, acc: 93.75, test_acc: 74.86, f1: 73.06
loss: 0.3183, acc: 93.23, test_acc: 73.55, f1: 72.23
loss: 0.1210, acc: 93.75, test_acc: 71.39, f1: 70.93
loss: 0.2283, acc: 93.75, test_acc: 70.52, f1: 70.62
loss: 0.2333, acc: 93.75, test_acc: 70.95, f1: 70.67
loss: 0.1008, acc: 94.14, test_acc: 72.98, f1: 71.64
loss: 0.0741, acc: 94.49, test_acc: 72.69, f1: 71.25
loss: 0.2545, acc: 93.75, test_acc: 70.81, f1: 70.63
loss: 0.1989, acc: 93.75, test_acc: 70.38, f1: 70.36
loss: 0.2160, acc: 93.44, test_acc: 71.82, f1: 71.70
loss: 0.1601, acc: 93.45, test_acc: 73.55, f1: 71.98
loss: 0.1842, acc: 93.18, test_acc: 73.41, f1: 71.45
loss: 0.3821, acc: 92.39, test_acc: 67.92, f1: 68.06
loss: 0.4325, acc: 92.45, test_acc: 70.38, f1: 70.15
loss: 0.4048, acc: 92.25, test_acc: 72.40, f1: 69.23
loss: 0.6151, acc: 91.59, test_acc: 72.98, f1: 71.80
loss: 0.5242, acc: 91.44, test_acc: 72.40, f1: 71.60
loss: 0.1294, acc: 91.52, test_acc: 73.99, f1: 71.56
loss: 0.1405, acc: 91.59, test_acc: 72.83, f1: 71.21
loss: 0.3805, acc: 91.46, test_acc: 73.55, f1: 72.26
loss: 0.1015, acc: 91.73, test_acc: 73.27, f1: 72.49
loss: 0.1074, acc: 91.99, test_acc: 71.68, f1: 71.48
loss: 0.2700, acc: 91.86, test_acc: 74.13, f1: 72.57
loss: 0.1816, acc: 91.73, test_acc: 73.99, f1: 72.60
loss: 0.4840, acc: 91.07, test_acc: 74.57, f1: 73.32
loss: 0.1004, acc: 91.32, test_acc: 71.10, f1: 70.36
loss: 0.2044, acc: 91.39, test_acc: 71.68, f1: 71.21
loss: 0.1774, acc: 91.45, test_acc: 71.82, f1: 71.31
loss: 0.2187, acc: 91.51, test_acc: 74.13, f1: 72.81
loss: 0.4248, acc: 91.56, test_acc: 74.13, f1: 72.84
loss: 0.2333, acc: 91.46, test_acc: 73.55, f1: 72.05
loss: 0.1838, acc: 91.52, test_acc: 73.12, f1: 71.73
loss: 0.7350, acc: 90.99, test_acc: 73.70, f1: 72.36
loss: 0.5705, acc: 91.05, test_acc: 72.69, f1: 71.99
loss: 0.3666, acc: 91.11, test_acc: 73.41, f1: 72.06
loss: 0.0887, acc: 91.17, test_acc: 71.39, f1: 71.11
loss: 0.5889, acc: 90.69, test_acc: 71.68, f1: 71.15
loss: 0.4220, acc: 90.23, test_acc: 73.70, f1: 71.08
loss: 0.1771, acc: 90.31, test_acc: 73.41, f1: 72.40
loss: 0.2571, acc: 90.12, test_acc: 70.09, f1: 69.86
loss: 0.2052, acc: 90.07, test_acc: 71.24, f1: 70.62
loss: 0.5795, acc: 89.90, test_acc: 74.57, f1: 73.06
loss: 0.5665, acc: 89.74, test_acc: 72.40, f1: 71.48
loss: 0.0916, acc: 89.93, test_acc: 71.39, f1: 70.89
loss: 0.2713, acc: 89.89, test_acc: 73.55, f1: 72.67
loss: 0.1519, acc: 89.96, test_acc: 74.13, f1: 73.01
loss: 0.2794, acc: 90.02, test_acc: 72.25, f1: 71.47
loss: 0.2849, acc: 89.98, test_acc: 71.68, f1: 70.97
loss: 0.3534, acc: 89.94, test_acc: 73.27, f1: 70.78
loss: 0.3639, acc: 89.79, test_acc: 71.97, f1: 70.15
loss: 0.4144, acc: 89.75, test_acc: 71.39, f1: 70.31
loss: 0.3779, acc: 89.62, test_acc: 69.36, f1: 68.68
loss: 0.3453, acc: 89.48, test_acc: 69.22, f1: 69.11
loss: 0.1964, acc: 89.55, test_acc: 72.11, f1: 70.81
loss: 0.6750, acc: 89.42, test_acc: 71.39, f1: 68.67
loss: 0.0764, acc: 89.58, test_acc: 72.54, f1: 71.64
loss: 0.6266, acc: 89.37, test_acc: 70.66, f1: 69.97
loss: 0.2747, acc: 89.43, test_acc: 71.97, f1: 70.95
loss: 0.0522, acc: 89.58, test_acc: 74.13, f1: 72.75
loss: 0.2897, acc: 89.55, test_acc: 73.27, f1: 71.81
loss: 0.6507, acc: 89.44, test_acc: 72.83, f1: 71.30
loss: 0.5030, acc: 89.50, test_acc: 70.66, f1: 69.72
loss: 0.1334, acc: 89.64, test_acc: 73.41, f1: 72.31
loss: 0.2954, acc: 89.61, test_acc: 71.39, f1: 69.58
loss: 0.1983, acc: 89.67, test_acc: 71.82, f1: 70.68
loss: 0.0985, acc: 89.80, test_acc: 72.25, f1: 71.76
loss: 0.2306, acc: 89.85, test_acc: 72.40, f1: 71.82
loss: 0.1250, acc: 89.98, test_acc: 73.27, f1: 71.79
####################################################################################################
max_test_acc_overall:75.28901734104046
max_f1_overall:74.20155781926651
####################################################################################################
1 test_acc_overall: 77.17  f1_overall:76.12
2 test_acc_overall: 77.17  f1_overall:76.39
3 test_acc_overall: 75.29  f1_overall:74.2
max_acc_overall:77.17  f1_overall:76.12
mean_acc_overall:76.54  mean_f1_overall:75.57
####################################################################################################
lcf_bert - twitter - cdw - No.4 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:1
>>> seed: 3
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc36.85
max_acc:36.85  f1:27.57
loss: 1.1993, acc: 37.50, test_acc: 36.85, f1: 27.57
>> saved: state_dict/lcf_bert_twitter_acc50.0
max_acc:50.0  f1:22.22
loss: 0.8850, acc: 46.88, test_acc: 50.00, f1: 22.22
loss: 1.1712, acc: 47.92, test_acc: 50.00, f1: 22.22
loss: 0.8630, acc: 51.56, test_acc: 50.00, f1: 22.22
loss: 0.9463, acc: 47.50, test_acc: 26.16, f1: 15.13
loss: 0.9026, acc: 50.00, test_acc: 49.86, f1: 34.76
>> saved: state_dict/lcf_bert_twitter_acc51.3
max_acc:51.3  f1:27.75
loss: 0.9715, acc: 50.89, test_acc: 51.30, f1: 27.75
loss: 1.1363, acc: 51.56, test_acc: 50.14, f1: 22.63
>> saved: state_dict/lcf_bert_twitter_acc53.18
max_acc:53.18  f1:37.61
loss: 1.0185, acc: 50.69, test_acc: 53.18, f1: 37.61
loss: 1.0140, acc: 50.62, test_acc: 52.02, f1: 30.03
loss: 0.9937, acc: 50.57, test_acc: 52.17, f1: 28.29
loss: 1.0845, acc: 49.48, test_acc: 46.97, f1: 38.62
>> saved: state_dict/lcf_bert_twitter_acc57.95
max_acc:57.95  f1:46.07
loss: 1.1560, acc: 48.08, test_acc: 57.95, f1: 46.07
>> saved: state_dict/lcf_bert_twitter_acc59.1
max_acc:59.1  f1:49.29
loss: 1.0281, acc: 48.66, test_acc: 59.10, f1: 49.29
loss: 1.3031, acc: 47.92, test_acc: 58.38, f1: 46.89
loss: 0.9067, acc: 48.83, test_acc: 55.64, f1: 56.01
>> saved: state_dict/lcf_bert_twitter_acc64.45
max_acc:64.45  f1:61.64
loss: 0.6603, acc: 50.37, test_acc: 64.45, f1: 61.64
loss: 0.6320, acc: 51.39, test_acc: 61.85, f1: 61.04
loss: 0.9075, acc: 51.97, test_acc: 61.71, f1: 61.97
>> saved: state_dict/lcf_bert_twitter_acc64.74
max_acc:64.74  f1:61.05
loss: 0.8849, acc: 52.50, test_acc: 64.74, f1: 61.05
loss: 0.8725, acc: 52.68, test_acc: 62.43, f1: 62.36
loss: 0.7651, acc: 53.12, test_acc: 56.21, f1: 56.49
loss: 0.8360, acc: 52.99, test_acc: 59.39, f1: 60.04
loss: 1.0023, acc: 53.12, test_acc: 56.50, f1: 42.87
>> saved: state_dict/lcf_bert_twitter_acc64.88
max_acc:64.88  f1:60.73
loss: 0.8047, acc: 53.50, test_acc: 64.88, f1: 60.73
loss: 0.8072, acc: 53.37, test_acc: 64.88, f1: 62.84
loss: 0.4557, acc: 54.17, test_acc: 63.87, f1: 57.34
>> saved: state_dict/lcf_bert_twitter_acc66.76
max_acc:66.76  f1:61.56
loss: 0.8433, acc: 54.24, test_acc: 66.76, f1: 61.56
loss: 1.2130, acc: 54.53, test_acc: 61.56, f1: 61.15
loss: 0.9755, acc: 54.17, test_acc: 60.26, f1: 60.82
>> saved: state_dict/lcf_bert_twitter_acc67.77
max_acc:67.77  f1:63.74
loss: 0.8964, acc: 54.64, test_acc: 67.77, f1: 63.74
>> saved: state_dict/lcf_bert_twitter_acc67.92
max_acc:67.92  f1:63.63
loss: 1.0826, acc: 54.69, test_acc: 67.92, f1: 63.63
loss: 0.5449, acc: 55.49, test_acc: 66.62, f1: 66.16
loss: 0.7067, acc: 55.70, test_acc: 65.46, f1: 65.31
>> saved: state_dict/lcf_bert_twitter_acc69.94
max_acc:69.94  f1:67.28
loss: 0.8499, acc: 55.54, test_acc: 69.94, f1: 67.28
loss: 0.6208, acc: 56.08, test_acc: 69.08, f1: 67.07
loss: 0.7623, acc: 56.42, test_acc: 68.93, f1: 68.05
loss: 0.7698, acc: 56.74, test_acc: 66.33, f1: 66.00
>> saved: state_dict/lcf_bert_twitter_acc70.23
max_acc:70.23  f1:68.24
loss: 0.6613, acc: 57.21, test_acc: 70.23, f1: 68.24
>> saved: state_dict/lcf_bert_twitter_acc71.24
max_acc:71.24  f1:69.56
loss: 0.4380, acc: 57.66, test_acc: 71.24, f1: 69.56
loss: 0.5026, acc: 58.23, test_acc: 67.63, f1: 67.21
loss: 0.5369, acc: 58.48, test_acc: 66.33, f1: 66.47
loss: 0.5381, acc: 59.16, test_acc: 65.90, f1: 66.04
loss: 0.8456, acc: 59.23, test_acc: 71.10, f1: 69.40
loss: 0.7267, acc: 59.44, test_acc: 68.93, f1: 68.09
loss: 0.5411, acc: 59.78, test_acc: 71.10, f1: 70.03
loss: 0.5582, acc: 60.24, test_acc: 70.38, f1: 67.96
loss: 0.9957, acc: 60.16, test_acc: 70.52, f1: 69.76
loss: 0.9070, acc: 60.20, test_acc: 69.51, f1: 69.32
loss: 0.7866, acc: 60.38, test_acc: 70.38, f1: 70.08
loss: 0.8955, acc: 60.42, test_acc: 71.24, f1: 70.07
>> saved: state_dict/lcf_bert_twitter_acc71.68
max_acc:71.68  f1:70.29
loss: 0.9056, acc: 60.46, test_acc: 71.68, f1: 70.29
loss: 0.6721, acc: 60.50, test_acc: 71.10, f1: 70.21
>> saved: state_dict/lcf_bert_twitter_acc71.82
max_acc:71.82  f1:71.12
loss: 0.7490, acc: 60.76, test_acc: 71.82, f1: 71.12
>> saved: state_dict/lcf_bert_twitter_acc72.25
max_acc:72.25  f1:71.03
loss: 0.5994, acc: 61.02, test_acc: 72.25, f1: 71.03
loss: 0.5619, acc: 61.27, test_acc: 70.95, f1: 70.00
loss: 0.7490, acc: 61.51, test_acc: 70.38, f1: 66.67
>> saved: state_dict/lcf_bert_twitter_acc72.54
max_acc:72.54  f1:70.57
loss: 0.8875, acc: 61.64, test_acc: 72.54, f1: 70.57
loss: 0.8464, acc: 61.65, test_acc: 69.22, f1: 69.12
loss: 0.7084, acc: 61.88, test_acc: 71.68, f1: 71.15
>> saved: state_dict/lcf_bert_twitter_acc72.69
max_acc:72.69  f1:68.36
loss: 0.5552, acc: 62.19, test_acc: 72.69, f1: 68.36
>> saved: state_dict/lcf_bert_twitter_acc73.84
max_acc:73.84  f1:72.21
loss: 0.8544, acc: 62.30, test_acc: 73.84, f1: 72.21
loss: 0.6208, acc: 62.50, test_acc: 60.69, f1: 61.61
loss: 0.9175, acc: 62.21, test_acc: 71.97, f1: 71.23
loss: 0.5810, acc: 62.40, test_acc: 70.23, f1: 65.82
loss: 0.4331, acc: 62.78, test_acc: 73.27, f1: 71.13
loss: 0.7309, acc: 62.87, test_acc: 73.27, f1: 71.83
loss: 0.4648, acc: 63.05, test_acc: 71.24, f1: 71.15
loss: 0.7733, acc: 63.04, test_acc: 72.40, f1: 72.15
loss: 0.4189, acc: 63.39, test_acc: 73.70, f1: 71.57
loss: 0.9344, acc: 63.29, test_acc: 73.41, f1: 71.63
loss: 0.5198, acc: 63.54, test_acc: 71.68, f1: 70.00
loss: 0.6101, acc: 63.61, test_acc: 73.55, f1: 71.17
>> saved: state_dict/lcf_bert_twitter_acc74.42
max_acc:74.42  f1:72.38
loss: 0.5134, acc: 63.68, test_acc: 74.42, f1: 72.38
loss: 0.5546, acc: 64.00, test_acc: 70.66, f1: 70.72
loss: 0.8873, acc: 63.82, test_acc: 69.94, f1: 70.25
loss: 0.8250, acc: 63.80, test_acc: 72.11, f1: 68.70
loss: 0.4516, acc: 63.94, test_acc: 71.82, f1: 68.48
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.4206, acc: 87.50, test_acc: 70.95, f1: 70.29
loss: 0.4118, acc: 84.38, test_acc: 70.23, f1: 69.79
loss: 0.6774, acc: 81.25, test_acc: 69.51, f1: 68.16
loss: 0.4122, acc: 79.69, test_acc: 70.95, f1: 69.55
loss: 0.3793, acc: 82.50, test_acc: 71.68, f1: 70.19
loss: 0.1862, acc: 84.38, test_acc: 72.25, f1: 71.19
loss: 0.2204, acc: 85.71, test_acc: 73.70, f1: 73.00
loss: 0.3472, acc: 85.94, test_acc: 72.98, f1: 72.47
loss: 0.2293, acc: 86.81, test_acc: 72.69, f1: 72.02
>> saved: state_dict/lcf_bert_twitter_acc74.57
max_acc:74.57  f1:73.69
loss: 0.6398, acc: 85.00, test_acc: 74.57, f1: 73.69
loss: 0.3403, acc: 85.23, test_acc: 70.52, f1: 70.54
loss: 0.4027, acc: 84.90, test_acc: 72.69, f1: 72.37
loss: 0.8113, acc: 84.13, test_acc: 74.13, f1: 73.06
loss: 0.4449, acc: 83.93, test_acc: 70.81, f1: 70.67
loss: 0.5702, acc: 83.33, test_acc: 69.80, f1: 70.05
loss: 0.4740, acc: 83.20, test_acc: 72.69, f1: 72.03
loss: 0.3726, acc: 82.72, test_acc: 73.99, f1: 72.04
loss: 0.6161, acc: 81.94, test_acc: 72.40, f1: 71.93
loss: 0.2379, acc: 82.57, test_acc: 72.11, f1: 71.80
loss: 0.7100, acc: 81.56, test_acc: 73.27, f1: 72.26
loss: 0.3137, acc: 81.55, test_acc: 73.12, f1: 72.67
loss: 0.7979, acc: 80.97, test_acc: 74.42, f1: 72.61
loss: 0.5931, acc: 80.98, test_acc: 74.42, f1: 73.17
loss: 0.1951, acc: 81.77, test_acc: 74.28, f1: 73.10
loss: 0.3099, acc: 82.25, test_acc: 67.92, f1: 68.05
loss: 0.3630, acc: 82.21, test_acc: 71.53, f1: 70.97
loss: 0.7166, acc: 81.71, test_acc: 72.11, f1: 71.91
loss: 0.4348, acc: 81.70, test_acc: 73.55, f1: 72.33
loss: 0.3366, acc: 81.90, test_acc: 73.27, f1: 70.08
>> saved: state_dict/lcf_bert_twitter_acc75.14
max_acc:75.14  f1:73.59
loss: 0.3089, acc: 82.29, test_acc: 75.14, f1: 73.59
loss: 0.6453, acc: 82.06, test_acc: 67.05, f1: 67.41
loss: 0.2888, acc: 82.23, test_acc: 71.68, f1: 70.83
loss: 0.6283, acc: 81.82, test_acc: 72.98, f1: 69.99
loss: 0.5220, acc: 81.80, test_acc: 70.66, f1: 69.03
loss: 0.3654, acc: 81.79, test_acc: 72.98, f1: 72.37
loss: 0.5392, acc: 81.94, test_acc: 72.54, f1: 71.61
loss: 0.1810, acc: 82.26, test_acc: 75.14, f1: 73.22
loss: 0.6224, acc: 82.07, test_acc: 73.70, f1: 73.13
loss: 0.7467, acc: 81.89, test_acc: 74.28, f1: 73.08
loss: 0.3863, acc: 82.03, test_acc: 74.13, f1: 72.59
loss: 0.6611, acc: 82.01, test_acc: 73.70, f1: 72.96
loss: 0.5121, acc: 82.14, test_acc: 71.24, f1: 70.89
loss: 0.5894, acc: 81.69, test_acc: 73.41, f1: 72.19
loss: 0.6605, acc: 81.25, test_acc: 69.94, f1: 69.58
loss: 0.5047, acc: 81.39, test_acc: 71.82, f1: 71.22
loss: 0.3712, acc: 81.52, test_acc: 72.54, f1: 71.07
loss: 0.3410, acc: 81.65, test_acc: 73.41, f1: 72.26
loss: 0.2670, acc: 81.77, test_acc: 70.09, f1: 69.41
loss: 0.6137, acc: 81.51, test_acc: 71.10, f1: 70.66
loss: 0.6321, acc: 81.38, test_acc: 71.24, f1: 69.66
loss: 0.5562, acc: 81.37, test_acc: 72.11, f1: 70.83
loss: 1.0305, acc: 80.77, test_acc: 68.35, f1: 68.29
loss: 0.5160, acc: 80.66, test_acc: 73.55, f1: 71.56
loss: 0.3982, acc: 80.79, test_acc: 72.69, f1: 70.43
loss: 0.5884, acc: 80.68, test_acc: 72.54, f1: 70.52
loss: 1.0319, acc: 80.25, test_acc: 68.64, f1: 67.92
loss: 0.4209, acc: 80.37, test_acc: 71.53, f1: 70.60
loss: 0.3377, acc: 80.50, test_acc: 71.97, f1: 71.00
loss: 0.3180, acc: 80.51, test_acc: 73.12, f1: 71.82
loss: 0.7740, acc: 80.42, test_acc: 73.99, f1: 72.13
loss: 0.8005, acc: 80.12, test_acc: 71.53, f1: 70.97
loss: 0.6145, acc: 80.14, test_acc: 72.25, f1: 71.50
loss: 0.4578, acc: 79.96, test_acc: 73.12, f1: 71.60
loss: 0.6547, acc: 79.79, test_acc: 71.39, f1: 70.80
loss: 0.5371, acc: 79.71, test_acc: 67.77, f1: 67.70
loss: 0.4296, acc: 79.73, test_acc: 69.80, f1: 69.29
loss: 0.7176, acc: 79.57, test_acc: 73.55, f1: 70.54
loss: 0.5371, acc: 79.69, test_acc: 73.84, f1: 72.44
loss: 0.6518, acc: 79.53, test_acc: 66.91, f1: 67.26
loss: 0.3562, acc: 79.55, test_acc: 71.97, f1: 71.45
>> saved: state_dict/lcf_bert_twitter_acc75.43
max_acc:75.43  f1:73.6
loss: 0.4083, acc: 79.49, test_acc: 75.43, f1: 73.60
>> saved: state_dict/lcf_bert_twitter_acc75.72
max_acc:75.72  f1:73.56
loss: 0.3989, acc: 79.60, test_acc: 75.72, f1: 73.56
loss: 0.4326, acc: 79.54, test_acc: 70.23, f1: 70.05
loss: 0.3294, acc: 79.65, test_acc: 73.99, f1: 72.73
loss: 0.7053, acc: 79.50, test_acc: 75.14, f1: 73.04
loss: 0.5217, acc: 79.52, test_acc: 71.97, f1: 71.25
loss: 0.4812, acc: 79.38, test_acc: 71.82, f1: 71.68
loss: 0.5223, acc: 79.25, test_acc: 68.06, f1: 68.05
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.6292, acc: 75.00, test_acc: 72.11, f1: 70.29
loss: 0.3543, acc: 81.25, test_acc: 73.55, f1: 72.20
loss: 0.2580, acc: 85.42, test_acc: 70.66, f1: 70.18
loss: 0.1788, acc: 87.50, test_acc: 72.54, f1: 71.47
loss: 0.1137, acc: 90.00, test_acc: 73.99, f1: 72.11
loss: 0.1001, acc: 90.62, test_acc: 73.27, f1: 71.82
loss: 0.1575, acc: 91.07, test_acc: 71.97, f1: 71.28
loss: 0.2038, acc: 91.41, test_acc: 73.70, f1: 72.72
loss: 0.4693, acc: 90.97, test_acc: 71.97, f1: 71.87
loss: 0.2537, acc: 90.62, test_acc: 75.00, f1: 74.16
loss: 0.1940, acc: 90.34, test_acc: 72.98, f1: 69.68
loss: 0.1929, acc: 90.62, test_acc: 73.27, f1: 72.95
loss: 0.2357, acc: 90.38, test_acc: 69.65, f1: 69.55
loss: 0.1872, acc: 90.62, test_acc: 74.42, f1: 71.99
loss: 0.1036, acc: 91.25, test_acc: 72.25, f1: 71.41
loss: 0.2270, acc: 91.02, test_acc: 70.23, f1: 70.54
loss: 0.3007, acc: 91.18, test_acc: 73.41, f1: 72.03
loss: 0.1657, acc: 91.32, test_acc: 73.70, f1: 70.57
loss: 0.2092, acc: 91.45, test_acc: 73.41, f1: 72.23
loss: 0.2388, acc: 91.25, test_acc: 71.10, f1: 70.55
loss: 0.1148, acc: 91.67, test_acc: 72.11, f1: 71.28
loss: 0.2685, acc: 91.76, test_acc: 71.53, f1: 70.86
loss: 0.2076, acc: 91.58, test_acc: 71.10, f1: 70.85
loss: 0.1826, acc: 91.67, test_acc: 70.09, f1: 70.03
loss: 0.2113, acc: 91.50, test_acc: 73.70, f1: 72.43
loss: 0.0750, acc: 91.83, test_acc: 72.25, f1: 71.67
loss: 0.1723, acc: 91.90, test_acc: 69.94, f1: 69.68
loss: 0.2350, acc: 91.74, test_acc: 70.81, f1: 70.35
loss: 0.1088, acc: 92.03, test_acc: 73.41, f1: 72.56
loss: 0.1773, acc: 92.08, test_acc: 73.99, f1: 72.53
loss: 0.3275, acc: 92.14, test_acc: 72.40, f1: 71.83
loss: 0.4920, acc: 91.60, test_acc: 69.08, f1: 69.16
loss: 0.1706, acc: 91.48, test_acc: 70.66, f1: 68.88
loss: 0.2033, acc: 91.36, test_acc: 74.57, f1: 73.49
loss: 0.1696, acc: 91.43, test_acc: 71.53, f1: 71.52
loss: 0.1426, acc: 91.49, test_acc: 72.98, f1: 72.42
loss: 0.0763, acc: 91.72, test_acc: 74.71, f1: 73.15
loss: 0.4227, acc: 91.61, test_acc: 71.53, f1: 70.90
loss: 0.0985, acc: 91.67, test_acc: 72.40, f1: 72.08
loss: 0.2595, acc: 91.56, test_acc: 73.84, f1: 72.90
loss: 0.2223, acc: 91.46, test_acc: 74.86, f1: 73.12
loss: 0.1959, acc: 91.37, test_acc: 72.54, f1: 72.01
loss: 0.5054, acc: 90.99, test_acc: 71.68, f1: 71.35
loss: 0.4351, acc: 90.77, test_acc: 73.70, f1: 72.83
loss: 0.2666, acc: 90.56, test_acc: 73.84, f1: 72.53
loss: 0.3306, acc: 90.35, test_acc: 66.91, f1: 67.27
loss: 0.2346, acc: 90.29, test_acc: 68.79, f1: 68.16
loss: 0.1857, acc: 90.36, test_acc: 71.68, f1: 67.88
loss: 0.3895, acc: 90.05, test_acc: 72.83, f1: 69.65
loss: 0.1153, acc: 90.25, test_acc: 69.51, f1: 69.68
loss: 0.3105, acc: 90.20, test_acc: 71.39, f1: 70.96
loss: 0.3007, acc: 90.26, test_acc: 73.12, f1: 70.44
loss: 0.1400, acc: 90.33, test_acc: 72.83, f1: 70.34
loss: 0.3230, acc: 90.28, test_acc: 71.53, f1: 71.16
loss: 0.5405, acc: 90.23, test_acc: 65.32, f1: 66.05
loss: 0.2017, acc: 90.18, test_acc: 73.12, f1: 71.76
loss: 0.2609, acc: 90.24, test_acc: 73.27, f1: 71.41
loss: 0.2151, acc: 90.30, test_acc: 70.95, f1: 71.01
loss: 0.5014, acc: 90.15, test_acc: 69.80, f1: 70.05
loss: 0.2966, acc: 90.00, test_acc: 72.40, f1: 71.27
loss: 0.6669, acc: 89.65, test_acc: 72.98, f1: 71.45
loss: 0.3054, acc: 89.62, test_acc: 72.54, f1: 71.79
loss: 0.2183, acc: 89.68, test_acc: 70.38, f1: 70.60
loss: 0.3563, acc: 89.75, test_acc: 72.40, f1: 71.70
loss: 0.5624, acc: 89.62, test_acc: 71.68, f1: 70.21
loss: 0.3389, acc: 89.58, test_acc: 72.98, f1: 71.06
loss: 0.2099, acc: 89.65, test_acc: 72.40, f1: 71.50
loss: 0.3320, acc: 89.71, test_acc: 71.97, f1: 71.76
loss: 0.1344, acc: 89.76, test_acc: 72.54, f1: 71.79
loss: 0.1983, acc: 89.82, test_acc: 73.27, f1: 72.41
loss: 0.2035, acc: 89.88, test_acc: 70.81, f1: 70.38
loss: 0.0986, acc: 90.02, test_acc: 71.10, f1: 70.70
loss: 0.1805, acc: 90.07, test_acc: 71.10, f1: 70.70
loss: 0.3196, acc: 90.03, test_acc: 73.27, f1: 71.81
loss: 0.2611, acc: 90.08, test_acc: 71.82, f1: 70.21
loss: 0.4949, acc: 90.05, test_acc: 72.69, f1: 72.04
loss: 0.1345, acc: 90.10, test_acc: 72.40, f1: 71.91
loss: 0.1569, acc: 90.14, test_acc: 70.81, f1: 70.58
####################################################################################################
max_test_acc_overall:75.72254335260115
max_f1_overall:74.16082121471342
####################################################################################################
1 test_acc_overall: 77.17  f1_overall:76.12
2 test_acc_overall: 77.17  f1_overall:76.39
3 test_acc_overall: 75.29  f1_overall:74.2
4 test_acc_overall: 75.72  f1_overall:74.16
max_acc_overall:77.17  f1_overall:76.12
mean_acc_overall:76.34  mean_f1_overall:75.22
####################################################################################################
lcf_bert - twitter - cdw - No.5 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: cdw
>>> device: cuda:1
>>> seed: 4
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc29.19
max_acc:29.19  f1:21.57
loss: 1.3552, acc: 31.25, test_acc: 29.19, f1: 21.57
>> saved: state_dict/lcf_bert_twitter_acc49.13
max_acc:49.13  f1:28.92
loss: 0.9514, acc: 43.75, test_acc: 49.13, f1: 28.92
>> saved: state_dict/lcf_bert_twitter_acc50.0
max_acc:50.0  f1:22.22
loss: 1.2198, acc: 47.92, test_acc: 50.00, f1: 22.22
loss: 1.1104, acc: 48.44, test_acc: 48.41, f1: 33.33
>> saved: state_dict/lcf_bert_twitter_acc51.59
max_acc:51.59  f1:27.05
loss: 1.1004, acc: 50.00, test_acc: 51.59, f1: 27.05
loss: 0.7047, acc: 53.12, test_acc: 51.59, f1: 27.02
loss: 1.1572, acc: 52.68, test_acc: 50.72, f1: 24.20
loss: 1.1160, acc: 49.22, test_acc: 25.58, f1: 14.44
loss: 0.9515, acc: 49.31, test_acc: 50.14, f1: 22.63
>> saved: state_dict/lcf_bert_twitter_acc54.48
max_acc:54.48  f1:34.71
loss: 1.2171, acc: 48.12, test_acc: 54.48, f1: 34.71
loss: 0.9984, acc: 47.16, test_acc: 46.82, f1: 46.68
>> saved: state_dict/lcf_bert_twitter_acc55.2
max_acc:55.2  f1:38.69
loss: 0.9653, acc: 45.31, test_acc: 55.20, f1: 38.69
>> saved: state_dict/lcf_bert_twitter_acc57.8
max_acc:57.8  f1:43.94
loss: 0.9038, acc: 47.12, test_acc: 57.80, f1: 43.94
>> saved: state_dict/lcf_bert_twitter_acc58.96
max_acc:58.96  f1:50.91
loss: 1.0673, acc: 46.88, test_acc: 58.96, f1: 50.91
loss: 0.8635, acc: 47.92, test_acc: 55.78, f1: 54.45
loss: 0.8051, acc: 48.83, test_acc: 56.94, f1: 40.74
>> saved: state_dict/lcf_bert_twitter_acc60.12
max_acc:60.12  f1:58.46
loss: 0.4896, acc: 50.74, test_acc: 60.12, f1: 58.46
loss: 0.8753, acc: 51.04, test_acc: 59.97, f1: 59.74
>> saved: state_dict/lcf_bert_twitter_acc65.75
max_acc:65.75  f1:63.18
loss: 0.6004, acc: 51.97, test_acc: 65.75, f1: 63.18
loss: 1.0772, acc: 52.50, test_acc: 61.56, f1: 56.93
loss: 1.1631, acc: 52.08, test_acc: 57.95, f1: 58.43
loss: 1.0790, acc: 52.84, test_acc: 57.66, f1: 50.52
loss: 0.9239, acc: 53.53, test_acc: 63.29, f1: 55.92
loss: 1.0795, acc: 52.86, test_acc: 56.07, f1: 54.05
loss: 1.0478, acc: 52.75, test_acc: 65.46, f1: 62.93
loss: 0.8224, acc: 53.61, test_acc: 65.61, f1: 63.47
loss: 0.7853, acc: 53.94, test_acc: 65.46, f1: 58.42
>> saved: state_dict/lcf_bert_twitter_acc67.49
max_acc:67.49  f1:63.96
loss: 0.9514, acc: 54.02, test_acc: 67.49, f1: 63.96
loss: 0.7486, acc: 54.74, test_acc: 64.02, f1: 63.93
loss: 1.0334, acc: 54.79, test_acc: 60.84, f1: 61.25
>> saved: state_dict/lcf_bert_twitter_acc68.79
max_acc:68.79  f1:64.69
loss: 0.6055, acc: 55.04, test_acc: 68.79, f1: 64.69
>> saved: state_dict/lcf_bert_twitter_acc69.36
max_acc:69.36  f1:67.18
loss: 0.5764, acc: 55.66, test_acc: 69.36, f1: 67.18
loss: 0.8576, acc: 55.87, test_acc: 64.74, f1: 64.57
loss: 0.4897, acc: 56.99, test_acc: 69.36, f1: 67.15
>> saved: state_dict/lcf_bert_twitter_acc69.8
max_acc:69.8  f1:66.14
loss: 0.8589, acc: 57.32, test_acc: 69.80, f1: 66.14
loss: 0.6370, acc: 57.64, test_acc: 68.06, f1: 66.87
loss: 0.6144, acc: 58.45, test_acc: 69.36, f1: 66.88
>> saved: state_dict/lcf_bert_twitter_acc70.23
max_acc:70.23  f1:66.58
loss: 0.9338, acc: 57.89, test_acc: 70.23, f1: 66.58
loss: 1.0360, acc: 58.01, test_acc: 66.47, f1: 65.43
loss: 0.6592, acc: 58.59, test_acc: 68.93, f1: 64.67
>> saved: state_dict/lcf_bert_twitter_acc70.66
max_acc:70.66  f1:68.15
loss: 0.5417, acc: 59.30, test_acc: 70.66, f1: 68.15
loss: 0.8574, acc: 59.23, test_acc: 69.08, f1: 67.83
loss: 0.6056, acc: 59.59, test_acc: 64.16, f1: 61.04
loss: 0.5010, acc: 60.23, test_acc: 67.20, f1: 66.03
loss: 0.5405, acc: 60.42, test_acc: 68.35, f1: 66.46
loss: 0.9640, acc: 60.19, test_acc: 69.22, f1: 67.17
loss: 0.6306, acc: 60.37, test_acc: 65.46, f1: 65.76
loss: 0.7489, acc: 60.68, test_acc: 67.05, f1: 66.88
loss: 0.8872, acc: 60.97, test_acc: 70.52, f1: 69.73
loss: 0.5792, acc: 61.12, test_acc: 70.66, f1: 70.23
loss: 0.9482, acc: 61.03, test_acc: 69.51, f1: 69.24
>> saved: state_dict/lcf_bert_twitter_acc72.4
max_acc:72.4  f1:70.15
loss: 0.7524, acc: 61.06, test_acc: 72.40, f1: 70.15
loss: 1.1750, acc: 60.97, test_acc: 72.11, f1: 69.43
loss: 0.6081, acc: 61.11, test_acc: 70.09, f1: 70.13
loss: 0.7028, acc: 61.36, test_acc: 71.82, f1: 70.87
>> saved: state_dict/lcf_bert_twitter_acc72.69
max_acc:72.69  f1:71.22
loss: 0.5976, acc: 61.72, test_acc: 72.69, f1: 71.22
>> saved: state_dict/lcf_bert_twitter_acc72.98
max_acc:72.98  f1:72.29
loss: 0.7000, acc: 61.95, test_acc: 72.98, f1: 72.29
loss: 0.8606, acc: 62.18, test_acc: 71.68, f1: 70.90
loss: 0.9424, acc: 61.97, test_acc: 71.53, f1: 67.85
loss: 0.9654, acc: 61.88, test_acc: 72.69, f1: 71.64
loss: 1.2396, acc: 61.58, test_acc: 63.73, f1: 64.20
loss: 0.5054, acc: 61.90, test_acc: 71.10, f1: 69.95
loss: 0.5536, acc: 62.10, test_acc: 71.82, f1: 70.65
loss: 0.5361, acc: 62.30, test_acc: 70.66, f1: 70.17
loss: 0.5769, acc: 62.50, test_acc: 67.63, f1: 67.58
>> saved: state_dict/lcf_bert_twitter_acc73.84
max_acc:73.84  f1:72.17
loss: 0.5112, acc: 62.59, test_acc: 73.84, f1: 72.17
loss: 0.7836, acc: 62.59, test_acc: 70.66, f1: 69.50
loss: 0.5714, acc: 62.87, test_acc: 72.40, f1: 70.65
loss: 0.9216, acc: 62.86, test_acc: 68.79, f1: 68.80
loss: 0.4297, acc: 63.21, test_acc: 70.52, f1: 70.34
loss: 1.0162, acc: 63.20, test_acc: 66.91, f1: 66.70
loss: 0.6124, acc: 63.28, test_acc: 73.12, f1: 72.74
loss: 0.8013, acc: 63.36, test_acc: 70.66, f1: 69.11
loss: 0.7438, acc: 63.34, test_acc: 73.27, f1: 72.29
loss: 0.9653, acc: 63.17, test_acc: 72.54, f1: 71.50
loss: 0.8527, acc: 63.32, test_acc: 72.69, f1: 71.41
>> saved: state_dict/lcf_bert_twitter_acc74.86
max_acc:74.86  f1:73.56
loss: 0.6730, acc: 63.56, test_acc: 74.86, f1: 73.56
loss: 0.5252, acc: 63.86, test_acc: 72.54, f1: 71.01
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.8772, acc: 68.75, test_acc: 72.69, f1: 70.54
loss: 0.4346, acc: 78.12, test_acc: 74.28, f1: 73.31
loss: 0.5117, acc: 77.08, test_acc: 69.65, f1: 69.80
loss: 0.3017, acc: 79.69, test_acc: 69.36, f1: 69.16
loss: 0.8134, acc: 78.75, test_acc: 72.40, f1: 71.89
loss: 0.4824, acc: 79.17, test_acc: 72.54, f1: 71.20
loss: 0.1475, acc: 82.14, test_acc: 73.99, f1: 73.15
>> saved: state_dict/lcf_bert_twitter_acc76.01
max_acc:76.01  f1:74.2
loss: 0.3380, acc: 83.59, test_acc: 76.01, f1: 74.20
loss: 0.4547, acc: 84.03, test_acc: 74.42, f1: 73.57
loss: 0.2335, acc: 84.38, test_acc: 74.13, f1: 73.49
loss: 0.2681, acc: 84.66, test_acc: 74.71, f1: 73.48
loss: 0.5505, acc: 84.90, test_acc: 74.13, f1: 72.70
loss: 0.4544, acc: 84.13, test_acc: 72.83, f1: 72.33
loss: 0.2584, acc: 84.82, test_acc: 74.42, f1: 73.29
loss: 0.2844, acc: 85.00, test_acc: 75.29, f1: 73.66
loss: 0.4795, acc: 84.77, test_acc: 72.54, f1: 71.73
loss: 0.3737, acc: 84.56, test_acc: 75.29, f1: 74.30
>> saved: state_dict/lcf_bert_twitter_acc76.16
max_acc:76.16  f1:74.43
loss: 0.3408, acc: 84.72, test_acc: 76.16, f1: 74.43
loss: 0.6871, acc: 83.88, test_acc: 68.79, f1: 69.13
loss: 0.7323, acc: 83.12, test_acc: 74.57, f1: 73.85
loss: 0.4000, acc: 83.33, test_acc: 72.40, f1: 70.61
loss: 0.8616, acc: 82.10, test_acc: 69.80, f1: 69.23
loss: 0.5867, acc: 82.34, test_acc: 70.66, f1: 70.36
loss: 0.2727, acc: 82.55, test_acc: 72.11, f1: 70.46
loss: 0.6505, acc: 82.00, test_acc: 71.68, f1: 71.89
loss: 0.5953, acc: 81.73, test_acc: 72.83, f1: 72.72
loss: 0.5725, acc: 81.48, test_acc: 73.99, f1: 72.42
loss: 0.6391, acc: 80.58, test_acc: 75.72, f1: 74.72
loss: 0.3574, acc: 80.82, test_acc: 73.41, f1: 72.38
loss: 0.4406, acc: 80.83, test_acc: 75.00, f1: 73.95
loss: 0.4615, acc: 80.85, test_acc: 75.00, f1: 73.74
loss: 0.4432, acc: 80.66, test_acc: 74.28, f1: 73.46
>> saved: state_dict/lcf_bert_twitter_acc76.45
max_acc:76.45  f1:75.3
loss: 0.6299, acc: 80.30, test_acc: 76.45, f1: 75.30
loss: 0.3527, acc: 80.51, test_acc: 72.98, f1: 72.51
loss: 0.3003, acc: 80.71, test_acc: 72.98, f1: 72.48
loss: 0.3147, acc: 80.90, test_acc: 73.70, f1: 73.24
loss: 0.3877, acc: 81.08, test_acc: 73.70, f1: 71.88
loss: 0.2100, acc: 81.41, test_acc: 74.28, f1: 73.16
loss: 0.6221, acc: 81.41, test_acc: 70.38, f1: 69.95
loss: 0.3756, acc: 81.41, test_acc: 73.70, f1: 72.75
loss: 0.6909, acc: 81.25, test_acc: 74.42, f1: 72.88
loss: 0.3658, acc: 81.55, test_acc: 69.80, f1: 69.93
loss: 0.4422, acc: 81.69, test_acc: 68.35, f1: 68.01
loss: 0.6387, acc: 81.53, test_acc: 74.86, f1: 73.46
loss: 0.4907, acc: 81.39, test_acc: 70.81, f1: 70.88
loss: 0.5886, acc: 81.25, test_acc: 75.58, f1: 73.82
loss: 0.6735, acc: 80.98, test_acc: 74.42, f1: 72.94
loss: 0.5785, acc: 80.86, test_acc: 71.82, f1: 71.72
loss: 0.4624, acc: 80.99, test_acc: 72.40, f1: 71.83
loss: 0.7175, acc: 81.00, test_acc: 75.14, f1: 73.79
loss: 0.3203, acc: 81.00, test_acc: 75.72, f1: 74.78
loss: 0.6404, acc: 81.01, test_acc: 71.53, f1: 71.53
loss: 0.3738, acc: 81.01, test_acc: 75.87, f1: 75.08
>> saved: state_dict/lcf_bert_twitter_acc76.88
max_acc:76.88  f1:75.57
loss: 0.5534, acc: 80.90, test_acc: 76.88, f1: 75.57
loss: 0.4993, acc: 80.91, test_acc: 70.09, f1: 70.05
loss: 0.4639, acc: 80.92, test_acc: 72.54, f1: 72.33
loss: 0.2894, acc: 81.03, test_acc: 74.71, f1: 73.30
loss: 0.3886, acc: 80.93, test_acc: 75.58, f1: 74.58
loss: 0.1590, acc: 81.14, test_acc: 70.95, f1: 70.82
loss: 0.3436, acc: 81.04, test_acc: 75.58, f1: 74.97
loss: 0.5137, acc: 81.15, test_acc: 75.58, f1: 73.50
loss: 0.2974, acc: 81.25, test_acc: 76.73, f1: 75.25
loss: 0.7878, acc: 80.85, test_acc: 76.73, f1: 75.64
loss: 0.6469, acc: 80.57, test_acc: 76.01, f1: 75.13
loss: 0.3947, acc: 80.67, test_acc: 75.87, f1: 74.64
loss: 0.2519, acc: 80.87, test_acc: 71.68, f1: 71.21
loss: 0.2586, acc: 81.16, test_acc: 70.81, f1: 70.60
loss: 1.1016, acc: 81.07, test_acc: 74.71, f1: 72.23
loss: 0.3845, acc: 81.07, test_acc: 75.43, f1: 73.56
loss: 0.5619, acc: 80.98, test_acc: 72.11, f1: 71.88
loss: 0.6370, acc: 80.90, test_acc: 73.84, f1: 72.68
loss: 0.7302, acc: 80.64, test_acc: 74.28, f1: 73.02
loss: 0.3394, acc: 80.74, test_acc: 73.84, f1: 71.90
loss: 0.4284, acc: 80.91, test_acc: 73.84, f1: 72.98
loss: 0.6702, acc: 80.67, test_acc: 71.10, f1: 71.05
loss: 0.7940, acc: 80.43, test_acc: 76.45, f1: 74.89
loss: 0.9061, acc: 80.28, test_acc: 75.58, f1: 73.55
loss: 0.5347, acc: 80.37, test_acc: 75.00, f1: 72.97
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1472, acc: 100.00, test_acc: 75.00, f1: 73.48
loss: 0.3122, acc: 96.88, test_acc: 74.42, f1: 73.66
loss: 0.3852, acc: 91.67, test_acc: 75.14, f1: 74.70
loss: 0.1613, acc: 92.19, test_acc: 74.86, f1: 74.42
loss: 0.1562, acc: 92.50, test_acc: 74.13, f1: 73.42
loss: 0.1762, acc: 92.71, test_acc: 73.12, f1: 72.49
loss: 0.1664, acc: 92.86, test_acc: 73.12, f1: 72.45
loss: 0.2149, acc: 92.97, test_acc: 72.25, f1: 71.53
loss: 0.0805, acc: 93.75, test_acc: 72.69, f1: 71.95
loss: 0.1103, acc: 94.38, test_acc: 75.00, f1: 73.77
loss: 0.2302, acc: 93.18, test_acc: 74.13, f1: 73.00
loss: 0.3041, acc: 92.71, test_acc: 73.70, f1: 73.23
loss: 0.6146, acc: 91.83, test_acc: 73.55, f1: 73.18
loss: 0.1018, acc: 92.41, test_acc: 75.43, f1: 74.48
loss: 0.1354, acc: 92.92, test_acc: 74.86, f1: 73.38
loss: 0.4806, acc: 92.97, test_acc: 75.29, f1: 74.32
loss: 0.1282, acc: 93.38, test_acc: 72.54, f1: 72.61
loss: 0.2815, acc: 92.71, test_acc: 75.14, f1: 74.27
loss: 0.2228, acc: 92.76, test_acc: 74.42, f1: 72.81
loss: 0.0695, acc: 93.12, test_acc: 74.57, f1: 73.53
loss: 0.3974, acc: 93.15, test_acc: 74.71, f1: 74.05
loss: 0.5421, acc: 92.90, test_acc: 72.83, f1: 71.27
loss: 0.1097, acc: 93.21, test_acc: 73.55, f1: 72.24
loss: 0.1762, acc: 92.97, test_acc: 71.10, f1: 70.98
loss: 0.3837, acc: 92.50, test_acc: 72.69, f1: 72.02
loss: 0.1103, acc: 92.79, test_acc: 71.82, f1: 69.18
loss: 0.2410, acc: 92.82, test_acc: 73.27, f1: 71.75
loss: 0.3622, acc: 92.63, test_acc: 74.86, f1: 73.68
loss: 0.4017, acc: 92.46, test_acc: 69.80, f1: 69.11
loss: 0.1605, acc: 92.50, test_acc: 70.23, f1: 69.77
loss: 0.6610, acc: 91.94, test_acc: 73.55, f1: 72.83
loss: 0.2431, acc: 91.80, test_acc: 69.94, f1: 67.98
loss: 0.2483, acc: 91.48, test_acc: 73.41, f1: 72.63
loss: 0.5892, acc: 90.81, test_acc: 64.88, f1: 65.27
loss: 0.3148, acc: 90.54, test_acc: 73.55, f1: 73.04
loss: 0.4053, acc: 90.28, test_acc: 71.97, f1: 70.27
loss: 0.2319, acc: 90.54, test_acc: 69.51, f1: 69.29
loss: 0.2049, acc: 90.62, test_acc: 69.51, f1: 69.06
loss: 0.2023, acc: 90.71, test_acc: 72.11, f1: 71.73
loss: 0.0927, acc: 90.94, test_acc: 72.25, f1: 70.30
loss: 0.3753, acc: 90.70, test_acc: 72.11, f1: 71.09
loss: 0.1322, acc: 90.77, test_acc: 70.52, f1: 70.68
loss: 0.2643, acc: 90.84, test_acc: 70.23, f1: 69.61
loss: 0.2451, acc: 90.77, test_acc: 71.39, f1: 70.36
loss: 0.3007, acc: 90.83, test_acc: 71.97, f1: 71.06
loss: 0.4037, acc: 90.62, test_acc: 72.83, f1: 72.38
loss: 0.0688, acc: 90.82, test_acc: 72.54, f1: 72.24
loss: 0.1325, acc: 90.89, test_acc: 72.40, f1: 72.17
loss: 0.2533, acc: 90.82, test_acc: 72.98, f1: 72.31
loss: 0.1252, acc: 91.00, test_acc: 73.55, f1: 72.41
loss: 0.3449, acc: 90.93, test_acc: 71.39, f1: 71.21
loss: 0.2729, acc: 90.99, test_acc: 71.82, f1: 71.32
loss: 0.2870, acc: 90.92, test_acc: 72.69, f1: 71.72
loss: 0.1482, acc: 90.97, test_acc: 73.99, f1: 73.14
loss: 0.4138, acc: 90.91, test_acc: 73.41, f1: 72.99
loss: 0.4676, acc: 90.74, test_acc: 75.00, f1: 73.69
loss: 0.1333, acc: 90.79, test_acc: 73.99, f1: 73.11
loss: 0.1150, acc: 90.95, test_acc: 72.83, f1: 72.74
loss: 0.3892, acc: 90.89, test_acc: 74.42, f1: 73.75
loss: 0.9099, acc: 90.73, test_acc: 75.43, f1: 74.28
loss: 0.2323, acc: 90.68, test_acc: 70.23, f1: 70.37
loss: 0.1339, acc: 90.73, test_acc: 72.40, f1: 71.88
loss: 0.4249, acc: 90.58, test_acc: 75.58, f1: 74.63
loss: 0.0535, acc: 90.72, test_acc: 74.28, f1: 73.73
loss: 0.4899, acc: 90.48, test_acc: 74.28, f1: 73.77
loss: 0.3595, acc: 90.53, test_acc: 75.72, f1: 74.23
loss: 0.1665, acc: 90.58, test_acc: 75.58, f1: 75.08
loss: 0.1923, acc: 90.53, test_acc: 75.43, f1: 74.78
loss: 0.2090, acc: 90.58, test_acc: 72.11, f1: 71.50
loss: 0.3412, acc: 90.62, test_acc: 74.28, f1: 73.77
loss: 0.3627, acc: 90.49, test_acc: 75.00, f1: 73.68
loss: 0.2833, acc: 90.45, test_acc: 73.84, f1: 73.13
loss: 0.0843, acc: 90.58, test_acc: 72.40, f1: 71.66
loss: 0.4214, acc: 90.46, test_acc: 75.72, f1: 74.17
loss: 0.2300, acc: 90.33, test_acc: 72.83, f1: 72.26
loss: 0.1406, acc: 90.38, test_acc: 70.09, f1: 70.26
loss: 0.4396, acc: 90.18, test_acc: 73.41, f1: 73.10
loss: 0.3873, acc: 90.14, test_acc: 74.57, f1: 72.83
####################################################################################################
max_test_acc_overall:76.878612716763
max_f1_overall:75.64386970372902
####################################################################################################
1 test_acc_overall: 77.17  f1_overall:76.12
2 test_acc_overall: 77.17  f1_overall:76.39
3 test_acc_overall: 75.29  f1_overall:74.2
4 test_acc_overall: 75.72  f1_overall:74.16
5 test_acc_overall: 76.88  f1_overall:75.64
max_acc_overall:77.17  f1_overall:76.12
mean_acc_overall:76.45  mean_f1_overall:75.3
####################################################################################################
lcf_bert - laptop - lcf_fusion - No.1 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 0
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc54.55
max_acc:54.55  f1:27.24
loss: 1.0865, acc: 50.00, test_acc: 54.55, f1: 27.24
loss: 1.1570, acc: 43.75, test_acc: 54.08, f1: 25.71
loss: 0.9016, acc: 50.00, test_acc: 22.10, f1: 13.96
loss: 0.9035, acc: 50.00, test_acc: 54.55, f1: 26.80
>> saved: state_dict/lcf_bert_laptop_acc65.36
max_acc:65.36  f1:48.38
loss: 0.9043, acc: 53.75, test_acc: 65.36, f1: 48.38
loss: 1.0610, acc: 53.12, test_acc: 61.76, f1: 45.61
>> saved: state_dict/lcf_bert_laptop_acc69.28
max_acc:69.28  f1:53.23
loss: 0.6816, acc: 56.25, test_acc: 69.28, f1: 53.23
loss: 0.6946, acc: 57.03, test_acc: 68.50, f1: 55.30
>> saved: state_dict/lcf_bert_laptop_acc71.79
max_acc:71.79  f1:60.58
loss: 0.8414, acc: 59.03, test_acc: 71.79, f1: 60.58
>> saved: state_dict/lcf_bert_laptop_acc72.26
max_acc:72.26  f1:60.25
loss: 0.7852, acc: 58.75, test_acc: 72.26, f1: 60.25
>> saved: state_dict/lcf_bert_laptop_acc74.14
max_acc:74.14  f1:66.47
loss: 0.5573, acc: 60.23, test_acc: 74.14, f1: 66.47
loss: 0.3424, acc: 62.50, test_acc: 73.98, f1: 64.47
>> saved: state_dict/lcf_bert_laptop_acc75.08
max_acc:75.08  f1:67.9
loss: 0.8148, acc: 62.98, test_acc: 75.08, f1: 67.90
loss: 0.7260, acc: 63.39, test_acc: 75.08, f1: 70.69
loss: 0.7434, acc: 63.75, test_acc: 73.35, f1: 66.86
>> saved: state_dict/lcf_bert_laptop_acc76.96
max_acc:76.96  f1:71.33
loss: 0.4939, acc: 65.23, test_acc: 76.96, f1: 71.33
loss: 0.4283, acc: 65.81, test_acc: 75.24, f1: 66.13
loss: 0.4166, acc: 66.67, test_acc: 72.26, f1: 61.90
loss: 0.3200, acc: 67.76, test_acc: 75.71, f1: 71.15
loss: 0.6492, acc: 68.44, test_acc: 76.33, f1: 70.96
loss: 0.6188, acc: 68.75, test_acc: 74.45, f1: 66.75
loss: 0.5494, acc: 68.47, test_acc: 74.92, f1: 67.51
>> saved: state_dict/lcf_bert_laptop_acc77.74
max_acc:77.74  f1:73.63
loss: 0.4174, acc: 68.75, test_acc: 77.74, f1: 73.63
>> saved: state_dict/lcf_bert_laptop_acc78.21
max_acc:78.21  f1:74.45
loss: 0.2810, acc: 69.53, test_acc: 78.21, f1: 74.45
>> saved: state_dict/lcf_bert_laptop_acc79.47
max_acc:79.47  f1:74.87
loss: 0.5301, acc: 69.75, test_acc: 79.47, f1: 74.87
>> saved: state_dict/lcf_bert_laptop_acc79.62
max_acc:79.62  f1:75.02
loss: 0.4047, acc: 70.43, test_acc: 79.62, f1: 75.02
loss: 0.2668, acc: 71.30, test_acc: 79.62, f1: 74.96
loss: 0.6842, acc: 71.65, test_acc: 76.65, f1: 70.31
loss: 0.4954, acc: 71.98, test_acc: 76.65, f1: 70.51
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.8454, acc: 56.25, test_acc: 78.68, f1: 73.76
loss: 0.2188, acc: 75.00, test_acc: 77.74, f1: 73.22
loss: 0.4701, acc: 77.08, test_acc: 76.33, f1: 70.62
loss: 0.3459, acc: 79.69, test_acc: 78.21, f1: 72.63
loss: 0.5825, acc: 80.00, test_acc: 78.21, f1: 72.72
loss: 0.2168, acc: 82.29, test_acc: 78.53, f1: 72.82
loss: 0.6068, acc: 82.14, test_acc: 75.55, f1: 67.87
loss: 0.5351, acc: 80.47, test_acc: 79.00, f1: 75.81
loss: 0.9655, acc: 78.47, test_acc: 78.37, f1: 73.00
>> saved: state_dict/lcf_bert_laptop_acc80.09
max_acc:80.09  f1:75.94
loss: 0.3512, acc: 78.75, test_acc: 80.09, f1: 75.94
loss: 0.3006, acc: 79.55, test_acc: 79.78, f1: 75.65
loss: 0.5286, acc: 79.69, test_acc: 79.47, f1: 76.08
loss: 0.5992, acc: 79.33, test_acc: 78.37, f1: 73.16
loss: 0.7165, acc: 78.57, test_acc: 78.68, f1: 73.52
loss: 0.2757, acc: 79.17, test_acc: 79.94, f1: 77.08
loss: 0.4610, acc: 79.30, test_acc: 77.90, f1: 72.47
loss: 0.5101, acc: 79.78, test_acc: 77.59, f1: 71.89
loss: 0.7062, acc: 79.86, test_acc: 79.62, f1: 76.19
>> saved: state_dict/lcf_bert_laptop_acc80.56
max_acc:80.56  f1:76.78
loss: 0.5085, acc: 79.61, test_acc: 80.56, f1: 76.78
loss: 0.2853, acc: 80.31, test_acc: 76.49, f1: 69.10
loss: 0.3678, acc: 80.65, test_acc: 75.55, f1: 67.04
loss: 0.4096, acc: 80.40, test_acc: 74.45, f1: 65.55
loss: 0.4509, acc: 80.16, test_acc: 78.21, f1: 73.85
loss: 0.4540, acc: 80.21, test_acc: 78.21, f1: 72.54
loss: 0.3935, acc: 80.75, test_acc: 73.98, f1: 65.58
loss: 0.2932, acc: 81.01, test_acc: 80.09, f1: 75.90
>> saved: state_dict/lcf_bert_laptop_acc80.88
max_acc:80.88  f1:77.53
loss: 0.3341, acc: 81.25, test_acc: 80.88, f1: 77.53
loss: 0.5101, acc: 81.03, test_acc: 78.37, f1: 74.91
loss: 0.4777, acc: 81.03, test_acc: 77.74, f1: 74.28
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2294, acc: 93.75, test_acc: 74.76, f1: 64.48
loss: 0.4501, acc: 90.62, test_acc: 73.82, f1: 62.58
loss: 0.0872, acc: 93.75, test_acc: 77.90, f1: 72.95
loss: 0.2108, acc: 93.75, test_acc: 78.21, f1: 74.87
loss: 0.0451, acc: 95.00, test_acc: 77.74, f1: 73.45
loss: 0.3254, acc: 93.75, test_acc: 78.84, f1: 74.29
loss: 0.2231, acc: 92.86, test_acc: 78.53, f1: 74.87
loss: 0.1185, acc: 92.97, test_acc: 79.62, f1: 74.69
loss: 0.0986, acc: 93.75, test_acc: 78.53, f1: 72.66
loss: 0.1317, acc: 93.75, test_acc: 80.25, f1: 76.06
loss: 0.3697, acc: 92.61, test_acc: 79.15, f1: 76.26
loss: 0.3102, acc: 92.19, test_acc: 78.84, f1: 74.07
loss: 0.3475, acc: 92.31, test_acc: 78.53, f1: 73.31
loss: 0.1387, acc: 92.86, test_acc: 80.72, f1: 77.65
>> saved: state_dict/lcf_bert_laptop_acc81.03
max_acc:81.03  f1:78.15
loss: 0.0795, acc: 93.33, test_acc: 81.03, f1: 78.15
>> saved: state_dict/lcf_bert_laptop_acc82.45
max_acc:82.45  f1:79.08
loss: 0.0958, acc: 93.75, test_acc: 82.45, f1: 79.08
loss: 0.2870, acc: 93.38, test_acc: 80.72, f1: 76.25
loss: 0.3498, acc: 93.06, test_acc: 80.72, f1: 76.69
loss: 0.6819, acc: 92.11, test_acc: 81.35, f1: 77.33
loss: 0.3245, acc: 91.88, test_acc: 77.12, f1: 70.14
loss: 0.3139, acc: 91.67, test_acc: 76.49, f1: 68.89
loss: 0.0972, acc: 92.05, test_acc: 80.72, f1: 76.64
loss: 0.1992, acc: 92.12, test_acc: 80.41, f1: 77.32
loss: 0.0640, acc: 92.45, test_acc: 80.88, f1: 77.40
loss: 0.3571, acc: 92.00, test_acc: 78.06, f1: 72.12
loss: 0.1136, acc: 92.07, test_acc: 77.43, f1: 70.82
loss: 0.0582, acc: 92.36, test_acc: 77.90, f1: 71.61
loss: 0.2918, acc: 92.19, test_acc: 78.21, f1: 72.55
loss: 0.1736, acc: 92.24, test_acc: 79.00, f1: 74.45
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.1184, acc: 93.75, test_acc: 79.31, f1: 73.66
loss: 0.0123, acc: 96.88, test_acc: 76.80, f1: 69.55
loss: 0.3695, acc: 93.75, test_acc: 77.59, f1: 70.84
loss: 0.2024, acc: 92.19, test_acc: 79.15, f1: 73.64
loss: 0.1428, acc: 92.50, test_acc: 79.47, f1: 74.35
loss: 0.0194, acc: 93.75, test_acc: 79.62, f1: 74.68
loss: 0.2168, acc: 92.86, test_acc: 78.53, f1: 72.34
loss: 0.1719, acc: 92.97, test_acc: 78.21, f1: 72.54
loss: 0.0511, acc: 93.75, test_acc: 80.25, f1: 76.68
loss: 0.0406, acc: 94.38, test_acc: 81.66, f1: 78.45
loss: 0.0596, acc: 94.32, test_acc: 80.25, f1: 75.65
loss: 0.0626, acc: 94.79, test_acc: 80.41, f1: 75.73
loss: 0.0686, acc: 95.19, test_acc: 79.78, f1: 75.26
loss: 0.0649, acc: 95.09, test_acc: 78.84, f1: 73.78
loss: 0.1455, acc: 94.58, test_acc: 79.62, f1: 74.54
loss: 0.4861, acc: 94.14, test_acc: 79.15, f1: 74.04
loss: 0.2744, acc: 93.75, test_acc: 81.35, f1: 77.69
loss: 0.1633, acc: 93.40, test_acc: 80.56, f1: 76.40
loss: 0.1850, acc: 93.09, test_acc: 80.09, f1: 75.33
loss: 0.1238, acc: 93.12, test_acc: 79.78, f1: 75.02
loss: 0.0330, acc: 93.45, test_acc: 80.88, f1: 76.93
loss: 0.0857, acc: 93.75, test_acc: 80.56, f1: 76.51
loss: 0.0069, acc: 94.02, test_acc: 78.21, f1: 73.57
loss: 0.0974, acc: 94.27, test_acc: 77.90, f1: 73.51
loss: 0.0632, acc: 94.50, test_acc: 80.88, f1: 77.22
loss: 0.0236, acc: 94.71, test_acc: 81.19, f1: 77.49
loss: 0.0982, acc: 94.68, test_acc: 79.47, f1: 75.12
loss: 0.3715, acc: 94.20, test_acc: 79.47, f1: 75.29
loss: 0.5641, acc: 93.75, test_acc: 79.94, f1: 75.89
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0258, acc: 100.00, test_acc: 79.31, f1: 74.57
loss: 0.3119, acc: 96.88, test_acc: 78.21, f1: 72.79
loss: 0.0222, acc: 97.92, test_acc: 79.15, f1: 74.30
loss: 0.0777, acc: 96.88, test_acc: 79.94, f1: 75.33
loss: 0.2654, acc: 93.75, test_acc: 80.72, f1: 76.56
loss: 0.0416, acc: 94.79, test_acc: 81.19, f1: 77.20
loss: 0.1107, acc: 94.64, test_acc: 81.03, f1: 77.02
loss: 0.3788, acc: 93.75, test_acc: 79.94, f1: 75.09
loss: 0.0118, acc: 94.44, test_acc: 79.15, f1: 74.05
loss: 0.0521, acc: 94.38, test_acc: 81.50, f1: 77.61
loss: 0.0241, acc: 94.89, test_acc: 81.50, f1: 78.49
loss: 0.0122, acc: 95.31, test_acc: 81.66, f1: 78.11
loss: 0.1141, acc: 95.19, test_acc: 79.00, f1: 73.36
loss: 0.0643, acc: 95.09, test_acc: 76.96, f1: 69.86
loss: 0.0409, acc: 95.42, test_acc: 79.94, f1: 74.97
loss: 0.0989, acc: 95.31, test_acc: 80.25, f1: 75.85
loss: 0.0398, acc: 95.59, test_acc: 78.68, f1: 73.03
loss: 0.2537, acc: 95.14, test_acc: 78.21, f1: 72.27
loss: 0.0356, acc: 95.39, test_acc: 77.12, f1: 70.54
loss: 0.0237, acc: 95.62, test_acc: 79.15, f1: 74.58
loss: 0.1164, acc: 95.54, test_acc: 79.94, f1: 76.60
loss: 0.0485, acc: 95.74, test_acc: 80.25, f1: 76.45
loss: 0.0326, acc: 95.92, test_acc: 78.06, f1: 72.50
loss: 0.1721, acc: 95.83, test_acc: 74.92, f1: 67.00
loss: 0.1024, acc: 95.75, test_acc: 77.59, f1: 71.88
loss: 0.2706, acc: 95.43, test_acc: 78.68, f1: 74.06
loss: 0.1713, acc: 95.37, test_acc: 79.78, f1: 75.68
loss: 0.0675, acc: 95.54, test_acc: 78.06, f1: 72.78
loss: 0.2669, acc: 95.47, test_acc: 79.15, f1: 74.10
loss: 0.0036, acc: 95.55, test_acc: 80.25, f1: 75.98
####################################################################################################
max_test_acc_overall:82.44514106583071
max_f1_overall:79.07838262484564
####################################################################################################
1 test_acc_overall: 82.45  f1_overall:79.08
max_acc_overall:82.45  f1_overall:79.08
mean_acc_overall:82.45  mean_f1_overall:79.08
####################################################################################################
lcf_bert - laptop - lcf_fusion - No.2 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 1
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc53.45
max_acc:53.45  f1:23.32
loss: 1.0523, acc: 56.25, test_acc: 53.45, f1: 23.32
loss: 1.1315, acc: 34.38, test_acc: 20.85, f1: 13.15
>> saved: state_dict/lcf_bert_laptop_acc56.27
max_acc:56.27  f1:31.44
loss: 0.8907, acc: 47.92, test_acc: 56.27, f1: 31.44
loss: 0.8338, acc: 50.00, test_acc: 45.14, f1: 34.39
>> saved: state_dict/lcf_bert_laptop_acc65.36
max_acc:65.36  f1:50.5
loss: 0.8986, acc: 55.00, test_acc: 65.36, f1: 50.50
>> saved: state_dict/lcf_bert_laptop_acc68.18
max_acc:68.18  f1:51.26
loss: 0.8954, acc: 55.21, test_acc: 68.18, f1: 51.26
>> saved: state_dict/lcf_bert_laptop_acc70.06
max_acc:70.06  f1:56.27
loss: 0.9310, acc: 56.25, test_acc: 70.06, f1: 56.27
>> saved: state_dict/lcf_bert_laptop_acc73.2
max_acc:73.2  f1:63.48
loss: 0.6499, acc: 57.03, test_acc: 73.20, f1: 63.48
loss: 0.7950, acc: 58.33, test_acc: 71.32, f1: 57.38
>> saved: state_dict/lcf_bert_laptop_acc73.51
max_acc:73.51  f1:66.27
loss: 0.4156, acc: 60.00, test_acc: 73.51, f1: 66.27
>> saved: state_dict/lcf_bert_laptop_acc73.67
max_acc:73.67  f1:64.56
loss: 0.7423, acc: 60.80, test_acc: 73.67, f1: 64.56
>> saved: state_dict/lcf_bert_laptop_acc76.96
max_acc:76.96  f1:73.35
loss: 0.6142, acc: 61.98, test_acc: 76.96, f1: 73.35
loss: 0.5542, acc: 63.46, test_acc: 74.14, f1: 66.86
loss: 0.7204, acc: 63.84, test_acc: 71.16, f1: 57.85
loss: 0.5042, acc: 65.00, test_acc: 76.33, f1: 72.92
>> saved: state_dict/lcf_bert_laptop_acc77.27
max_acc:77.27  f1:72.59
loss: 1.2307, acc: 64.06, test_acc: 77.27, f1: 72.59
loss: 0.5631, acc: 65.07, test_acc: 71.16, f1: 57.82
>> saved: state_dict/lcf_bert_laptop_acc78.06
max_acc:78.06  f1:71.64
loss: 0.8777, acc: 65.28, test_acc: 78.06, f1: 71.64
>> saved: state_dict/lcf_bert_laptop_acc79.0
max_acc:79.0  f1:73.93
loss: 0.2474, acc: 66.78, test_acc: 79.00, f1: 73.93
loss: 0.5839, acc: 66.88, test_acc: 73.67, f1: 63.13
loss: 0.3159, acc: 67.86, test_acc: 77.27, f1: 70.83
loss: 0.7526, acc: 67.90, test_acc: 78.68, f1: 75.34
loss: 0.1099, acc: 69.29, test_acc: 75.55, f1: 66.78
loss: 0.4941, acc: 69.53, test_acc: 75.71, f1: 67.00
>> saved: state_dict/lcf_bert_laptop_acc80.72
max_acc:80.72  f1:76.23
loss: 0.8948, acc: 69.50, test_acc: 80.72, f1: 76.23
loss: 0.5534, acc: 69.95, test_acc: 78.84, f1: 73.04
loss: 0.4925, acc: 70.37, test_acc: 77.43, f1: 70.27
>> saved: state_dict/lcf_bert_laptop_acc81.03
max_acc:81.03  f1:76.41
loss: 0.4035, acc: 70.76, test_acc: 81.03, f1: 76.41
loss: 0.7233, acc: 70.69, test_acc: 80.72, f1: 76.31
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.5952, acc: 75.00, test_acc: 79.94, f1: 74.91
loss: 0.3212, acc: 81.25, test_acc: 80.25, f1: 76.41
loss: 0.2739, acc: 83.33, test_acc: 80.56, f1: 77.23
loss: 0.6583, acc: 81.25, test_acc: 79.31, f1: 73.72
loss: 0.1694, acc: 83.75, test_acc: 78.21, f1: 72.63
loss: 0.3573, acc: 83.33, test_acc: 79.00, f1: 74.13
loss: 0.3067, acc: 83.93, test_acc: 80.09, f1: 75.65
loss: 0.4900, acc: 84.38, test_acc: 77.43, f1: 70.43
loss: 0.1199, acc: 85.42, test_acc: 78.21, f1: 72.30
loss: 0.4322, acc: 85.00, test_acc: 76.33, f1: 73.97
loss: 0.8953, acc: 83.52, test_acc: 79.31, f1: 75.59
loss: 0.4074, acc: 83.33, test_acc: 78.37, f1: 73.75
loss: 0.5063, acc: 82.69, test_acc: 76.18, f1: 67.89
loss: 0.5207, acc: 82.59, test_acc: 76.49, f1: 68.56
loss: 0.2862, acc: 83.33, test_acc: 77.43, f1: 73.30
loss: 0.5565, acc: 82.81, test_acc: 77.59, f1: 74.27
loss: 0.1505, acc: 83.46, test_acc: 80.09, f1: 76.53
loss: 0.3876, acc: 83.68, test_acc: 79.15, f1: 73.53
loss: 0.6077, acc: 83.88, test_acc: 79.31, f1: 74.86
loss: 0.1486, acc: 84.69, test_acc: 79.78, f1: 76.83
loss: 0.2200, acc: 85.12, test_acc: 79.62, f1: 75.16
loss: 0.3479, acc: 85.23, test_acc: 76.96, f1: 70.06
>> saved: state_dict/lcf_bert_laptop_acc81.19
max_acc:81.19  f1:78.08
loss: 0.0802, acc: 85.87, test_acc: 81.19, f1: 78.08
loss: 0.1793, acc: 86.20, test_acc: 80.72, f1: 76.72
loss: 0.1398, acc: 86.50, test_acc: 79.47, f1: 74.59
loss: 0.3484, acc: 86.30, test_acc: 78.84, f1: 74.72
loss: 0.4971, acc: 86.34, test_acc: 78.06, f1: 73.27
loss: 0.3738, acc: 86.38, test_acc: 80.72, f1: 76.51
loss: 0.4394, acc: 86.42, test_acc: 78.68, f1: 73.30
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.0880, acc: 100.00, test_acc: 80.41, f1: 76.36
loss: 0.3122, acc: 90.62, test_acc: 78.53, f1: 74.39
loss: 0.3106, acc: 91.67, test_acc: 78.53, f1: 74.37
loss: 0.0979, acc: 92.19, test_acc: 79.47, f1: 75.17
loss: 0.3393, acc: 90.00, test_acc: 79.78, f1: 75.39
loss: 0.0774, acc: 91.67, test_acc: 78.68, f1: 72.60
loss: 0.0469, acc: 92.86, test_acc: 79.15, f1: 72.84
loss: 0.0462, acc: 93.75, test_acc: 80.09, f1: 75.22
loss: 0.3502, acc: 93.06, test_acc: 80.41, f1: 76.41
loss: 0.0508, acc: 93.75, test_acc: 79.78, f1: 75.41
loss: 0.0516, acc: 94.32, test_acc: 79.00, f1: 74.39
loss: 0.0790, acc: 94.79, test_acc: 78.21, f1: 73.92
loss: 0.1090, acc: 95.19, test_acc: 79.47, f1: 74.89
loss: 0.1826, acc: 95.54, test_acc: 79.78, f1: 74.79
loss: 0.5940, acc: 94.58, test_acc: 80.41, f1: 75.29
loss: 0.3249, acc: 93.75, test_acc: 79.00, f1: 74.05
loss: 0.2914, acc: 93.75, test_acc: 75.24, f1: 71.37
loss: 0.2905, acc: 93.40, test_acc: 78.84, f1: 74.34
>> saved: state_dict/lcf_bert_laptop_acc81.82
max_acc:81.82  f1:77.94
loss: 0.1686, acc: 93.42, test_acc: 81.82, f1: 77.94
loss: 0.5659, acc: 92.50, test_acc: 80.25, f1: 75.98
loss: 0.3672, acc: 92.26, test_acc: 79.94, f1: 75.15
loss: 0.1995, acc: 92.33, test_acc: 77.74, f1: 73.76
loss: 0.2384, acc: 92.39, test_acc: 76.96, f1: 72.23
loss: 0.2836, acc: 92.19, test_acc: 78.21, f1: 72.96
loss: 0.0625, acc: 92.50, test_acc: 77.12, f1: 69.34
loss: 0.1864, acc: 92.55, test_acc: 77.43, f1: 71.07
loss: 0.1558, acc: 92.59, test_acc: 79.78, f1: 76.81
loss: 0.1357, acc: 92.86, test_acc: 78.84, f1: 74.04
loss: 0.1456, acc: 93.10, test_acc: 77.90, f1: 71.81
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.1571, acc: 93.75, test_acc: 77.90, f1: 70.55
loss: 0.1330, acc: 93.75, test_acc: 80.56, f1: 76.61
loss: 0.1851, acc: 93.75, test_acc: 80.25, f1: 76.87
loss: 0.0896, acc: 95.31, test_acc: 80.25, f1: 76.64
loss: 0.0871, acc: 96.25, test_acc: 79.15, f1: 75.10
loss: 0.0677, acc: 96.88, test_acc: 78.06, f1: 72.40
loss: 0.2859, acc: 95.54, test_acc: 79.94, f1: 75.59
loss: 0.1083, acc: 96.09, test_acc: 81.50, f1: 78.37
loss: 0.1993, acc: 95.83, test_acc: 80.72, f1: 77.41
loss: 0.2371, acc: 94.38, test_acc: 77.12, f1: 70.84
loss: 0.0819, acc: 94.32, test_acc: 77.43, f1: 70.22
loss: 0.0808, acc: 94.27, test_acc: 79.31, f1: 74.56
loss: 0.0079, acc: 94.71, test_acc: 80.09, f1: 77.07
loss: 0.1232, acc: 94.64, test_acc: 81.19, f1: 78.03
loss: 0.2706, acc: 94.17, test_acc: 76.33, f1: 68.59
loss: 0.2004, acc: 93.75, test_acc: 75.08, f1: 65.18
loss: 0.2482, acc: 93.38, test_acc: 79.31, f1: 74.13
loss: 0.2511, acc: 93.06, test_acc: 81.03, f1: 77.60
loss: 0.0435, acc: 93.42, test_acc: 78.84, f1: 73.97
loss: 0.1842, acc: 93.44, test_acc: 76.65, f1: 69.76
loss: 0.1254, acc: 93.45, test_acc: 78.84, f1: 73.51
loss: 0.0938, acc: 93.47, test_acc: 81.03, f1: 77.52
loss: 0.0986, acc: 93.48, test_acc: 80.88, f1: 77.12
loss: 0.0602, acc: 93.75, test_acc: 80.09, f1: 74.57
loss: 0.2605, acc: 93.50, test_acc: 79.47, f1: 74.00
loss: 0.3107, acc: 93.27, test_acc: 78.37, f1: 74.58
loss: 0.8251, acc: 92.82, test_acc: 76.33, f1: 74.08
loss: 0.0161, acc: 93.08, test_acc: 81.35, f1: 77.22
loss: 0.0399, acc: 93.32, test_acc: 75.55, f1: 66.31
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.1357, acc: 93.75, test_acc: 74.76, f1: 64.84
loss: 0.0498, acc: 96.88, test_acc: 78.21, f1: 71.89
loss: 0.0613, acc: 95.83, test_acc: 80.25, f1: 75.35
loss: 0.0216, acc: 96.88, test_acc: 80.25, f1: 76.14
loss: 0.3683, acc: 93.75, test_acc: 79.31, f1: 74.75
loss: 0.0612, acc: 94.79, test_acc: 79.31, f1: 74.35
loss: 0.2607, acc: 93.75, test_acc: 79.78, f1: 74.65
loss: 0.1258, acc: 93.75, test_acc: 79.31, f1: 73.93
loss: 0.4530, acc: 93.06, test_acc: 79.00, f1: 73.51
loss: 0.1152, acc: 93.12, test_acc: 79.47, f1: 74.21
loss: 0.0791, acc: 93.18, test_acc: 78.84, f1: 73.08
loss: 0.1110, acc: 93.23, test_acc: 78.53, f1: 72.27
loss: 0.1555, acc: 92.79, test_acc: 79.62, f1: 75.03
loss: 0.0097, acc: 93.30, test_acc: 80.09, f1: 75.92
loss: 0.2113, acc: 92.92, test_acc: 79.78, f1: 75.57
loss: 0.2021, acc: 92.97, test_acc: 79.00, f1: 73.23
loss: 0.1090, acc: 93.01, test_acc: 78.84, f1: 73.40
loss: 0.1298, acc: 92.71, test_acc: 80.72, f1: 76.95
loss: 0.0707, acc: 93.09, test_acc: 81.03, f1: 77.30
loss: 0.0666, acc: 93.44, test_acc: 79.47, f1: 74.68
loss: 0.1406, acc: 93.45, test_acc: 79.47, f1: 74.46
loss: 0.0215, acc: 93.75, test_acc: 79.78, f1: 75.19
loss: 0.0028, acc: 94.02, test_acc: 80.25, f1: 75.88
loss: 0.0077, acc: 94.27, test_acc: 81.66, f1: 78.10
loss: 0.2471, acc: 94.25, test_acc: 79.94, f1: 75.64
loss: 0.2711, acc: 94.23, test_acc: 79.78, f1: 75.26
loss: 0.6074, acc: 93.98, test_acc: 79.00, f1: 73.75
loss: 0.0219, acc: 94.20, test_acc: 78.53, f1: 73.21
loss: 0.1196, acc: 94.18, test_acc: 79.31, f1: 74.87
loss: 0.0296, acc: 94.28, test_acc: 79.62, f1: 74.60
####################################################################################################
max_test_acc_overall:81.81818181818183
max_f1_overall:78.37092168939618
####################################################################################################
1 test_acc_overall: 82.45  f1_overall:79.08
2 test_acc_overall: 81.82  f1_overall:78.37
max_acc_overall:82.45  f1_overall:79.08
mean_acc_overall:82.13  mean_f1_overall:78.72
####################################################################################################
lcf_bert - laptop - lcf_fusion - No.3 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 2
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc52.66
max_acc:52.66  f1:39.97
loss: 1.0720, acc: 43.75, test_acc: 52.66, f1: 39.97
>> saved: state_dict/lcf_bert_laptop_acc63.17
max_acc:63.17  f1:49.01
loss: 0.9822, acc: 46.88, test_acc: 63.17, f1: 49.01
loss: 1.0073, acc: 47.92, test_acc: 55.33, f1: 30.51
>> saved: state_dict/lcf_bert_laptop_acc63.48
max_acc:63.48  f1:48.19
loss: 0.8973, acc: 45.31, test_acc: 63.48, f1: 48.19
>> saved: state_dict/lcf_bert_laptop_acc72.26
max_acc:72.26  f1:61.84
loss: 0.6851, acc: 52.50, test_acc: 72.26, f1: 61.84
loss: 0.7165, acc: 55.21, test_acc: 72.26, f1: 60.46
>> saved: state_dict/lcf_bert_laptop_acc74.14
max_acc:74.14  f1:65.85
loss: 0.6738, acc: 58.04, test_acc: 74.14, f1: 65.85
loss: 0.8167, acc: 59.38, test_acc: 72.57, f1: 62.42
loss: 0.6418, acc: 61.11, test_acc: 74.14, f1: 66.13
>> saved: state_dict/lcf_bert_laptop_acc76.49
max_acc:76.49  f1:72.87
loss: 0.5118, acc: 62.50, test_acc: 76.49, f1: 72.87
loss: 0.7709, acc: 63.64, test_acc: 70.85, f1: 58.37
>> saved: state_dict/lcf_bert_laptop_acc78.06
max_acc:78.06  f1:72.41
loss: 1.0656, acc: 62.50, test_acc: 78.06, f1: 72.41
loss: 0.8256, acc: 62.98, test_acc: 77.12, f1: 72.63
loss: 0.7028, acc: 64.29, test_acc: 76.80, f1: 69.92
loss: 0.4902, acc: 65.42, test_acc: 74.29, f1: 63.90
loss: 0.5159, acc: 66.41, test_acc: 77.59, f1: 69.92
>> saved: state_dict/lcf_bert_laptop_acc78.37
max_acc:78.37  f1:72.58
loss: 0.7524, acc: 66.18, test_acc: 78.37, f1: 72.58
>> saved: state_dict/lcf_bert_laptop_acc78.68
max_acc:78.68  f1:71.73
loss: 0.3811, acc: 67.01, test_acc: 78.68, f1: 71.73
loss: 0.7598, acc: 67.11, test_acc: 77.12, f1: 69.79
loss: 0.6536, acc: 67.50, test_acc: 77.59, f1: 71.13
loss: 0.7222, acc: 67.56, test_acc: 76.49, f1: 71.50
>> saved: state_dict/lcf_bert_laptop_acc79.15
max_acc:79.15  f1:74.6
loss: 0.6070, acc: 67.61, test_acc: 79.15, f1: 74.60
loss: 0.4668, acc: 68.48, test_acc: 78.84, f1: 73.53
loss: 0.4650, acc: 69.01, test_acc: 78.21, f1: 71.73
loss: 0.7147, acc: 69.00, test_acc: 78.37, f1: 72.00
loss: 0.4294, acc: 69.71, test_acc: 79.00, f1: 76.05
loss: 0.2734, acc: 69.91, test_acc: 77.59, f1: 71.51
loss: 0.3045, acc: 70.76, test_acc: 76.33, f1: 68.19
>> saved: state_dict/lcf_bert_laptop_acc80.88
max_acc:80.88  f1:77.45
loss: 0.6841, acc: 70.69, test_acc: 80.88, f1: 77.45
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.0924, acc: 100.00, test_acc: 77.74, f1: 71.64
loss: 0.2461, acc: 93.75, test_acc: 80.25, f1: 77.30
loss: 0.6395, acc: 87.50, test_acc: 80.41, f1: 77.19
loss: 0.1792, acc: 90.62, test_acc: 76.33, f1: 68.91
loss: 0.3801, acc: 88.75, test_acc: 77.74, f1: 72.09
>> saved: state_dict/lcf_bert_laptop_acc81.35
max_acc:81.35  f1:78.7
loss: 0.3521, acc: 88.54, test_acc: 81.35, f1: 78.70
loss: 0.3625, acc: 88.39, test_acc: 78.06, f1: 73.94
loss: 0.2779, acc: 88.28, test_acc: 76.02, f1: 71.18
loss: 0.6803, acc: 86.81, test_acc: 79.31, f1: 76.08
loss: 0.3336, acc: 86.25, test_acc: 78.21, f1: 75.04
loss: 0.1213, acc: 86.93, test_acc: 79.31, f1: 74.70
loss: 0.1080, acc: 88.02, test_acc: 76.02, f1: 67.51
loss: 0.7317, acc: 87.02, test_acc: 75.24, f1: 66.37
loss: 0.2449, acc: 87.50, test_acc: 78.06, f1: 72.19
loss: 0.5864, acc: 86.67, test_acc: 79.00, f1: 74.47
loss: 0.4548, acc: 85.94, test_acc: 79.62, f1: 75.94
loss: 0.4977, acc: 86.03, test_acc: 77.90, f1: 73.59
loss: 0.2706, acc: 86.11, test_acc: 77.27, f1: 70.59
loss: 0.1525, acc: 86.51, test_acc: 79.15, f1: 74.33
loss: 0.3556, acc: 86.56, test_acc: 81.35, f1: 78.10
loss: 0.4603, acc: 86.61, test_acc: 79.31, f1: 75.27
loss: 0.3764, acc: 86.36, test_acc: 80.41, f1: 76.48
loss: 0.3806, acc: 86.68, test_acc: 80.41, f1: 75.90
loss: 0.1490, acc: 87.24, test_acc: 79.78, f1: 75.38
loss: 0.3931, acc: 87.25, test_acc: 79.94, f1: 75.99
loss: 0.6953, acc: 87.02, test_acc: 76.80, f1: 73.90
loss: 0.2592, acc: 87.27, test_acc: 77.43, f1: 71.80
loss: 0.2886, acc: 87.28, test_acc: 74.29, f1: 65.00
loss: 0.2866, acc: 87.07, test_acc: 75.39, f1: 67.03
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2279, acc: 87.50, test_acc: 77.74, f1: 73.61
loss: 0.3104, acc: 87.50, test_acc: 78.37, f1: 74.34
loss: 0.1858, acc: 87.50, test_acc: 78.84, f1: 74.00
loss: 0.1622, acc: 87.50, test_acc: 77.59, f1: 71.93
loss: 0.2052, acc: 88.75, test_acc: 78.84, f1: 73.93
loss: 0.1982, acc: 88.54, test_acc: 78.68, f1: 73.89
loss: 0.0848, acc: 90.18, test_acc: 79.78, f1: 75.91
loss: 0.2564, acc: 89.84, test_acc: 81.19, f1: 77.32
loss: 0.1207, acc: 90.28, test_acc: 79.15, f1: 74.28
loss: 0.2086, acc: 90.62, test_acc: 79.15, f1: 74.27
loss: 0.0353, acc: 91.48, test_acc: 78.84, f1: 73.37
loss: 0.3268, acc: 91.15, test_acc: 79.15, f1: 73.95
loss: 0.2498, acc: 91.35, test_acc: 80.41, f1: 76.15
loss: 0.3145, acc: 91.07, test_acc: 80.72, f1: 77.18
loss: 0.3572, acc: 90.42, test_acc: 80.72, f1: 77.19
loss: 0.3399, acc: 89.84, test_acc: 79.94, f1: 75.56
loss: 0.4032, acc: 89.71, test_acc: 77.27, f1: 71.35
loss: 0.3383, acc: 89.58, test_acc: 79.62, f1: 75.15
loss: 0.0904, acc: 90.13, test_acc: 80.25, f1: 76.67
loss: 0.2232, acc: 89.69, test_acc: 80.56, f1: 76.92
loss: 0.1091, acc: 90.18, test_acc: 79.15, f1: 74.43
loss: 0.3701, acc: 90.06, test_acc: 80.41, f1: 76.82
loss: 0.0363, acc: 90.49, test_acc: 79.31, f1: 75.69
loss: 0.0860, acc: 90.62, test_acc: 78.37, f1: 74.76
loss: 0.2292, acc: 90.50, test_acc: 79.15, f1: 75.47
loss: 0.4963, acc: 90.14, test_acc: 81.35, f1: 78.23
>> saved: state_dict/lcf_bert_laptop_acc81.5
max_acc:81.5  f1:77.96
loss: 0.1506, acc: 90.28, test_acc: 81.50, f1: 77.96
loss: 0.7313, acc: 89.73, test_acc: 81.35, f1: 77.78
loss: 0.1942, acc: 89.87, test_acc: 81.35, f1: 78.54
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.1168, acc: 100.00, test_acc: 81.35, f1: 78.38
loss: 0.1661, acc: 96.88, test_acc: 80.72, f1: 77.09
loss: 0.0462, acc: 97.92, test_acc: 78.84, f1: 73.25
loss: 0.1237, acc: 98.44, test_acc: 79.78, f1: 74.52
loss: 0.3678, acc: 97.50, test_acc: 80.41, f1: 76.39
loss: 0.1243, acc: 96.88, test_acc: 79.94, f1: 76.06
loss: 0.0218, acc: 97.32, test_acc: 80.09, f1: 75.46
loss: 0.4321, acc: 96.09, test_acc: 78.84, f1: 72.68
loss: 0.0136, acc: 96.53, test_acc: 80.56, f1: 76.17
loss: 0.1968, acc: 95.62, test_acc: 80.09, f1: 76.61
loss: 0.0740, acc: 96.02, test_acc: 78.84, f1: 75.23
loss: 0.3929, acc: 94.79, test_acc: 80.09, f1: 75.28
loss: 0.1761, acc: 93.75, test_acc: 77.27, f1: 70.69
loss: 0.1141, acc: 93.75, test_acc: 79.62, f1: 75.12
loss: 0.0333, acc: 94.17, test_acc: 80.41, f1: 76.80
loss: 0.0961, acc: 94.14, test_acc: 81.03, f1: 77.23
loss: 0.5783, acc: 93.38, test_acc: 79.47, f1: 74.78
loss: 0.1463, acc: 93.06, test_acc: 80.41, f1: 76.09
loss: 0.0310, acc: 93.42, test_acc: 79.00, f1: 73.57
loss: 0.0818, acc: 93.75, test_acc: 76.80, f1: 68.24
loss: 0.0317, acc: 94.05, test_acc: 77.43, f1: 71.30
loss: 0.0488, acc: 94.32, test_acc: 76.33, f1: 72.61
loss: 0.1667, acc: 94.29, test_acc: 76.96, f1: 72.69
loss: 0.1907, acc: 94.01, test_acc: 79.47, f1: 74.31
loss: 0.0557, acc: 94.25, test_acc: 80.72, f1: 76.71
loss: 0.0996, acc: 94.47, test_acc: 81.19, f1: 77.49
loss: 0.0765, acc: 94.44, test_acc: 79.00, f1: 73.82
loss: 0.2866, acc: 93.97, test_acc: 78.84, f1: 72.80
loss: 0.2185, acc: 93.75, test_acc: 80.56, f1: 76.42
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.1413, acc: 93.75, test_acc: 80.09, f1: 76.63
>> saved: state_dict/lcf_bert_laptop_acc81.66
max_acc:81.66  f1:78.33
loss: 0.1508, acc: 96.88, test_acc: 81.66, f1: 78.33
loss: 0.0968, acc: 97.92, test_acc: 78.21, f1: 72.92
loss: 0.2619, acc: 95.31, test_acc: 77.43, f1: 71.61
loss: 0.0208, acc: 96.25, test_acc: 79.94, f1: 75.06
loss: 0.0580, acc: 96.88, test_acc: 81.50, f1: 77.63
>> saved: state_dict/lcf_bert_laptop_acc82.13
max_acc:82.13  f1:78.62
loss: 0.0661, acc: 97.32, test_acc: 82.13, f1: 78.62
loss: 0.2529, acc: 96.88, test_acc: 80.56, f1: 77.27
loss: 0.0177, acc: 97.22, test_acc: 79.31, f1: 75.59
loss: 0.1737, acc: 95.62, test_acc: 80.25, f1: 76.62
loss: 0.0362, acc: 96.02, test_acc: 80.56, f1: 77.14
loss: 0.0190, acc: 96.35, test_acc: 80.88, f1: 77.34
loss: 0.2147, acc: 96.15, test_acc: 81.03, f1: 77.02
loss: 0.0250, acc: 96.43, test_acc: 80.88, f1: 76.68
loss: 0.0395, acc: 96.67, test_acc: 80.56, f1: 77.09
loss: 0.3248, acc: 96.48, test_acc: 79.31, f1: 76.27
loss: 0.0034, acc: 96.69, test_acc: 80.09, f1: 76.57
loss: 0.0217, acc: 96.88, test_acc: 79.62, f1: 75.71
loss: 0.0226, acc: 97.04, test_acc: 80.56, f1: 76.36
loss: 0.0482, acc: 97.19, test_acc: 80.25, f1: 75.86
loss: 0.0265, acc: 97.32, test_acc: 81.35, f1: 77.46
loss: 0.0162, acc: 97.44, test_acc: 81.66, f1: 78.06
loss: 0.0067, acc: 97.55, test_acc: 81.03, f1: 77.84
loss: 0.0376, acc: 97.66, test_acc: 80.88, f1: 76.88
loss: 0.0081, acc: 97.75, test_acc: 79.94, f1: 74.85
loss: 0.0163, acc: 97.84, test_acc: 78.37, f1: 72.70
loss: 0.1631, acc: 97.69, test_acc: 78.21, f1: 73.76
loss: 0.2125, acc: 97.54, test_acc: 78.53, f1: 75.33
loss: 0.0159, acc: 97.63, test_acc: 79.47, f1: 76.66
loss: 0.0390, acc: 97.67, test_acc: 80.56, f1: 76.85
####################################################################################################
max_test_acc_overall:82.13166144200626
max_f1_overall:78.69811753284766
####################################################################################################
1 test_acc_overall: 82.45  f1_overall:79.08
2 test_acc_overall: 81.82  f1_overall:78.37
3 test_acc_overall: 82.13  f1_overall:78.7
max_acc_overall:82.45  f1_overall:79.08
mean_acc_overall:82.13  mean_f1_overall:78.72
####################################################################################################
lcf_bert - laptop - lcf_fusion - No.4 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 3
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc20.38
max_acc:20.38  f1:11.56
loss: 1.0711, acc: 50.00, test_acc: 20.38, f1: 11.56
>> saved: state_dict/lcf_bert_laptop_acc55.33
max_acc:55.33  f1:32.92
loss: 1.0589, acc: 53.12, test_acc: 55.33, f1: 32.92
>> saved: state_dict/lcf_bert_laptop_acc59.4
max_acc:59.4  f1:40.37
loss: 1.1820, acc: 43.75, test_acc: 59.40, f1: 40.37
>> saved: state_dict/lcf_bert_laptop_acc66.3
max_acc:66.3  f1:53.04
loss: 0.9471, acc: 42.19, test_acc: 66.30, f1: 53.04
loss: 1.0764, acc: 41.25, test_acc: 54.70, f1: 27.96
>> saved: state_dict/lcf_bert_laptop_acc68.97
max_acc:68.97  f1:52.62
loss: 0.9486, acc: 43.75, test_acc: 68.97, f1: 52.62
>> saved: state_dict/lcf_bert_laptop_acc69.12
max_acc:69.12  f1:52.92
loss: 0.9549, acc: 44.64, test_acc: 69.12, f1: 52.92
loss: 0.7939, acc: 46.88, test_acc: 63.48, f1: 47.70
>> saved: state_dict/lcf_bert_laptop_acc72.57
max_acc:72.57  f1:61.63
loss: 0.6729, acc: 48.61, test_acc: 72.57, f1: 61.63
loss: 0.5830, acc: 51.88, test_acc: 71.63, f1: 57.46
>> saved: state_dict/lcf_bert_laptop_acc74.29
max_acc:74.29  f1:64.55
loss: 0.4122, acc: 54.55, test_acc: 74.29, f1: 64.55
>> saved: state_dict/lcf_bert_laptop_acc76.65
max_acc:76.65  f1:69.53
loss: 0.6797, acc: 56.25, test_acc: 76.65, f1: 69.53
loss: 0.4165, acc: 58.17, test_acc: 74.76, f1: 72.51
loss: 0.7320, acc: 58.48, test_acc: 74.29, f1: 64.87
loss: 0.3985, acc: 60.00, test_acc: 74.92, f1: 66.32
>> saved: state_dict/lcf_bert_laptop_acc77.27
max_acc:77.27  f1:72.51
loss: 0.4788, acc: 60.55, test_acc: 77.27, f1: 72.51
>> saved: state_dict/lcf_bert_laptop_acc77.74
max_acc:77.74  f1:71.96
loss: 0.7955, acc: 60.66, test_acc: 77.74, f1: 71.96
loss: 0.5480, acc: 61.81, test_acc: 75.86, f1: 70.47
loss: 0.6331, acc: 62.50, test_acc: 77.27, f1: 74.09
loss: 0.6366, acc: 62.81, test_acc: 75.71, f1: 70.16
loss: 0.6656, acc: 63.39, test_acc: 75.24, f1: 65.72
loss: 0.7204, acc: 64.20, test_acc: 72.57, f1: 62.99
loss: 0.4207, acc: 65.49, test_acc: 76.33, f1: 67.97
>> saved: state_dict/lcf_bert_laptop_acc79.47
max_acc:79.47  f1:76.15
loss: 0.4026, acc: 66.67, test_acc: 79.47, f1: 76.15
loss: 0.6320, acc: 67.00, test_acc: 78.06, f1: 72.55
loss: 0.4209, acc: 67.55, test_acc: 77.12, f1: 72.64
loss: 0.3882, acc: 68.29, test_acc: 74.45, f1: 69.41
loss: 0.7427, acc: 68.30, test_acc: 77.74, f1: 70.26
loss: 0.7929, acc: 68.10, test_acc: 77.27, f1: 70.62
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
>> saved: state_dict/lcf_bert_laptop_acc79.94
max_acc:79.94  f1:75.53
loss: 0.4832, acc: 87.50, test_acc: 79.94, f1: 75.53
loss: 0.5363, acc: 81.25, test_acc: 76.18, f1: 71.72
loss: 0.4449, acc: 83.33, test_acc: 75.55, f1: 67.60
loss: 0.4587, acc: 81.25, test_acc: 74.45, f1: 65.43
loss: 0.4414, acc: 82.50, test_acc: 77.90, f1: 72.25
loss: 0.0633, acc: 85.42, test_acc: 78.21, f1: 72.04
loss: 0.2680, acc: 85.71, test_acc: 78.06, f1: 71.68
>> saved: state_dict/lcf_bert_laptop_acc82.13
max_acc:82.13  f1:78.87
loss: 0.4560, acc: 85.16, test_acc: 82.13, f1: 78.87
loss: 0.5269, acc: 84.72, test_acc: 81.35, f1: 78.29
loss: 0.4880, acc: 85.00, test_acc: 76.96, f1: 70.51
loss: 0.0699, acc: 86.36, test_acc: 74.76, f1: 67.28
loss: 0.4629, acc: 85.94, test_acc: 76.33, f1: 70.53
loss: 0.2964, acc: 86.06, test_acc: 80.25, f1: 76.59
loss: 0.2907, acc: 86.16, test_acc: 79.00, f1: 74.66
loss: 0.2117, acc: 86.67, test_acc: 77.74, f1: 71.65
loss: 0.3938, acc: 86.33, test_acc: 78.53, f1: 73.13
loss: 0.3663, acc: 86.76, test_acc: 78.53, f1: 73.47
loss: 0.2596, acc: 87.15, test_acc: 79.15, f1: 74.67
loss: 0.1859, acc: 87.50, test_acc: 78.84, f1: 73.62
loss: 0.3929, acc: 87.50, test_acc: 78.68, f1: 73.26
loss: 0.1760, acc: 87.80, test_acc: 81.66, f1: 78.28
loss: 0.2416, acc: 88.07, test_acc: 79.94, f1: 76.20
loss: 0.6168, acc: 87.77, test_acc: 78.84, f1: 75.85
loss: 0.3388, acc: 87.50, test_acc: 78.84, f1: 74.43
loss: 0.6495, acc: 87.00, test_acc: 76.02, f1: 69.10
loss: 0.3275, acc: 87.02, test_acc: 76.49, f1: 70.80
loss: 0.4389, acc: 87.04, test_acc: 77.59, f1: 71.79
loss: 0.2684, acc: 87.05, test_acc: 77.74, f1: 71.97
loss: 0.3604, acc: 86.64, test_acc: 78.21, f1: 73.48
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.0923, acc: 100.00, test_acc: 80.25, f1: 76.04
loss: 0.6324, acc: 84.38, test_acc: 78.06, f1: 73.06
loss: 0.3244, acc: 85.42, test_acc: 78.68, f1: 74.28
loss: 0.2092, acc: 85.94, test_acc: 78.37, f1: 74.49
loss: 0.1387, acc: 88.75, test_acc: 79.15, f1: 75.85
loss: 0.1280, acc: 89.58, test_acc: 78.21, f1: 73.70
loss: 0.3651, acc: 90.18, test_acc: 78.37, f1: 74.04
loss: 0.1921, acc: 89.84, test_acc: 78.68, f1: 74.54
loss: 0.1653, acc: 90.97, test_acc: 78.37, f1: 73.34
loss: 0.1901, acc: 90.62, test_acc: 77.43, f1: 71.20
loss: 0.2513, acc: 90.91, test_acc: 78.06, f1: 72.87
loss: 0.0745, acc: 91.67, test_acc: 78.06, f1: 72.32
loss: 0.0275, acc: 92.31, test_acc: 81.35, f1: 77.50
loss: 0.2397, acc: 92.41, test_acc: 78.21, f1: 73.04
loss: 0.0653, acc: 92.92, test_acc: 77.74, f1: 71.91
loss: 0.3677, acc: 92.58, test_acc: 81.03, f1: 77.33
loss: 0.0558, acc: 93.01, test_acc: 79.62, f1: 74.90
loss: 0.0420, acc: 93.40, test_acc: 77.74, f1: 71.35
loss: 0.1698, acc: 93.42, test_acc: 77.12, f1: 72.99
loss: 0.1908, acc: 93.44, test_acc: 78.68, f1: 75.45
loss: 0.2689, acc: 93.15, test_acc: 81.97, f1: 78.45
loss: 0.1917, acc: 92.90, test_acc: 80.56, f1: 76.69
loss: 0.0128, acc: 93.21, test_acc: 81.03, f1: 76.74
loss: 0.1698, acc: 93.23, test_acc: 78.53, f1: 72.68
loss: 0.2189, acc: 93.25, test_acc: 79.00, f1: 73.95
loss: 0.2036, acc: 93.27, test_acc: 80.09, f1: 75.77
loss: 0.1061, acc: 93.52, test_acc: 81.03, f1: 77.13
loss: 0.5613, acc: 92.63, test_acc: 78.06, f1: 73.52
loss: 0.1939, acc: 92.67, test_acc: 80.88, f1: 76.96
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.1364, acc: 93.75, test_acc: 78.06, f1: 72.35
loss: 0.0975, acc: 93.75, test_acc: 78.21, f1: 72.29
loss: 0.1433, acc: 91.67, test_acc: 79.47, f1: 74.40
loss: 0.0492, acc: 93.75, test_acc: 80.88, f1: 77.01
loss: 0.0449, acc: 95.00, test_acc: 81.03, f1: 77.13
loss: 0.1010, acc: 94.79, test_acc: 79.15, f1: 74.59
loss: 0.2966, acc: 94.64, test_acc: 79.62, f1: 74.78
loss: 0.0472, acc: 95.31, test_acc: 80.72, f1: 76.99
loss: 0.0727, acc: 95.83, test_acc: 80.88, f1: 77.72
loss: 0.1932, acc: 95.62, test_acc: 80.88, f1: 77.42
loss: 0.0082, acc: 96.02, test_acc: 78.84, f1: 73.95
loss: 0.2014, acc: 95.83, test_acc: 79.62, f1: 75.31
loss: 0.1435, acc: 95.19, test_acc: 80.72, f1: 77.13
loss: 0.1078, acc: 95.54, test_acc: 79.47, f1: 76.26
loss: 0.0547, acc: 95.83, test_acc: 78.53, f1: 73.99
loss: 0.1317, acc: 95.70, test_acc: 77.12, f1: 71.44
loss: 0.0386, acc: 95.96, test_acc: 80.41, f1: 76.56
loss: 0.0094, acc: 96.18, test_acc: 79.78, f1: 76.21
loss: 0.0062, acc: 96.38, test_acc: 79.62, f1: 75.41
loss: 0.1078, acc: 96.25, test_acc: 79.94, f1: 75.36
loss: 0.0398, acc: 96.43, test_acc: 78.68, f1: 73.96
loss: 0.1352, acc: 96.59, test_acc: 79.94, f1: 75.53
loss: 0.0282, acc: 96.74, test_acc: 78.06, f1: 73.15
loss: 0.0433, acc: 96.88, test_acc: 77.12, f1: 71.37
loss: 0.2920, acc: 96.75, test_acc: 77.59, f1: 72.11
loss: 0.0328, acc: 96.88, test_acc: 79.62, f1: 74.90
loss: 0.2839, acc: 96.53, test_acc: 79.78, f1: 75.53
loss: 0.0217, acc: 96.65, test_acc: 78.84, f1: 73.46
loss: 0.3206, acc: 96.34, test_acc: 78.06, f1: 71.71
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0161, acc: 100.00, test_acc: 79.31, f1: 74.44
loss: 0.0758, acc: 100.00, test_acc: 79.62, f1: 75.86
loss: 0.0332, acc: 100.00, test_acc: 79.47, f1: 76.07
loss: 0.0163, acc: 100.00, test_acc: 79.15, f1: 75.54
loss: 0.0930, acc: 98.75, test_acc: 79.78, f1: 75.18
loss: 0.0069, acc: 98.96, test_acc: 78.53, f1: 72.81
loss: 0.0040, acc: 99.11, test_acc: 79.00, f1: 73.87
loss: 0.0091, acc: 99.22, test_acc: 79.47, f1: 75.12
loss: 0.0757, acc: 99.31, test_acc: 80.25, f1: 76.59
loss: 0.1097, acc: 98.75, test_acc: 80.25, f1: 76.05
loss: 0.0023, acc: 98.86, test_acc: 78.68, f1: 73.22
loss: 0.0144, acc: 98.96, test_acc: 79.00, f1: 73.77
loss: 0.1893, acc: 98.56, test_acc: 80.25, f1: 75.79
loss: 0.1643, acc: 98.21, test_acc: 81.50, f1: 78.29
loss: 0.0546, acc: 98.33, test_acc: 80.88, f1: 77.53
loss: 0.1008, acc: 98.05, test_acc: 80.09, f1: 76.42
loss: 0.0160, acc: 98.16, test_acc: 76.96, f1: 71.27
loss: 0.0822, acc: 98.26, test_acc: 77.12, f1: 70.47
loss: 0.1408, acc: 98.03, test_acc: 78.84, f1: 73.56
loss: 0.0071, acc: 98.12, test_acc: 80.25, f1: 76.51
loss: 0.0204, acc: 98.21, test_acc: 81.35, f1: 78.23
loss: 0.0504, acc: 98.30, test_acc: 80.25, f1: 75.92
loss: 0.0207, acc: 98.37, test_acc: 80.41, f1: 76.02
loss: 0.1221, acc: 98.18, test_acc: 79.94, f1: 75.18
loss: 0.6329, acc: 97.75, test_acc: 79.47, f1: 74.34
loss: 0.0221, acc: 97.84, test_acc: 79.31, f1: 74.90
loss: 0.0750, acc: 97.92, test_acc: 80.25, f1: 76.42
loss: 0.1233, acc: 97.77, test_acc: 80.41, f1: 76.64
loss: 0.2679, acc: 97.63, test_acc: 78.68, f1: 74.09
loss: 0.0503, acc: 97.67, test_acc: 79.78, f1: 75.32
####################################################################################################
max_test_acc_overall:82.13166144200626
max_f1_overall:78.8730421991715
####################################################################################################
1 test_acc_overall: 82.45  f1_overall:79.08
2 test_acc_overall: 81.82  f1_overall:78.37
3 test_acc_overall: 82.13  f1_overall:78.7
4 test_acc_overall: 82.13  f1_overall:78.87
max_acc_overall:82.45  f1_overall:79.08
mean_acc_overall:82.13  mean_f1_overall:78.76
####################################################################################################
lcf_bert - laptop - lcf_fusion - No.5 in 5
Model name 'bert_pretrained_models/laptop' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/laptop' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/laptop/vocab.txt
loading file bert_pretrained_models/laptop/added_tokens.json
loading file bert_pretrained_models/laptop/special_tokens_map.json
loading configuration file bert_pretrained_models/laptop/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/laptop/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: laptop
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/laptop
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 4
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Laptops_Train.xml.seg', 'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_laptop_acc21.16
max_acc:21.16  f1:12.76
loss: 1.1093, acc: 25.00, test_acc: 21.16, f1: 12.76
>> saved: state_dict/lcf_bert_laptop_acc54.23
max_acc:54.23  f1:32.73
loss: 1.1010, acc: 37.50, test_acc: 54.23, f1: 32.73
>> saved: state_dict/lcf_bert_laptop_acc55.64
max_acc:55.64  f1:31.7
loss: 0.8250, acc: 50.00, test_acc: 55.64, f1: 31.70
>> saved: state_dict/lcf_bert_laptop_acc63.48
max_acc:63.48  f1:44.91
loss: 0.9206, acc: 54.69, test_acc: 63.48, f1: 44.91
loss: 0.9031, acc: 57.50, test_acc: 52.19, f1: 45.01
>> saved: state_dict/lcf_bert_laptop_acc70.69
max_acc:70.69  f1:60.0
loss: 0.7423, acc: 60.42, test_acc: 70.69, f1: 60.00
loss: 0.5730, acc: 63.39, test_acc: 70.06, f1: 52.37
>> saved: state_dict/lcf_bert_laptop_acc72.88
max_acc:72.88  f1:62.13
loss: 0.2910, acc: 67.19, test_acc: 72.88, f1: 62.13
>> saved: state_dict/lcf_bert_laptop_acc75.24
max_acc:75.24  f1:68.19
loss: 0.5699, acc: 68.06, test_acc: 75.24, f1: 68.19
loss: 0.8135, acc: 68.75, test_acc: 73.82, f1: 70.78
loss: 0.7978, acc: 68.18, test_acc: 72.73, f1: 62.81
loss: 0.5317, acc: 68.75, test_acc: 74.76, f1: 66.54
loss: 0.4514, acc: 70.19, test_acc: 68.97, f1: 53.44
loss: 0.7201, acc: 69.64, test_acc: 72.57, f1: 60.45
>> saved: state_dict/lcf_bert_laptop_acc80.25
max_acc:80.25  f1:75.96
loss: 0.6709, acc: 70.00, test_acc: 80.25, f1: 75.96
loss: 0.6093, acc: 70.70, test_acc: 78.21, f1: 72.55
loss: 1.1817, acc: 69.85, test_acc: 75.86, f1: 67.39
loss: 0.7219, acc: 70.14, test_acc: 78.06, f1: 70.88
loss: 0.3919, acc: 71.05, test_acc: 79.78, f1: 74.93
loss: 0.5863, acc: 71.88, test_acc: 75.86, f1: 66.52
loss: 0.7487, acc: 71.73, test_acc: 73.51, f1: 61.73
loss: 0.3121, acc: 72.73, test_acc: 77.43, f1: 71.20
loss: 0.5919, acc: 72.55, test_acc: 77.59, f1: 71.39
loss: 0.1419, acc: 73.70, test_acc: 79.62, f1: 75.05
loss: 0.8054, acc: 73.25, test_acc: 77.43, f1: 70.79
loss: 0.5786, acc: 73.32, test_acc: 75.39, f1: 66.99
>> saved: state_dict/lcf_bert_laptop_acc80.56
max_acc:80.56  f1:76.79
loss: 0.8286, acc: 73.15, test_acc: 80.56, f1: 76.79
loss: 0.6378, acc: 73.44, test_acc: 77.12, f1: 73.79
loss: 0.3822, acc: 73.92, test_acc: 78.06, f1: 72.89
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.3227, acc: 87.50, test_acc: 79.15, f1: 73.03
loss: 0.3291, acc: 84.38, test_acc: 79.31, f1: 73.78
loss: 0.1953, acc: 89.58, test_acc: 79.62, f1: 74.30
loss: 0.5351, acc: 85.94, test_acc: 79.00, f1: 74.39
loss: 0.1546, acc: 88.75, test_acc: 79.62, f1: 74.30
loss: 0.3746, acc: 87.50, test_acc: 79.62, f1: 74.53
loss: 0.3147, acc: 86.61, test_acc: 79.15, f1: 74.89
loss: 0.5449, acc: 85.16, test_acc: 77.90, f1: 71.37
loss: 0.6187, acc: 84.72, test_acc: 78.53, f1: 71.76
loss: 0.3754, acc: 84.38, test_acc: 78.84, f1: 73.93
loss: 0.2522, acc: 85.23, test_acc: 79.62, f1: 76.10
loss: 0.2230, acc: 85.42, test_acc: 77.12, f1: 68.77
loss: 0.2181, acc: 86.06, test_acc: 76.80, f1: 68.47
loss: 0.2624, acc: 86.16, test_acc: 78.53, f1: 73.13
loss: 0.3569, acc: 86.25, test_acc: 76.80, f1: 73.38
loss: 0.6262, acc: 85.55, test_acc: 78.37, f1: 75.43
>> saved: state_dict/lcf_bert_laptop_acc81.03
max_acc:81.03  f1:76.8
loss: 0.3321, acc: 85.66, test_acc: 81.03, f1: 76.80
loss: 0.4814, acc: 85.42, test_acc: 79.47, f1: 73.49
loss: 0.3643, acc: 85.53, test_acc: 79.31, f1: 74.33
loss: 0.5390, acc: 85.62, test_acc: 78.21, f1: 75.53
loss: 0.7073, acc: 84.52, test_acc: 80.72, f1: 76.11
loss: 0.3365, acc: 84.09, test_acc: 76.80, f1: 68.43
>> saved: state_dict/lcf_bert_laptop_acc81.19
max_acc:81.19  f1:78.08
loss: 0.1673, acc: 84.78, test_acc: 81.19, f1: 78.08
loss: 0.5688, acc: 84.64, test_acc: 78.53, f1: 74.63
loss: 0.2394, acc: 85.00, test_acc: 77.43, f1: 70.79
loss: 0.4679, acc: 85.34, test_acc: 78.06, f1: 71.38
loss: 0.1359, acc: 85.88, test_acc: 77.74, f1: 73.31
loss: 0.5289, acc: 85.94, test_acc: 78.06, f1: 73.60
loss: 0.4342, acc: 85.56, test_acc: 76.49, f1: 69.01
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2203, acc: 87.50, test_acc: 78.53, f1: 72.94
loss: 0.0501, acc: 93.75, test_acc: 80.09, f1: 75.90
loss: 0.0558, acc: 95.83, test_acc: 80.41, f1: 76.61
loss: 0.1105, acc: 96.88, test_acc: 80.56, f1: 76.44
>> saved: state_dict/lcf_bert_laptop_acc81.35
max_acc:81.35  f1:77.82
loss: 0.0374, acc: 97.50, test_acc: 81.35, f1: 77.82
>> saved: state_dict/lcf_bert_laptop_acc81.66
max_acc:81.66  f1:78.25
loss: 0.3256, acc: 95.83, test_acc: 81.66, f1: 78.25
loss: 0.2049, acc: 95.54, test_acc: 80.56, f1: 76.18
loss: 0.2937, acc: 94.53, test_acc: 81.03, f1: 76.88
loss: 0.2389, acc: 93.75, test_acc: 81.66, f1: 78.02
loss: 0.1396, acc: 93.75, test_acc: 80.41, f1: 75.63
loss: 0.2359, acc: 93.75, test_acc: 77.43, f1: 70.16
loss: 0.1430, acc: 93.75, test_acc: 81.50, f1: 77.78
loss: 0.2216, acc: 93.27, test_acc: 80.41, f1: 77.89
loss: 0.1744, acc: 93.30, test_acc: 80.72, f1: 75.71
loss: 0.2057, acc: 93.33, test_acc: 81.19, f1: 76.53
>> saved: state_dict/lcf_bert_laptop_acc81.82
max_acc:81.82  f1:78.56
loss: 0.2892, acc: 92.97, test_acc: 81.82, f1: 78.56
loss: 0.2717, acc: 92.65, test_acc: 81.66, f1: 78.60
loss: 0.3715, acc: 92.36, test_acc: 79.62, f1: 74.40
loss: 0.3490, acc: 92.11, test_acc: 77.90, f1: 70.94
loss: 0.1519, acc: 92.19, test_acc: 79.62, f1: 73.88
loss: 0.4534, acc: 91.37, test_acc: 81.35, f1: 77.04
loss: 0.1930, acc: 91.48, test_acc: 81.66, f1: 78.19
loss: 0.2997, acc: 91.30, test_acc: 80.72, f1: 76.32
loss: 0.0902, acc: 91.67, test_acc: 80.25, f1: 75.57
loss: 0.0889, acc: 92.00, test_acc: 80.09, f1: 75.80
loss: 0.2246, acc: 92.07, test_acc: 79.94, f1: 75.61
loss: 0.2280, acc: 91.90, test_acc: 79.15, f1: 74.67
loss: 0.0253, acc: 92.19, test_acc: 78.37, f1: 72.65
loss: 0.8551, acc: 91.38, test_acc: 78.06, f1: 71.84
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0714, acc: 100.00, test_acc: 79.94, f1: 75.56
loss: 0.1318, acc: 100.00, test_acc: 80.56, f1: 76.70
loss: 0.0924, acc: 100.00, test_acc: 79.78, f1: 74.84
loss: 0.0184, acc: 100.00, test_acc: 77.74, f1: 71.26
loss: 0.1585, acc: 98.75, test_acc: 79.78, f1: 74.94
loss: 0.1271, acc: 97.92, test_acc: 80.72, f1: 76.90
loss: 0.0558, acc: 97.32, test_acc: 79.94, f1: 75.48
loss: 0.0411, acc: 97.66, test_acc: 80.09, f1: 75.59
loss: 0.1515, acc: 97.22, test_acc: 80.72, f1: 76.33
loss: 0.0681, acc: 97.50, test_acc: 79.94, f1: 75.22
loss: 0.0073, acc: 97.73, test_acc: 78.84, f1: 73.22
loss: 0.0936, acc: 97.40, test_acc: 78.53, f1: 73.04
loss: 0.3600, acc: 97.12, test_acc: 78.53, f1: 73.31
loss: 0.1003, acc: 96.88, test_acc: 81.19, f1: 77.12
loss: 0.0577, acc: 97.08, test_acc: 79.15, f1: 75.88
loss: 0.1831, acc: 96.48, test_acc: 76.02, f1: 71.77
loss: 0.4218, acc: 95.96, test_acc: 77.12, f1: 72.81
loss: 0.1011, acc: 95.83, test_acc: 80.09, f1: 76.07
loss: 0.2687, acc: 95.72, test_acc: 78.84, f1: 73.94
loss: 0.0654, acc: 95.94, test_acc: 78.06, f1: 72.31
loss: 0.0163, acc: 96.13, test_acc: 78.68, f1: 73.42
loss: 0.0600, acc: 96.02, test_acc: 79.47, f1: 74.95
loss: 0.1714, acc: 95.65, test_acc: 80.56, f1: 77.12
loss: 0.0593, acc: 95.83, test_acc: 80.25, f1: 76.26
loss: 0.1814, acc: 95.75, test_acc: 78.84, f1: 73.30
loss: 0.0619, acc: 95.91, test_acc: 80.72, f1: 76.90
loss: 0.1491, acc: 95.83, test_acc: 80.88, f1: 76.51
loss: 0.3516, acc: 95.54, test_acc: 79.62, f1: 74.32
loss: 0.2021, acc: 95.26, test_acc: 79.62, f1: 75.14
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0542, acc: 100.00, test_acc: 80.25, f1: 75.77
loss: 0.0375, acc: 100.00, test_acc: 79.47, f1: 74.49
loss: 0.1042, acc: 97.92, test_acc: 79.00, f1: 73.71
loss: 0.0213, acc: 98.44, test_acc: 79.00, f1: 73.82
loss: 0.0171, acc: 98.75, test_acc: 79.47, f1: 74.48
loss: 0.0471, acc: 98.96, test_acc: 79.78, f1: 74.87
loss: 0.0726, acc: 98.21, test_acc: 81.19, f1: 77.36
loss: 0.0991, acc: 98.44, test_acc: 81.19, f1: 77.18
loss: 0.0970, acc: 98.61, test_acc: 79.47, f1: 74.76
loss: 0.1822, acc: 98.12, test_acc: 79.47, f1: 74.66
loss: 0.0201, acc: 98.30, test_acc: 79.78, f1: 75.23
loss: 0.1724, acc: 97.92, test_acc: 79.00, f1: 74.60
loss: 0.0553, acc: 97.60, test_acc: 79.47, f1: 74.55
loss: 0.0330, acc: 97.77, test_acc: 79.62, f1: 74.31
loss: 0.0365, acc: 97.92, test_acc: 79.15, f1: 74.39
loss: 0.0613, acc: 97.66, test_acc: 79.15, f1: 74.42
loss: 0.0137, acc: 97.79, test_acc: 80.25, f1: 74.95
loss: 0.3247, acc: 97.57, test_acc: 80.56, f1: 75.38
loss: 0.1378, acc: 97.37, test_acc: 80.56, f1: 76.41
loss: 0.0753, acc: 97.19, test_acc: 80.72, f1: 76.50
loss: 0.0204, acc: 97.32, test_acc: 80.25, f1: 76.16
loss: 0.0088, acc: 97.44, test_acc: 80.88, f1: 77.23
loss: 0.1523, acc: 97.28, test_acc: 81.19, f1: 77.18
loss: 0.1403, acc: 97.14, test_acc: 79.47, f1: 74.26
loss: 0.0148, acc: 97.25, test_acc: 78.68, f1: 73.04
loss: 0.0486, acc: 97.36, test_acc: 79.78, f1: 74.94
loss: 0.0110, acc: 97.45, test_acc: 81.82, f1: 77.91
loss: 0.0385, acc: 97.54, test_acc: 81.19, f1: 76.94
loss: 0.1659, acc: 97.41, test_acc: 80.09, f1: 75.55
loss: 0.0006, acc: 97.46, test_acc: 79.15, f1: 74.22
####################################################################################################
max_test_acc_overall:81.81818181818183
max_f1_overall:78.60083476521834
####################################################################################################
1 test_acc_overall: 82.45  f1_overall:79.08
2 test_acc_overall: 81.82  f1_overall:78.37
3 test_acc_overall: 82.13  f1_overall:78.7
4 test_acc_overall: 82.13  f1_overall:78.87
5 test_acc_overall: 81.82  f1_overall:78.6
max_acc_overall:82.45  f1_overall:79.08
mean_acc_overall:82.07  mean_f1_overall:78.72
####################################################################################################
lcf_bert - restaurant - lcf_fusion - No.1 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 0
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc20.89
max_acc:20.89  f1:14.45
loss: 1.0968, acc: 25.00, test_acc: 20.89, f1: 14.45
>> saved: state_dict/lcf_bert_restaurant_acc65.09
max_acc:65.09  f1:26.62
loss: 0.7802, acc: 46.88, test_acc: 65.09, f1: 26.62
>> saved: state_dict/lcf_bert_restaurant_acc65.27
max_acc:65.27  f1:27.33
loss: 1.0536, acc: 43.75, test_acc: 65.27, f1: 27.33
loss: 0.8851, acc: 48.44, test_acc: 65.00, f1: 26.26
loss: 0.8309, acc: 53.75, test_acc: 65.00, f1: 26.26
>> saved: state_dict/lcf_bert_restaurant_acc68.84
max_acc:68.84  f1:39.53
loss: 0.8702, acc: 55.21, test_acc: 68.84, f1: 39.53
loss: 0.8729, acc: 55.36, test_acc: 65.98, f1: 30.22
loss: 0.7891, acc: 57.81, test_acc: 68.57, f1: 38.93
>> saved: state_dict/lcf_bert_restaurant_acc70.45
max_acc:70.45  f1:42.35
loss: 0.9768, acc: 56.94, test_acc: 70.45, f1: 42.35
loss: 1.1129, acc: 56.25, test_acc: 66.61, f1: 32.24
>> saved: state_dict/lcf_bert_restaurant_acc78.04
max_acc:78.04  f1:58.45
loss: 0.7630, acc: 58.52, test_acc: 78.04, f1: 58.45
loss: 0.7002, acc: 59.38, test_acc: 77.32, f1: 53.91
>> saved: state_dict/lcf_bert_restaurant_acc79.29
max_acc:79.29  f1:60.57
loss: 0.6200, acc: 60.10, test_acc: 79.29, f1: 60.57
loss: 0.6649, acc: 60.71, test_acc: 78.30, f1: 70.37
loss: 0.5612, acc: 61.67, test_acc: 77.77, f1: 57.78
loss: 1.1550, acc: 60.55, test_acc: 78.48, f1: 55.89
loss: 0.7285, acc: 61.03, test_acc: 78.84, f1: 60.36
>> saved: state_dict/lcf_bert_restaurant_acc79.91
max_acc:79.91  f1:63.8
loss: 0.5138, acc: 61.81, test_acc: 79.91, f1: 63.80
loss: 0.7141, acc: 62.17, test_acc: 78.75, f1: 64.70
>> saved: state_dict/lcf_bert_restaurant_acc80.89
max_acc:80.89  f1:68.3
loss: 0.4479, acc: 62.81, test_acc: 80.89, f1: 68.30
>> saved: state_dict/lcf_bert_restaurant_acc81.16
max_acc:81.16  f1:67.96
loss: 0.3786, acc: 63.99, test_acc: 81.16, f1: 67.96
loss: 0.2925, acc: 65.34, test_acc: 78.84, f1: 56.59
loss: 0.4548, acc: 65.76, test_acc: 80.18, f1: 61.14
loss: 0.4947, acc: 66.67, test_acc: 80.36, f1: 68.74
loss: 0.6178, acc: 66.50, test_acc: 78.66, f1: 56.43
loss: 0.5555, acc: 67.07, test_acc: 80.18, f1: 62.56
loss: 0.6076, acc: 67.59, test_acc: 78.84, f1: 63.66
>> saved: state_dict/lcf_bert_restaurant_acc81.34
max_acc:81.34  f1:66.22
loss: 0.5637, acc: 68.08, test_acc: 81.34, f1: 66.22
loss: 0.7743, acc: 67.89, test_acc: 79.02, f1: 65.15
>> saved: state_dict/lcf_bert_restaurant_acc82.59
max_acc:82.59  f1:73.31
loss: 0.3993, acc: 68.33, test_acc: 82.59, f1: 73.31
loss: 0.3688, acc: 69.15, test_acc: 82.32, f1: 67.50
loss: 0.6581, acc: 69.34, test_acc: 80.45, f1: 61.97
loss: 0.3760, acc: 69.70, test_acc: 80.62, f1: 62.71
>> saved: state_dict/lcf_bert_restaurant_acc84.29
max_acc:84.29  f1:74.42
loss: 0.4524, acc: 69.85, test_acc: 84.29, f1: 74.42
loss: 0.5458, acc: 69.82, test_acc: 84.02, f1: 77.15
loss: 0.5468, acc: 69.79, test_acc: 83.12, f1: 69.49
loss: 0.6572, acc: 69.93, test_acc: 79.64, f1: 59.68
loss: 0.3975, acc: 69.90, test_acc: 83.66, f1: 72.77
>> saved: state_dict/lcf_bert_restaurant_acc84.64
max_acc:84.64  f1:77.63
loss: 0.5495, acc: 70.03, test_acc: 84.64, f1: 77.63
>> saved: state_dict/lcf_bert_restaurant_acc84.73
max_acc:84.73  f1:75.71
loss: 0.2995, acc: 70.78, test_acc: 84.73, f1: 75.71
loss: 0.7066, acc: 71.04, test_acc: 81.70, f1: 66.94
loss: 0.3261, acc: 71.43, test_acc: 82.32, f1: 68.08
loss: 0.3532, acc: 71.95, test_acc: 83.57, f1: 72.98
loss: 0.3550, acc: 72.44, test_acc: 84.38, f1: 74.82
>> saved: state_dict/lcf_bert_restaurant_acc85.45
max_acc:85.45  f1:77.79
loss: 0.4544, acc: 72.50, test_acc: 85.45, f1: 77.79
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.6784, acc: 81.25, test_acc: 83.84, f1: 75.34
loss: 0.2166, acc: 90.62, test_acc: 84.82, f1: 74.43
loss: 0.3222, acc: 87.50, test_acc: 83.93, f1: 70.65
loss: 0.6058, acc: 85.94, test_acc: 83.48, f1: 71.95
loss: 0.5470, acc: 83.75, test_acc: 85.18, f1: 77.89
loss: 0.3103, acc: 85.42, test_acc: 84.46, f1: 76.40
loss: 0.4776, acc: 83.93, test_acc: 84.29, f1: 75.19
loss: 0.2385, acc: 85.16, test_acc: 82.68, f1: 70.94
loss: 0.2690, acc: 85.42, test_acc: 83.39, f1: 73.34
loss: 0.2754, acc: 85.62, test_acc: 83.84, f1: 73.38
loss: 0.2827, acc: 85.80, test_acc: 83.30, f1: 73.59
loss: 0.1562, acc: 86.98, test_acc: 84.02, f1: 72.90
loss: 0.4132, acc: 86.54, test_acc: 84.82, f1: 75.74
loss: 0.2239, acc: 87.05, test_acc: 85.36, f1: 78.56
loss: 0.4171, acc: 86.25, test_acc: 83.93, f1: 73.30
loss: 0.1428, acc: 86.72, test_acc: 82.32, f1: 64.67
loss: 0.1593, acc: 87.13, test_acc: 81.61, f1: 63.43
loss: 0.1194, acc: 87.50, test_acc: 84.29, f1: 74.12
loss: 0.5299, acc: 86.84, test_acc: 84.02, f1: 77.22
loss: 0.2936, acc: 86.88, test_acc: 83.84, f1: 74.66
loss: 0.1569, acc: 87.50, test_acc: 82.86, f1: 69.45
loss: 0.4922, acc: 87.22, test_acc: 83.30, f1: 70.24
>> saved: state_dict/lcf_bert_restaurant_acc85.62
max_acc:85.62  f1:77.0
loss: 0.3625, acc: 87.23, test_acc: 85.62, f1: 77.00
loss: 0.4560, acc: 86.72, test_acc: 84.91, f1: 78.74
loss: 0.5817, acc: 85.75, test_acc: 85.62, f1: 77.48
loss: 0.4470, acc: 85.82, test_acc: 83.57, f1: 71.60
loss: 0.2081, acc: 86.11, test_acc: 85.00, f1: 74.38
>> saved: state_dict/lcf_bert_restaurant_acc86.52
max_acc:86.52  f1:78.69
loss: 0.7905, acc: 85.71, test_acc: 86.52, f1: 78.69
>> saved: state_dict/lcf_bert_restaurant_acc87.32
max_acc:87.32  f1:82.19
loss: 0.3309, acc: 85.99, test_acc: 87.32, f1: 82.19
loss: 0.4650, acc: 85.83, test_acc: 86.16, f1: 78.06
loss: 0.5703, acc: 85.48, test_acc: 85.00, f1: 75.09
loss: 0.3147, acc: 85.55, test_acc: 83.84, f1: 74.20
loss: 0.2024, acc: 85.80, test_acc: 85.98, f1: 78.36
loss: 0.4409, acc: 85.85, test_acc: 86.43, f1: 78.37
loss: 0.2513, acc: 85.89, test_acc: 86.25, f1: 78.98
loss: 0.4879, acc: 85.76, test_acc: 85.80, f1: 79.29
loss: 0.4491, acc: 85.64, test_acc: 83.93, f1: 75.79
loss: 0.7733, acc: 85.20, test_acc: 84.64, f1: 73.96
loss: 0.4159, acc: 85.26, test_acc: 85.62, f1: 77.01
loss: 0.3451, acc: 85.31, test_acc: 85.45, f1: 77.19
loss: 0.2705, acc: 85.37, test_acc: 85.18, f1: 77.02
loss: 0.3589, acc: 85.42, test_acc: 85.89, f1: 77.93
loss: 0.4455, acc: 85.61, test_acc: 85.62, f1: 76.31
loss: 0.2095, acc: 85.65, test_acc: 86.25, f1: 77.37
loss: 0.1569, acc: 85.83, test_acc: 86.52, f1: 76.80
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1993, acc: 93.75, test_acc: 85.09, f1: 73.84
loss: 0.0405, acc: 96.88, test_acc: 86.07, f1: 77.12
loss: 0.1258, acc: 95.83, test_acc: 86.43, f1: 78.79
loss: 0.2556, acc: 93.75, test_acc: 85.98, f1: 78.42
loss: 0.2907, acc: 93.75, test_acc: 86.52, f1: 78.94
loss: 0.2049, acc: 92.71, test_acc: 85.00, f1: 74.98
loss: 0.0601, acc: 93.75, test_acc: 85.62, f1: 76.55
loss: 0.2393, acc: 92.97, test_acc: 86.25, f1: 77.70
loss: 0.1570, acc: 93.06, test_acc: 86.07, f1: 78.08
>> saved: state_dict/lcf_bert_restaurant_acc87.41
max_acc:87.41  f1:80.82
loss: 0.2346, acc: 92.50, test_acc: 87.41, f1: 80.82
loss: 0.0585, acc: 93.18, test_acc: 86.34, f1: 77.54
loss: 0.2696, acc: 92.71, test_acc: 85.80, f1: 76.41
loss: 0.1425, acc: 92.79, test_acc: 86.61, f1: 78.13
loss: 0.7075, acc: 91.07, test_acc: 86.70, f1: 78.33
loss: 0.2315, acc: 91.25, test_acc: 85.89, f1: 78.13
loss: 0.1927, acc: 91.02, test_acc: 85.80, f1: 77.44
loss: 0.0872, acc: 91.18, test_acc: 85.98, f1: 78.19
loss: 0.1092, acc: 91.32, test_acc: 86.16, f1: 76.84
loss: 0.1143, acc: 91.45, test_acc: 86.16, f1: 77.91
loss: 0.2135, acc: 91.25, test_acc: 86.16, f1: 78.97
loss: 0.1348, acc: 91.37, test_acc: 86.79, f1: 80.16
loss: 0.3699, acc: 91.19, test_acc: 85.09, f1: 75.12
loss: 0.0343, acc: 91.58, test_acc: 85.36, f1: 76.19
loss: 0.1736, acc: 91.41, test_acc: 85.98, f1: 78.65
loss: 0.3408, acc: 91.25, test_acc: 85.80, f1: 78.14
loss: 0.0960, acc: 91.59, test_acc: 85.62, f1: 77.26
>> saved: state_dict/lcf_bert_restaurant_acc87.95
max_acc:87.95  f1:81.44
loss: 0.2755, acc: 91.67, test_acc: 87.95, f1: 81.44
loss: 0.0722, acc: 91.96, test_acc: 87.23, f1: 79.28
>> saved: state_dict/lcf_bert_restaurant_acc88.04
max_acc:88.04  f1:81.59
loss: 0.1828, acc: 92.03, test_acc: 88.04, f1: 81.59
>> saved: state_dict/lcf_bert_restaurant_acc88.39
max_acc:88.39  f1:82.83
loss: 0.3854, acc: 91.67, test_acc: 88.39, f1: 82.83
loss: 0.5550, acc: 91.13, test_acc: 88.21, f1: 82.28
loss: 0.4398, acc: 90.82, test_acc: 87.95, f1: 81.08
loss: 0.1849, acc: 90.91, test_acc: 87.95, f1: 81.27
loss: 0.3418, acc: 90.81, test_acc: 86.79, f1: 80.03
loss: 0.0991, acc: 90.89, test_acc: 85.45, f1: 77.84
loss: 0.3216, acc: 90.80, test_acc: 85.89, f1: 77.66
loss: 0.3597, acc: 90.54, test_acc: 86.07, f1: 77.28
loss: 0.2378, acc: 90.46, test_acc: 87.68, f1: 81.29
loss: 0.6450, acc: 90.38, test_acc: 86.88, f1: 80.72
loss: 0.0929, acc: 90.47, test_acc: 87.14, f1: 81.20
loss: 0.0900, acc: 90.70, test_acc: 87.68, f1: 80.84
loss: 0.2069, acc: 90.62, test_acc: 86.70, f1: 78.33
loss: 0.2080, acc: 90.70, test_acc: 86.34, f1: 78.02
loss: 0.1378, acc: 90.77, test_acc: 85.54, f1: 77.45
loss: 0.1357, acc: 90.97, test_acc: 85.89, f1: 78.16
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0565, acc: 100.00, test_acc: 85.09, f1: 74.64
loss: 0.1433, acc: 96.88, test_acc: 85.00, f1: 74.33
loss: 0.1500, acc: 97.92, test_acc: 86.16, f1: 78.10
loss: 0.0551, acc: 98.44, test_acc: 86.88, f1: 79.98
loss: 0.1419, acc: 97.50, test_acc: 87.50, f1: 81.15
loss: 0.0273, acc: 97.92, test_acc: 87.77, f1: 81.64
loss: 0.0253, acc: 98.21, test_acc: 87.32, f1: 80.62
loss: 0.1171, acc: 97.66, test_acc: 86.88, f1: 79.86
loss: 0.2413, acc: 96.53, test_acc: 86.61, f1: 78.82
loss: 0.0575, acc: 96.25, test_acc: 86.61, f1: 79.10
loss: 0.1267, acc: 96.02, test_acc: 86.70, f1: 79.90
loss: 0.0054, acc: 96.35, test_acc: 86.61, f1: 79.68
loss: 0.0245, acc: 96.63, test_acc: 86.88, f1: 79.81
loss: 0.0326, acc: 96.88, test_acc: 85.98, f1: 76.24
loss: 0.1570, acc: 96.67, test_acc: 85.71, f1: 74.88
loss: 0.0280, acc: 96.88, test_acc: 86.52, f1: 77.88
loss: 0.2435, acc: 96.69, test_acc: 87.59, f1: 81.10
loss: 0.0681, acc: 96.88, test_acc: 88.12, f1: 81.91
loss: 0.0166, acc: 97.04, test_acc: 87.32, f1: 80.39
loss: 0.0226, acc: 97.19, test_acc: 87.41, f1: 80.47
loss: 0.0630, acc: 97.32, test_acc: 87.59, f1: 80.83
>> saved: state_dict/lcf_bert_restaurant_acc88.93
max_acc:88.93  f1:83.8
loss: 0.6384, acc: 96.31, test_acc: 88.93, f1: 83.80
loss: 0.0623, acc: 96.47, test_acc: 88.30, f1: 82.91
loss: 0.0946, acc: 96.61, test_acc: 87.95, f1: 81.61
loss: 0.0721, acc: 96.75, test_acc: 86.34, f1: 78.38
loss: 0.0350, acc: 96.88, test_acc: 86.43, f1: 78.70
loss: 0.0259, acc: 96.99, test_acc: 87.32, f1: 80.81
loss: 0.0653, acc: 96.88, test_acc: 87.68, f1: 81.54
loss: 0.2079, acc: 96.77, test_acc: 87.59, f1: 81.12
loss: 0.0144, acc: 96.88, test_acc: 87.41, f1: 80.99
loss: 0.2972, acc: 96.77, test_acc: 87.50, f1: 81.20
loss: 0.0671, acc: 96.88, test_acc: 86.88, f1: 79.90
loss: 0.0353, acc: 96.97, test_acc: 86.61, f1: 79.72
loss: 0.0234, acc: 97.06, test_acc: 87.32, f1: 80.94
loss: 0.2587, acc: 96.96, test_acc: 87.05, f1: 80.43
loss: 0.0994, acc: 96.88, test_acc: 86.34, f1: 79.30
loss: 0.2213, acc: 96.79, test_acc: 87.05, f1: 80.24
loss: 0.2775, acc: 96.71, test_acc: 86.34, f1: 77.52
loss: 0.1376, acc: 96.63, test_acc: 87.41, f1: 80.54
loss: 0.0198, acc: 96.72, test_acc: 87.86, f1: 82.14
loss: 0.3411, acc: 96.49, test_acc: 86.79, f1: 79.84
loss: 0.0086, acc: 96.58, test_acc: 85.36, f1: 76.81
loss: 0.0116, acc: 96.66, test_acc: 85.18, f1: 75.82
loss: 0.2725, acc: 96.59, test_acc: 85.27, f1: 76.04
loss: 0.2022, acc: 96.53, test_acc: 86.96, f1: 80.23
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0912, acc: 100.00, test_acc: 86.43, f1: 79.80
loss: 0.1349, acc: 96.88, test_acc: 87.14, f1: 80.82
loss: 0.0124, acc: 97.92, test_acc: 87.41, f1: 80.74
loss: 0.0544, acc: 98.44, test_acc: 87.05, f1: 79.36
loss: 0.0024, acc: 98.75, test_acc: 86.34, f1: 77.91
loss: 0.0060, acc: 98.96, test_acc: 86.07, f1: 77.21
loss: 0.0258, acc: 99.11, test_acc: 87.59, f1: 80.99
loss: 0.0083, acc: 99.22, test_acc: 87.86, f1: 81.59
loss: 0.0065, acc: 99.31, test_acc: 87.59, f1: 81.26
loss: 0.0043, acc: 99.38, test_acc: 88.12, f1: 82.16
loss: 0.0058, acc: 99.43, test_acc: 88.75, f1: 83.18
loss: 0.0051, acc: 99.48, test_acc: 88.39, f1: 82.33
loss: 0.0123, acc: 99.52, test_acc: 87.86, f1: 81.39
loss: 0.0070, acc: 99.55, test_acc: 88.04, f1: 81.70
loss: 0.0963, acc: 99.17, test_acc: 88.30, f1: 81.75
loss: 0.1866, acc: 98.83, test_acc: 86.16, f1: 75.95
loss: 0.0198, acc: 98.90, test_acc: 87.77, f1: 80.60
>> saved: state_dict/lcf_bert_restaurant_acc89.55
max_acc:89.55  f1:84.65
loss: 0.0847, acc: 98.96, test_acc: 89.55, f1: 84.65
loss: 0.0096, acc: 99.01, test_acc: 89.38, f1: 84.30
loss: 0.2978, acc: 98.75, test_acc: 87.77, f1: 81.37
loss: 0.0213, acc: 98.81, test_acc: 88.04, f1: 81.99
loss: 0.0225, acc: 98.86, test_acc: 88.39, f1: 83.02
loss: 0.0089, acc: 98.91, test_acc: 87.23, f1: 81.00
loss: 0.0247, acc: 98.96, test_acc: 86.34, f1: 78.98
loss: 0.0055, acc: 99.00, test_acc: 86.25, f1: 78.80
loss: 0.1243, acc: 98.80, test_acc: 86.61, f1: 79.43
loss: 0.0841, acc: 98.84, test_acc: 86.34, f1: 79.27
loss: 0.0242, acc: 98.88, test_acc: 86.79, f1: 79.04
loss: 0.0213, acc: 98.92, test_acc: 87.23, f1: 79.86
loss: 0.0164, acc: 98.96, test_acc: 87.68, f1: 81.24
loss: 0.0143, acc: 98.99, test_acc: 87.23, f1: 80.92
loss: 0.0097, acc: 99.02, test_acc: 87.59, f1: 81.41
loss: 0.0611, acc: 98.86, test_acc: 87.77, f1: 81.49
loss: 0.0562, acc: 98.90, test_acc: 87.95, f1: 81.84
loss: 0.0121, acc: 98.93, test_acc: 87.86, f1: 81.90
loss: 0.0114, acc: 98.96, test_acc: 87.23, f1: 80.80
loss: 0.1870, acc: 98.82, test_acc: 88.30, f1: 82.68
loss: 0.1397, acc: 98.85, test_acc: 87.68, f1: 81.38
loss: 0.0018, acc: 98.88, test_acc: 86.96, f1: 78.89
loss: 0.0277, acc: 98.91, test_acc: 87.32, f1: 79.48
loss: 0.0330, acc: 98.93, test_acc: 87.95, f1: 81.05
loss: 0.0100, acc: 98.96, test_acc: 88.30, f1: 82.61
loss: 0.0122, acc: 98.98, test_acc: 88.30, f1: 82.62
loss: 0.2545, acc: 98.86, test_acc: 88.12, f1: 82.28
loss: 0.0052, acc: 98.89, test_acc: 88.21, f1: 82.52
loss: 0.0032, acc: 98.90, test_acc: 87.95, f1: 82.05
####################################################################################################
max_test_acc_overall:89.55357142857143
max_f1_overall:84.64743962264811
####################################################################################################
1 test_acc_overall: 89.55  f1_overall:84.65
max_acc_overall:89.55  f1_overall:84.65
mean_acc_overall:89.55  mean_f1_overall:84.65
####################################################################################################
lcf_bert - restaurant - lcf_fusion - No.2 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 1
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc46.25
max_acc:46.25  f1:30.53
loss: 1.1456, acc: 43.75, test_acc: 46.25, f1: 30.53
>> saved: state_dict/lcf_bert_restaurant_acc65.0
max_acc:65.0  f1:26.26
loss: 0.7454, acc: 56.25, test_acc: 65.00, f1: 26.26
loss: 0.8397, acc: 60.42, test_acc: 65.00, f1: 26.26
>> saved: state_dict/lcf_bert_restaurant_acc68.12
max_acc:68.12  f1:38.88
loss: 0.9944, acc: 59.38, test_acc: 68.12, f1: 38.88
loss: 0.6207, acc: 63.75, test_acc: 65.00, f1: 26.59
loss: 0.8866, acc: 62.50, test_acc: 66.96, f1: 33.40
>> saved: state_dict/lcf_bert_restaurant_acc73.21
max_acc:73.21  f1:47.99
loss: 0.7708, acc: 62.50, test_acc: 73.21, f1: 47.99
>> saved: state_dict/lcf_bert_restaurant_acc76.52
max_acc:76.52  f1:60.57
loss: 0.8043, acc: 63.28, test_acc: 76.52, f1: 60.57
>> saved: state_dict/lcf_bert_restaurant_acc77.41
max_acc:77.41  f1:54.07
loss: 0.9817, acc: 63.89, test_acc: 77.41, f1: 54.07
>> saved: state_dict/lcf_bert_restaurant_acc78.12
max_acc:78.12  f1:55.13
loss: 0.6770, acc: 64.38, test_acc: 78.12, f1: 55.13
>> saved: state_dict/lcf_bert_restaurant_acc81.07
max_acc:81.07  f1:65.51
loss: 0.5642, acc: 65.91, test_acc: 81.07, f1: 65.51
loss: 0.4873, acc: 66.67, test_acc: 78.84, f1: 56.08
loss: 0.8897, acc: 66.35, test_acc: 77.23, f1: 58.99
loss: 0.4006, acc: 67.86, test_acc: 80.09, f1: 69.83
>> saved: state_dict/lcf_bert_restaurant_acc82.5
max_acc:82.5  f1:73.1
loss: 0.8525, acc: 66.67, test_acc: 82.50, f1: 73.10
loss: 0.3126, acc: 67.97, test_acc: 79.64, f1: 58.24
loss: 0.9633, acc: 67.65, test_acc: 80.00, f1: 60.00
loss: 0.4233, acc: 68.40, test_acc: 81.34, f1: 71.44
loss: 0.7229, acc: 68.09, test_acc: 82.14, f1: 71.47
loss: 0.5538, acc: 68.75, test_acc: 80.00, f1: 59.06
loss: 0.5110, acc: 69.05, test_acc: 80.36, f1: 61.02
>> saved: state_dict/lcf_bert_restaurant_acc82.77
max_acc:82.77  f1:69.58
loss: 0.8600, acc: 68.47, test_acc: 82.77, f1: 69.58
loss: 1.0240, acc: 67.93, test_acc: 81.61, f1: 65.84
loss: 0.7050, acc: 68.23, test_acc: 82.05, f1: 68.14
loss: 0.2968, acc: 69.00, test_acc: 82.14, f1: 67.49
loss: 1.0554, acc: 68.03, test_acc: 81.16, f1: 64.84
loss: 0.2489, acc: 68.98, test_acc: 80.62, f1: 67.89
>> saved: state_dict/lcf_bert_restaurant_acc83.57
max_acc:83.57  f1:75.49
loss: 0.9618, acc: 68.53, test_acc: 83.57, f1: 75.49
loss: 0.8052, acc: 68.53, test_acc: 83.57, f1: 75.09
loss: 0.3128, acc: 69.17, test_acc: 82.95, f1: 69.11
loss: 0.6248, acc: 69.15, test_acc: 80.98, f1: 64.49
loss: 0.5053, acc: 69.34, test_acc: 82.14, f1: 65.95
>> saved: state_dict/lcf_bert_restaurant_acc83.66
max_acc:83.66  f1:71.05
loss: 0.2523, acc: 70.08, test_acc: 83.66, f1: 71.05
>> saved: state_dict/lcf_bert_restaurant_acc85.62
max_acc:85.62  f1:76.68
loss: 0.6532, acc: 70.04, test_acc: 85.62, f1: 76.68
loss: 0.4797, acc: 70.36, test_acc: 83.48, f1: 71.60
loss: 0.8113, acc: 70.49, test_acc: 82.32, f1: 67.79
loss: 0.2497, acc: 71.11, test_acc: 83.21, f1: 68.67
loss: 0.5311, acc: 71.38, test_acc: 82.86, f1: 67.60
loss: 0.4399, acc: 71.79, test_acc: 84.73, f1: 73.65
loss: 0.5976, acc: 72.03, test_acc: 84.20, f1: 74.94
loss: 0.3409, acc: 72.41, test_acc: 84.55, f1: 75.56
loss: 0.5149, acc: 72.47, test_acc: 84.29, f1: 74.07
loss: 0.4334, acc: 72.53, test_acc: 83.93, f1: 72.49
loss: 0.3692, acc: 72.73, test_acc: 84.11, f1: 72.42
loss: 0.4121, acc: 72.78, test_acc: 83.57, f1: 73.44
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.7264, acc: 81.25, test_acc: 84.82, f1: 74.87
loss: 0.1111, acc: 90.62, test_acc: 84.64, f1: 75.53
loss: 0.5470, acc: 87.50, test_acc: 84.11, f1: 74.11
loss: 0.2646, acc: 87.50, test_acc: 84.91, f1: 73.61
loss: 0.1277, acc: 88.75, test_acc: 84.55, f1: 74.09
loss: 0.5691, acc: 85.42, test_acc: 84.91, f1: 75.50
loss: 0.4307, acc: 85.71, test_acc: 84.29, f1: 77.72
loss: 0.4874, acc: 83.59, test_acc: 84.64, f1: 72.94
loss: 0.1696, acc: 85.42, test_acc: 83.93, f1: 71.07
loss: 0.3112, acc: 86.25, test_acc: 84.11, f1: 73.84
loss: 0.4347, acc: 86.36, test_acc: 84.38, f1: 75.09
loss: 0.1931, acc: 86.98, test_acc: 84.73, f1: 74.97
loss: 0.4670, acc: 87.02, test_acc: 83.04, f1: 67.56
loss: 0.6162, acc: 86.16, test_acc: 84.20, f1: 71.45
loss: 0.1641, acc: 86.67, test_acc: 85.45, f1: 76.93
loss: 0.6327, acc: 86.72, test_acc: 85.45, f1: 76.42
loss: 0.2943, acc: 87.13, test_acc: 84.20, f1: 72.67
loss: 0.2698, acc: 87.15, test_acc: 85.54, f1: 76.10
>> saved: state_dict/lcf_bert_restaurant_acc85.71
max_acc:85.71  f1:78.54
loss: 0.5698, acc: 86.18, test_acc: 85.71, f1: 78.54
loss: 0.1546, acc: 86.56, test_acc: 85.54, f1: 76.94
loss: 0.7109, acc: 86.01, test_acc: 84.55, f1: 72.92
loss: 0.5270, acc: 85.80, test_acc: 85.54, f1: 78.06
loss: 0.3105, acc: 86.14, test_acc: 85.09, f1: 76.05
loss: 0.3298, acc: 86.20, test_acc: 84.73, f1: 73.42
loss: 0.5484, acc: 85.75, test_acc: 84.91, f1: 73.89
>> saved: state_dict/lcf_bert_restaurant_acc85.8
max_acc:85.8  f1:77.33
loss: 0.3166, acc: 85.58, test_acc: 85.80, f1: 77.33
loss: 0.1870, acc: 85.88, test_acc: 83.84, f1: 72.36
loss: 0.1157, acc: 86.38, test_acc: 83.66, f1: 71.24
loss: 0.1951, acc: 86.42, test_acc: 85.27, f1: 76.22
>> saved: state_dict/lcf_bert_restaurant_acc85.89
max_acc:85.89  f1:79.25
loss: 0.7465, acc: 86.04, test_acc: 85.89, f1: 79.25
loss: 0.3767, acc: 86.09, test_acc: 85.45, f1: 77.01
loss: 0.3809, acc: 85.94, test_acc: 84.11, f1: 73.02
>> saved: state_dict/lcf_bert_restaurant_acc86.34
max_acc:86.34  f1:78.0
loss: 0.2032, acc: 86.17, test_acc: 86.34, f1: 78.00
loss: 0.5873, acc: 86.03, test_acc: 86.16, f1: 78.59
loss: 0.2805, acc: 86.07, test_acc: 83.12, f1: 69.95
loss: 0.2602, acc: 86.11, test_acc: 83.93, f1: 74.09
loss: 0.2243, acc: 86.32, test_acc: 84.38, f1: 75.67
loss: 0.3181, acc: 86.18, test_acc: 85.62, f1: 77.14
loss: 0.2028, acc: 86.22, test_acc: 84.55, f1: 72.53
>> saved: state_dict/lcf_bert_restaurant_acc86.52
max_acc:86.52  f1:80.51
loss: 0.3716, acc: 86.09, test_acc: 86.52, f1: 80.51
loss: 0.6668, acc: 85.67, test_acc: 85.98, f1: 77.94
loss: 0.5682, acc: 85.42, test_acc: 82.23, f1: 67.62
loss: 0.0456, acc: 85.76, test_acc: 83.48, f1: 71.13
>> saved: state_dict/lcf_bert_restaurant_acc86.61
max_acc:86.61  f1:79.59
loss: 0.3580, acc: 85.80, test_acc: 86.61, f1: 79.59
loss: 0.3294, acc: 85.69, test_acc: 86.61, f1: 79.65
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2852, acc: 93.75, test_acc: 86.43, f1: 78.28
loss: 0.1987, acc: 93.75, test_acc: 86.25, f1: 77.45
loss: 0.2622, acc: 93.75, test_acc: 86.07, f1: 76.80
loss: 0.0430, acc: 95.31, test_acc: 86.16, f1: 77.26
>> saved: state_dict/lcf_bert_restaurant_acc87.14
max_acc:87.14  f1:80.04
loss: 0.2374, acc: 93.75, test_acc: 87.14, f1: 80.04
>> saved: state_dict/lcf_bert_restaurant_acc87.68
max_acc:87.68  f1:80.9
loss: 0.0642, acc: 94.79, test_acc: 87.68, f1: 80.90
loss: 0.1325, acc: 94.64, test_acc: 86.25, f1: 77.70
loss: 0.1715, acc: 94.53, test_acc: 86.96, f1: 79.51
loss: 0.1140, acc: 95.14, test_acc: 87.32, f1: 81.42
loss: 0.0162, acc: 95.62, test_acc: 86.43, f1: 79.63
loss: 0.2550, acc: 94.89, test_acc: 85.54, f1: 75.90
loss: 0.3394, acc: 94.79, test_acc: 84.82, f1: 75.33
loss: 0.2549, acc: 94.71, test_acc: 85.80, f1: 78.93
loss: 0.2741, acc: 94.64, test_acc: 86.52, f1: 79.38
loss: 0.2523, acc: 94.58, test_acc: 84.82, f1: 73.28
loss: 0.2636, acc: 94.14, test_acc: 85.98, f1: 77.55
loss: 0.0966, acc: 94.49, test_acc: 85.09, f1: 76.95
loss: 0.2194, acc: 94.10, test_acc: 87.32, f1: 81.33
loss: 0.2495, acc: 94.08, test_acc: 87.41, f1: 80.37
loss: 1.0489, acc: 92.50, test_acc: 84.11, f1: 70.81
loss: 0.0930, acc: 92.56, test_acc: 84.55, f1: 73.94
loss: 0.1718, acc: 92.61, test_acc: 85.71, f1: 77.88
loss: 0.3800, acc: 92.39, test_acc: 86.16, f1: 78.34
loss: 0.2010, acc: 92.45, test_acc: 86.25, f1: 78.70
loss: 0.0782, acc: 92.75, test_acc: 85.98, f1: 78.70
loss: 0.3677, acc: 91.83, test_acc: 85.62, f1: 77.05
loss: 0.1032, acc: 92.13, test_acc: 85.62, f1: 76.19
loss: 0.5300, acc: 91.74, test_acc: 85.36, f1: 75.38
loss: 0.0278, acc: 92.03, test_acc: 86.16, f1: 78.25
loss: 0.1111, acc: 92.29, test_acc: 86.88, f1: 79.76
loss: 0.1380, acc: 92.34, test_acc: 85.89, f1: 77.89
loss: 0.2795, acc: 91.99, test_acc: 86.96, f1: 80.17
loss: 0.2434, acc: 92.05, test_acc: 87.23, f1: 80.15
loss: 0.3102, acc: 91.91, test_acc: 87.23, f1: 80.17
loss: 0.0902, acc: 92.14, test_acc: 86.96, f1: 79.57
loss: 0.1256, acc: 92.36, test_acc: 86.52, f1: 78.95
loss: 0.2022, acc: 92.23, test_acc: 86.34, f1: 78.59
loss: 0.0159, acc: 92.43, test_acc: 86.61, f1: 79.09
loss: 0.1541, acc: 92.47, test_acc: 86.25, f1: 77.34
loss: 0.3455, acc: 92.34, test_acc: 86.70, f1: 79.32
loss: 0.2891, acc: 92.23, test_acc: 87.05, f1: 80.22
loss: 0.1211, acc: 92.26, test_acc: 86.43, f1: 79.07
loss: 0.1890, acc: 92.30, test_acc: 85.80, f1: 77.30
loss: 0.4925, acc: 92.19, test_acc: 85.71, f1: 76.61
loss: 0.0153, acc: 92.36, test_acc: 86.43, f1: 77.75
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0166, acc: 100.00, test_acc: 86.52, f1: 78.23
loss: 0.0425, acc: 100.00, test_acc: 86.52, f1: 78.32
loss: 0.0061, acc: 100.00, test_acc: 86.34, f1: 78.42
loss: 0.0157, acc: 100.00, test_acc: 87.23, f1: 80.11
loss: 0.0895, acc: 100.00, test_acc: 86.43, f1: 78.89
loss: 0.0415, acc: 100.00, test_acc: 86.70, f1: 79.72
loss: 0.0138, acc: 100.00, test_acc: 86.70, f1: 79.25
loss: 0.2623, acc: 99.22, test_acc: 86.70, f1: 79.82
loss: 0.0195, acc: 99.31, test_acc: 87.23, f1: 80.50
loss: 0.1416, acc: 98.75, test_acc: 86.61, f1: 78.67
>> saved: state_dict/lcf_bert_restaurant_acc87.77
max_acc:87.77  f1:81.06
loss: 0.3076, acc: 97.73, test_acc: 87.77, f1: 81.06
>> saved: state_dict/lcf_bert_restaurant_acc88.04
max_acc:88.04  f1:83.06
loss: 0.0341, acc: 97.92, test_acc: 88.04, f1: 83.06
>> saved: state_dict/lcf_bert_restaurant_acc88.48
max_acc:88.48  f1:83.15
loss: 0.0294, acc: 98.08, test_acc: 88.48, f1: 83.15
loss: 0.0671, acc: 98.21, test_acc: 86.96, f1: 79.91
loss: 0.0426, acc: 98.33, test_acc: 86.61, f1: 78.64
loss: 0.0203, acc: 98.44, test_acc: 86.16, f1: 77.60
loss: 0.1304, acc: 97.79, test_acc: 87.14, f1: 80.48
loss: 0.3088, acc: 97.22, test_acc: 87.86, f1: 82.14
loss: 0.1058, acc: 97.04, test_acc: 86.34, f1: 78.08
loss: 0.0705, acc: 96.88, test_acc: 85.09, f1: 74.67
loss: 0.1109, acc: 96.73, test_acc: 86.07, f1: 76.76
loss: 0.0066, acc: 96.88, test_acc: 86.43, f1: 77.64
loss: 0.3092, acc: 96.74, test_acc: 87.23, f1: 79.60
loss: 0.2299, acc: 96.61, test_acc: 87.50, f1: 80.75
loss: 0.0932, acc: 96.50, test_acc: 88.48, f1: 82.46
loss: 0.0127, acc: 96.63, test_acc: 87.14, f1: 79.95
loss: 0.0805, acc: 96.53, test_acc: 86.61, f1: 78.51
loss: 0.0169, acc: 96.65, test_acc: 86.34, f1: 78.27
loss: 0.0286, acc: 96.77, test_acc: 86.61, f1: 78.75
loss: 0.1146, acc: 96.67, test_acc: 87.50, f1: 80.95
loss: 0.0534, acc: 96.77, test_acc: 86.43, f1: 77.89
loss: 0.1561, acc: 96.68, test_acc: 86.52, f1: 78.22
loss: 0.0021, acc: 96.78, test_acc: 86.61, f1: 79.37
loss: 0.0281, acc: 96.88, test_acc: 86.34, f1: 78.87
loss: 0.0518, acc: 96.96, test_acc: 87.14, f1: 79.92
loss: 0.0102, acc: 97.05, test_acc: 86.88, f1: 78.66
loss: 0.1333, acc: 96.96, test_acc: 86.07, f1: 75.72
loss: 0.0999, acc: 96.88, test_acc: 85.98, f1: 75.64
loss: 0.2203, acc: 96.79, test_acc: 87.23, f1: 79.01
loss: 0.1302, acc: 96.56, test_acc: 87.68, f1: 81.10
loss: 0.0302, acc: 96.65, test_acc: 86.88, f1: 79.53
loss: 0.2545, acc: 96.43, test_acc: 86.16, f1: 77.34
loss: 0.2286, acc: 96.37, test_acc: 87.23, f1: 80.57
loss: 0.0553, acc: 96.45, test_acc: 85.89, f1: 78.25
loss: 0.1155, acc: 96.39, test_acc: 84.91, f1: 76.06
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0929, acc: 93.75, test_acc: 84.11, f1: 74.45
loss: 0.0125, acc: 96.88, test_acc: 85.36, f1: 76.91
loss: 0.0156, acc: 97.92, test_acc: 86.61, f1: 79.14
loss: 0.0489, acc: 98.44, test_acc: 87.68, f1: 80.73
loss: 0.0570, acc: 98.75, test_acc: 87.50, f1: 80.81
loss: 0.0259, acc: 98.96, test_acc: 88.30, f1: 82.74
>> saved: state_dict/lcf_bert_restaurant_acc88.57
max_acc:88.57  f1:82.97
loss: 0.0173, acc: 99.11, test_acc: 88.57, f1: 82.97
loss: 0.0061, acc: 99.22, test_acc: 88.39, f1: 82.21
loss: 0.0697, acc: 99.31, test_acc: 87.41, f1: 80.29
>> saved: state_dict/lcf_bert_restaurant_acc88.66
max_acc:88.66  f1:82.7
loss: 0.0207, acc: 99.38, test_acc: 88.66, f1: 82.70
>> saved: state_dict/lcf_bert_restaurant_acc88.93
max_acc:88.93  f1:83.32
loss: 0.0063, acc: 99.43, test_acc: 88.93, f1: 83.32
loss: 0.0156, acc: 99.48, test_acc: 88.30, f1: 81.59
loss: 0.0130, acc: 99.52, test_acc: 87.77, f1: 79.67
loss: 0.1994, acc: 99.11, test_acc: 87.86, f1: 79.91
loss: 0.0021, acc: 99.17, test_acc: 88.66, f1: 82.23
loss: 0.0053, acc: 99.22, test_acc: 88.21, f1: 81.53
loss: 0.0177, acc: 99.26, test_acc: 86.34, f1: 77.29
loss: 0.1126, acc: 98.96, test_acc: 85.89, f1: 76.23
loss: 0.0042, acc: 99.01, test_acc: 87.23, f1: 79.46
loss: 0.1084, acc: 98.75, test_acc: 87.86, f1: 80.89
loss: 0.0725, acc: 98.51, test_acc: 88.04, f1: 82.29
loss: 0.0808, acc: 98.58, test_acc: 87.23, f1: 80.69
loss: 0.0228, acc: 98.64, test_acc: 86.52, f1: 78.79
loss: 0.0332, acc: 98.70, test_acc: 85.80, f1: 77.30
loss: 0.0525, acc: 98.75, test_acc: 86.52, f1: 78.75
loss: 0.0064, acc: 98.80, test_acc: 86.25, f1: 78.65
loss: 0.0681, acc: 98.61, test_acc: 86.70, f1: 78.67
loss: 0.0774, acc: 98.44, test_acc: 85.80, f1: 76.02
loss: 0.0038, acc: 98.49, test_acc: 87.41, f1: 79.69
loss: 0.0283, acc: 98.54, test_acc: 88.57, f1: 82.87
loss: 0.0026, acc: 98.59, test_acc: 88.75, f1: 83.19
loss: 0.0164, acc: 98.63, test_acc: 86.70, f1: 78.09
loss: 0.0930, acc: 98.67, test_acc: 85.36, f1: 74.24
loss: 0.0181, acc: 98.71, test_acc: 86.52, f1: 78.06
loss: 0.1756, acc: 98.57, test_acc: 88.39, f1: 82.60
loss: 0.0728, acc: 98.44, test_acc: 87.68, f1: 81.25
loss: 0.0286, acc: 98.48, test_acc: 85.80, f1: 76.57
loss: 0.1239, acc: 98.36, test_acc: 85.27, f1: 74.97
loss: 0.0020, acc: 98.40, test_acc: 85.00, f1: 74.30
loss: 0.0145, acc: 98.44, test_acc: 85.98, f1: 76.47
loss: 0.1287, acc: 98.32, test_acc: 86.43, f1: 78.40
loss: 0.0158, acc: 98.36, test_acc: 86.61, f1: 78.99
loss: 0.0498, acc: 98.40, test_acc: 86.34, f1: 78.47
loss: 0.0592, acc: 98.30, test_acc: 86.34, f1: 78.22
loss: 0.0775, acc: 98.19, test_acc: 86.52, f1: 78.58
loss: 0.0122, acc: 98.21, test_acc: 86.34, f1: 78.19
####################################################################################################
max_test_acc_overall:88.92857142857142
max_f1_overall:83.32149945322475
####################################################################################################
1 test_acc_overall: 89.55  f1_overall:84.65
2 test_acc_overall: 88.93  f1_overall:83.32
max_acc_overall:89.55  f1_overall:84.65
mean_acc_overall:89.24  mean_f1_overall:83.98
####################################################################################################
lcf_bert - restaurant - lcf_fusion - No.3 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 2
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc58.66
max_acc:58.66  f1:30.41
loss: 0.8664, acc: 62.50, test_acc: 58.66, f1: 30.41
loss: 0.8924, acc: 59.38, test_acc: 40.45, f1: 29.42
>> saved: state_dict/lcf_bert_restaurant_acc65.0
max_acc:65.0  f1:26.26
loss: 0.8404, acc: 62.50, test_acc: 65.00, f1: 26.26
loss: 1.2839, acc: 54.69, test_acc: 65.00, f1: 26.26
>> saved: state_dict/lcf_bert_restaurant_acc66.52
max_acc:66.52  f1:32.28
loss: 0.9854, acc: 55.00, test_acc: 66.52, f1: 32.28
>> saved: state_dict/lcf_bert_restaurant_acc66.96
max_acc:66.96  f1:34.02
loss: 0.8962, acc: 56.25, test_acc: 66.96, f1: 34.02
>> saved: state_dict/lcf_bert_restaurant_acc69.38
max_acc:69.38  f1:41.71
loss: 0.7200, acc: 59.82, test_acc: 69.38, f1: 41.71
>> saved: state_dict/lcf_bert_restaurant_acc72.68
max_acc:72.68  f1:47.12
loss: 0.8337, acc: 60.94, test_acc: 72.68, f1: 47.12
>> saved: state_dict/lcf_bert_restaurant_acc77.41
max_acc:77.41  f1:53.52
loss: 0.4175, acc: 63.89, test_acc: 77.41, f1: 53.52
>> saved: state_dict/lcf_bert_restaurant_acc78.66
max_acc:78.66  f1:60.69
loss: 0.5184, acc: 65.62, test_acc: 78.66, f1: 60.69
loss: 0.8487, acc: 66.48, test_acc: 70.54, f1: 46.69
loss: 0.7267, acc: 66.67, test_acc: 73.75, f1: 55.69
loss: 0.5453, acc: 66.83, test_acc: 78.21, f1: 58.58
loss: 0.5985, acc: 67.41, test_acc: 77.86, f1: 54.91
loss: 0.5840, acc: 67.50, test_acc: 78.12, f1: 58.09
loss: 0.5266, acc: 67.97, test_acc: 78.12, f1: 55.41
>> saved: state_dict/lcf_bert_restaurant_acc78.75
max_acc:78.75  f1:59.64
loss: 0.6165, acc: 68.38, test_acc: 78.75, f1: 59.64
>> saved: state_dict/lcf_bert_restaurant_acc79.91
max_acc:79.91  f1:63.83
loss: 0.4419, acc: 69.44, test_acc: 79.91, f1: 63.83
loss: 0.5071, acc: 70.07, test_acc: 79.02, f1: 59.87
loss: 0.3941, acc: 70.00, test_acc: 78.30, f1: 62.35
>> saved: state_dict/lcf_bert_restaurant_acc82.41
max_acc:82.41  f1:70.93
loss: 0.4009, acc: 70.54, test_acc: 82.41, f1: 70.93
loss: 0.2682, acc: 71.88, test_acc: 80.98, f1: 65.18
loss: 0.6245, acc: 72.28, test_acc: 78.66, f1: 55.58
loss: 0.6751, acc: 72.14, test_acc: 79.38, f1: 56.16
loss: 0.6848, acc: 72.50, test_acc: 81.52, f1: 65.78
loss: 0.6751, acc: 72.36, test_acc: 82.05, f1: 70.51
loss: 0.4917, acc: 72.45, test_acc: 80.54, f1: 61.79
loss: 0.3934, acc: 72.77, test_acc: 81.79, f1: 65.67
>> saved: state_dict/lcf_bert_restaurant_acc83.3
max_acc:83.3  f1:72.27
loss: 0.6967, acc: 72.63, test_acc: 83.30, f1: 72.27
>> saved: state_dict/lcf_bert_restaurant_acc83.66
max_acc:83.66  f1:73.81
loss: 0.5719, acc: 72.71, test_acc: 83.66, f1: 73.81
>> saved: state_dict/lcf_bert_restaurant_acc83.93
max_acc:83.93  f1:73.83
loss: 0.7104, acc: 72.78, test_acc: 83.93, f1: 73.83
loss: 0.5711, acc: 72.85, test_acc: 81.96, f1: 64.56
loss: 0.6270, acc: 73.11, test_acc: 80.18, f1: 59.91
loss: 0.5684, acc: 73.16, test_acc: 81.79, f1: 66.46
>> saved: state_dict/lcf_bert_restaurant_acc84.64
max_acc:84.64  f1:74.52
loss: 0.6614, acc: 73.21, test_acc: 84.64, f1: 74.52
loss: 0.4358, acc: 73.09, test_acc: 83.57, f1: 73.86
loss: 0.7751, acc: 72.97, test_acc: 83.04, f1: 71.75
loss: 0.4873, acc: 73.03, test_acc: 84.55, f1: 76.65
loss: 0.2480, acc: 73.56, test_acc: 83.39, f1: 71.89
loss: 0.2518, acc: 73.91, test_acc: 83.12, f1: 68.64
loss: 0.3911, acc: 74.09, test_acc: 82.77, f1: 70.48
loss: 0.2770, acc: 74.40, test_acc: 83.39, f1: 72.73
>> saved: state_dict/lcf_bert_restaurant_acc85.0
max_acc:85.0  f1:76.72
loss: 0.5040, acc: 74.42, test_acc: 85.00, f1: 76.72
loss: 0.3232, acc: 74.57, test_acc: 84.29, f1: 71.91
loss: 0.7256, acc: 74.58, test_acc: 83.93, f1: 70.40
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.3174, acc: 87.50, test_acc: 84.55, f1: 73.58
loss: 0.1945, acc: 93.75, test_acc: 84.46, f1: 72.86
loss: 0.1483, acc: 93.75, test_acc: 84.82, f1: 72.77
>> saved: state_dict/lcf_bert_restaurant_acc85.45
max_acc:85.45  f1:75.19
loss: 0.4584, acc: 92.19, test_acc: 85.45, f1: 75.19
loss: 0.5002, acc: 88.75, test_acc: 85.27, f1: 76.45
>> saved: state_dict/lcf_bert_restaurant_acc85.8
max_acc:85.8  f1:76.8
loss: 0.3507, acc: 85.42, test_acc: 85.80, f1: 76.80
loss: 0.1424, acc: 86.61, test_acc: 84.46, f1: 72.75
loss: 0.2125, acc: 87.50, test_acc: 85.71, f1: 77.02
loss: 0.2561, acc: 87.50, test_acc: 84.55, f1: 76.67
loss: 0.4987, acc: 86.88, test_acc: 85.54, f1: 76.85
loss: 0.5494, acc: 86.36, test_acc: 83.84, f1: 70.81
loss: 0.1577, acc: 86.98, test_acc: 82.59, f1: 65.84
loss: 0.4621, acc: 86.54, test_acc: 83.21, f1: 70.57
>> saved: state_dict/lcf_bert_restaurant_acc85.98
max_acc:85.98  f1:77.98
loss: 0.4386, acc: 86.16, test_acc: 85.98, f1: 77.98
loss: 0.1905, acc: 87.08, test_acc: 85.54, f1: 75.42
loss: 0.3185, acc: 87.50, test_acc: 84.55, f1: 72.94
>> saved: state_dict/lcf_bert_restaurant_acc86.07
max_acc:86.07  f1:77.76
loss: 0.1690, acc: 87.87, test_acc: 86.07, f1: 77.76
loss: 0.4654, acc: 87.15, test_acc: 84.73, f1: 76.56
loss: 0.1743, acc: 87.17, test_acc: 84.55, f1: 75.29
loss: 0.0571, acc: 87.81, test_acc: 83.75, f1: 72.25
loss: 0.4025, acc: 87.50, test_acc: 84.55, f1: 74.04
loss: 0.4910, acc: 87.22, test_acc: 85.71, f1: 77.90
loss: 0.4812, acc: 86.96, test_acc: 85.54, f1: 77.27
loss: 0.3254, acc: 86.98, test_acc: 84.02, f1: 74.65
loss: 0.1960, acc: 87.25, test_acc: 84.55, f1: 74.00
loss: 0.5990, acc: 86.78, test_acc: 84.20, f1: 72.48
loss: 0.4630, acc: 86.34, test_acc: 84.73, f1: 75.07
loss: 0.4155, acc: 86.16, test_acc: 84.82, f1: 75.49
loss: 0.1465, acc: 86.42, test_acc: 85.54, f1: 77.59
loss: 0.4379, acc: 86.25, test_acc: 85.71, f1: 77.33
loss: 0.4343, acc: 86.29, test_acc: 86.07, f1: 77.65
loss: 0.3164, acc: 86.33, test_acc: 85.71, f1: 76.89
loss: 0.4258, acc: 86.36, test_acc: 85.80, f1: 76.71
>> saved: state_dict/lcf_bert_restaurant_acc86.16
max_acc:86.16  f1:78.09
loss: 0.5531, acc: 86.21, test_acc: 86.16, f1: 78.09
>> saved: state_dict/lcf_bert_restaurant_acc86.79
max_acc:86.79  f1:78.43
loss: 0.5403, acc: 85.89, test_acc: 86.79, f1: 78.43
loss: 0.4631, acc: 85.76, test_acc: 84.82, f1: 73.10
loss: 0.2221, acc: 85.98, test_acc: 85.71, f1: 77.46
loss: 0.3527, acc: 86.02, test_acc: 85.45, f1: 77.44
loss: 0.4307, acc: 86.22, test_acc: 85.36, f1: 75.95
loss: 0.2890, acc: 86.25, test_acc: 85.09, f1: 75.00
loss: 0.2533, acc: 86.43, test_acc: 85.54, f1: 75.99
loss: 0.4061, acc: 86.46, test_acc: 86.34, f1: 78.97
loss: 0.5852, acc: 86.05, test_acc: 85.27, f1: 76.19
loss: 0.2872, acc: 86.22, test_acc: 84.20, f1: 72.15
loss: 0.5643, acc: 86.11, test_acc: 84.29, f1: 72.86
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1150, acc: 100.00, test_acc: 84.20, f1: 74.51
loss: 0.2636, acc: 93.75, test_acc: 84.11, f1: 74.57
loss: 0.3391, acc: 91.67, test_acc: 86.25, f1: 77.70
loss: 0.0584, acc: 93.75, test_acc: 84.29, f1: 71.03
loss: 0.1343, acc: 93.75, test_acc: 85.09, f1: 74.12
loss: 0.0995, acc: 94.79, test_acc: 85.62, f1: 77.32
loss: 0.1839, acc: 94.64, test_acc: 85.62, f1: 77.48
loss: 0.0506, acc: 95.31, test_acc: 86.52, f1: 78.93
loss: 0.0559, acc: 95.83, test_acc: 86.61, f1: 78.57
loss: 0.3884, acc: 95.00, test_acc: 86.52, f1: 79.02
loss: 0.2945, acc: 94.89, test_acc: 85.98, f1: 79.26
loss: 0.6004, acc: 92.71, test_acc: 85.98, f1: 77.55
loss: 0.1975, acc: 92.31, test_acc: 85.45, f1: 77.10
loss: 0.0404, acc: 92.86, test_acc: 85.45, f1: 76.86
loss: 0.1833, acc: 92.92, test_acc: 85.45, f1: 75.82
loss: 0.4865, acc: 92.58, test_acc: 85.45, f1: 74.57
>> saved: state_dict/lcf_bert_restaurant_acc87.14
max_acc:87.14  f1:80.3
loss: 0.3391, acc: 92.28, test_acc: 87.14, f1: 80.30
loss: 0.0986, acc: 92.71, test_acc: 86.79, f1: 79.67
loss: 0.0546, acc: 93.09, test_acc: 86.61, f1: 79.26
loss: 0.1096, acc: 93.12, test_acc: 86.96, f1: 79.50
>> saved: state_dict/lcf_bert_restaurant_acc87.59
max_acc:87.59  f1:80.72
loss: 0.2809, acc: 93.15, test_acc: 87.59, f1: 80.72
loss: 0.0141, acc: 93.47, test_acc: 85.54, f1: 77.39
loss: 0.1314, acc: 93.48, test_acc: 85.89, f1: 77.94
loss: 0.4126, acc: 92.97, test_acc: 85.62, f1: 76.35
loss: 0.0477, acc: 93.25, test_acc: 86.88, f1: 80.75
loss: 0.2186, acc: 93.27, test_acc: 85.98, f1: 78.52
loss: 0.1748, acc: 92.82, test_acc: 85.71, f1: 75.47
loss: 0.0602, acc: 93.08, test_acc: 85.27, f1: 75.42
loss: 0.1366, acc: 93.10, test_acc: 85.18, f1: 76.54
loss: 0.0965, acc: 93.12, test_acc: 84.29, f1: 75.47
loss: 0.2789, acc: 92.94, test_acc: 85.98, f1: 78.17
loss: 0.3853, acc: 92.97, test_acc: 87.23, f1: 80.64
loss: 0.3770, acc: 92.99, test_acc: 85.80, f1: 77.17
loss: 0.1885, acc: 92.83, test_acc: 85.18, f1: 74.56
loss: 0.1199, acc: 92.86, test_acc: 85.98, f1: 78.00
loss: 0.3062, acc: 92.88, test_acc: 86.34, f1: 79.02
loss: 0.0640, acc: 93.07, test_acc: 86.43, f1: 79.38
loss: 0.2695, acc: 92.93, test_acc: 86.34, f1: 78.59
loss: 0.3324, acc: 92.79, test_acc: 84.20, f1: 70.67
loss: 0.2307, acc: 92.66, test_acc: 85.80, f1: 76.46
loss: 0.1064, acc: 92.84, test_acc: 87.05, f1: 81.18
loss: 0.3194, acc: 92.71, test_acc: 87.14, f1: 81.12
loss: 0.2397, acc: 92.59, test_acc: 86.16, f1: 77.82
loss: 0.4183, acc: 92.33, test_acc: 85.89, f1: 76.90
>> saved: state_dict/lcf_bert_restaurant_acc87.95
max_acc:87.95  f1:81.75
loss: 0.0987, acc: 92.36, test_acc: 87.95, f1: 81.75
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0438, acc: 100.00, test_acc: 87.86, f1: 81.36
loss: 0.1054, acc: 96.88, test_acc: 86.88, f1: 78.12
loss: 0.4371, acc: 91.67, test_acc: 86.70, f1: 77.97
loss: 0.1242, acc: 92.19, test_acc: 87.77, f1: 81.25
loss: 0.1177, acc: 92.50, test_acc: 86.79, f1: 79.61
loss: 0.0610, acc: 93.75, test_acc: 86.07, f1: 77.96
loss: 0.1327, acc: 93.75, test_acc: 86.07, f1: 77.36
loss: 0.0581, acc: 94.53, test_acc: 87.59, f1: 80.68
>> saved: state_dict/lcf_bert_restaurant_acc88.12
max_acc:88.12  f1:82.07
loss: 0.0554, acc: 95.14, test_acc: 88.12, f1: 82.07
loss: 0.0141, acc: 95.62, test_acc: 87.50, f1: 80.63
loss: 0.0190, acc: 96.02, test_acc: 85.89, f1: 77.09
loss: 0.0064, acc: 96.35, test_acc: 86.34, f1: 77.93
loss: 0.0175, acc: 96.63, test_acc: 86.70, f1: 78.81
loss: 0.0166, acc: 96.88, test_acc: 87.59, f1: 80.30
loss: 0.0174, acc: 97.08, test_acc: 86.88, f1: 78.94
loss: 0.0248, acc: 97.27, test_acc: 86.61, f1: 78.48
loss: 0.0319, acc: 97.43, test_acc: 87.50, f1: 81.31
loss: 0.2125, acc: 97.22, test_acc: 87.32, f1: 81.73
loss: 0.1389, acc: 97.04, test_acc: 87.05, f1: 80.28
loss: 0.2203, acc: 96.56, test_acc: 86.43, f1: 77.98
loss: 0.0135, acc: 96.73, test_acc: 85.71, f1: 76.22
loss: 0.2078, acc: 96.59, test_acc: 87.05, f1: 79.72
loss: 0.0226, acc: 96.74, test_acc: 86.70, f1: 80.71
loss: 0.0448, acc: 96.88, test_acc: 87.68, f1: 81.09
loss: 0.0028, acc: 97.00, test_acc: 86.07, f1: 76.65
loss: 0.2167, acc: 96.88, test_acc: 85.09, f1: 74.92
loss: 0.2407, acc: 96.76, test_acc: 87.05, f1: 80.45
loss: 0.1195, acc: 96.65, test_acc: 84.46, f1: 80.10
loss: 0.0545, acc: 96.77, test_acc: 87.23, f1: 80.61
loss: 0.2163, acc: 96.67, test_acc: 85.45, f1: 76.61
loss: 0.2208, acc: 96.57, test_acc: 85.18, f1: 75.36
loss: 0.0601, acc: 96.68, test_acc: 85.00, f1: 75.61
loss: 0.0203, acc: 96.78, test_acc: 85.45, f1: 76.75
loss: 0.0450, acc: 96.88, test_acc: 85.89, f1: 77.38
loss: 0.4016, acc: 96.25, test_acc: 85.98, f1: 77.70
loss: 0.0762, acc: 96.35, test_acc: 85.54, f1: 77.12
loss: 0.2980, acc: 96.11, test_acc: 85.36, f1: 76.88
loss: 0.6012, acc: 95.72, test_acc: 85.89, f1: 78.44
loss: 0.0222, acc: 95.83, test_acc: 85.54, f1: 76.94
loss: 0.0854, acc: 95.78, test_acc: 85.54, f1: 77.72
loss: 0.0167, acc: 95.88, test_acc: 86.52, f1: 79.65
loss: 0.0612, acc: 95.98, test_acc: 86.96, f1: 80.22
loss: 0.0135, acc: 96.08, test_acc: 86.34, f1: 78.05
loss: 0.1379, acc: 96.02, test_acc: 85.71, f1: 75.91
loss: 0.1236, acc: 95.97, test_acc: 85.45, f1: 76.43
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0265, acc: 100.00, test_acc: 85.89, f1: 78.24
loss: 0.2255, acc: 96.88, test_acc: 86.43, f1: 79.66
loss: 0.0311, acc: 97.92, test_acc: 86.52, f1: 79.85
loss: 0.0308, acc: 98.44, test_acc: 86.70, f1: 80.13
loss: 0.0156, acc: 98.75, test_acc: 86.88, f1: 79.84
loss: 0.0173, acc: 98.96, test_acc: 86.70, f1: 78.69
loss: 0.0455, acc: 99.11, test_acc: 86.16, f1: 77.42
loss: 0.0151, acc: 99.22, test_acc: 86.52, f1: 78.34
loss: 0.0172, acc: 99.31, test_acc: 87.32, f1: 80.45
loss: 0.0199, acc: 99.38, test_acc: 87.68, f1: 81.15
loss: 0.0612, acc: 99.43, test_acc: 87.23, f1: 80.68
loss: 0.0081, acc: 99.48, test_acc: 87.23, f1: 80.66
loss: 0.0199, acc: 99.52, test_acc: 87.23, f1: 79.95
loss: 0.0204, acc: 99.55, test_acc: 87.05, f1: 79.64
loss: 0.0316, acc: 99.58, test_acc: 86.07, f1: 78.11
loss: 0.0054, acc: 99.61, test_acc: 85.36, f1: 77.41
loss: 0.0958, acc: 99.26, test_acc: 85.54, f1: 78.02
loss: 0.0174, acc: 99.31, test_acc: 85.62, f1: 76.81
loss: 0.0030, acc: 99.34, test_acc: 85.80, f1: 76.77
loss: 0.2098, acc: 99.06, test_acc: 86.16, f1: 77.86
loss: 0.0037, acc: 99.11, test_acc: 86.61, f1: 78.34
loss: 0.1854, acc: 98.86, test_acc: 86.52, f1: 78.15
loss: 0.0132, acc: 98.91, test_acc: 86.61, f1: 79.20
loss: 0.0364, acc: 98.96, test_acc: 86.70, f1: 79.73
loss: 0.0093, acc: 99.00, test_acc: 86.34, f1: 79.22
loss: 0.0028, acc: 99.04, test_acc: 86.07, f1: 78.79
loss: 0.1247, acc: 98.84, test_acc: 85.54, f1: 77.63
loss: 0.0039, acc: 98.88, test_acc: 86.16, f1: 78.28
loss: 0.0066, acc: 98.92, test_acc: 87.05, f1: 79.13
loss: 0.2811, acc: 98.75, test_acc: 86.79, f1: 78.68
loss: 0.0325, acc: 98.79, test_acc: 86.61, f1: 78.74
loss: 0.0277, acc: 98.83, test_acc: 86.70, f1: 79.97
loss: 0.1113, acc: 98.67, test_acc: 86.79, f1: 80.11
loss: 0.0076, acc: 98.71, test_acc: 86.70, f1: 79.28
loss: 0.0079, acc: 98.75, test_acc: 86.34, f1: 77.91
loss: 0.1008, acc: 98.61, test_acc: 86.70, f1: 78.43
loss: 0.2246, acc: 98.48, test_acc: 87.14, f1: 79.93
loss: 0.0154, acc: 98.52, test_acc: 87.14, f1: 80.04
loss: 0.0030, acc: 98.56, test_acc: 86.79, f1: 78.97
loss: 0.0928, acc: 98.44, test_acc: 86.61, f1: 78.55
loss: 0.0140, acc: 98.48, test_acc: 86.61, f1: 78.93
loss: 0.1495, acc: 98.36, test_acc: 86.88, f1: 79.39
loss: 0.0359, acc: 98.40, test_acc: 86.70, f1: 78.86
loss: 0.1133, acc: 98.30, test_acc: 86.88, f1: 79.19
loss: 0.0012, acc: 98.33, test_acc: 86.88, f1: 79.44
loss: 0.1912, acc: 98.21, test_acc: 86.79, f1: 79.10
####################################################################################################
max_test_acc_overall:88.125
max_f1_overall:82.06551210360227
####################################################################################################
1 test_acc_overall: 89.55  f1_overall:84.65
2 test_acc_overall: 88.93  f1_overall:83.32
3 test_acc_overall: 88.12  f1_overall:82.07
max_acc_overall:89.55  f1_overall:84.65
mean_acc_overall:88.87  mean_f1_overall:83.34
####################################################################################################
lcf_bert - restaurant - lcf_fusion - No.4 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 3
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc51.25
max_acc:51.25  f1:34.58
loss: 0.9472, acc: 62.50, test_acc: 51.25, f1: 34.58
>> saved: state_dict/lcf_bert_restaurant_acc65.36
max_acc:65.36  f1:27.65
loss: 0.5187, acc: 68.75, test_acc: 65.36, f1: 27.65
>> saved: state_dict/lcf_bert_restaurant_acc69.91
max_acc:69.91  f1:43.82
loss: 1.0694, acc: 60.42, test_acc: 69.91, f1: 43.82
loss: 0.8356, acc: 60.94, test_acc: 65.36, f1: 27.65
>> saved: state_dict/lcf_bert_restaurant_acc70.36
max_acc:70.36  f1:42.21
loss: 0.7723, acc: 62.50, test_acc: 70.36, f1: 42.21
>> saved: state_dict/lcf_bert_restaurant_acc74.11
max_acc:74.11  f1:49.4
loss: 0.6130, acc: 67.71, test_acc: 74.11, f1: 49.40
>> saved: state_dict/lcf_bert_restaurant_acc76.61
max_acc:76.61  f1:52.71
loss: 0.5532, acc: 69.64, test_acc: 76.61, f1: 52.71
>> saved: state_dict/lcf_bert_restaurant_acc78.48
max_acc:78.48  f1:60.56
loss: 0.5688, acc: 71.09, test_acc: 78.48, f1: 60.56
>> saved: state_dict/lcf_bert_restaurant_acc80.54
max_acc:80.54  f1:67.0
loss: 0.5283, acc: 71.53, test_acc: 80.54, f1: 67.00
loss: 0.7316, acc: 70.62, test_acc: 79.73, f1: 65.90
loss: 0.4445, acc: 71.59, test_acc: 79.82, f1: 64.27
>> saved: state_dict/lcf_bert_restaurant_acc82.05
max_acc:82.05  f1:71.82
loss: 0.4155, acc: 72.40, test_acc: 82.05, f1: 71.82
loss: 0.5454, acc: 72.60, test_acc: 78.30, f1: 62.83
loss: 0.5413, acc: 73.21, test_acc: 78.84, f1: 61.77
loss: 0.5542, acc: 72.92, test_acc: 80.80, f1: 65.01
loss: 0.8381, acc: 73.05, test_acc: 79.73, f1: 59.84
>> saved: state_dict/lcf_bert_restaurant_acc82.5
max_acc:82.5  f1:69.42
loss: 0.6153, acc: 73.53, test_acc: 82.50, f1: 69.42
loss: 0.7240, acc: 72.92, test_acc: 82.50, f1: 70.62
>> saved: state_dict/lcf_bert_restaurant_acc82.68
max_acc:82.68  f1:71.93
loss: 0.4496, acc: 73.36, test_acc: 82.68, f1: 71.93
>> saved: state_dict/lcf_bert_restaurant_acc82.86
max_acc:82.86  f1:70.41
loss: 0.6874, acc: 73.12, test_acc: 82.86, f1: 70.41
>> saved: state_dict/lcf_bert_restaurant_acc83.3
max_acc:83.3  f1:70.87
loss: 0.4029, acc: 73.81, test_acc: 83.30, f1: 70.87
loss: 0.8030, acc: 73.58, test_acc: 82.68, f1: 71.03
loss: 0.8551, acc: 73.37, test_acc: 82.32, f1: 71.74
loss: 0.6747, acc: 73.70, test_acc: 82.14, f1: 71.01
loss: 0.5837, acc: 73.75, test_acc: 82.32, f1: 70.27
loss: 0.3924, acc: 74.04, test_acc: 82.32, f1: 67.31
loss: 0.6683, acc: 73.61, test_acc: 83.21, f1: 74.22
>> saved: state_dict/lcf_bert_restaurant_acc83.75
max_acc:83.75  f1:74.11
loss: 0.6786, acc: 73.44, test_acc: 83.75, f1: 74.11
loss: 0.8883, acc: 73.06, test_acc: 82.59, f1: 68.41
>> saved: state_dict/lcf_bert_restaurant_acc84.2
max_acc:84.2  f1:72.9
loss: 0.6053, acc: 73.33, test_acc: 84.20, f1: 72.90
>> saved: state_dict/lcf_bert_restaurant_acc84.91
max_acc:84.91  f1:75.24
loss: 0.3947, acc: 73.79, test_acc: 84.91, f1: 75.24
>> saved: state_dict/lcf_bert_restaurant_acc85.09
max_acc:85.09  f1:75.65
loss: 0.7166, acc: 73.63, test_acc: 85.09, f1: 75.65
loss: 0.3240, acc: 74.05, test_acc: 84.02, f1: 73.15
loss: 0.1855, acc: 74.82, test_acc: 84.02, f1: 72.93
>> saved: state_dict/lcf_bert_restaurant_acc85.36
max_acc:85.36  f1:77.27
loss: 0.3871, acc: 75.00, test_acc: 85.36, f1: 77.27
loss: 0.3525, acc: 75.35, test_acc: 85.27, f1: 77.34
loss: 0.5540, acc: 75.51, test_acc: 85.27, f1: 78.19
loss: 0.4875, acc: 75.66, test_acc: 83.48, f1: 72.45
loss: 0.3853, acc: 75.80, test_acc: 83.39, f1: 69.35
loss: 0.2136, acc: 76.09, test_acc: 84.55, f1: 73.29
>> saved: state_dict/lcf_bert_restaurant_acc86.34
max_acc:86.34  f1:78.81
loss: 0.5249, acc: 76.07, test_acc: 86.34, f1: 78.81
loss: 0.4870, acc: 76.04, test_acc: 85.09, f1: 76.87
loss: 0.8457, acc: 75.87, test_acc: 84.38, f1: 74.95
loss: 0.4910, acc: 75.85, test_acc: 85.09, f1: 74.33
loss: 0.3671, acc: 76.11, test_acc: 85.62, f1: 76.03
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.1440, acc: 100.00, test_acc: 85.62, f1: 75.76
loss: 0.5698, acc: 87.50, test_acc: 83.66, f1: 72.02
loss: 0.5805, acc: 85.42, test_acc: 84.29, f1: 73.18
loss: 0.2779, acc: 85.94, test_acc: 85.00, f1: 73.90
loss: 0.6146, acc: 85.00, test_acc: 85.45, f1: 76.81
loss: 0.7136, acc: 82.29, test_acc: 85.89, f1: 80.22
loss: 0.2805, acc: 83.04, test_acc: 83.39, f1: 69.10
loss: 0.2539, acc: 84.38, test_acc: 82.14, f1: 63.74
loss: 0.3428, acc: 84.72, test_acc: 85.62, f1: 75.61
>> saved: state_dict/lcf_bert_restaurant_acc86.79
max_acc:86.79  f1:79.5
loss: 0.1848, acc: 85.00, test_acc: 86.79, f1: 79.50
loss: 0.2113, acc: 85.80, test_acc: 85.98, f1: 77.53
loss: 0.4073, acc: 85.42, test_acc: 86.07, f1: 76.85
loss: 0.5651, acc: 84.13, test_acc: 86.79, f1: 79.26
loss: 0.1615, acc: 84.82, test_acc: 82.68, f1: 73.28
loss: 0.2080, acc: 85.00, test_acc: 83.39, f1: 73.64
loss: 1.0743, acc: 84.38, test_acc: 83.48, f1: 71.29
loss: 0.4935, acc: 84.19, test_acc: 84.82, f1: 74.62
loss: 0.2939, acc: 84.38, test_acc: 85.71, f1: 76.69
loss: 0.3475, acc: 83.88, test_acc: 84.11, f1: 73.84
loss: 0.6846, acc: 83.75, test_acc: 85.18, f1: 76.03
loss: 0.3357, acc: 84.23, test_acc: 85.54, f1: 78.19
loss: 0.3364, acc: 84.09, test_acc: 85.36, f1: 75.54
loss: 0.6958, acc: 83.97, test_acc: 85.27, f1: 74.63
loss: 0.2855, acc: 83.85, test_acc: 85.71, f1: 77.44
loss: 0.5957, acc: 83.50, test_acc: 85.80, f1: 77.84
loss: 0.3950, acc: 83.41, test_acc: 85.89, f1: 78.15
loss: 0.2364, acc: 83.80, test_acc: 86.16, f1: 78.40
loss: 0.1934, acc: 84.15, test_acc: 85.89, f1: 77.22
loss: 0.6537, acc: 84.05, test_acc: 86.07, f1: 77.53
loss: 0.3738, acc: 84.17, test_acc: 85.98, f1: 77.45
loss: 0.3156, acc: 84.27, test_acc: 85.71, f1: 76.32
loss: 0.4768, acc: 84.18, test_acc: 85.98, f1: 77.74
loss: 0.5490, acc: 84.09, test_acc: 84.73, f1: 76.35
loss: 0.3567, acc: 84.19, test_acc: 84.91, f1: 76.83
loss: 0.1606, acc: 84.46, test_acc: 85.36, f1: 75.11
loss: 0.3904, acc: 84.38, test_acc: 84.55, f1: 71.55
loss: 0.2141, acc: 84.63, test_acc: 85.89, f1: 76.16
loss: 0.4358, acc: 84.38, test_acc: 85.27, f1: 76.88
loss: 0.3189, acc: 84.46, test_acc: 85.09, f1: 77.43
loss: 0.2850, acc: 84.53, test_acc: 85.00, f1: 76.45
loss: 0.2671, acc: 84.60, test_acc: 85.18, f1: 76.29
>> saved: state_dict/lcf_bert_restaurant_acc87.14
max_acc:87.14  f1:79.6
loss: 0.5849, acc: 84.38, test_acc: 87.14, f1: 79.60
loss: 0.0873, acc: 84.74, test_acc: 86.07, f1: 78.05
loss: 0.2565, acc: 84.80, test_acc: 85.36, f1: 76.77
loss: 0.2315, acc: 84.86, test_acc: 85.71, f1: 76.86
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2320, acc: 87.50, test_acc: 84.46, f1: 73.19
loss: 0.1031, acc: 90.62, test_acc: 85.62, f1: 76.06
>> saved: state_dict/lcf_bert_restaurant_acc87.41
max_acc:87.41  f1:80.58
loss: 0.0758, acc: 93.75, test_acc: 87.41, f1: 80.58
loss: 0.0680, acc: 95.31, test_acc: 87.41, f1: 81.18
loss: 0.0686, acc: 96.25, test_acc: 85.62, f1: 77.16
loss: 0.0749, acc: 96.88, test_acc: 84.46, f1: 74.05
loss: 0.2329, acc: 95.54, test_acc: 84.73, f1: 74.66
loss: 0.1409, acc: 95.31, test_acc: 85.71, f1: 77.55
loss: 0.2126, acc: 94.44, test_acc: 86.34, f1: 78.70
loss: 0.1935, acc: 94.38, test_acc: 84.91, f1: 75.24
loss: 0.1822, acc: 93.75, test_acc: 85.62, f1: 76.89
loss: 0.1525, acc: 93.75, test_acc: 86.43, f1: 78.74
loss: 0.2262, acc: 93.75, test_acc: 87.41, f1: 80.95
loss: 0.0738, acc: 94.20, test_acc: 86.96, f1: 79.84
loss: 0.1130, acc: 94.17, test_acc: 85.98, f1: 77.59
loss: 0.1938, acc: 93.75, test_acc: 85.98, f1: 77.13
>> saved: state_dict/lcf_bert_restaurant_acc88.39
max_acc:88.39  f1:82.99
loss: 0.2233, acc: 93.75, test_acc: 88.39, f1: 82.99
loss: 0.1355, acc: 93.75, test_acc: 87.23, f1: 79.85
loss: 0.2432, acc: 93.42, test_acc: 86.88, f1: 77.97
loss: 0.0834, acc: 93.44, test_acc: 86.88, f1: 78.71
loss: 0.2953, acc: 93.45, test_acc: 88.12, f1: 81.82
loss: 0.1817, acc: 93.18, test_acc: 86.25, f1: 77.33
loss: 0.3236, acc: 92.93, test_acc: 85.62, f1: 75.55
loss: 0.0581, acc: 93.23, test_acc: 87.86, f1: 81.17
loss: 0.4890, acc: 92.75, test_acc: 88.21, f1: 82.56
>> saved: state_dict/lcf_bert_restaurant_acc89.46
max_acc:89.46  f1:84.71
loss: 0.2617, acc: 92.55, test_acc: 89.46, f1: 84.71
loss: 0.0969, acc: 92.59, test_acc: 87.50, f1: 80.39
loss: 0.0514, acc: 92.86, test_acc: 86.25, f1: 78.09
loss: 0.4696, acc: 92.67, test_acc: 85.71, f1: 77.50
loss: 0.3182, acc: 92.50, test_acc: 85.89, f1: 77.66
loss: 0.2331, acc: 92.34, test_acc: 87.95, f1: 81.74
loss: 0.0609, acc: 92.58, test_acc: 87.86, f1: 81.17
loss: 0.0234, acc: 92.80, test_acc: 88.48, f1: 82.87
loss: 0.3682, acc: 92.65, test_acc: 88.30, f1: 82.21
loss: 0.0722, acc: 92.68, test_acc: 87.50, f1: 80.43
loss: 0.1795, acc: 92.71, test_acc: 87.68, f1: 80.72
loss: 0.1356, acc: 92.74, test_acc: 88.48, f1: 82.08
loss: 0.2402, acc: 92.76, test_acc: 87.68, f1: 80.66
loss: 0.2946, acc: 92.47, test_acc: 86.34, f1: 78.41
loss: 0.8390, acc: 91.88, test_acc: 85.00, f1: 75.77
loss: 0.2625, acc: 91.92, test_acc: 86.96, f1: 79.63
loss: 0.1772, acc: 91.96, test_acc: 87.59, f1: 80.98
loss: 0.2886, acc: 91.72, test_acc: 86.79, f1: 78.79
loss: 0.0407, acc: 91.90, test_acc: 87.41, f1: 80.11
loss: 0.2341, acc: 91.81, test_acc: 86.52, f1: 78.25
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0978, acc: 100.00, test_acc: 86.88, f1: 79.04
loss: 0.2326, acc: 93.75, test_acc: 87.59, f1: 81.10
loss: 0.0404, acc: 95.83, test_acc: 87.23, f1: 79.83
loss: 0.0654, acc: 95.31, test_acc: 87.14, f1: 79.14
loss: 0.0440, acc: 96.25, test_acc: 88.39, f1: 81.73
loss: 0.1282, acc: 95.83, test_acc: 88.39, f1: 81.69
loss: 0.0905, acc: 95.54, test_acc: 88.12, f1: 80.74
loss: 0.0195, acc: 96.09, test_acc: 87.86, f1: 81.02
loss: 0.0138, acc: 96.53, test_acc: 88.12, f1: 81.90
loss: 0.0642, acc: 96.25, test_acc: 87.77, f1: 81.29
loss: 0.0554, acc: 96.59, test_acc: 87.41, f1: 80.86
loss: 0.5812, acc: 95.83, test_acc: 88.12, f1: 82.10
loss: 0.0370, acc: 96.15, test_acc: 89.11, f1: 84.33
loss: 0.2524, acc: 95.54, test_acc: 89.02, f1: 83.56
loss: 0.0707, acc: 95.42, test_acc: 87.68, f1: 80.07
loss: 0.2110, acc: 94.92, test_acc: 87.50, f1: 79.56
loss: 0.2702, acc: 94.85, test_acc: 89.20, f1: 83.62
loss: 0.0194, acc: 95.14, test_acc: 89.29, f1: 84.40
loss: 0.0040, acc: 95.39, test_acc: 87.86, f1: 81.62
loss: 0.0250, acc: 95.62, test_acc: 87.68, f1: 81.24
loss: 0.0826, acc: 95.83, test_acc: 87.59, f1: 80.93
loss: 0.0207, acc: 96.02, test_acc: 87.05, f1: 80.05
loss: 0.1088, acc: 95.92, test_acc: 86.07, f1: 78.20
loss: 0.1092, acc: 95.83, test_acc: 86.07, f1: 78.26
loss: 0.1061, acc: 95.75, test_acc: 85.62, f1: 77.45
loss: 0.1219, acc: 95.67, test_acc: 85.98, f1: 78.19
loss: 0.0633, acc: 95.60, test_acc: 86.43, f1: 79.43
loss: 0.0138, acc: 95.76, test_acc: 86.16, f1: 78.44
loss: 0.0691, acc: 95.69, test_acc: 86.25, f1: 78.42
loss: 0.0143, acc: 95.83, test_acc: 87.50, f1: 81.20
loss: 0.0130, acc: 95.97, test_acc: 87.05, f1: 79.71
loss: 0.1256, acc: 95.90, test_acc: 87.23, f1: 79.17
loss: 0.1644, acc: 95.83, test_acc: 87.05, f1: 79.79
loss: 0.3194, acc: 95.77, test_acc: 87.68, f1: 81.19
loss: 0.0317, acc: 95.89, test_acc: 87.14, f1: 79.46
loss: 0.1879, acc: 95.83, test_acc: 87.05, f1: 79.52
loss: 0.1141, acc: 95.78, test_acc: 87.95, f1: 81.62
loss: 0.0669, acc: 95.89, test_acc: 87.95, f1: 82.00
loss: 0.0703, acc: 95.83, test_acc: 88.12, f1: 82.31
loss: 0.0042, acc: 95.94, test_acc: 86.52, f1: 78.09
loss: 0.1872, acc: 95.73, test_acc: 86.52, f1: 77.89
loss: 0.0137, acc: 95.83, test_acc: 86.34, f1: 77.72
loss: 0.0442, acc: 95.93, test_acc: 86.96, f1: 79.74
loss: 0.1366, acc: 95.74, test_acc: 87.59, f1: 81.31
loss: 0.0157, acc: 95.83, test_acc: 87.77, f1: 81.23
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0274, acc: 100.00, test_acc: 87.14, f1: 80.34
loss: 0.0079, acc: 100.00, test_acc: 87.50, f1: 81.01
loss: 0.0296, acc: 100.00, test_acc: 86.96, f1: 79.80
loss: 0.0180, acc: 100.00, test_acc: 85.89, f1: 76.30
loss: 0.0677, acc: 98.75, test_acc: 85.00, f1: 73.79
loss: 0.0087, acc: 98.96, test_acc: 86.79, f1: 77.85
loss: 0.0465, acc: 99.11, test_acc: 87.86, f1: 81.18
loss: 0.0398, acc: 99.22, test_acc: 88.12, f1: 82.42
loss: 0.0072, acc: 99.31, test_acc: 88.21, f1: 82.25
loss: 0.1263, acc: 98.75, test_acc: 87.41, f1: 80.15
loss: 0.0724, acc: 98.30, test_acc: 86.34, f1: 77.50
loss: 0.0138, acc: 98.44, test_acc: 86.61, f1: 78.04
loss: 0.0048, acc: 98.56, test_acc: 87.59, f1: 80.62
loss: 0.0053, acc: 98.66, test_acc: 88.12, f1: 81.81
loss: 0.0033, acc: 98.75, test_acc: 88.30, f1: 82.32
loss: 0.0118, acc: 98.83, test_acc: 88.30, f1: 82.45
loss: 0.0030, acc: 98.90, test_acc: 88.21, f1: 82.50
loss: 0.0053, acc: 98.96, test_acc: 88.66, f1: 83.10
loss: 0.0026, acc: 99.01, test_acc: 88.66, f1: 82.69
loss: 0.0153, acc: 99.06, test_acc: 88.48, f1: 82.39
loss: 0.0077, acc: 99.11, test_acc: 88.84, f1: 83.83
loss: 0.1102, acc: 98.58, test_acc: 88.04, f1: 83.17
loss: 0.0263, acc: 98.64, test_acc: 88.04, f1: 81.77
loss: 0.0008, acc: 98.70, test_acc: 86.52, f1: 77.98
loss: 0.0511, acc: 98.50, test_acc: 85.89, f1: 77.00
loss: 0.0343, acc: 98.56, test_acc: 86.96, f1: 80.19
loss: 0.0733, acc: 98.61, test_acc: 87.86, f1: 81.74
loss: 0.0076, acc: 98.66, test_acc: 88.12, f1: 82.14
loss: 0.0062, acc: 98.71, test_acc: 88.57, f1: 82.58
loss: 0.0146, acc: 98.75, test_acc: 87.95, f1: 80.95
loss: 0.1475, acc: 98.59, test_acc: 88.75, f1: 82.67
loss: 0.0113, acc: 98.63, test_acc: 88.57, f1: 82.75
loss: 0.1488, acc: 98.48, test_acc: 88.39, f1: 82.33
loss: 0.1099, acc: 98.35, test_acc: 88.12, f1: 81.35
loss: 0.0449, acc: 98.39, test_acc: 86.96, f1: 78.69
loss: 0.0080, acc: 98.44, test_acc: 86.07, f1: 77.11
loss: 0.6228, acc: 98.14, test_acc: 87.14, f1: 79.63
loss: 0.0144, acc: 98.19, test_acc: 88.84, f1: 83.51
loss: 0.0082, acc: 98.24, test_acc: 88.57, f1: 83.44
loss: 0.0110, acc: 98.28, test_acc: 88.30, f1: 81.74
loss: 0.0112, acc: 98.32, test_acc: 88.39, f1: 80.94
loss: 0.0705, acc: 98.21, test_acc: 87.95, f1: 80.01
loss: 0.0065, acc: 98.26, test_acc: 87.86, f1: 80.01
loss: 0.0125, acc: 98.30, test_acc: 89.02, f1: 83.73
loss: 0.0044, acc: 98.33, test_acc: 88.93, f1: 83.72
loss: 0.0297, acc: 98.35, test_acc: 89.02, f1: 83.96
####################################################################################################
max_test_acc_overall:89.46428571428572
max_f1_overall:84.71254577601292
####################################################################################################
1 test_acc_overall: 89.55  f1_overall:84.65
2 test_acc_overall: 88.93  f1_overall:83.32
3 test_acc_overall: 88.12  f1_overall:82.07
4 test_acc_overall: 89.46  f1_overall:84.71
max_acc_overall:89.55  f1_overall:84.65
mean_acc_overall:89.02  mean_f1_overall:83.69
####################################################################################################
lcf_bert - restaurant - lcf_fusion - No.5 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: restaurant
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 5
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 4
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_restaurant_acc65.0
max_acc:65.0  f1:26.26
loss: 1.2124, acc: 62.50, test_acc: 65.00, f1: 26.26
>> saved: state_dict/lcf_bert_restaurant_acc65.36
max_acc:65.36  f1:28.57
loss: 1.0723, acc: 53.12, test_acc: 65.36, f1: 28.57
>> saved: state_dict/lcf_bert_restaurant_acc65.62
max_acc:65.62  f1:28.66
loss: 0.9828, acc: 56.25, test_acc: 65.62, f1: 28.66
>> saved: state_dict/lcf_bert_restaurant_acc66.16
max_acc:66.16  f1:30.82
loss: 1.0166, acc: 54.69, test_acc: 66.16, f1: 30.82
loss: 0.6345, acc: 60.00, test_acc: 65.54, f1: 28.63
>> saved: state_dict/lcf_bert_restaurant_acc72.95
max_acc:72.95  f1:49.62
loss: 0.8169, acc: 60.42, test_acc: 72.95, f1: 49.62
>> saved: state_dict/lcf_bert_restaurant_acc73.39
max_acc:73.39  f1:48.16
loss: 0.6705, acc: 63.39, test_acc: 73.39, f1: 48.16
loss: 0.8757, acc: 63.28, test_acc: 72.77, f1: 51.23
>> saved: state_dict/lcf_bert_restaurant_acc78.66
max_acc:78.66  f1:63.43
loss: 0.9689, acc: 62.50, test_acc: 78.66, f1: 63.43
loss: 0.8214, acc: 63.12, test_acc: 75.71, f1: 51.17
loss: 0.9584, acc: 62.50, test_acc: 78.21, f1: 54.63
>> saved: state_dict/lcf_bert_restaurant_acc79.02
max_acc:79.02  f1:60.48
loss: 0.5080, acc: 63.54, test_acc: 79.02, f1: 60.48
loss: 0.5872, acc: 63.94, test_acc: 78.66, f1: 58.35
>> saved: state_dict/lcf_bert_restaurant_acc80.0
max_acc:80.0  f1:61.28
loss: 0.6320, acc: 64.29, test_acc: 80.00, f1: 61.28
>> saved: state_dict/lcf_bert_restaurant_acc82.32
max_acc:82.32  f1:70.3
loss: 0.7008, acc: 64.17, test_acc: 82.32, f1: 70.30
>> saved: state_dict/lcf_bert_restaurant_acc82.41
max_acc:82.41  f1:70.46
loss: 0.2187, acc: 66.41, test_acc: 82.41, f1: 70.46
loss: 0.5689, acc: 66.91, test_acc: 80.89, f1: 65.52
loss: 0.4771, acc: 68.06, test_acc: 81.34, f1: 65.12
loss: 0.7955, acc: 68.09, test_acc: 80.62, f1: 63.21
loss: 0.7190, acc: 68.44, test_acc: 81.79, f1: 68.68
>> saved: state_dict/lcf_bert_restaurant_acc83.12
max_acc:83.12  f1:73.48
loss: 0.6935, acc: 67.86, test_acc: 83.12, f1: 73.48
loss: 0.4986, acc: 68.18, test_acc: 79.55, f1: 59.63
loss: 0.3887, acc: 69.02, test_acc: 78.84, f1: 56.92
>> saved: state_dict/lcf_bert_restaurant_acc83.48
max_acc:83.48  f1:74.7
loss: 0.3856, acc: 69.53, test_acc: 83.48, f1: 74.70
loss: 0.6628, acc: 69.25, test_acc: 83.48, f1: 74.78
loss: 0.9604, acc: 68.75, test_acc: 81.16, f1: 66.93
loss: 0.8106, acc: 68.98, test_acc: 82.32, f1: 67.64
>> saved: state_dict/lcf_bert_restaurant_acc83.57
max_acc:83.57  f1:73.16
loss: 0.6150, acc: 69.42, test_acc: 83.57, f1: 73.16
>> saved: state_dict/lcf_bert_restaurant_acc84.38
max_acc:84.38  f1:75.23
loss: 0.3324, acc: 70.26, test_acc: 84.38, f1: 75.23
loss: 0.6197, acc: 70.42, test_acc: 81.96, f1: 66.85
loss: 0.2183, acc: 71.17, test_acc: 81.25, f1: 63.12
loss: 0.8789, acc: 70.90, test_acc: 83.84, f1: 72.63
>> saved: state_dict/lcf_bert_restaurant_acc85.8
max_acc:85.8  f1:78.0
loss: 0.6194, acc: 71.40, test_acc: 85.80, f1: 78.00
loss: 0.5291, acc: 71.69, test_acc: 83.93, f1: 72.33
loss: 0.6568, acc: 71.43, test_acc: 82.14, f1: 67.35
loss: 0.4568, acc: 71.70, test_acc: 84.73, f1: 75.29
loss: 0.4078, acc: 72.13, test_acc: 85.27, f1: 78.17
loss: 0.2288, acc: 72.70, test_acc: 83.93, f1: 72.22
loss: 0.5925, acc: 72.92, test_acc: 84.20, f1: 73.13
loss: 0.1951, acc: 73.44, test_acc: 82.77, f1: 71.67
loss: 0.2073, acc: 73.93, test_acc: 83.66, f1: 72.77
loss: 1.2721, acc: 73.51, test_acc: 84.64, f1: 74.62
loss: 0.2273, acc: 73.84, test_acc: 84.46, f1: 73.69
loss: 0.8129, acc: 73.58, test_acc: 85.71, f1: 78.92
loss: 0.5595, acc: 73.47, test_acc: 85.80, f1: 77.51
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.0951, acc: 100.00, test_acc: 80.98, f1: 63.62
loss: 0.2994, acc: 93.75, test_acc: 80.54, f1: 61.97
loss: 0.1448, acc: 95.83, test_acc: 82.95, f1: 67.12
loss: 0.1419, acc: 95.31, test_acc: 84.38, f1: 71.81
loss: 0.5112, acc: 93.75, test_acc: 85.80, f1: 77.79
loss: 0.5298, acc: 92.71, test_acc: 85.71, f1: 77.64
loss: 0.3171, acc: 91.07, test_acc: 84.91, f1: 75.57
loss: 0.1537, acc: 91.41, test_acc: 84.20, f1: 74.00
loss: 0.3845, acc: 90.28, test_acc: 84.73, f1: 76.81
loss: 0.4706, acc: 90.00, test_acc: 84.73, f1: 75.76
loss: 0.3090, acc: 89.20, test_acc: 85.27, f1: 76.92
>> saved: state_dict/lcf_bert_restaurant_acc86.61
max_acc:86.61  f1:80.63
loss: 0.5410, acc: 88.54, test_acc: 86.61, f1: 80.63
loss: 0.2636, acc: 88.94, test_acc: 85.27, f1: 77.00
loss: 0.0980, acc: 89.73, test_acc: 84.82, f1: 75.28
loss: 0.2737, acc: 90.00, test_acc: 84.64, f1: 75.50
loss: 0.3794, acc: 89.84, test_acc: 84.46, f1: 74.56
loss: 0.2285, acc: 89.71, test_acc: 84.73, f1: 75.58
loss: 0.1829, acc: 89.93, test_acc: 84.11, f1: 73.63
loss: 0.0876, acc: 90.46, test_acc: 84.11, f1: 74.12
loss: 0.4059, acc: 90.00, test_acc: 85.89, f1: 78.38
loss: 0.7133, acc: 89.29, test_acc: 86.16, f1: 78.48
loss: 0.2377, acc: 89.20, test_acc: 85.54, f1: 76.89
loss: 0.4176, acc: 88.86, test_acc: 83.66, f1: 73.95
loss: 0.2090, acc: 88.80, test_acc: 84.91, f1: 76.23
loss: 0.3491, acc: 89.00, test_acc: 85.18, f1: 78.42
loss: 0.6682, acc: 88.46, test_acc: 86.43, f1: 78.56
loss: 0.2949, acc: 88.43, test_acc: 83.75, f1: 71.61
loss: 0.5620, acc: 87.95, test_acc: 84.46, f1: 74.27
loss: 0.2600, acc: 88.15, test_acc: 86.61, f1: 79.82
>> saved: state_dict/lcf_bert_restaurant_acc86.7
max_acc:86.7  f1:80.06
loss: 0.5544, acc: 87.71, test_acc: 86.70, f1: 80.06
loss: 0.3520, acc: 87.50, test_acc: 84.46, f1: 73.67
loss: 0.3846, acc: 87.50, test_acc: 84.11, f1: 72.85
loss: 0.4422, acc: 87.50, test_acc: 84.73, f1: 76.26
loss: 0.3831, acc: 87.32, test_acc: 83.75, f1: 74.65
loss: 0.4050, acc: 86.96, test_acc: 85.71, f1: 77.59
loss: 0.1444, acc: 87.33, test_acc: 85.54, f1: 75.38
loss: 0.2173, acc: 87.33, test_acc: 84.46, f1: 73.54
loss: 0.2112, acc: 87.34, test_acc: 85.54, f1: 76.97
loss: 0.2376, acc: 87.34, test_acc: 85.45, f1: 76.17
loss: 1.0420, acc: 86.72, test_acc: 84.29, f1: 73.06
loss: 0.4485, acc: 86.59, test_acc: 83.93, f1: 72.52
loss: 0.1741, acc: 86.76, test_acc: 85.00, f1: 76.08
loss: 0.4487, acc: 86.63, test_acc: 86.34, f1: 78.01
loss: 0.3284, acc: 86.65, test_acc: 84.64, f1: 72.70
loss: 0.1769, acc: 86.67, test_acc: 83.04, f1: 70.30
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.5194, acc: 81.25, test_acc: 84.20, f1: 74.39
loss: 0.0523, acc: 90.62, test_acc: 85.89, f1: 77.89
loss: 0.1657, acc: 91.67, test_acc: 85.98, f1: 78.82
loss: 0.2024, acc: 90.62, test_acc: 86.25, f1: 78.34
loss: 0.3298, acc: 90.00, test_acc: 85.27, f1: 76.12
loss: 0.0976, acc: 90.62, test_acc: 85.80, f1: 77.57
loss: 0.2808, acc: 90.18, test_acc: 86.25, f1: 79.30
>> saved: state_dict/lcf_bert_restaurant_acc87.32
max_acc:87.32  f1:81.11
loss: 0.1732, acc: 90.62, test_acc: 87.32, f1: 81.11
loss: 0.1657, acc: 90.97, test_acc: 87.23, f1: 80.56
loss: 0.1278, acc: 91.25, test_acc: 85.27, f1: 75.69
loss: 0.3091, acc: 90.91, test_acc: 85.98, f1: 77.27
loss: 0.1787, acc: 90.62, test_acc: 85.89, f1: 77.99
loss: 0.2628, acc: 90.38, test_acc: 86.70, f1: 81.13
loss: 0.0689, acc: 91.07, test_acc: 86.70, f1: 79.86
loss: 0.0230, acc: 91.67, test_acc: 85.45, f1: 75.78
loss: 0.0666, acc: 92.19, test_acc: 87.05, f1: 80.21
loss: 0.4541, acc: 91.91, test_acc: 86.96, f1: 80.80
loss: 0.0541, acc: 92.36, test_acc: 86.07, f1: 77.85
loss: 0.1224, acc: 92.43, test_acc: 84.29, f1: 74.05
loss: 0.7825, acc: 91.56, test_acc: 84.29, f1: 72.97
loss: 0.0432, acc: 91.96, test_acc: 84.82, f1: 75.87
loss: 0.3169, acc: 92.05, test_acc: 84.46, f1: 75.72
loss: 0.1646, acc: 92.12, test_acc: 84.20, f1: 74.50
loss: 0.2075, acc: 91.93, test_acc: 83.57, f1: 72.76
loss: 0.2640, acc: 92.00, test_acc: 84.46, f1: 74.19
loss: 0.0228, acc: 92.31, test_acc: 85.45, f1: 76.48
loss: 0.1882, acc: 92.36, test_acc: 86.25, f1: 79.28
loss: 0.2310, acc: 92.19, test_acc: 85.89, f1: 76.98
loss: 0.0644, acc: 92.46, test_acc: 85.71, f1: 76.03
loss: 0.1584, acc: 92.50, test_acc: 85.98, f1: 76.83
loss: 0.0847, acc: 92.74, test_acc: 86.70, f1: 79.60
loss: 0.3244, acc: 92.38, test_acc: 87.14, f1: 80.33
>> saved: state_dict/lcf_bert_restaurant_acc87.5
max_acc:87.5  f1:80.51
loss: 0.1283, acc: 92.42, test_acc: 87.50, f1: 80.51
loss: 0.0367, acc: 92.65, test_acc: 86.79, f1: 79.14
loss: 0.1855, acc: 92.68, test_acc: 86.88, f1: 79.09
loss: 0.3644, acc: 92.53, test_acc: 86.96, f1: 78.53
loss: 0.4262, acc: 92.23, test_acc: 86.88, f1: 78.77
loss: 0.4697, acc: 92.11, test_acc: 87.50, f1: 80.98
>> saved: state_dict/lcf_bert_restaurant_acc88.21
max_acc:88.21  f1:82.44
loss: 0.3782, acc: 91.83, test_acc: 88.21, f1: 82.44
loss: 0.2158, acc: 91.88, test_acc: 86.07, f1: 76.14
loss: 0.1451, acc: 91.92, test_acc: 84.91, f1: 73.05
loss: 0.1766, acc: 91.82, test_acc: 85.98, f1: 77.27
loss: 0.2771, acc: 91.57, test_acc: 86.25, f1: 79.04
loss: 0.1566, acc: 91.62, test_acc: 86.70, f1: 80.14
loss: 0.0650, acc: 91.81, test_acc: 85.80, f1: 76.04
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.0784, acc: 100.00, test_acc: 85.54, f1: 74.71
loss: 0.0332, acc: 100.00, test_acc: 85.45, f1: 75.82
loss: 0.0207, acc: 100.00, test_acc: 85.89, f1: 77.65
loss: 0.1060, acc: 98.44, test_acc: 86.16, f1: 79.35
loss: 0.1092, acc: 97.50, test_acc: 86.43, f1: 79.67
loss: 0.1053, acc: 96.88, test_acc: 86.34, f1: 79.04
loss: 0.2493, acc: 96.43, test_acc: 86.16, f1: 77.02
loss: 0.0073, acc: 96.88, test_acc: 85.36, f1: 74.56
loss: 0.0592, acc: 97.22, test_acc: 85.71, f1: 75.46
loss: 0.0252, acc: 97.50, test_acc: 86.52, f1: 78.72
loss: 0.0249, acc: 97.73, test_acc: 87.50, f1: 81.22
loss: 0.0257, acc: 97.92, test_acc: 87.05, f1: 80.23
loss: 0.0250, acc: 98.08, test_acc: 86.07, f1: 78.03
loss: 0.0117, acc: 98.21, test_acc: 86.61, f1: 78.45
loss: 0.0573, acc: 98.33, test_acc: 86.34, f1: 77.42
loss: 0.3113, acc: 97.66, test_acc: 86.88, f1: 79.01
loss: 0.0856, acc: 97.43, test_acc: 86.16, f1: 78.26
loss: 0.0529, acc: 97.57, test_acc: 85.89, f1: 77.87
loss: 0.0520, acc: 97.70, test_acc: 85.09, f1: 76.13
loss: 0.1526, acc: 97.50, test_acc: 85.89, f1: 78.01
loss: 0.0438, acc: 97.62, test_acc: 87.32, f1: 80.95
loss: 0.2188, acc: 97.44, test_acc: 87.05, f1: 80.09
loss: 0.0197, acc: 97.55, test_acc: 86.88, f1: 79.33
loss: 0.1273, acc: 97.40, test_acc: 87.68, f1: 80.92
loss: 0.1274, acc: 97.50, test_acc: 87.77, f1: 81.90
loss: 0.0087, acc: 97.60, test_acc: 87.05, f1: 80.27
loss: 0.5264, acc: 96.99, test_acc: 85.80, f1: 77.57
loss: 0.0751, acc: 97.10, test_acc: 85.27, f1: 76.55
loss: 0.0048, acc: 97.20, test_acc: 85.62, f1: 77.15
loss: 0.0499, acc: 97.29, test_acc: 86.96, f1: 79.73
loss: 0.1791, acc: 96.98, test_acc: 87.41, f1: 80.43
loss: 0.0824, acc: 97.07, test_acc: 86.70, f1: 80.32
loss: 0.1053, acc: 96.97, test_acc: 86.88, f1: 79.99
loss: 0.1706, acc: 96.88, test_acc: 86.16, f1: 77.79
loss: 0.4183, acc: 96.79, test_acc: 85.71, f1: 76.89
loss: 0.0263, acc: 96.88, test_acc: 86.07, f1: 77.39
loss: 0.1159, acc: 96.96, test_acc: 85.98, f1: 77.61
loss: 0.0576, acc: 97.04, test_acc: 86.16, f1: 77.52
loss: 0.0170, acc: 97.12, test_acc: 86.07, f1: 77.23
loss: 0.3596, acc: 96.88, test_acc: 86.70, f1: 78.89
loss: 0.1173, acc: 96.80, test_acc: 86.88, f1: 79.41
loss: 0.1444, acc: 96.73, test_acc: 87.05, f1: 79.99
loss: 0.0126, acc: 96.80, test_acc: 87.23, f1: 79.86
loss: 0.1625, acc: 96.73, test_acc: 87.14, f1: 79.63
loss: 0.0205, acc: 96.81, test_acc: 87.41, f1: 80.34
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.0166, acc: 100.00, test_acc: 86.79, f1: 79.37
loss: 0.1658, acc: 96.88, test_acc: 86.25, f1: 78.42
loss: 0.0117, acc: 97.92, test_acc: 86.52, f1: 78.94
loss: 0.0184, acc: 98.44, test_acc: 86.61, f1: 79.17
loss: 0.0133, acc: 98.75, test_acc: 86.88, f1: 79.73
loss: 0.1751, acc: 97.92, test_acc: 86.34, f1: 78.35
loss: 0.0400, acc: 98.21, test_acc: 85.80, f1: 76.27
loss: 0.0102, acc: 98.44, test_acc: 85.89, f1: 76.13
loss: 0.0025, acc: 98.61, test_acc: 86.16, f1: 76.82
loss: 0.1136, acc: 98.12, test_acc: 86.52, f1: 77.51
loss: 0.2859, acc: 97.16, test_acc: 86.79, f1: 78.48
loss: 0.0681, acc: 97.40, test_acc: 87.14, f1: 79.82
loss: 0.0190, acc: 97.60, test_acc: 86.43, f1: 79.08
loss: 0.0799, acc: 97.32, test_acc: 86.52, f1: 79.37
loss: 0.0057, acc: 97.50, test_acc: 86.70, f1: 79.31
loss: 0.0274, acc: 97.66, test_acc: 86.79, f1: 78.89
loss: 0.0110, acc: 97.79, test_acc: 87.32, f1: 80.00
loss: 0.0039, acc: 97.92, test_acc: 87.14, f1: 80.03
loss: 0.0519, acc: 98.03, test_acc: 87.50, f1: 80.92
loss: 0.0305, acc: 98.12, test_acc: 87.14, f1: 80.16
loss: 0.0428, acc: 98.21, test_acc: 87.23, f1: 80.22
loss: 0.0039, acc: 98.30, test_acc: 86.52, f1: 78.30
loss: 0.0106, acc: 98.37, test_acc: 86.88, f1: 78.79
loss: 0.2674, acc: 98.18, test_acc: 87.14, f1: 79.23
loss: 0.0139, acc: 98.25, test_acc: 88.04, f1: 81.28
>> saved: state_dict/lcf_bert_restaurant_acc88.3
max_acc:88.3  f1:82.27
loss: 0.0289, acc: 98.32, test_acc: 88.30, f1: 82.27
loss: 0.0175, acc: 98.38, test_acc: 88.12, f1: 81.65
loss: 0.0413, acc: 98.44, test_acc: 87.59, f1: 80.78
loss: 0.0111, acc: 98.49, test_acc: 87.05, f1: 79.60
loss: 0.0225, acc: 98.54, test_acc: 86.70, f1: 79.23
loss: 0.0244, acc: 98.59, test_acc: 86.96, f1: 79.35
loss: 0.0521, acc: 98.63, test_acc: 87.86, f1: 81.11
>> saved: state_dict/lcf_bert_restaurant_acc88.66
max_acc:88.66  f1:82.88
loss: 0.0120, acc: 98.67, test_acc: 88.66, f1: 82.88
loss: 0.0035, acc: 98.71, test_acc: 87.95, f1: 81.29
loss: 0.0257, acc: 98.75, test_acc: 88.04, f1: 81.52
loss: 0.0025, acc: 98.78, test_acc: 86.61, f1: 78.24
loss: 0.1486, acc: 98.65, test_acc: 87.41, f1: 80.04
loss: 0.0068, acc: 98.68, test_acc: 87.59, f1: 81.16
loss: 0.0154, acc: 98.72, test_acc: 86.88, f1: 80.03
loss: 0.0226, acc: 98.75, test_acc: 87.59, f1: 81.07
loss: 0.0287, acc: 98.78, test_acc: 88.21, f1: 82.18
loss: 0.2446, acc: 98.66, test_acc: 88.12, f1: 82.00
loss: 0.0029, acc: 98.69, test_acc: 87.77, f1: 80.98
loss: 0.0463, acc: 98.72, test_acc: 86.16, f1: 77.09
loss: 0.1645, acc: 98.61, test_acc: 87.23, f1: 79.73
loss: 0.0383, acc: 98.63, test_acc: 86.61, f1: 78.26
####################################################################################################
max_test_acc_overall:88.66071428571428
max_f1_overall:82.87552931420392
####################################################################################################
1 test_acc_overall: 89.55  f1_overall:84.65
2 test_acc_overall: 88.93  f1_overall:83.32
3 test_acc_overall: 88.12  f1_overall:82.07
4 test_acc_overall: 89.46  f1_overall:84.71
5 test_acc_overall: 88.66  f1_overall:82.88
max_acc_overall:89.55  f1_overall:84.65
mean_acc_overall:88.95  mean_f1_overall:83.52
####################################################################################################
lcf_bert - twitter - lcf_fusion - No.1 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 0
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc50.0
max_acc:50.0  f1:22.22
loss: 1.7919, acc: 31.25, test_acc: 50.00, f1: 22.22
loss: 1.0043, acc: 43.75, test_acc: 50.00, f1: 22.22
loss: 1.2957, acc: 45.83, test_acc: 48.99, f1: 31.02
loss: 0.9768, acc: 42.19, test_acc: 28.76, f1: 20.33
loss: 0.9528, acc: 45.00, test_acc: 50.00, f1: 22.22
loss: 1.0095, acc: 45.83, test_acc: 38.58, f1: 30.62
>> saved: state_dict/lcf_bert_twitter_acc50.14
max_acc:50.14  f1:22.63
loss: 1.1664, acc: 43.75, test_acc: 50.14, f1: 22.63
loss: 0.9631, acc: 47.66, test_acc: 50.14, f1: 22.63
loss: 1.5413, acc: 43.75, test_acc: 50.00, f1: 22.22
loss: 1.3211, acc: 41.25, test_acc: 27.89, f1: 20.63
>> saved: state_dict/lcf_bert_twitter_acc51.16
max_acc:51.16  f1:25.34
loss: 0.9779, acc: 42.05, test_acc: 51.16, f1: 25.34
loss: 0.9751, acc: 42.71, test_acc: 50.29, f1: 23.03
>> saved: state_dict/lcf_bert_twitter_acc59.25
max_acc:59.25  f1:46.82
loss: 0.9677, acc: 42.31, test_acc: 59.25, f1: 46.82
>> saved: state_dict/lcf_bert_twitter_acc63.15
max_acc:63.15  f1:58.55
loss: 0.9470, acc: 43.30, test_acc: 63.15, f1: 58.55
>> saved: state_dict/lcf_bert_twitter_acc64.74
max_acc:64.74  f1:60.17
loss: 0.9195, acc: 43.33, test_acc: 64.74, f1: 60.17
loss: 0.9104, acc: 43.36, test_acc: 60.69, f1: 58.20
loss: 0.9968, acc: 44.12, test_acc: 62.57, f1: 61.06
>> saved: state_dict/lcf_bert_twitter_acc65.17
max_acc:65.17  f1:61.0
loss: 0.7849, acc: 44.79, test_acc: 65.17, f1: 61.00
loss: 0.7447, acc: 45.07, test_acc: 59.10, f1: 59.33
loss: 1.1908, acc: 44.69, test_acc: 60.12, f1: 46.63
loss: 0.9388, acc: 44.94, test_acc: 64.16, f1: 55.16
loss: 0.7717, acc: 45.74, test_acc: 58.67, f1: 59.12
loss: 0.9356, acc: 45.38, test_acc: 62.86, f1: 63.38
>> saved: state_dict/lcf_bert_twitter_acc66.18
max_acc:66.18  f1:60.17
loss: 0.6669, acc: 46.09, test_acc: 66.18, f1: 60.17
>> saved: state_dict/lcf_bert_twitter_acc69.36
max_acc:69.36  f1:65.56
loss: 0.8113, acc: 46.50, test_acc: 69.36, f1: 65.56
loss: 0.5727, acc: 47.60, test_acc: 66.47, f1: 64.83
loss: 0.6100, acc: 48.38, test_acc: 66.76, f1: 66.00
loss: 0.7679, acc: 48.66, test_acc: 64.02, f1: 63.63
loss: 1.1915, acc: 48.49, test_acc: 66.04, f1: 64.95
loss: 1.0130, acc: 48.75, test_acc: 66.47, f1: 65.18
loss: 0.6049, acc: 49.40, test_acc: 67.20, f1: 66.50
loss: 0.8329, acc: 50.00, test_acc: 69.08, f1: 67.65
loss: 0.8208, acc: 50.38, test_acc: 67.20, f1: 64.05
loss: 0.8475, acc: 50.92, test_acc: 68.06, f1: 67.72
>> saved: state_dict/lcf_bert_twitter_acc70.66
max_acc:70.66  f1:68.57
loss: 0.6359, acc: 51.25, test_acc: 70.66, f1: 68.57
loss: 0.9924, acc: 51.74, test_acc: 70.23, f1: 68.26
loss: 0.6607, acc: 52.36, test_acc: 69.80, f1: 69.10
loss: 0.5410, acc: 53.12, test_acc: 68.21, f1: 67.88
loss: 0.5635, acc: 54.01, test_acc: 69.94, f1: 67.09
loss: 0.8844, acc: 54.22, test_acc: 67.77, f1: 67.75
loss: 1.1164, acc: 54.27, test_acc: 59.25, f1: 59.42
loss: 0.5800, acc: 54.76, test_acc: 68.21, f1: 63.55
loss: 0.6997, acc: 54.94, test_acc: 66.76, f1: 60.71
loss: 0.6474, acc: 55.54, test_acc: 69.22, f1: 68.77
loss: 0.5680, acc: 55.83, test_acc: 70.23, f1: 69.04
loss: 0.3992, acc: 56.52, test_acc: 68.93, f1: 63.68
>> saved: state_dict/lcf_bert_twitter_acc72.69
max_acc:72.69  f1:70.44
loss: 1.0079, acc: 56.38, test_acc: 72.69, f1: 70.44
loss: 1.0023, acc: 56.25, test_acc: 60.69, f1: 61.02
loss: 0.7417, acc: 56.76, test_acc: 72.54, f1: 71.26
loss: 0.7171, acc: 57.00, test_acc: 70.95, f1: 66.67
loss: 0.8205, acc: 57.11, test_acc: 68.79, f1: 67.31
loss: 0.7426, acc: 57.33, test_acc: 71.68, f1: 69.77
loss: 0.4822, acc: 57.78, test_acc: 63.73, f1: 56.48
loss: 0.7357, acc: 57.75, test_acc: 71.10, f1: 68.30
loss: 0.7801, acc: 57.61, test_acc: 71.10, f1: 69.55
>> saved: state_dict/lcf_bert_twitter_acc73.99
max_acc:73.99  f1:73.08
loss: 0.4447, acc: 58.15, test_acc: 73.99, f1: 73.08
loss: 0.5451, acc: 58.77, test_acc: 73.70, f1: 72.28
loss: 0.8004, acc: 58.84, test_acc: 70.66, f1: 66.49
loss: 0.8027, acc: 59.00, test_acc: 66.47, f1: 64.70
loss: 0.9943, acc: 59.06, test_acc: 67.20, f1: 67.43
loss: 0.5342, acc: 59.53, test_acc: 72.40, f1: 70.83
loss: 0.7360, acc: 59.78, test_acc: 73.12, f1: 71.80
loss: 0.9700, acc: 59.72, test_acc: 72.40, f1: 70.34
loss: 0.3242, acc: 60.25, test_acc: 73.41, f1: 71.09
loss: 0.5895, acc: 60.48, test_acc: 72.40, f1: 71.32
loss: 0.6794, acc: 60.61, test_acc: 67.05, f1: 67.27
loss: 0.5365, acc: 60.82, test_acc: 71.39, f1: 70.97
loss: 0.4665, acc: 61.12, test_acc: 72.69, f1: 70.26
>> saved: state_dict/lcf_bert_twitter_acc74.28
max_acc:74.28  f1:73.46
loss: 0.5479, acc: 61.41, test_acc: 74.28, f1: 73.46
loss: 0.4808, acc: 61.70, test_acc: 70.81, f1: 70.13
>> saved: state_dict/lcf_bert_twitter_acc74.57
max_acc:74.57  f1:73.71
loss: 0.5420, acc: 61.88, test_acc: 74.57, f1: 73.71
loss: 0.9595, acc: 61.89, test_acc: 74.57, f1: 72.90
loss: 0.4088, acc: 62.16, test_acc: 72.69, f1: 69.32
loss: 0.4021, acc: 62.42, test_acc: 71.82, f1: 71.39
loss: 0.4699, acc: 62.67, test_acc: 69.94, f1: 69.91
loss: 0.4476, acc: 62.83, test_acc: 72.98, f1: 71.86
>> saved: state_dict/lcf_bert_twitter_acc74.71
max_acc:74.71  f1:73.29
loss: 0.7641, acc: 62.91, test_acc: 74.71, f1: 73.29
loss: 0.7122, acc: 62.98, test_acc: 73.99, f1: 72.26
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.8354, acc: 56.25, test_acc: 72.54, f1: 71.63
loss: 0.6951, acc: 59.38, test_acc: 71.24, f1: 70.49
loss: 0.7122, acc: 62.50, test_acc: 74.28, f1: 72.84
>> saved: state_dict/lcf_bert_twitter_acc74.86
max_acc:74.86  f1:72.77
loss: 0.8574, acc: 64.06, test_acc: 74.86, f1: 72.77
loss: 0.5697, acc: 66.25, test_acc: 72.83, f1: 72.31
loss: 0.7663, acc: 63.54, test_acc: 72.83, f1: 72.41
>> saved: state_dict/lcf_bert_twitter_acc76.45
max_acc:76.45  f1:75.35
loss: 0.2442, acc: 67.86, test_acc: 76.45, f1: 75.35
loss: 0.3247, acc: 70.31, test_acc: 76.16, f1: 74.72
loss: 0.4093, acc: 70.83, test_acc: 75.72, f1: 74.58
loss: 0.6361, acc: 71.88, test_acc: 74.42, f1: 73.78
loss: 0.4254, acc: 73.30, test_acc: 73.70, f1: 72.49
loss: 0.2111, acc: 75.52, test_acc: 72.40, f1: 70.69
loss: 0.5901, acc: 75.96, test_acc: 73.41, f1: 72.38
loss: 0.7154, acc: 75.45, test_acc: 72.11, f1: 71.44
loss: 0.3089, acc: 77.08, test_acc: 72.83, f1: 72.27
loss: 0.3577, acc: 77.34, test_acc: 73.55, f1: 70.99
loss: 0.5990, acc: 77.21, test_acc: 74.28, f1: 73.19
loss: 0.4050, acc: 77.43, test_acc: 75.29, f1: 74.16
loss: 0.4873, acc: 77.96, test_acc: 75.14, f1: 73.38
loss: 0.6982, acc: 78.12, test_acc: 75.58, f1: 73.42
loss: 0.3426, acc: 78.87, test_acc: 75.72, f1: 73.86
loss: 0.2968, acc: 79.26, test_acc: 75.58, f1: 74.62
loss: 0.1808, acc: 80.16, test_acc: 71.82, f1: 71.97
loss: 0.1511, acc: 80.73, test_acc: 74.71, f1: 73.58
loss: 0.9727, acc: 80.00, test_acc: 74.28, f1: 71.58
loss: 0.4224, acc: 79.81, test_acc: 76.45, f1: 75.33
loss: 0.5926, acc: 79.86, test_acc: 72.25, f1: 72.31
loss: 0.2880, acc: 79.91, test_acc: 71.53, f1: 71.39
loss: 0.3589, acc: 80.39, test_acc: 74.57, f1: 72.85
loss: 0.5834, acc: 80.21, test_acc: 76.01, f1: 74.61
loss: 0.3852, acc: 80.65, test_acc: 72.69, f1: 71.79
loss: 0.4302, acc: 80.86, test_acc: 74.57, f1: 73.65
loss: 0.7233, acc: 80.30, test_acc: 74.71, f1: 73.30
loss: 0.4815, acc: 80.51, test_acc: 75.29, f1: 73.30
loss: 0.4676, acc: 80.36, test_acc: 75.00, f1: 73.56
loss: 0.4295, acc: 80.56, test_acc: 73.12, f1: 72.50
loss: 0.4987, acc: 80.41, test_acc: 73.27, f1: 72.90
loss: 0.6419, acc: 80.10, test_acc: 73.70, f1: 72.93
loss: 0.5670, acc: 80.13, test_acc: 71.97, f1: 69.28
loss: 0.3835, acc: 80.31, test_acc: 75.72, f1: 73.57
loss: 0.8440, acc: 79.73, test_acc: 68.50, f1: 69.18
loss: 0.5244, acc: 79.61, test_acc: 73.55, f1: 73.22
loss: 0.7955, acc: 79.65, test_acc: 75.72, f1: 73.93
loss: 0.5122, acc: 79.83, test_acc: 76.30, f1: 74.87
loss: 0.3386, acc: 79.86, test_acc: 70.09, f1: 69.89
loss: 0.3737, acc: 80.03, test_acc: 72.69, f1: 72.53
loss: 0.4045, acc: 80.32, test_acc: 71.68, f1: 71.76
loss: 0.8667, acc: 79.82, test_acc: 73.84, f1: 72.97
loss: 0.7067, acc: 79.46, test_acc: 76.16, f1: 74.62
loss: 0.4215, acc: 79.50, test_acc: 76.16, f1: 74.61
loss: 0.2685, acc: 79.78, test_acc: 74.13, f1: 72.87
loss: 0.6959, acc: 79.69, test_acc: 74.13, f1: 71.82
loss: 0.1920, acc: 79.95, test_acc: 73.99, f1: 70.76
loss: 0.4541, acc: 79.86, test_acc: 74.57, f1: 73.66
loss: 0.5672, acc: 79.66, test_acc: 75.14, f1: 74.55
loss: 0.3013, acc: 79.91, test_acc: 75.72, f1: 74.45
loss: 0.8343, acc: 79.71, test_acc: 75.00, f1: 72.85
loss: 0.2202, acc: 79.96, test_acc: 74.57, f1: 72.49
loss: 0.5599, acc: 80.08, test_acc: 72.54, f1: 72.46
loss: 0.9905, acc: 79.58, test_acc: 73.99, f1: 73.08
loss: 0.9152, acc: 79.00, test_acc: 75.00, f1: 72.80
loss: 0.3214, acc: 79.23, test_acc: 75.00, f1: 74.28
loss: 0.5707, acc: 79.17, test_acc: 74.28, f1: 73.45
loss: 0.5138, acc: 79.20, test_acc: 72.98, f1: 72.28
loss: 0.6963, acc: 79.13, test_acc: 75.72, f1: 74.49
loss: 0.5840, acc: 79.07, test_acc: 75.72, f1: 74.32
loss: 0.6354, acc: 79.01, test_acc: 76.45, f1: 74.61
loss: 0.5092, acc: 78.86, test_acc: 75.00, f1: 73.93
loss: 0.5792, acc: 78.89, test_acc: 74.57, f1: 73.37
loss: 0.3370, acc: 79.02, test_acc: 74.86, f1: 73.79
loss: 0.2576, acc: 79.23, test_acc: 75.72, f1: 74.66
loss: 0.6388, acc: 78.99, test_acc: 73.55, f1: 72.49
loss: 0.4705, acc: 78.94, test_acc: 74.13, f1: 71.92
loss: 0.9377, acc: 78.80, test_acc: 72.98, f1: 68.50
loss: 0.6155, acc: 78.67, test_acc: 75.72, f1: 74.96
loss: 0.7749, acc: 78.62, test_acc: 67.92, f1: 68.16
loss: 0.8208, acc: 78.57, test_acc: 75.14, f1: 73.88
loss: 0.9126, acc: 78.37, test_acc: 74.57, f1: 73.11
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2417, acc: 93.75, test_acc: 69.51, f1: 69.79
loss: 0.2804, acc: 90.62, test_acc: 76.45, f1: 75.37
loss: 0.3275, acc: 89.58, test_acc: 75.29, f1: 73.30
loss: 0.4142, acc: 89.06, test_acc: 75.29, f1: 74.55
loss: 0.4266, acc: 86.25, test_acc: 70.38, f1: 70.35
loss: 0.3797, acc: 85.42, test_acc: 75.43, f1: 74.42
>> saved: state_dict/lcf_bert_twitter_acc77.02
max_acc:77.02  f1:74.76
loss: 0.3642, acc: 85.71, test_acc: 77.02, f1: 74.76
>> saved: state_dict/lcf_bert_twitter_acc77.31
max_acc:77.31  f1:75.77
loss: 0.1989, acc: 85.94, test_acc: 77.31, f1: 75.77
loss: 0.0882, acc: 87.50, test_acc: 73.55, f1: 73.51
loss: 0.1208, acc: 88.75, test_acc: 74.28, f1: 73.98
loss: 0.2943, acc: 88.64, test_acc: 73.84, f1: 73.77
loss: 0.0693, acc: 89.58, test_acc: 74.28, f1: 73.71
loss: 0.1965, acc: 89.42, test_acc: 76.45, f1: 74.77
loss: 0.6147, acc: 88.84, test_acc: 76.45, f1: 74.62
loss: 0.4045, acc: 88.33, test_acc: 73.55, f1: 73.00
loss: 0.4387, acc: 88.67, test_acc: 72.40, f1: 71.03
loss: 0.2356, acc: 88.97, test_acc: 74.42, f1: 73.13
loss: 0.0935, acc: 89.58, test_acc: 74.28, f1: 73.32
loss: 0.1789, acc: 89.47, test_acc: 74.13, f1: 73.38
loss: 0.3244, acc: 89.06, test_acc: 76.88, f1: 75.58
loss: 0.1977, acc: 88.99, test_acc: 75.87, f1: 74.71
loss: 0.2909, acc: 88.64, test_acc: 73.99, f1: 73.60
loss: 0.1043, acc: 89.13, test_acc: 77.17, f1: 75.95
loss: 0.5700, acc: 88.54, test_acc: 74.42, f1: 72.25
loss: 0.1108, acc: 89.00, test_acc: 74.28, f1: 73.57
loss: 0.3514, acc: 88.70, test_acc: 72.40, f1: 72.12
loss: 0.2150, acc: 88.43, test_acc: 75.14, f1: 73.05
loss: 0.5319, acc: 87.95, test_acc: 75.87, f1: 73.70
loss: 0.1063, acc: 88.36, test_acc: 73.12, f1: 72.43
loss: 0.2359, acc: 88.33, test_acc: 69.36, f1: 69.46
loss: 0.3460, acc: 88.10, test_acc: 75.58, f1: 73.91
loss: 0.4246, acc: 88.09, test_acc: 74.86, f1: 72.07
loss: 0.2083, acc: 88.26, test_acc: 76.30, f1: 74.42
loss: 0.1923, acc: 88.24, test_acc: 72.54, f1: 72.00
loss: 0.1612, acc: 88.57, test_acc: 73.12, f1: 72.50
loss: 0.3314, acc: 88.37, test_acc: 74.42, f1: 73.67
loss: 0.0859, acc: 88.68, test_acc: 74.13, f1: 73.63
loss: 0.1175, acc: 88.98, test_acc: 74.86, f1: 74.35
loss: 0.4797, acc: 88.78, test_acc: 75.72, f1: 73.98
loss: 0.4562, acc: 88.75, test_acc: 73.99, f1: 73.66
loss: 0.2408, acc: 88.72, test_acc: 74.42, f1: 73.13
loss: 0.4828, acc: 88.69, test_acc: 74.42, f1: 72.87
loss: 0.4544, acc: 88.52, test_acc: 68.64, f1: 69.36
>> saved: state_dict/lcf_bert_twitter_acc77.75
max_acc:77.75  f1:75.99
loss: 0.2960, acc: 88.49, test_acc: 77.75, f1: 75.99
loss: 0.2879, acc: 88.33, test_acc: 73.55, f1: 69.45
loss: 0.5539, acc: 87.91, test_acc: 74.13, f1: 73.59
loss: 0.3833, acc: 87.77, test_acc: 73.55, f1: 73.10
loss: 0.2322, acc: 87.89, test_acc: 76.01, f1: 74.23
loss: 0.3445, acc: 87.88, test_acc: 75.43, f1: 73.65
loss: 0.3381, acc: 87.75, test_acc: 75.14, f1: 73.74
loss: 0.1675, acc: 87.87, test_acc: 74.42, f1: 73.63
loss: 0.2420, acc: 87.98, test_acc: 72.40, f1: 72.08
loss: 0.1268, acc: 87.97, test_acc: 72.69, f1: 72.26
loss: 0.3614, acc: 87.96, test_acc: 70.95, f1: 70.69
loss: 0.1152, acc: 88.18, test_acc: 74.86, f1: 73.72
loss: 0.3742, acc: 88.06, test_acc: 74.86, f1: 72.97
loss: 0.0844, acc: 88.27, test_acc: 75.00, f1: 73.56
loss: 0.2367, acc: 88.36, test_acc: 72.69, f1: 72.30
loss: 0.2686, acc: 88.35, test_acc: 69.94, f1: 70.00
loss: 0.2523, acc: 88.44, test_acc: 71.53, f1: 71.17
loss: 0.1672, acc: 88.63, test_acc: 73.12, f1: 72.21
loss: 0.2024, acc: 88.61, test_acc: 75.00, f1: 73.76
loss: 0.1518, acc: 88.69, test_acc: 73.27, f1: 72.19
loss: 0.2685, acc: 88.57, test_acc: 74.57, f1: 73.63
loss: 0.2899, acc: 88.65, test_acc: 71.53, f1: 71.38
loss: 0.4325, acc: 88.54, test_acc: 73.84, f1: 73.05
loss: 0.1120, acc: 88.62, test_acc: 72.11, f1: 71.09
loss: 0.1631, acc: 88.69, test_acc: 71.82, f1: 70.44
loss: 0.5765, acc: 88.59, test_acc: 70.95, f1: 70.37
loss: 0.3024, acc: 88.66, test_acc: 69.80, f1: 69.77
loss: 0.2277, acc: 88.64, test_acc: 69.51, f1: 69.64
loss: 0.1628, acc: 88.72, test_acc: 72.40, f1: 72.09
loss: 0.3834, acc: 88.70, test_acc: 73.41, f1: 72.90
loss: 0.0580, acc: 88.85, test_acc: 73.84, f1: 73.26
loss: 0.0555, acc: 89.00, test_acc: 73.84, f1: 72.92
loss: 0.1051, acc: 89.14, test_acc: 73.84, f1: 73.25
loss: 0.3997, acc: 89.04, test_acc: 72.25, f1: 71.96
loss: 0.5094, acc: 88.94, test_acc: 73.70, f1: 72.94
####################################################################################################
max_test_acc_overall:77.74566473988439
max_f1_overall:75.98526720600385
####################################################################################################
1 test_acc_overall: 77.75  f1_overall:75.99
max_acc_overall:77.75  f1_overall:75.99
mean_acc_overall:77.75  mean_f1_overall:75.99
####################################################################################################
lcf_bert - twitter - lcf_fusion - No.2 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 1
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc25.58
max_acc:25.58  f1:15.15
loss: 1.0669, acc: 37.50, test_acc: 25.58, f1: 15.15
>> saved: state_dict/lcf_bert_twitter_acc48.55
max_acc:48.55  f1:32.7
loss: 1.0950, acc: 43.75, test_acc: 48.55, f1: 32.70
>> saved: state_dict/lcf_bert_twitter_acc50.0
max_acc:50.0  f1:22.22
loss: 1.1278, acc: 41.67, test_acc: 50.00, f1: 22.22
loss: 1.0308, acc: 43.75, test_acc: 49.86, f1: 24.26
loss: 1.1029, acc: 45.00, test_acc: 50.00, f1: 22.22
loss: 1.1752, acc: 41.67, test_acc: 26.73, f1: 16.02
loss: 1.1546, acc: 42.86, test_acc: 50.00, f1: 22.22
>> saved: state_dict/lcf_bert_twitter_acc53.9
max_acc:53.9  f1:35.49
loss: 1.2996, acc: 41.41, test_acc: 53.90, f1: 35.49
loss: 1.0790, acc: 40.97, test_acc: 49.13, f1: 49.30
loss: 0.7818, acc: 45.00, test_acc: 52.60, f1: 29.41
loss: 0.8171, acc: 47.16, test_acc: 51.01, f1: 24.97
>> saved: state_dict/lcf_bert_twitter_acc57.95
max_acc:57.95  f1:45.92
loss: 0.7513, acc: 49.48, test_acc: 57.95, f1: 45.92
>> saved: state_dict/lcf_bert_twitter_acc62.57
max_acc:62.57  f1:59.94
loss: 0.9200, acc: 50.00, test_acc: 62.57, f1: 59.94
loss: 0.6996, acc: 50.89, test_acc: 57.95, f1: 44.89
loss: 0.7740, acc: 51.67, test_acc: 56.79, f1: 57.18
loss: 1.1204, acc: 51.95, test_acc: 62.43, f1: 54.40
loss: 0.9918, acc: 52.21, test_acc: 57.66, f1: 49.05
>> saved: state_dict/lcf_bert_twitter_acc66.04
max_acc:66.04  f1:64.99
loss: 0.8053, acc: 52.78, test_acc: 66.04, f1: 64.99
>> saved: state_dict/lcf_bert_twitter_acc66.91
max_acc:66.91  f1:64.88
loss: 0.6674, acc: 53.62, test_acc: 66.91, f1: 64.88
loss: 0.9675, acc: 54.06, test_acc: 59.68, f1: 60.35
>> saved: state_dict/lcf_bert_twitter_acc69.08
max_acc:69.08  f1:65.36
loss: 0.8460, acc: 54.17, test_acc: 69.08, f1: 65.36
loss: 0.5347, acc: 55.40, test_acc: 67.05, f1: 60.80
loss: 0.6930, acc: 56.52, test_acc: 67.20, f1: 66.07
loss: 0.8421, acc: 56.51, test_acc: 63.01, f1: 63.38
loss: 0.7591, acc: 57.00, test_acc: 66.47, f1: 60.91
loss: 0.6145, acc: 57.93, test_acc: 67.05, f1: 65.62
loss: 0.9923, acc: 57.87, test_acc: 66.62, f1: 66.00
loss: 0.6465, acc: 58.26, test_acc: 68.06, f1: 67.27
loss: 0.8581, acc: 58.19, test_acc: 68.06, f1: 67.14
>> saved: state_dict/lcf_bert_twitter_acc70.09
max_acc:70.09  f1:67.17
loss: 0.7058, acc: 58.54, test_acc: 70.09, f1: 67.17
loss: 0.5837, acc: 59.27, test_acc: 69.08, f1: 67.24
loss: 0.7533, acc: 59.18, test_acc: 63.44, f1: 63.57
loss: 0.9695, acc: 59.09, test_acc: 69.08, f1: 67.91
loss: 0.5787, acc: 59.74, test_acc: 67.92, f1: 66.47
>> saved: state_dict/lcf_bert_twitter_acc70.81
max_acc:70.81  f1:69.15
loss: 0.6943, acc: 60.18, test_acc: 70.81, f1: 69.15
loss: 0.6343, acc: 60.42, test_acc: 69.94, f1: 67.12
loss: 0.6365, acc: 60.81, test_acc: 65.61, f1: 65.41
>> saved: state_dict/lcf_bert_twitter_acc71.53
max_acc:71.53  f1:69.48
loss: 0.8350, acc: 60.69, test_acc: 71.53, f1: 69.48
>> saved: state_dict/lcf_bert_twitter_acc71.82
max_acc:71.82  f1:68.82
loss: 0.9381, acc: 60.74, test_acc: 71.82, f1: 68.82
loss: 0.5442, acc: 61.25, test_acc: 69.51, f1: 68.37
loss: 0.8561, acc: 61.28, test_acc: 71.39, f1: 69.65
loss: 0.8968, acc: 61.16, test_acc: 68.79, f1: 67.43
loss: 0.8701, acc: 61.19, test_acc: 68.50, f1: 67.36
loss: 0.6008, acc: 61.51, test_acc: 69.36, f1: 68.64
loss: 0.4905, acc: 61.94, test_acc: 67.77, f1: 65.95
loss: 0.6444, acc: 62.09, test_acc: 68.93, f1: 64.58
loss: 0.5762, acc: 62.23, test_acc: 68.06, f1: 67.10
loss: 0.9479, acc: 62.24, test_acc: 65.32, f1: 65.18
loss: 1.2215, acc: 61.99, test_acc: 62.57, f1: 62.88
loss: 0.5974, acc: 62.25, test_acc: 66.91, f1: 67.07
loss: 0.6187, acc: 62.38, test_acc: 68.79, f1: 67.01
loss: 0.4437, acc: 62.74, test_acc: 69.65, f1: 67.46
loss: 0.5119, acc: 62.74, test_acc: 68.93, f1: 68.27
loss: 0.9055, acc: 62.62, test_acc: 64.45, f1: 64.54
loss: 0.6302, acc: 62.84, test_acc: 69.80, f1: 66.80
>> saved: state_dict/lcf_bert_twitter_acc72.98
max_acc:72.98  f1:71.58
loss: 0.5936, acc: 63.06, test_acc: 72.98, f1: 71.58
loss: 0.6232, acc: 63.38, test_acc: 66.33, f1: 65.97
loss: 0.8679, acc: 63.25, test_acc: 72.83, f1: 70.43
loss: 0.9087, acc: 63.24, test_acc: 68.79, f1: 63.72
loss: 0.7388, acc: 63.12, test_acc: 67.49, f1: 67.64
loss: 0.5914, acc: 63.32, test_acc: 70.95, f1: 70.20
loss: 0.5072, acc: 63.41, test_acc: 72.25, f1: 70.39
>> saved: state_dict/lcf_bert_twitter_acc74.42
max_acc:74.42  f1:72.2
loss: 0.7878, acc: 63.29, test_acc: 74.42, f1: 72.20
loss: 0.4056, acc: 63.67, test_acc: 72.11, f1: 70.94
loss: 0.3890, acc: 64.13, test_acc: 72.54, f1: 71.03
loss: 0.6310, acc: 64.20, test_acc: 74.13, f1: 71.87
loss: 0.8235, acc: 64.18, test_acc: 70.66, f1: 70.10
loss: 0.7043, acc: 64.25, test_acc: 69.65, f1: 69.59
loss: 0.4563, acc: 64.40, test_acc: 73.41, f1: 71.44
loss: 0.7511, acc: 64.46, test_acc: 73.70, f1: 70.78
loss: 0.8829, acc: 64.35, test_acc: 73.12, f1: 72.83
loss: 0.5943, acc: 64.50, test_acc: 63.15, f1: 63.77
>> saved: state_dict/lcf_bert_twitter_acc75.14
max_acc:75.14  f1:73.57
loss: 0.3079, acc: 64.90, test_acc: 75.14, f1: 73.57
loss: 0.9932, acc: 64.70, test_acc: 74.28, f1: 72.04
loss: 0.7159, acc: 64.83, test_acc: 71.82, f1: 71.83
loss: 1.0296, acc: 64.64, test_acc: 71.68, f1: 71.89
loss: 0.7887, acc: 64.53, test_acc: 75.14, f1: 74.15
>> saved: state_dict/lcf_bert_twitter_acc76.16
max_acc:76.16  f1:74.8
loss: 0.4913, acc: 64.66, test_acc: 76.16, f1: 74.80
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.4194, acc: 93.75, test_acc: 74.71, f1: 74.03
loss: 0.6503, acc: 84.38, test_acc: 74.71, f1: 73.67
>> saved: state_dict/lcf_bert_twitter_acc76.59
max_acc:76.59  f1:75.11
loss: 0.5371, acc: 83.33, test_acc: 76.59, f1: 75.11
loss: 0.4474, acc: 84.38, test_acc: 70.81, f1: 70.66
loss: 0.2847, acc: 86.25, test_acc: 67.34, f1: 67.50
loss: 0.5986, acc: 84.38, test_acc: 75.87, f1: 74.92
loss: 0.2423, acc: 85.71, test_acc: 73.27, f1: 70.00
loss: 0.2114, acc: 87.50, test_acc: 74.28, f1: 73.54
loss: 0.6319, acc: 86.11, test_acc: 71.24, f1: 71.20
loss: 0.5295, acc: 84.38, test_acc: 73.55, f1: 73.18
loss: 0.4903, acc: 82.95, test_acc: 75.00, f1: 73.92
loss: 0.2120, acc: 83.85, test_acc: 74.13, f1: 73.28
loss: 0.4126, acc: 84.13, test_acc: 75.58, f1: 74.42
loss: 0.4397, acc: 83.48, test_acc: 74.86, f1: 73.37
loss: 0.4578, acc: 83.75, test_acc: 74.13, f1: 73.15
loss: 0.4376, acc: 83.98, test_acc: 71.68, f1: 71.60
loss: 0.5585, acc: 84.19, test_acc: 75.43, f1: 74.01
loss: 0.3946, acc: 84.03, test_acc: 76.16, f1: 74.36
loss: 0.3951, acc: 84.54, test_acc: 73.99, f1: 73.74
loss: 0.4602, acc: 84.38, test_acc: 75.29, f1: 73.79
loss: 0.3321, acc: 84.52, test_acc: 74.57, f1: 72.69
loss: 0.2790, acc: 84.94, test_acc: 74.13, f1: 73.22
loss: 0.4687, acc: 84.78, test_acc: 72.11, f1: 72.00
loss: 0.4420, acc: 84.11, test_acc: 74.42, f1: 73.35
loss: 0.5574, acc: 84.25, test_acc: 73.55, f1: 71.08
loss: 0.6029, acc: 83.89, test_acc: 72.54, f1: 71.66
loss: 0.5690, acc: 84.03, test_acc: 70.95, f1: 70.91
loss: 0.3651, acc: 83.71, test_acc: 73.27, f1: 72.60
loss: 0.3813, acc: 83.62, test_acc: 74.13, f1: 73.18
loss: 0.5376, acc: 83.33, test_acc: 73.99, f1: 72.96
loss: 0.3884, acc: 83.47, test_acc: 74.42, f1: 73.00
loss: 0.1109, acc: 83.98, test_acc: 69.65, f1: 70.06
loss: 0.3516, acc: 84.09, test_acc: 72.69, f1: 71.89
loss: 0.7947, acc: 83.09, test_acc: 74.42, f1: 72.36
loss: 0.3633, acc: 83.04, test_acc: 71.68, f1: 70.69
loss: 0.6724, acc: 82.99, test_acc: 70.66, f1: 69.70
loss: 0.5311, acc: 83.11, test_acc: 70.38, f1: 69.17
loss: 0.6409, acc: 82.73, test_acc: 69.08, f1: 68.19
loss: 0.4524, acc: 82.69, test_acc: 69.80, f1: 67.72
loss: 0.7195, acc: 82.19, test_acc: 72.25, f1: 70.75
loss: 0.5494, acc: 82.32, test_acc: 72.69, f1: 71.42
loss: 0.6920, acc: 81.70, test_acc: 73.41, f1: 71.39
loss: 0.6011, acc: 81.69, test_acc: 71.82, f1: 71.56
loss: 0.5971, acc: 81.53, test_acc: 71.68, f1: 71.00
loss: 0.4545, acc: 81.53, test_acc: 74.28, f1: 71.90
loss: 1.2771, acc: 80.84, test_acc: 72.54, f1: 69.50
loss: 0.5657, acc: 80.85, test_acc: 68.93, f1: 68.96
loss: 0.2848, acc: 81.12, test_acc: 71.97, f1: 71.09
loss: 0.6338, acc: 80.87, test_acc: 73.41, f1: 71.15
loss: 0.2507, acc: 80.88, test_acc: 71.68, f1: 70.98
loss: 0.5605, acc: 80.76, test_acc: 67.92, f1: 68.30
loss: 0.3203, acc: 80.89, test_acc: 74.71, f1: 73.43
loss: 1.0483, acc: 80.31, test_acc: 75.72, f1: 74.31
loss: 0.5408, acc: 80.32, test_acc: 72.83, f1: 72.01
loss: 0.7520, acc: 80.11, test_acc: 74.57, f1: 73.36
loss: 0.4658, acc: 80.13, test_acc: 71.53, f1: 71.21
loss: 0.4551, acc: 80.04, test_acc: 72.98, f1: 72.19
loss: 0.3530, acc: 80.17, test_acc: 73.12, f1: 72.40
loss: 0.5358, acc: 80.08, test_acc: 74.86, f1: 73.64
loss: 0.5031, acc: 80.00, test_acc: 75.58, f1: 74.76
loss: 0.2820, acc: 80.33, test_acc: 72.69, f1: 72.03
loss: 0.2323, acc: 80.44, test_acc: 74.57, f1: 73.56
loss: 0.4061, acc: 80.46, test_acc: 74.42, f1: 72.76
loss: 0.5305, acc: 80.47, test_acc: 74.71, f1: 72.91
loss: 0.6067, acc: 80.48, test_acc: 74.42, f1: 72.94
loss: 0.6389, acc: 80.40, test_acc: 72.25, f1: 71.79
loss: 0.6493, acc: 80.32, test_acc: 73.27, f1: 72.21
loss: 0.4116, acc: 80.24, test_acc: 73.41, f1: 71.38
loss: 0.7600, acc: 80.16, test_acc: 74.42, f1: 72.38
loss: 0.3975, acc: 80.18, test_acc: 74.42, f1: 72.72
loss: 0.3222, acc: 80.28, test_acc: 73.55, f1: 72.59
loss: 0.3323, acc: 80.47, test_acc: 75.58, f1: 74.05
loss: 0.9602, acc: 80.14, test_acc: 71.24, f1: 70.67
loss: 0.5972, acc: 80.07, test_acc: 76.30, f1: 75.09
loss: 0.4611, acc: 79.92, test_acc: 75.14, f1: 73.06
loss: 0.8454, acc: 79.77, test_acc: 72.69, f1: 70.77
loss: 0.3564, acc: 79.87, test_acc: 75.72, f1: 74.61
loss: 0.5310, acc: 79.73, test_acc: 75.14, f1: 73.36
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1242, acc: 100.00, test_acc: 75.14, f1: 72.38
loss: 0.3149, acc: 96.88, test_acc: 76.01, f1: 74.61
loss: 0.1799, acc: 95.83, test_acc: 74.13, f1: 73.37
loss: 0.7418, acc: 92.19, test_acc: 73.84, f1: 73.41
loss: 0.1879, acc: 92.50, test_acc: 73.84, f1: 73.03
loss: 0.0732, acc: 93.75, test_acc: 75.58, f1: 73.55
loss: 0.2940, acc: 93.75, test_acc: 74.71, f1: 73.61
loss: 0.3071, acc: 92.97, test_acc: 71.10, f1: 71.02
loss: 0.1032, acc: 93.75, test_acc: 68.50, f1: 68.58
loss: 0.1138, acc: 94.38, test_acc: 76.59, f1: 74.70
loss: 0.3404, acc: 94.32, test_acc: 71.39, f1: 70.41
loss: 0.4957, acc: 93.75, test_acc: 71.53, f1: 71.37
loss: 0.4597, acc: 92.79, test_acc: 75.00, f1: 74.26
loss: 0.4506, acc: 91.52, test_acc: 75.58, f1: 74.16
loss: 0.1329, acc: 92.08, test_acc: 73.55, f1: 72.48
loss: 0.1007, acc: 92.19, test_acc: 72.54, f1: 71.75
loss: 0.3698, acc: 91.91, test_acc: 74.57, f1: 73.17
loss: 0.3318, acc: 92.01, test_acc: 73.12, f1: 72.62
loss: 0.1556, acc: 92.11, test_acc: 72.69, f1: 72.15
loss: 0.1628, acc: 92.19, test_acc: 74.86, f1: 73.03
loss: 0.2798, acc: 91.96, test_acc: 74.57, f1: 72.37
loss: 0.3672, acc: 91.76, test_acc: 72.98, f1: 72.77
loss: 0.2420, acc: 91.85, test_acc: 70.38, f1: 70.60
loss: 0.1264, acc: 91.93, test_acc: 74.86, f1: 74.09
loss: 1.2522, acc: 91.00, test_acc: 76.01, f1: 74.39
loss: 0.2118, acc: 91.11, test_acc: 74.42, f1: 73.67
loss: 0.1309, acc: 91.44, test_acc: 72.69, f1: 72.32
loss: 0.0508, acc: 91.74, test_acc: 72.83, f1: 72.25
loss: 0.5755, acc: 91.16, test_acc: 70.95, f1: 69.64
loss: 0.1667, acc: 91.25, test_acc: 74.86, f1: 73.42
loss: 0.1671, acc: 91.33, test_acc: 74.42, f1: 73.28
loss: 0.0919, acc: 91.60, test_acc: 72.54, f1: 71.93
loss: 0.1439, acc: 91.67, test_acc: 74.71, f1: 72.78
loss: 0.2355, acc: 91.73, test_acc: 74.71, f1: 72.91
loss: 0.4016, acc: 91.61, test_acc: 74.86, f1: 73.81
loss: 0.4076, acc: 91.15, test_acc: 72.25, f1: 71.84
loss: 0.1421, acc: 91.22, test_acc: 71.53, f1: 71.33
loss: 0.2324, acc: 91.28, test_acc: 74.71, f1: 74.25
loss: 0.0846, acc: 91.51, test_acc: 74.86, f1: 73.94
loss: 0.8112, acc: 91.09, test_acc: 74.57, f1: 73.70
loss: 0.2749, acc: 91.16, test_acc: 73.70, f1: 73.37
loss: 0.4094, acc: 90.92, test_acc: 74.57, f1: 74.18
loss: 0.1425, acc: 90.99, test_acc: 73.99, f1: 71.82
loss: 0.1671, acc: 91.05, test_acc: 76.16, f1: 74.88
loss: 0.0780, acc: 91.25, test_acc: 73.84, f1: 73.56
loss: 0.2919, acc: 91.03, test_acc: 74.28, f1: 73.93
loss: 0.1021, acc: 91.22, test_acc: 72.83, f1: 70.44
loss: 0.3354, acc: 91.15, test_acc: 70.09, f1: 68.88
loss: 0.1208, acc: 91.33, test_acc: 67.05, f1: 67.78
loss: 0.2364, acc: 91.38, test_acc: 70.95, f1: 70.80
loss: 0.2168, acc: 91.30, test_acc: 72.11, f1: 68.57
loss: 0.3988, acc: 91.23, test_acc: 73.99, f1: 72.11
loss: 0.1943, acc: 91.27, test_acc: 71.82, f1: 70.83
loss: 0.1373, acc: 91.32, test_acc: 72.25, f1: 72.24
loss: 0.2130, acc: 91.36, test_acc: 73.41, f1: 72.51
loss: 0.6748, acc: 90.96, test_acc: 71.97, f1: 71.70
loss: 0.1626, acc: 91.01, test_acc: 72.25, f1: 72.04
loss: 0.3865, acc: 90.95, test_acc: 74.57, f1: 73.31
loss: 0.1857, acc: 91.00, test_acc: 72.54, f1: 71.90
loss: 0.6242, acc: 90.94, test_acc: 66.04, f1: 66.43
loss: 0.1813, acc: 90.98, test_acc: 71.24, f1: 70.53
loss: 0.1147, acc: 91.13, test_acc: 72.69, f1: 70.33
loss: 0.0568, acc: 91.27, test_acc: 75.00, f1: 72.93
loss: 0.2876, acc: 91.31, test_acc: 70.81, f1: 70.47
loss: 0.4755, acc: 90.87, test_acc: 70.95, f1: 70.76
loss: 0.5348, acc: 90.72, test_acc: 74.71, f1: 73.48
loss: 0.4671, acc: 90.67, test_acc: 74.86, f1: 73.43
loss: 0.2520, acc: 90.72, test_acc: 72.40, f1: 71.86
loss: 0.0897, acc: 90.85, test_acc: 72.98, f1: 72.40
loss: 0.1677, acc: 90.80, test_acc: 71.53, f1: 71.16
loss: 0.1897, acc: 90.85, test_acc: 73.70, f1: 72.85
loss: 0.1111, acc: 90.97, test_acc: 73.12, f1: 71.75
loss: 0.3524, acc: 90.92, test_acc: 72.83, f1: 71.56
loss: 0.2129, acc: 90.96, test_acc: 73.41, f1: 72.97
loss: 0.2129, acc: 91.00, test_acc: 70.81, f1: 70.43
loss: 0.2203, acc: 91.04, test_acc: 72.54, f1: 71.68
loss: 0.4233, acc: 90.83, test_acc: 71.53, f1: 71.02
loss: 0.8228, acc: 90.54, test_acc: 68.93, f1: 69.04
####################################################################################################
max_test_acc_overall:76.58959537572254
max_f1_overall:75.11315975324582
####################################################################################################
1 test_acc_overall: 77.75  f1_overall:75.99
2 test_acc_overall: 76.59  f1_overall:75.11
max_acc_overall:77.75  f1_overall:75.99
mean_acc_overall:77.17  mean_f1_overall:75.55
####################################################################################################
lcf_bert - twitter - lcf_fusion - No.3 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 2
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc36.27
max_acc:36.27  f1:28.3
loss: 1.0851, acc: 31.25, test_acc: 36.27, f1: 28.30
>> saved: state_dict/lcf_bert_twitter_acc50.0
max_acc:50.0  f1:22.22
loss: 0.9115, acc: 50.00, test_acc: 50.00, f1: 22.22
loss: 1.1392, acc: 41.67, test_acc: 25.14, f1: 13.54
loss: 0.9598, acc: 43.75, test_acc: 50.00, f1: 22.22
loss: 1.0584, acc: 46.25, test_acc: 50.00, f1: 22.22
loss: 1.0114, acc: 47.92, test_acc: 26.73, f1: 15.92
loss: 1.0609, acc: 48.21, test_acc: 40.03, f1: 38.34
loss: 1.0322, acc: 47.66, test_acc: 50.00, f1: 22.22
>> saved: state_dict/lcf_bert_twitter_acc56.79
max_acc:56.79  f1:40.28
loss: 1.0478, acc: 47.22, test_acc: 56.79, f1: 40.28
loss: 0.9986, acc: 46.88, test_acc: 55.78, f1: 46.70
>> saved: state_dict/lcf_bert_twitter_acc60.84
max_acc:60.84  f1:58.4
loss: 0.9207, acc: 47.16, test_acc: 60.84, f1: 58.40
loss: 1.1552, acc: 46.88, test_acc: 54.34, f1: 39.87
loss: 1.0034, acc: 46.15, test_acc: 56.36, f1: 42.76
loss: 0.8031, acc: 47.77, test_acc: 57.51, f1: 45.22
loss: 1.2781, acc: 47.92, test_acc: 54.34, f1: 41.58
>> saved: state_dict/lcf_bert_twitter_acc63.58
max_acc:63.58  f1:56.68
loss: 1.0049, acc: 47.66, test_acc: 63.58, f1: 56.68
loss: 0.8490, acc: 48.53, test_acc: 60.12, f1: 59.72
loss: 0.8128, acc: 49.31, test_acc: 60.98, f1: 52.34
loss: 0.8656, acc: 49.34, test_acc: 63.29, f1: 57.69
loss: 0.6625, acc: 50.62, test_acc: 63.01, f1: 62.91
>> saved: state_dict/lcf_bert_twitter_acc65.46
max_acc:65.46  f1:63.19
loss: 0.9763, acc: 50.89, test_acc: 65.46, f1: 63.19
loss: 0.8033, acc: 51.14, test_acc: 64.60, f1: 63.93
loss: 0.6951, acc: 52.45, test_acc: 63.87, f1: 64.77
loss: 0.8956, acc: 52.86, test_acc: 62.43, f1: 61.11
>> saved: state_dict/lcf_bert_twitter_acc70.38
max_acc:70.38  f1:67.29
loss: 0.4745, acc: 53.75, test_acc: 70.38, f1: 67.29
>> saved: state_dict/lcf_bert_twitter_acc70.52
max_acc:70.52  f1:67.68
loss: 0.7445, acc: 54.33, test_acc: 70.52, f1: 67.68
loss: 0.7436, acc: 54.63, test_acc: 68.06, f1: 66.36
loss: 0.7900, acc: 54.46, test_acc: 69.08, f1: 68.42
loss: 0.7286, acc: 54.74, test_acc: 66.33, f1: 66.64
loss: 0.5745, acc: 55.62, test_acc: 68.50, f1: 64.83
loss: 0.6075, acc: 55.85, test_acc: 66.47, f1: 58.26
loss: 0.6490, acc: 56.64, test_acc: 69.80, f1: 67.96
loss: 0.7857, acc: 56.82, test_acc: 67.49, f1: 66.43
loss: 0.2527, acc: 57.72, test_acc: 64.45, f1: 63.61
loss: 0.8066, acc: 57.32, test_acc: 70.52, f1: 69.85
loss: 0.7756, acc: 57.47, test_acc: 67.63, f1: 65.42
>> saved: state_dict/lcf_bert_twitter_acc71.82
max_acc:71.82  f1:69.85
loss: 0.9401, acc: 57.09, test_acc: 71.82, f1: 69.85
loss: 0.7489, acc: 57.07, test_acc: 67.34, f1: 67.77
>> saved: state_dict/lcf_bert_twitter_acc71.97
max_acc:71.97  f1:69.67
loss: 0.7626, acc: 57.37, test_acc: 71.97, f1: 69.67
>> saved: state_dict/lcf_bert_twitter_acc72.25
max_acc:72.25  f1:70.87
loss: 0.5881, acc: 57.97, test_acc: 72.25, f1: 70.87
loss: 0.7927, acc: 58.08, test_acc: 70.38, f1: 70.09
loss: 0.6433, acc: 58.48, test_acc: 72.11, f1: 70.34
loss: 1.2053, acc: 58.43, test_acc: 70.38, f1: 67.09
loss: 0.8635, acc: 58.38, test_acc: 68.93, f1: 68.62
loss: 0.5881, acc: 58.89, test_acc: 71.68, f1: 71.04
loss: 0.8870, acc: 58.83, test_acc: 69.51, f1: 69.38
loss: 0.9343, acc: 58.91, test_acc: 71.24, f1: 69.07
loss: 0.7387, acc: 59.11, test_acc: 69.08, f1: 65.19
loss: 0.5317, acc: 59.57, test_acc: 70.66, f1: 69.99
loss: 0.4107, acc: 60.12, test_acc: 72.11, f1: 70.44
>> saved: state_dict/lcf_bert_twitter_acc72.83
max_acc:72.83  f1:71.73
loss: 0.5548, acc: 60.54, test_acc: 72.83, f1: 71.73
loss: 0.7779, acc: 60.46, test_acc: 72.11, f1: 71.42
loss: 0.5357, acc: 60.73, test_acc: 72.40, f1: 69.52
>> saved: state_dict/lcf_bert_twitter_acc73.27
max_acc:73.27  f1:71.7
loss: 0.6060, acc: 60.65, test_acc: 73.27, f1: 71.70
loss: 0.5933, acc: 61.02, test_acc: 72.25, f1: 71.46
loss: 0.9068, acc: 60.94, test_acc: 72.25, f1: 70.71
loss: 0.6122, acc: 61.18, test_acc: 72.54, f1: 71.41
loss: 0.6401, acc: 61.53, test_acc: 73.12, f1: 70.62
loss: 0.6811, acc: 61.65, test_acc: 72.40, f1: 70.18
>> saved: state_dict/lcf_bert_twitter_acc75.43
max_acc:75.43  f1:74.38
loss: 0.4544, acc: 61.98, test_acc: 75.43, f1: 74.38
loss: 0.6048, acc: 62.09, test_acc: 73.55, f1: 71.82
loss: 0.4945, acc: 62.40, test_acc: 72.25, f1: 72.01
>> saved: state_dict/lcf_bert_twitter_acc75.58
max_acc:75.58  f1:74.71
loss: 0.6757, acc: 62.50, test_acc: 75.58, f1: 74.71
>> saved: state_dict/lcf_bert_twitter_acc76.73
max_acc:76.73  f1:75.34
loss: 0.4258, acc: 62.89, test_acc: 76.73, f1: 75.34
>> saved: state_dict/lcf_bert_twitter_acc77.31
max_acc:77.31  f1:76.21
loss: 0.6442, acc: 63.08, test_acc: 77.31, f1: 76.21
loss: 0.5244, acc: 63.35, test_acc: 75.43, f1: 74.74
loss: 0.5279, acc: 63.62, test_acc: 76.45, f1: 73.99
loss: 0.5558, acc: 63.88, test_acc: 74.28, f1: 73.29
loss: 0.6729, acc: 64.04, test_acc: 71.53, f1: 70.73
loss: 0.7342, acc: 64.20, test_acc: 71.97, f1: 71.65
loss: 1.0039, acc: 64.26, test_acc: 72.25, f1: 71.31
loss: 0.6982, acc: 64.50, test_acc: 72.25, f1: 68.47
loss: 0.4079, acc: 64.81, test_acc: 72.11, f1: 71.08
loss: 0.5588, acc: 65.03, test_acc: 66.91, f1: 67.13
loss: 0.6763, acc: 65.08, test_acc: 66.33, f1: 66.47
loss: 0.6937, acc: 65.13, test_acc: 73.70, f1: 72.19
loss: 0.7109, acc: 65.26, test_acc: 71.10, f1: 68.45
loss: 0.8965, acc: 65.14, test_acc: 75.14, f1: 74.17
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.7394, acc: 68.75, test_acc: 68.93, f1: 69.11
loss: 0.6301, acc: 62.50, test_acc: 75.72, f1: 74.29
loss: 0.7176, acc: 62.50, test_acc: 73.12, f1: 72.69
loss: 0.1858, acc: 71.88, test_acc: 71.10, f1: 71.19
loss: 0.3182, acc: 75.00, test_acc: 75.58, f1: 74.05
loss: 0.3945, acc: 77.08, test_acc: 75.43, f1: 73.24
loss: 0.2215, acc: 79.46, test_acc: 76.45, f1: 74.89
loss: 0.6789, acc: 78.91, test_acc: 71.68, f1: 71.81
loss: 0.3063, acc: 80.56, test_acc: 75.72, f1: 74.80
loss: 0.2890, acc: 81.88, test_acc: 74.57, f1: 71.48
>> saved: state_dict/lcf_bert_twitter_acc77.46
max_acc:77.46  f1:75.83
loss: 0.4304, acc: 81.82, test_acc: 77.46, f1: 75.83
loss: 0.4737, acc: 81.77, test_acc: 75.14, f1: 74.11
loss: 0.2960, acc: 83.17, test_acc: 73.55, f1: 72.95
loss: 0.2433, acc: 83.93, test_acc: 77.02, f1: 75.45
loss: 0.4590, acc: 83.75, test_acc: 75.00, f1: 73.94
loss: 0.4745, acc: 83.59, test_acc: 71.82, f1: 71.53
loss: 0.9614, acc: 82.35, test_acc: 74.42, f1: 73.29
loss: 0.3535, acc: 82.64, test_acc: 73.99, f1: 72.84
loss: 0.8109, acc: 81.91, test_acc: 70.81, f1: 70.57
loss: 0.6278, acc: 81.56, test_acc: 68.35, f1: 68.54
loss: 0.3482, acc: 81.55, test_acc: 76.30, f1: 74.04
loss: 0.4886, acc: 81.25, test_acc: 74.71, f1: 73.38
loss: 0.5588, acc: 81.25, test_acc: 73.70, f1: 72.87
loss: 0.2281, acc: 82.03, test_acc: 73.12, f1: 72.60
loss: 0.5459, acc: 82.00, test_acc: 71.24, f1: 70.40
loss: 0.4842, acc: 82.21, test_acc: 75.14, f1: 72.99
loss: 0.4529, acc: 82.64, test_acc: 71.82, f1: 71.20
loss: 0.1897, acc: 83.04, test_acc: 70.66, f1: 70.46
loss: 0.4835, acc: 82.76, test_acc: 72.25, f1: 71.34
loss: 0.2889, acc: 83.12, test_acc: 72.69, f1: 71.26
loss: 0.5116, acc: 83.06, test_acc: 72.83, f1: 71.93
loss: 0.3557, acc: 83.40, test_acc: 71.53, f1: 71.43
loss: 0.5780, acc: 83.14, test_acc: 74.57, f1: 72.43
loss: 0.5359, acc: 82.72, test_acc: 72.98, f1: 72.36
loss: 0.3568, acc: 82.86, test_acc: 66.76, f1: 67.09
loss: 0.8593, acc: 82.12, test_acc: 72.69, f1: 71.68
loss: 0.3534, acc: 82.26, test_acc: 73.12, f1: 69.09
loss: 0.6700, acc: 81.91, test_acc: 75.00, f1: 73.77
loss: 0.8657, acc: 81.09, test_acc: 68.06, f1: 68.38
loss: 0.4417, acc: 81.41, test_acc: 74.28, f1: 73.79
loss: 0.7154, acc: 80.95, test_acc: 76.30, f1: 74.05
loss: 0.5345, acc: 80.80, test_acc: 74.86, f1: 73.70
loss: 0.5919, acc: 80.52, test_acc: 72.25, f1: 72.14
loss: 0.2973, acc: 80.68, test_acc: 77.02, f1: 76.10
loss: 0.4565, acc: 80.97, test_acc: 76.01, f1: 74.02
loss: 0.3607, acc: 81.25, test_acc: 77.31, f1: 75.88
loss: 0.5233, acc: 81.12, test_acc: 75.29, f1: 74.20
loss: 0.5729, acc: 80.99, test_acc: 75.43, f1: 74.40
loss: 0.2000, acc: 81.38, test_acc: 75.14, f1: 73.70
loss: 0.2816, acc: 81.62, test_acc: 73.70, f1: 73.11
loss: 0.1815, acc: 81.99, test_acc: 74.13, f1: 73.18
loss: 0.3079, acc: 82.09, test_acc: 75.00, f1: 73.33
loss: 0.3812, acc: 82.08, test_acc: 75.58, f1: 73.60
loss: 0.3182, acc: 82.18, test_acc: 72.98, f1: 72.60
loss: 0.6813, acc: 82.16, test_acc: 73.99, f1: 72.77
loss: 0.2307, acc: 82.37, test_acc: 72.69, f1: 71.25
loss: 0.4917, acc: 82.46, test_acc: 73.84, f1: 73.27
loss: 0.2550, acc: 82.76, test_acc: 74.86, f1: 73.64
loss: 0.7336, acc: 82.42, test_acc: 75.14, f1: 73.39
loss: 0.4766, acc: 82.40, test_acc: 75.58, f1: 75.33
loss: 0.7033, acc: 82.07, test_acc: 71.10, f1: 71.18
loss: 0.5711, acc: 81.96, test_acc: 75.00, f1: 73.47
loss: 0.6496, acc: 81.94, test_acc: 76.88, f1: 75.48
loss: 0.2978, acc: 82.03, test_acc: 77.02, f1: 75.88
loss: 0.4866, acc: 81.92, test_acc: 76.45, f1: 75.13
loss: 0.4426, acc: 81.82, test_acc: 75.43, f1: 74.95
loss: 0.3808, acc: 82.00, test_acc: 76.30, f1: 75.24
loss: 0.6549, acc: 81.99, test_acc: 75.87, f1: 73.99
loss: 0.2846, acc: 82.07, test_acc: 76.73, f1: 75.25
loss: 0.3573, acc: 82.23, test_acc: 70.38, f1: 70.47
loss: 0.4685, acc: 82.13, test_acc: 72.69, f1: 72.82
loss: 0.9265, acc: 81.94, test_acc: 77.02, f1: 75.69
loss: 0.6152, acc: 81.93, test_acc: 76.45, f1: 75.45
loss: 0.4522, acc: 82.01, test_acc: 75.00, f1: 74.52
loss: 0.3077, acc: 82.17, test_acc: 73.99, f1: 73.79
loss: 0.4874, acc: 82.15, test_acc: 75.00, f1: 74.28
loss: 0.4671, acc: 82.06, test_acc: 75.00, f1: 73.33
loss: 0.2008, acc: 82.21, test_acc: 77.31, f1: 76.00
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1656, acc: 100.00, test_acc: 75.58, f1: 74.61
loss: 0.1394, acc: 100.00, test_acc: 76.16, f1: 74.99
loss: 0.3322, acc: 95.83, test_acc: 75.58, f1: 74.66
loss: 0.2894, acc: 93.75, test_acc: 74.86, f1: 74.09
loss: 0.2852, acc: 92.50, test_acc: 73.55, f1: 73.14
loss: 0.0815, acc: 93.75, test_acc: 73.84, f1: 73.15
loss: 0.1637, acc: 92.86, test_acc: 73.99, f1: 73.32
loss: 0.2791, acc: 92.19, test_acc: 76.01, f1: 74.87
loss: 0.0783, acc: 93.06, test_acc: 76.01, f1: 74.92
loss: 0.1082, acc: 93.12, test_acc: 73.55, f1: 73.15
loss: 0.0920, acc: 93.75, test_acc: 75.72, f1: 74.57
loss: 0.3943, acc: 93.23, test_acc: 76.30, f1: 74.95
loss: 0.1836, acc: 93.27, test_acc: 76.16, f1: 74.88
loss: 0.1590, acc: 93.30, test_acc: 71.53, f1: 71.41
loss: 0.2131, acc: 93.33, test_acc: 73.55, f1: 73.09
loss: 0.0878, acc: 93.75, test_acc: 74.42, f1: 72.82
loss: 0.1478, acc: 93.38, test_acc: 74.71, f1: 73.35
loss: 0.1871, acc: 93.40, test_acc: 71.68, f1: 71.46
loss: 0.1237, acc: 93.75, test_acc: 70.95, f1: 70.77
loss: 0.2170, acc: 93.75, test_acc: 72.98, f1: 72.21
loss: 0.2104, acc: 93.75, test_acc: 74.57, f1: 73.01
loss: 0.0890, acc: 94.03, test_acc: 74.57, f1: 73.49
loss: 0.4016, acc: 93.21, test_acc: 72.11, f1: 72.08
loss: 0.4565, acc: 92.97, test_acc: 73.12, f1: 72.79
loss: 0.1175, acc: 93.25, test_acc: 73.27, f1: 71.15
loss: 0.4365, acc: 92.79, test_acc: 73.99, f1: 72.85
loss: 0.6510, acc: 92.36, test_acc: 74.42, f1: 73.92
loss: 0.1066, acc: 92.41, test_acc: 73.55, f1: 71.49
loss: 0.1099, acc: 92.67, test_acc: 73.70, f1: 71.90
loss: 0.3625, acc: 92.29, test_acc: 73.84, f1: 72.61
loss: 0.0926, acc: 92.54, test_acc: 74.42, f1: 73.39
loss: 0.0461, acc: 92.77, test_acc: 73.99, f1: 73.61
loss: 0.2228, acc: 92.61, test_acc: 75.29, f1: 73.98
loss: 0.1482, acc: 92.83, test_acc: 75.00, f1: 73.87
loss: 0.4519, acc: 92.50, test_acc: 76.16, f1: 75.23
loss: 0.1817, acc: 92.53, test_acc: 73.55, f1: 73.10
loss: 0.1436, acc: 92.57, test_acc: 74.28, f1: 73.87
loss: 0.4054, acc: 92.27, test_acc: 74.57, f1: 73.74
loss: 0.3133, acc: 92.31, test_acc: 73.12, f1: 72.31
loss: 0.4579, acc: 92.34, test_acc: 74.42, f1: 73.84
loss: 0.2885, acc: 92.23, test_acc: 74.86, f1: 74.01
loss: 0.0650, acc: 92.41, test_acc: 75.14, f1: 74.18
loss: 0.5560, acc: 92.30, test_acc: 76.01, f1: 74.63
loss: 0.5241, acc: 92.19, test_acc: 74.28, f1: 73.52
loss: 0.3790, acc: 92.08, test_acc: 75.43, f1: 74.75
loss: 0.1548, acc: 92.12, test_acc: 73.70, f1: 73.36
loss: 0.4078, acc: 91.76, test_acc: 75.14, f1: 74.49
loss: 0.2540, acc: 91.80, test_acc: 75.72, f1: 73.99
loss: 0.3134, acc: 91.45, test_acc: 74.71, f1: 73.94
loss: 0.0901, acc: 91.62, test_acc: 73.55, f1: 73.23
loss: 0.1692, acc: 91.67, test_acc: 74.13, f1: 73.57
loss: 0.4322, acc: 91.59, test_acc: 76.01, f1: 74.60
loss: 0.2223, acc: 91.51, test_acc: 74.71, f1: 73.45
loss: 0.0340, acc: 91.67, test_acc: 72.83, f1: 72.26
loss: 0.3641, acc: 91.59, test_acc: 75.72, f1: 74.62
loss: 0.2993, acc: 91.41, test_acc: 76.01, f1: 73.82
loss: 0.3588, acc: 91.23, test_acc: 73.55, f1: 72.81
loss: 0.2841, acc: 91.06, test_acc: 71.39, f1: 71.18
loss: 0.1981, acc: 91.00, test_acc: 75.14, f1: 72.82
loss: 0.3655, acc: 90.83, test_acc: 74.42, f1: 72.19
loss: 0.3587, acc: 90.68, test_acc: 74.57, f1: 73.15
loss: 0.2587, acc: 90.52, test_acc: 73.41, f1: 72.53
loss: 0.4872, acc: 90.28, test_acc: 71.39, f1: 71.31
loss: 0.0923, acc: 90.43, test_acc: 73.55, f1: 71.81
loss: 0.6017, acc: 90.29, test_acc: 74.57, f1: 71.97
loss: 0.0698, acc: 90.44, test_acc: 74.13, f1: 73.40
loss: 0.3306, acc: 90.39, test_acc: 73.55, f1: 72.94
loss: 0.2061, acc: 90.44, test_acc: 73.99, f1: 73.02
loss: 0.0192, acc: 90.58, test_acc: 74.57, f1: 73.65
loss: 0.5250, acc: 90.45, test_acc: 73.84, f1: 73.08
loss: 0.5777, acc: 90.32, test_acc: 73.99, f1: 71.89
loss: 0.5066, acc: 90.28, test_acc: 73.70, f1: 71.38
loss: 0.1268, acc: 90.41, test_acc: 75.00, f1: 73.46
loss: 0.2931, acc: 90.37, test_acc: 72.98, f1: 71.74
loss: 0.2481, acc: 90.42, test_acc: 72.25, f1: 70.84
loss: 0.1041, acc: 90.54, test_acc: 74.57, f1: 73.62
loss: 0.1623, acc: 90.58, test_acc: 73.12, f1: 72.55
loss: 0.1588, acc: 90.62, test_acc: 72.40, f1: 71.61
####################################################################################################
max_test_acc_overall:77.45664739884393
max_f1_overall:76.20838290690565
####################################################################################################
1 test_acc_overall: 77.75  f1_overall:75.99
2 test_acc_overall: 76.59  f1_overall:75.11
3 test_acc_overall: 77.46  f1_overall:76.21
max_acc_overall:77.75  f1_overall:75.99
mean_acc_overall:77.26  mean_f1_overall:75.77
####################################################################################################
lcf_bert - twitter - lcf_fusion - No.4 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 3
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc36.13
max_acc:36.13  f1:27.22
loss: 1.1113, acc: 31.25, test_acc: 36.13, f1: 27.22
>> saved: state_dict/lcf_bert_twitter_acc51.01
max_acc:51.01  f1:28.05
loss: 0.8926, acc: 43.75, test_acc: 51.01, f1: 28.05
loss: 1.2165, acc: 45.83, test_acc: 50.00, f1: 22.22
loss: 0.8530, acc: 50.00, test_acc: 50.00, f1: 22.22
loss: 0.8532, acc: 51.25, test_acc: 36.13, f1: 27.28
>> saved: state_dict/lcf_bert_twitter_acc51.73
max_acc:51.73  f1:27.91
loss: 0.9095, acc: 55.21, test_acc: 51.73, f1: 27.91
>> saved: state_dict/lcf_bert_twitter_acc53.18
max_acc:53.18  f1:33.31
loss: 0.9364, acc: 56.25, test_acc: 53.18, f1: 33.31
loss: 1.0467, acc: 56.25, test_acc: 51.30, f1: 26.02
>> saved: state_dict/lcf_bert_twitter_acc56.21
max_acc:56.21  f1:39.92
loss: 1.0747, acc: 54.86, test_acc: 56.21, f1: 39.92
>> saved: state_dict/lcf_bert_twitter_acc58.82
max_acc:58.82  f1:55.05
loss: 0.9312, acc: 56.25, test_acc: 58.82, f1: 55.05
loss: 0.9227, acc: 56.25, test_acc: 57.08, f1: 41.95
>> saved: state_dict/lcf_bert_twitter_acc64.45
max_acc:64.45  f1:61.19
loss: 0.9703, acc: 57.29, test_acc: 64.45, f1: 61.19
loss: 0.8793, acc: 56.73, test_acc: 62.28, f1: 60.94
loss: 0.9477, acc: 55.80, test_acc: 60.84, f1: 51.26
loss: 1.3402, acc: 54.58, test_acc: 62.43, f1: 58.78
loss: 0.7815, acc: 55.47, test_acc: 58.24, f1: 58.57
loss: 0.6435, acc: 56.62, test_acc: 64.16, f1: 58.83
loss: 0.6487, acc: 57.29, test_acc: 63.73, f1: 61.02
>> saved: state_dict/lcf_bert_twitter_acc66.18
max_acc:66.18  f1:65.24
loss: 0.9361, acc: 56.25, test_acc: 66.18, f1: 65.24
loss: 0.8920, acc: 55.94, test_acc: 64.02, f1: 58.73
>> saved: state_dict/lcf_bert_twitter_acc68.5
max_acc:68.5  f1:66.81
loss: 0.9426, acc: 55.95, test_acc: 68.50, f1: 66.81
loss: 0.7451, acc: 56.25, test_acc: 56.65, f1: 57.34
loss: 0.9543, acc: 55.98, test_acc: 56.21, f1: 56.57
loss: 0.8598, acc: 55.99, test_acc: 60.12, f1: 46.84
loss: 0.8658, acc: 56.00, test_acc: 61.56, f1: 50.75
loss: 0.7056, acc: 56.49, test_acc: 67.49, f1: 65.85
>> saved: state_dict/lcf_bert_twitter_acc69.22
max_acc:69.22  f1:67.78
loss: 0.4841, acc: 57.64, test_acc: 69.22, f1: 67.78
loss: 0.7728, acc: 57.37, test_acc: 64.60, f1: 56.52
>> saved: state_dict/lcf_bert_twitter_acc69.94
max_acc:69.94  f1:68.33
loss: 1.0497, acc: 57.97, test_acc: 69.94, f1: 68.33
loss: 0.9583, acc: 57.71, test_acc: 61.56, f1: 62.20
>> saved: state_dict/lcf_bert_twitter_acc70.38
max_acc:70.38  f1:68.85
loss: 0.8851, acc: 57.86, test_acc: 70.38, f1: 68.85
loss: 1.0054, acc: 58.20, test_acc: 66.91, f1: 60.33
>> saved: state_dict/lcf_bert_twitter_acc70.52
max_acc:70.52  f1:69.04
loss: 0.5695, acc: 58.90, test_acc: 70.52, f1: 69.04
loss: 0.7831, acc: 58.64, test_acc: 62.57, f1: 63.07
>> saved: state_dict/lcf_bert_twitter_acc70.95
max_acc:70.95  f1:69.08
loss: 0.7367, acc: 58.93, test_acc: 70.95, f1: 69.08
loss: 0.6045, acc: 59.72, test_acc: 70.09, f1: 66.53
>> saved: state_dict/lcf_bert_twitter_acc71.39
max_acc:71.39  f1:70.03
loss: 0.7723, acc: 59.63, test_acc: 71.39, f1: 70.03
loss: 0.7951, acc: 59.87, test_acc: 65.75, f1: 65.83
loss: 0.6608, acc: 60.26, test_acc: 68.79, f1: 66.20
loss: 0.5168, acc: 60.62, test_acc: 70.81, f1: 67.78
loss: 0.4940, acc: 61.13, test_acc: 70.38, f1: 69.37
loss: 0.5714, acc: 61.31, test_acc: 68.21, f1: 68.24
loss: 0.5357, acc: 61.77, test_acc: 67.49, f1: 67.38
>> saved: state_dict/lcf_bert_twitter_acc72.83
max_acc:72.83  f1:71.39
loss: 0.7744, acc: 61.65, test_acc: 72.83, f1: 71.39
loss: 0.6430, acc: 61.94, test_acc: 72.40, f1: 71.29
>> saved: state_dict/lcf_bert_twitter_acc74.13
max_acc:74.13  f1:73.11
loss: 0.4589, acc: 62.50, test_acc: 74.13, f1: 73.11
>> saved: state_dict/lcf_bert_twitter_acc74.28
max_acc:74.28  f1:72.55
loss: 0.4882, acc: 62.90, test_acc: 74.28, f1: 72.55
>> saved: state_dict/lcf_bert_twitter_acc74.57
max_acc:74.57  f1:73.04
loss: 1.0185, acc: 62.63, test_acc: 74.57, f1: 73.04
loss: 0.9326, acc: 62.76, test_acc: 69.51, f1: 69.54
loss: 0.6857, acc: 63.00, test_acc: 70.38, f1: 70.48
loss: 0.9713, acc: 62.99, test_acc: 73.84, f1: 72.45
loss: 0.9207, acc: 62.74, test_acc: 73.12, f1: 71.12
loss: 0.6209, acc: 62.74, test_acc: 72.40, f1: 71.22
loss: 0.6001, acc: 62.96, test_acc: 70.95, f1: 69.86
loss: 0.6002, acc: 63.30, test_acc: 72.54, f1: 71.20
loss: 0.5121, acc: 63.50, test_acc: 73.12, f1: 71.77
loss: 0.8431, acc: 63.49, test_acc: 69.65, f1: 64.65
loss: 0.8814, acc: 63.47, test_acc: 72.83, f1: 70.27
loss: 0.7678, acc: 63.56, test_acc: 70.09, f1: 70.05
loss: 0.6946, acc: 63.85, test_acc: 71.97, f1: 71.61
loss: 0.6423, acc: 64.14, test_acc: 72.11, f1: 67.19
loss: 0.7583, acc: 64.42, test_acc: 74.13, f1: 71.79
loss: 0.5685, acc: 64.58, test_acc: 62.72, f1: 63.52
loss: 0.9482, acc: 64.16, test_acc: 72.11, f1: 71.87
loss: 0.6032, acc: 64.23, test_acc: 70.81, f1: 66.07
loss: 0.3311, acc: 64.68, test_acc: 74.57, f1: 71.67
loss: 0.7459, acc: 64.74, test_acc: 71.68, f1: 70.95
loss: 0.3858, acc: 65.07, test_acc: 70.95, f1: 70.64
loss: 0.8112, acc: 65.04, test_acc: 72.40, f1: 72.00
>> saved: state_dict/lcf_bert_twitter_acc75.43
max_acc:75.43  f1:73.43
loss: 0.4406, acc: 65.27, test_acc: 75.43, f1: 73.43
loss: 0.9099, acc: 65.05, test_acc: 74.71, f1: 72.91
loss: 0.5032, acc: 65.28, test_acc: 72.25, f1: 70.55
loss: 0.6130, acc: 65.41, test_acc: 73.27, f1: 70.56
loss: 0.5431, acc: 65.46, test_acc: 73.55, f1: 70.69
loss: 0.5755, acc: 65.75, test_acc: 71.39, f1: 70.94
loss: 0.8629, acc: 65.71, test_acc: 68.06, f1: 68.45
loss: 0.7876, acc: 65.75, test_acc: 72.25, f1: 69.21
loss: 0.4536, acc: 65.87, test_acc: 70.66, f1: 66.34
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.4421, acc: 87.50, test_acc: 73.27, f1: 72.08
loss: 0.5700, acc: 84.38, test_acc: 69.36, f1: 68.77
loss: 0.6580, acc: 83.33, test_acc: 70.38, f1: 68.86
loss: 0.5542, acc: 82.81, test_acc: 70.66, f1: 69.08
loss: 0.3388, acc: 85.00, test_acc: 70.81, f1: 69.89
loss: 0.1624, acc: 87.50, test_acc: 73.12, f1: 72.23
loss: 0.2252, acc: 88.39, test_acc: 72.98, f1: 71.83
loss: 0.3498, acc: 88.28, test_acc: 70.23, f1: 69.65
loss: 0.2358, acc: 89.58, test_acc: 73.41, f1: 72.51
loss: 0.7544, acc: 86.25, test_acc: 73.84, f1: 71.94
loss: 0.3889, acc: 85.80, test_acc: 71.24, f1: 71.16
loss: 0.4625, acc: 85.42, test_acc: 71.24, f1: 70.97
loss: 0.7835, acc: 84.62, test_acc: 75.14, f1: 73.70
loss: 0.4452, acc: 84.82, test_acc: 72.98, f1: 72.31
loss: 0.6554, acc: 84.58, test_acc: 70.23, f1: 70.22
loss: 0.3692, acc: 84.38, test_acc: 73.27, f1: 72.57
loss: 0.3515, acc: 84.56, test_acc: 73.99, f1: 71.42
loss: 0.6693, acc: 83.68, test_acc: 73.41, f1: 71.76
loss: 0.2386, acc: 83.88, test_acc: 73.70, f1: 72.71
loss: 0.6942, acc: 82.81, test_acc: 73.12, f1: 72.09
loss: 0.2996, acc: 83.33, test_acc: 72.83, f1: 72.42
loss: 0.7311, acc: 82.67, test_acc: 74.57, f1: 73.05
loss: 0.6276, acc: 82.61, test_acc: 74.86, f1: 73.32
loss: 0.1598, acc: 83.33, test_acc: 74.71, f1: 73.33
loss: 0.2636, acc: 84.00, test_acc: 68.50, f1: 68.42
loss: 0.3086, acc: 84.13, test_acc: 73.41, f1: 72.52
loss: 0.8675, acc: 83.33, test_acc: 73.12, f1: 72.78
loss: 0.4845, acc: 83.26, test_acc: 74.28, f1: 73.34
loss: 0.3137, acc: 83.41, test_acc: 74.28, f1: 71.02
>> saved: state_dict/lcf_bert_twitter_acc75.72
max_acc:75.72  f1:73.63
loss: 0.2962, acc: 83.54, test_acc: 75.72, f1: 73.63
loss: 0.4637, acc: 83.67, test_acc: 68.93, f1: 68.92
loss: 0.4369, acc: 83.98, test_acc: 70.09, f1: 69.68
loss: 0.6336, acc: 83.52, test_acc: 74.13, f1: 71.83
loss: 0.6615, acc: 83.27, test_acc: 71.97, f1: 69.65
loss: 0.3892, acc: 83.39, test_acc: 75.72, f1: 74.73
loss: 0.5758, acc: 83.51, test_acc: 72.54, f1: 71.65
loss: 0.2261, acc: 83.61, test_acc: 75.29, f1: 73.92
loss: 0.6837, acc: 83.39, test_acc: 73.84, f1: 73.43
loss: 0.7989, acc: 83.17, test_acc: 73.99, f1: 72.83
loss: 0.4321, acc: 83.12, test_acc: 73.12, f1: 71.09
loss: 0.6967, acc: 82.93, test_acc: 73.27, f1: 72.07
loss: 0.3770, acc: 83.04, test_acc: 73.27, f1: 72.65
loss: 0.5988, acc: 82.70, test_acc: 73.70, f1: 72.56
loss: 0.7635, acc: 82.39, test_acc: 72.98, f1: 72.00
loss: 0.4083, acc: 82.50, test_acc: 72.40, f1: 71.56
loss: 0.3495, acc: 82.61, test_acc: 73.84, f1: 72.06
>> saved: state_dict/lcf_bert_twitter_acc76.01
max_acc:76.01  f1:74.36
loss: 0.3954, acc: 82.58, test_acc: 76.01, f1: 74.36
loss: 0.3302, acc: 82.55, test_acc: 72.69, f1: 71.21
loss: 0.6918, acc: 82.40, test_acc: 74.42, f1: 73.80
loss: 0.6680, acc: 82.25, test_acc: 72.11, f1: 71.08
loss: 0.6169, acc: 82.23, test_acc: 74.42, f1: 73.23
loss: 0.8415, acc: 81.97, test_acc: 71.24, f1: 70.69
>> saved: state_dict/lcf_bert_twitter_acc76.16
max_acc:76.16  f1:74.49
loss: 0.4511, acc: 81.84, test_acc: 76.16, f1: 74.49
loss: 0.2689, acc: 82.18, test_acc: 75.00, f1: 72.94
loss: 0.9136, acc: 81.82, test_acc: 72.98, f1: 70.67
loss: 1.2195, acc: 81.36, test_acc: 70.95, f1: 70.08
loss: 0.4125, acc: 81.36, test_acc: 73.70, f1: 72.40
loss: 0.3934, acc: 81.36, test_acc: 76.01, f1: 74.63
loss: 0.2974, acc: 81.57, test_acc: 75.14, f1: 74.13
loss: 0.7232, acc: 81.46, test_acc: 75.72, f1: 73.51
loss: 0.7599, acc: 81.25, test_acc: 74.42, f1: 73.60
loss: 0.7529, acc: 81.05, test_acc: 75.58, f1: 74.77
>> saved: state_dict/lcf_bert_twitter_acc77.02
max_acc:77.02  f1:75.48
loss: 0.5007, acc: 80.85, test_acc: 77.02, f1: 75.48
loss: 0.6059, acc: 80.57, test_acc: 74.13, f1: 73.41
loss: 0.4983, acc: 80.58, test_acc: 69.80, f1: 69.71
loss: 0.3829, acc: 80.68, test_acc: 69.36, f1: 69.68
loss: 0.6428, acc: 80.69, test_acc: 74.71, f1: 71.73
loss: 0.5886, acc: 80.70, test_acc: 74.42, f1: 71.25
loss: 0.6418, acc: 80.62, test_acc: 69.08, f1: 69.26
loss: 0.4672, acc: 80.54, test_acc: 69.36, f1: 69.34
loss: 0.3734, acc: 80.63, test_acc: 75.14, f1: 73.13
loss: 0.5253, acc: 80.64, test_acc: 75.58, f1: 72.24
loss: 0.3496, acc: 80.65, test_acc: 73.12, f1: 71.83
loss: 0.4018, acc: 80.66, test_acc: 73.55, f1: 72.36
loss: 0.4936, acc: 80.67, test_acc: 74.42, f1: 73.37
loss: 0.5287, acc: 80.67, test_acc: 72.83, f1: 71.49
loss: 0.6426, acc: 80.36, test_acc: 73.55, f1: 72.99
loss: 0.6250, acc: 80.13, test_acc: 66.62, f1: 66.77
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.5368, acc: 81.25, test_acc: 73.70, f1: 71.51
loss: 0.3795, acc: 87.50, test_acc: 72.69, f1: 70.88
loss: 0.2604, acc: 89.58, test_acc: 69.51, f1: 69.01
loss: 0.1514, acc: 90.62, test_acc: 71.82, f1: 70.65
loss: 0.0698, acc: 92.50, test_acc: 72.83, f1: 70.85
loss: 0.1271, acc: 92.71, test_acc: 75.14, f1: 72.83
loss: 0.1349, acc: 92.86, test_acc: 74.71, f1: 72.91
loss: 0.1612, acc: 92.97, test_acc: 72.54, f1: 71.54
loss: 0.3009, acc: 92.36, test_acc: 70.23, f1: 70.37
loss: 0.2427, acc: 91.88, test_acc: 73.70, f1: 72.69
loss: 0.1564, acc: 91.48, test_acc: 73.99, f1: 70.95
loss: 0.2071, acc: 91.67, test_acc: 74.28, f1: 73.37
loss: 0.1762, acc: 91.83, test_acc: 70.38, f1: 69.98
loss: 0.2269, acc: 91.52, test_acc: 75.00, f1: 73.40
loss: 0.1062, acc: 91.67, test_acc: 72.69, f1: 71.13
loss: 0.2549, acc: 91.80, test_acc: 71.53, f1: 71.09
loss: 0.2366, acc: 91.54, test_acc: 71.10, f1: 69.59
loss: 0.1306, acc: 91.67, test_acc: 75.58, f1: 73.70
loss: 0.2939, acc: 91.12, test_acc: 74.28, f1: 73.26
loss: 0.3143, acc: 91.25, test_acc: 72.98, f1: 72.03
loss: 0.1464, acc: 91.37, test_acc: 73.84, f1: 72.39
loss: 0.2647, acc: 91.19, test_acc: 72.11, f1: 71.25
loss: 0.1553, acc: 91.58, test_acc: 71.82, f1: 71.25
loss: 0.0809, acc: 91.93, test_acc: 74.71, f1: 73.64
loss: 0.4210, acc: 91.75, test_acc: 75.29, f1: 73.93
loss: 0.1087, acc: 92.07, test_acc: 71.24, f1: 70.99
loss: 0.2007, acc: 92.13, test_acc: 72.25, f1: 71.69
loss: 0.2031, acc: 91.96, test_acc: 73.55, f1: 72.52
loss: 0.0875, acc: 92.24, test_acc: 75.29, f1: 73.62
loss: 0.1095, acc: 92.29, test_acc: 75.14, f1: 73.39
loss: 0.3370, acc: 92.34, test_acc: 74.86, f1: 73.55
loss: 0.2175, acc: 92.19, test_acc: 69.51, f1: 69.20
loss: 0.0618, acc: 92.42, test_acc: 70.38, f1: 69.36
loss: 0.3471, acc: 92.28, test_acc: 72.98, f1: 71.18
loss: 0.4151, acc: 92.32, test_acc: 75.29, f1: 73.87
loss: 0.0645, acc: 92.53, test_acc: 73.70, f1: 72.64
loss: 0.0722, acc: 92.74, test_acc: 74.13, f1: 72.68
loss: 0.3901, acc: 92.60, test_acc: 73.84, f1: 72.60
loss: 0.1272, acc: 92.79, test_acc: 74.28, f1: 73.40
loss: 0.2919, acc: 92.66, test_acc: 74.57, f1: 73.18
loss: 0.3626, acc: 92.38, test_acc: 75.87, f1: 74.21
loss: 0.1121, acc: 92.41, test_acc: 71.68, f1: 70.89
loss: 0.3532, acc: 92.15, test_acc: 71.82, f1: 71.34
loss: 0.5790, acc: 92.05, test_acc: 71.53, f1: 70.98
loss: 0.4459, acc: 91.81, test_acc: 72.83, f1: 71.41
loss: 0.2676, acc: 91.58, test_acc: 67.34, f1: 67.70
loss: 0.2144, acc: 91.49, test_acc: 70.95, f1: 70.27
loss: 0.1895, acc: 91.54, test_acc: 72.83, f1: 68.65
loss: 0.4811, acc: 91.20, test_acc: 74.57, f1: 71.64
loss: 0.2726, acc: 91.25, test_acc: 68.21, f1: 68.61
loss: 0.3570, acc: 91.18, test_acc: 70.23, f1: 69.99
loss: 0.4375, acc: 91.11, test_acc: 73.55, f1: 70.63
loss: 0.2890, acc: 91.04, test_acc: 73.55, f1: 70.24
loss: 0.4297, acc: 90.74, test_acc: 73.55, f1: 73.02
loss: 0.5501, acc: 90.68, test_acc: 67.20, f1: 67.91
loss: 0.1559, acc: 90.62, test_acc: 71.82, f1: 71.42
loss: 0.1732, acc: 90.68, test_acc: 75.14, f1: 73.59
loss: 0.1102, acc: 90.84, test_acc: 70.66, f1: 70.71
loss: 0.5210, acc: 90.68, test_acc: 69.36, f1: 69.26
loss: 0.2814, acc: 90.62, test_acc: 74.86, f1: 73.50
loss: 0.6132, acc: 90.27, test_acc: 74.57, f1: 73.45
loss: 0.4222, acc: 90.12, test_acc: 71.39, f1: 70.95
loss: 0.2796, acc: 90.18, test_acc: 70.66, f1: 70.85
loss: 0.3954, acc: 90.14, test_acc: 73.55, f1: 72.79
loss: 0.3837, acc: 90.00, test_acc: 73.55, f1: 72.16
loss: 0.4192, acc: 89.77, test_acc: 74.42, f1: 72.93
loss: 0.1026, acc: 89.93, test_acc: 74.13, f1: 73.57
loss: 0.2318, acc: 89.98, test_acc: 72.25, f1: 72.07
loss: 0.0515, acc: 90.13, test_acc: 73.84, f1: 72.42
loss: 0.1864, acc: 90.18, test_acc: 74.71, f1: 73.53
loss: 0.2794, acc: 90.14, test_acc: 70.38, f1: 70.02
loss: 0.1252, acc: 90.19, test_acc: 71.97, f1: 71.33
loss: 0.2873, acc: 90.24, test_acc: 71.68, f1: 70.73
loss: 0.2846, acc: 90.12, test_acc: 72.69, f1: 70.78
loss: 0.1164, acc: 90.17, test_acc: 72.40, f1: 71.25
loss: 0.6667, acc: 89.97, test_acc: 73.99, f1: 73.34
loss: 0.1248, acc: 90.02, test_acc: 73.12, f1: 71.87
loss: 0.2115, acc: 89.98, test_acc: 74.28, f1: 73.58
####################################################################################################
max_test_acc_overall:77.02312138728324
max_f1_overall:75.48400926478024
####################################################################################################
1 test_acc_overall: 77.75  f1_overall:75.99
2 test_acc_overall: 76.59  f1_overall:75.11
3 test_acc_overall: 77.46  f1_overall:76.21
4 test_acc_overall: 77.02  f1_overall:75.48
max_acc_overall:77.75  f1_overall:75.99
mean_acc_overall:77.2  mean_f1_overall:75.7
####################################################################################################
lcf_bert - twitter - lcf_fusion - No.5 in 5
Model name 'bert_pretrained_models/restaurant' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_pretrained_models/restaurant' is a path or url to a directory containing tokenizer files.
loading file bert_pretrained_models/restaurant/vocab.txt
loading file bert_pretrained_models/restaurant/added_tokens.json
loading file bert_pretrained_models/restaurant/special_tokens_map.json
loading configuration file bert_pretrained_models/restaurant/config.json
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file bert_pretrained_models/restaurant/pytorch_model.bin
buliding word indices...
buliding word indices...
cuda memory allocated:898152960
n_trainable_params: 224279811, n_nontrainable_params: 0
>>> model_name: lcf_bert
>>> dataset: twitter
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f3531ebf2f0>
>>> learning_rate: 2e-05
>>> dropout: 0
>>> l2reg: 1e-05
>>> num_epoch: 3
>>> batch_size: 16
>>> log_step: 5
>>> logdir: log
>>> bert_dim: 768
>>> pretrained_bert_name: bert_pretrained_models/restaurant
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> SRD: 5
>>> local_context_focus: lcf_fusion
>>> device: cuda:1
>>> seed: 4
>>> model_class: <class 'models.lcf_bert.LCF_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids', 'text_raw_bert_indices', 'aspect_bert_indices']
repeat: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: state_dict/lcf_bert_twitter_acc26.16
max_acc:26.16  f1:15.74
loss: 1.2650, acc: 31.25, test_acc: 26.16, f1: 15.74
>> saved: state_dict/lcf_bert_twitter_acc51.45
max_acc:51.45  f1:26.38
loss: 0.9547, acc: 43.75, test_acc: 51.45, f1: 26.38
loss: 1.2459, acc: 47.92, test_acc: 50.00, f1: 22.22
>> saved: state_dict/lcf_bert_twitter_acc52.02
max_acc:52.02  f1:34.83
loss: 1.0877, acc: 48.44, test_acc: 52.02, f1: 34.83
>> saved: state_dict/lcf_bert_twitter_acc52.6
max_acc:52.6  f1:29.45
loss: 1.0619, acc: 48.75, test_acc: 52.60, f1: 29.45
>> saved: state_dict/lcf_bert_twitter_acc52.89
max_acc:52.89  f1:30.06
loss: 0.6982, acc: 52.08, test_acc: 52.89, f1: 30.06
loss: 1.1208, acc: 51.79, test_acc: 52.60, f1: 29.66
loss: 1.0524, acc: 48.44, test_acc: 27.60, f1: 18.75
loss: 0.8730, acc: 49.31, test_acc: 52.17, f1: 28.47
>> saved: state_dict/lcf_bert_twitter_acc56.21
max_acc:56.21  f1:39.49
loss: 1.1659, acc: 48.75, test_acc: 56.21, f1: 39.49
loss: 0.7996, acc: 51.14, test_acc: 51.45, f1: 51.66
>> saved: state_dict/lcf_bert_twitter_acc62.57
max_acc:62.57  f1:57.03
loss: 0.6756, acc: 53.12, test_acc: 62.57, f1: 57.03
loss: 0.8415, acc: 53.85, test_acc: 60.98, f1: 54.03
>> saved: state_dict/lcf_bert_twitter_acc64.02
max_acc:64.02  f1:62.55
loss: 0.8423, acc: 54.02, test_acc: 64.02, f1: 62.55
loss: 0.7597, acc: 54.58, test_acc: 55.20, f1: 55.50
loss: 0.7205, acc: 55.86, test_acc: 61.27, f1: 50.22
loss: 0.4553, acc: 57.35, test_acc: 63.15, f1: 58.99
loss: 0.7842, acc: 57.64, test_acc: 60.55, f1: 60.58
>> saved: state_dict/lcf_bert_twitter_acc65.17
max_acc:65.17  f1:64.29
loss: 0.6267, acc: 58.22, test_acc: 65.17, f1: 64.29
loss: 0.9489, acc: 58.44, test_acc: 64.31, f1: 57.72
loss: 1.1241, acc: 58.33, test_acc: 58.96, f1: 59.55
loss: 0.9174, acc: 58.81, test_acc: 59.83, f1: 58.04
loss: 0.8700, acc: 59.24, test_acc: 65.03, f1: 58.23
>> saved: state_dict/lcf_bert_twitter_acc65.32
max_acc:65.32  f1:61.89
loss: 0.8357, acc: 59.38, test_acc: 65.32, f1: 61.89
>> saved: state_dict/lcf_bert_twitter_acc66.04
max_acc:66.04  f1:64.77
loss: 1.0327, acc: 58.50, test_acc: 66.04, f1: 64.77
loss: 0.8080, acc: 58.89, test_acc: 65.17, f1: 64.18
>> saved: state_dict/lcf_bert_twitter_acc66.33
max_acc:66.33  f1:59.9
loss: 0.7833, acc: 59.03, test_acc: 66.33, f1: 59.90
>> saved: state_dict/lcf_bert_twitter_acc67.63
max_acc:67.63  f1:63.72
loss: 0.9195, acc: 58.93, test_acc: 67.63, f1: 63.72
loss: 0.7476, acc: 59.27, test_acc: 64.74, f1: 64.92
loss: 1.1551, acc: 58.96, test_acc: 60.12, f1: 60.51
>> saved: state_dict/lcf_bert_twitter_acc68.79
max_acc:68.79  f1:65.18
loss: 0.5642, acc: 59.27, test_acc: 68.79, f1: 65.18
>> saved: state_dict/lcf_bert_twitter_acc69.65
max_acc:69.65  f1:67.33
loss: 0.5967, acc: 59.96, test_acc: 69.65, f1: 67.33
loss: 0.8234, acc: 60.23, test_acc: 64.02, f1: 64.00
loss: 0.4914, acc: 61.03, test_acc: 68.64, f1: 67.47
>> saved: state_dict/lcf_bert_twitter_acc70.52
max_acc:70.52  f1:67.54
loss: 0.8457, acc: 61.07, test_acc: 70.52, f1: 67.54
loss: 0.5271, acc: 61.46, test_acc: 68.50, f1: 67.48
loss: 0.5859, acc: 61.82, test_acc: 70.38, f1: 68.68
>> saved: state_dict/lcf_bert_twitter_acc71.1
max_acc:71.1  f1:68.41
loss: 0.8226, acc: 61.35, test_acc: 71.10, f1: 68.41
loss: 1.0503, acc: 61.22, test_acc: 67.34, f1: 66.35
loss: 0.6771, acc: 61.56, test_acc: 69.36, f1: 65.80
loss: 0.5444, acc: 61.89, test_acc: 70.38, f1: 67.94
loss: 0.8308, acc: 62.05, test_acc: 69.51, f1: 68.56
loss: 0.5167, acc: 62.50, test_acc: 63.58, f1: 61.29
loss: 0.4930, acc: 63.07, test_acc: 67.77, f1: 67.09
loss: 0.4457, acc: 63.19, test_acc: 68.64, f1: 67.47
>> saved: state_dict/lcf_bert_twitter_acc72.4
max_acc:72.4  f1:70.81
loss: 0.9577, acc: 63.18, test_acc: 72.40, f1: 70.81
loss: 0.7819, acc: 63.16, test_acc: 66.62, f1: 66.93
loss: 0.8316, acc: 63.28, test_acc: 66.76, f1: 67.24
loss: 0.9098, acc: 63.65, test_acc: 70.66, f1: 69.74
loss: 0.5633, acc: 63.75, test_acc: 70.38, f1: 69.72
loss: 0.9599, acc: 63.73, test_acc: 67.49, f1: 67.34
loss: 0.6771, acc: 63.70, test_acc: 71.68, f1: 70.45
>> saved: state_dict/lcf_bert_twitter_acc72.98
max_acc:72.98  f1:70.08
loss: 1.2046, acc: 63.56, test_acc: 72.98, f1: 70.08
loss: 0.4873, acc: 63.66, test_acc: 70.23, f1: 69.41
loss: 0.7423, acc: 63.86, test_acc: 69.22, f1: 68.95
loss: 0.5359, acc: 64.17, test_acc: 71.53, f1: 70.69
>> saved: state_dict/lcf_bert_twitter_acc73.99
max_acc:73.99  f1:72.84
loss: 0.6282, acc: 64.47, test_acc: 73.99, f1: 72.84
loss: 0.8216, acc: 64.66, test_acc: 71.82, f1: 70.96
loss: 1.0259, acc: 64.30, test_acc: 73.99, f1: 71.85
loss: 0.9975, acc: 64.17, test_acc: 73.99, f1: 72.20
loss: 0.9902, acc: 64.24, test_acc: 64.74, f1: 64.96
loss: 0.5828, acc: 64.52, test_acc: 68.06, f1: 67.74
loss: 0.6275, acc: 64.38, test_acc: 71.82, f1: 70.55
loss: 0.5257, acc: 64.45, test_acc: 72.54, f1: 71.54
loss: 0.4772, acc: 64.71, test_acc: 65.03, f1: 65.30
loss: 0.4611, acc: 64.96, test_acc: 72.69, f1: 71.84
loss: 0.6305, acc: 65.21, test_acc: 73.55, f1: 72.15
>> saved: state_dict/lcf_bert_twitter_acc74.13
max_acc:74.13  f1:71.82
loss: 0.4797, acc: 65.53, test_acc: 74.13, f1: 71.82
loss: 1.0247, acc: 65.40, test_acc: 69.80, f1: 70.00
loss: 0.3428, acc: 65.80, test_acc: 69.08, f1: 69.06
loss: 0.9864, acc: 65.76, test_acc: 67.63, f1: 67.29
loss: 0.6627, acc: 65.80, test_acc: 71.97, f1: 71.55
loss: 0.7305, acc: 65.84, test_acc: 71.10, f1: 70.20
loss: 0.6305, acc: 65.79, test_acc: 72.54, f1: 71.72
loss: 1.0455, acc: 65.58, test_acc: 73.12, f1: 71.87
loss: 0.8570, acc: 65.71, test_acc: 72.54, f1: 71.46
loss: 0.6414, acc: 65.99, test_acc: 73.41, f1: 72.45
loss: 0.5801, acc: 66.19, test_acc: 72.25, f1: 70.99
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.7166, acc: 81.25, test_acc: 73.84, f1: 71.53
loss: 0.4336, acc: 84.38, test_acc: 74.13, f1: 73.52
loss: 0.4396, acc: 81.25, test_acc: 67.49, f1: 67.70
loss: 0.3303, acc: 82.81, test_acc: 68.79, f1: 68.75
loss: 0.7621, acc: 81.25, test_acc: 72.69, f1: 72.31
loss: 0.4787, acc: 80.21, test_acc: 71.24, f1: 69.98
loss: 0.2000, acc: 82.14, test_acc: 72.98, f1: 72.64
loss: 0.2351, acc: 83.59, test_acc: 73.55, f1: 72.09
loss: 0.4551, acc: 84.03, test_acc: 73.70, f1: 72.56
loss: 0.1520, acc: 85.00, test_acc: 71.10, f1: 70.80
loss: 0.2934, acc: 85.80, test_acc: 73.99, f1: 73.37
loss: 0.5396, acc: 85.42, test_acc: 72.54, f1: 70.34
loss: 0.4805, acc: 85.10, test_acc: 71.97, f1: 71.56
loss: 0.2128, acc: 85.71, test_acc: 72.69, f1: 72.26
>> saved: state_dict/lcf_bert_twitter_acc75.29
max_acc:75.29  f1:73.66
loss: 0.2839, acc: 85.83, test_acc: 75.29, f1: 73.66
loss: 0.6011, acc: 85.55, test_acc: 71.24, f1: 70.35
loss: 0.3938, acc: 85.29, test_acc: 74.42, f1: 73.23
>> saved: state_dict/lcf_bert_twitter_acc75.87
max_acc:75.87  f1:74.25
loss: 0.4178, acc: 85.42, test_acc: 75.87, f1: 74.25
loss: 0.7041, acc: 84.87, test_acc: 71.24, f1: 71.29
loss: 0.7166, acc: 84.38, test_acc: 73.12, f1: 73.11
loss: 0.4196, acc: 83.93, test_acc: 73.12, f1: 71.74
loss: 0.8939, acc: 83.52, test_acc: 72.40, f1: 71.02
loss: 0.5827, acc: 83.70, test_acc: 73.70, f1: 73.14
loss: 0.2400, acc: 84.11, test_acc: 70.38, f1: 69.65
loss: 0.5584, acc: 84.00, test_acc: 69.80, f1: 70.20
loss: 0.6022, acc: 83.65, test_acc: 71.39, f1: 71.17
loss: 0.6317, acc: 83.10, test_acc: 73.55, f1: 71.76
loss: 0.7089, acc: 82.37, test_acc: 72.83, f1: 71.88
loss: 0.3314, acc: 82.54, test_acc: 72.25, f1: 71.45
loss: 0.3677, acc: 82.50, test_acc: 71.53, f1: 70.70
loss: 0.4984, acc: 82.46, test_acc: 73.12, f1: 71.56
loss: 0.4862, acc: 82.23, test_acc: 73.27, f1: 72.55
loss: 0.5956, acc: 81.82, test_acc: 74.42, f1: 73.61
loss: 0.3592, acc: 81.99, test_acc: 73.70, f1: 73.20
loss: 0.3014, acc: 82.32, test_acc: 72.40, f1: 71.95
loss: 0.3736, acc: 82.29, test_acc: 73.12, f1: 72.90
loss: 0.3795, acc: 82.60, test_acc: 71.24, f1: 69.49
loss: 0.1828, acc: 82.89, test_acc: 73.99, f1: 72.82
loss: 0.5344, acc: 82.85, test_acc: 69.36, f1: 68.76
loss: 0.3621, acc: 82.81, test_acc: 72.25, f1: 71.37
loss: 0.6595, acc: 82.77, test_acc: 73.70, f1: 72.00
loss: 0.4027, acc: 83.04, test_acc: 70.52, f1: 70.66
loss: 0.3804, acc: 83.14, test_acc: 67.92, f1: 67.40
loss: 0.5831, acc: 83.10, test_acc: 73.41, f1: 72.55
loss: 0.4734, acc: 82.92, test_acc: 70.81, f1: 70.80
loss: 0.7139, acc: 82.61, test_acc: 75.00, f1: 73.48
loss: 0.7232, acc: 82.45, test_acc: 72.40, f1: 70.77
loss: 0.4705, acc: 82.42, test_acc: 70.52, f1: 70.18
loss: 0.4561, acc: 82.40, test_acc: 72.40, f1: 71.59
loss: 0.7529, acc: 82.38, test_acc: 74.71, f1: 73.49
loss: 0.2259, acc: 82.60, test_acc: 72.98, f1: 72.52
loss: 0.7489, acc: 82.21, test_acc: 71.53, f1: 71.22
>> saved: state_dict/lcf_bert_twitter_acc76.01
max_acc:76.01  f1:74.48
loss: 0.4144, acc: 82.19, test_acc: 76.01, f1: 74.48
loss: 0.5969, acc: 81.94, test_acc: 75.43, f1: 73.68
loss: 0.6282, acc: 81.70, test_acc: 68.79, f1: 68.75
loss: 0.5123, acc: 81.58, test_acc: 70.66, f1: 70.28
loss: 0.3308, acc: 81.69, test_acc: 73.41, f1: 71.60
loss: 0.4412, acc: 81.68, test_acc: 72.69, f1: 71.71
loss: 0.1577, acc: 81.99, test_acc: 71.24, f1: 70.89
loss: 0.5858, acc: 81.88, test_acc: 71.82, f1: 71.19
loss: 0.5282, acc: 81.86, test_acc: 74.57, f1: 72.84
loss: 0.3636, acc: 81.85, test_acc: 74.13, f1: 72.49
loss: 0.9135, acc: 81.55, test_acc: 73.12, f1: 71.92
loss: 0.4564, acc: 81.45, test_acc: 72.98, f1: 71.92
loss: 0.4696, acc: 81.35, test_acc: 75.00, f1: 73.91
loss: 0.1937, acc: 81.53, test_acc: 74.13, f1: 73.18
loss: 0.2039, acc: 81.72, test_acc: 69.94, f1: 69.79
loss: 1.0812, acc: 81.53, test_acc: 73.70, f1: 72.36
loss: 0.3368, acc: 81.61, test_acc: 75.29, f1: 73.14
loss: 0.4347, acc: 81.61, test_acc: 72.54, f1: 71.96
loss: 0.7128, acc: 81.43, test_acc: 72.98, f1: 72.65
loss: 0.7935, acc: 81.25, test_acc: 74.13, f1: 73.22
loss: 0.3439, acc: 81.51, test_acc: 72.83, f1: 70.68
loss: 0.4476, acc: 81.50, test_acc: 73.99, f1: 73.10
loss: 0.6481, acc: 81.25, test_acc: 70.23, f1: 70.32
loss: 0.8017, acc: 81.17, test_acc: 75.00, f1: 73.82
loss: 0.6623, acc: 81.09, test_acc: 74.13, f1: 71.75
loss: 0.5410, acc: 81.25, test_acc: 74.86, f1: 72.30
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.1044, acc: 100.00, test_acc: 75.72, f1: 74.26
loss: 0.2301, acc: 96.88, test_acc: 73.84, f1: 73.44
loss: 0.3174, acc: 93.75, test_acc: 74.13, f1: 73.38
loss: 0.1554, acc: 93.75, test_acc: 72.69, f1: 72.37
loss: 0.1382, acc: 93.75, test_acc: 75.14, f1: 74.63
loss: 0.2411, acc: 92.71, test_acc: 75.14, f1: 74.39
loss: 0.1534, acc: 92.86, test_acc: 71.24, f1: 70.98
loss: 0.2930, acc: 92.97, test_acc: 71.53, f1: 70.94
loss: 0.0545, acc: 93.75, test_acc: 72.83, f1: 71.60
loss: 0.0593, acc: 94.38, test_acc: 73.99, f1: 72.84
loss: 0.1744, acc: 94.32, test_acc: 73.99, f1: 73.09
loss: 0.2831, acc: 93.75, test_acc: 73.27, f1: 72.82
loss: 0.5184, acc: 92.79, test_acc: 72.69, f1: 72.16
loss: 0.1367, acc: 92.86, test_acc: 74.71, f1: 73.47
loss: 0.1131, acc: 93.33, test_acc: 74.57, f1: 73.33
loss: 0.3557, acc: 93.36, test_acc: 74.86, f1: 73.75
loss: 0.2245, acc: 93.38, test_acc: 73.70, f1: 73.35
loss: 0.2838, acc: 93.06, test_acc: 75.00, f1: 73.50
loss: 0.2830, acc: 92.43, test_acc: 73.12, f1: 71.36
loss: 0.1950, acc: 92.50, test_acc: 73.99, f1: 72.76
loss: 0.3536, acc: 92.56, test_acc: 73.27, f1: 72.38
loss: 0.4950, acc: 92.33, test_acc: 74.42, f1: 72.79
loss: 0.1777, acc: 92.39, test_acc: 73.55, f1: 71.78
loss: 0.2614, acc: 92.19, test_acc: 70.52, f1: 70.39
loss: 0.3412, acc: 92.00, test_acc: 72.40, f1: 71.82
loss: 0.1202, acc: 92.31, test_acc: 71.53, f1: 68.03
loss: 0.3281, acc: 92.13, test_acc: 74.86, f1: 73.76
loss: 0.3122, acc: 92.19, test_acc: 72.98, f1: 71.61
loss: 0.3673, acc: 92.03, test_acc: 71.53, f1: 70.30
loss: 0.1256, acc: 92.08, test_acc: 73.12, f1: 71.87
loss: 0.5550, acc: 91.73, test_acc: 73.70, f1: 72.50
loss: 0.2353, acc: 91.80, test_acc: 71.97, f1: 70.68
loss: 0.1909, acc: 91.67, test_acc: 74.28, f1: 72.90
loss: 0.3831, acc: 91.54, test_acc: 70.23, f1: 69.89
loss: 0.4041, acc: 91.07, test_acc: 71.39, f1: 71.06
loss: 0.2443, acc: 90.97, test_acc: 73.12, f1: 71.87
loss: 0.1999, acc: 91.05, test_acc: 71.53, f1: 71.14
loss: 0.2023, acc: 91.12, test_acc: 73.27, f1: 71.98
loss: 0.2182, acc: 91.19, test_acc: 72.40, f1: 71.57
loss: 0.0601, acc: 91.41, test_acc: 71.53, f1: 70.15
loss: 0.2563, acc: 91.46, test_acc: 72.11, f1: 71.31
loss: 0.1784, acc: 91.52, test_acc: 70.81, f1: 70.83
loss: 0.4389, acc: 91.42, test_acc: 72.98, f1: 72.31
loss: 0.1759, acc: 91.48, test_acc: 73.99, f1: 72.43
loss: 0.2414, acc: 91.39, test_acc: 72.40, f1: 71.54
loss: 0.3730, acc: 91.30, test_acc: 72.25, f1: 71.90
loss: 0.1885, acc: 91.22, test_acc: 73.12, f1: 72.71
loss: 0.1408, acc: 91.28, test_acc: 73.70, f1: 73.11
loss: 0.3014, acc: 90.94, test_acc: 73.70, f1: 73.10
loss: 0.1870, acc: 91.00, test_acc: 75.58, f1: 74.24
loss: 0.1152, acc: 91.05, test_acc: 74.57, f1: 73.25
loss: 0.3467, acc: 90.99, test_acc: 72.25, f1: 71.90
loss: 0.1809, acc: 91.04, test_acc: 74.42, f1: 73.82
loss: 0.1134, acc: 91.20, test_acc: 73.70, f1: 72.24
loss: 0.2226, acc: 91.14, test_acc: 73.84, f1: 72.74
loss: 0.2111, acc: 90.96, test_acc: 74.28, f1: 73.42
loss: 0.0750, acc: 91.12, test_acc: 74.13, f1: 72.92
loss: 0.0750, acc: 91.27, test_acc: 74.28, f1: 73.29
loss: 0.4427, acc: 91.31, test_acc: 72.98, f1: 72.69
loss: 0.7344, acc: 91.15, test_acc: 74.28, f1: 73.36
loss: 0.0493, acc: 91.29, test_acc: 72.54, f1: 71.86
loss: 0.1452, acc: 91.43, test_acc: 73.27, f1: 72.50
loss: 0.1118, acc: 91.57, test_acc: 73.84, f1: 72.95
loss: 0.0583, acc: 91.70, test_acc: 73.41, f1: 72.65
loss: 0.5963, acc: 91.44, test_acc: 73.84, f1: 72.92
loss: 0.3622, acc: 91.48, test_acc: 74.28, f1: 72.19
loss: 0.2177, acc: 91.42, test_acc: 73.27, f1: 72.43
loss: 0.1617, acc: 91.45, test_acc: 73.84, f1: 72.82
loss: 0.2258, acc: 91.49, test_acc: 70.81, f1: 69.90
loss: 0.4141, acc: 91.43, test_acc: 72.11, f1: 71.57
loss: 0.1252, acc: 91.46, test_acc: 72.40, f1: 70.94
loss: 0.3996, acc: 91.41, test_acc: 72.11, f1: 71.18
loss: 0.1452, acc: 91.44, test_acc: 68.35, f1: 67.72
loss: 0.3491, acc: 91.30, test_acc: 72.54, f1: 71.45
loss: 0.2117, acc: 91.25, test_acc: 73.12, f1: 72.41
loss: 0.1200, acc: 91.28, test_acc: 70.66, f1: 70.62
loss: 0.2795, acc: 91.23, test_acc: 70.09, f1: 70.08
loss: 0.4735, acc: 91.11, test_acc: 73.41, f1: 71.26
####################################################################################################
max_test_acc_overall:76.01156069364163
max_f1_overall:74.6288880283394
####################################################################################################
1 test_acc_overall: 77.75  f1_overall:75.99
2 test_acc_overall: 76.59  f1_overall:75.11
3 test_acc_overall: 77.46  f1_overall:76.21
4 test_acc_overall: 77.02  f1_overall:75.48
5 test_acc_overall: 76.01  f1_overall:74.63
max_acc_overall:77.75  f1_overall:75.99
mean_acc_overall:76.97  mean_f1_overall:75.48
####################################################################################################
/home/yh/python37/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
